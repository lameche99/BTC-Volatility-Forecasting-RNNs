{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 09:30:30.824355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from handler import build_dataset\n",
    "from models import cnn_model, lstm_model, lstm_cnn_model, run_model\n",
    "from tuning import create_study, get_optimized_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 72\n",
    "N_HORIZON = 24\n",
    "N_FEATURES = 6\n",
    "train_df, val_df, test_df = build_dataset(path='./src/rv_sentiment.csv', n_steps=N_STEPS, n_horizon=N_HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:295: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2023-12-05 09:30:34,963] A new study created in RDB with name: no-name-8500913f-a78a-45e4-aef0-4c53f5a45383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0679 - mae: 0.2963 - val_loss: 0.0301 - val_mae: 0.1760\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0473 - mae: 0.2444 - val_loss: 0.0274 - val_mae: 0.1627\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0527 - mae: 0.2578 - val_loss: 0.0253 - val_mae: 0.1513\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0355 - mae: 0.2053 - val_loss: 0.0238 - val_mae: 0.1421\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0430 - mae: 0.2286 - val_loss: 0.0225 - val_mae: 0.1342\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0322 - mae: 0.1971 - val_loss: 0.0217 - val_mae: 0.1273\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0320 - mae: 0.1963 - val_loss: 0.0211 - val_mae: 0.1235\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0321 - mae: 0.1993 - val_loss: 0.0207 - val_mae: 0.1214\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.1977 - val_loss: 0.0205 - val_mae: 0.1194\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0264 - mae: 0.1849 - val_loss: 0.0203 - val_mae: 0.1174\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0291 - mae: 0.1927 - val_loss: 0.0203 - val_mae: 0.1156\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0222 - mae: 0.1676 - val_loss: 0.0202 - val_mae: 0.1141\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0242 - mae: 0.1781 - val_loss: 0.0202 - val_mae: 0.1139\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0210 - mae: 0.1653 - val_loss: 0.0202 - val_mae: 0.1143\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0237 - mae: 0.1721 - val_loss: 0.0202 - val_mae: 0.1144\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0209 - mae: 0.1634 - val_loss: 0.0201 - val_mae: 0.1143\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0222 - mae: 0.1653 - val_loss: 0.0200 - val_mae: 0.1137\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0202 - mae: 0.1554 - val_loss: 0.0199 - val_mae: 0.1127\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0203 - mae: 0.1565 - val_loss: 0.0197 - val_mae: 0.1116\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0238 - mae: 0.1696 - val_loss: 0.0195 - val_mae: 0.1103\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0197 - mae: 0.1541 - val_loss: 0.0192 - val_mae: 0.1089\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0187 - mae: 0.1491 - val_loss: 0.0189 - val_mae: 0.1075\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0162 - mae: 0.1443 - val_loss: 0.0187 - val_mae: 0.1061\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0164 - mae: 0.1440 - val_loss: 0.0185 - val_mae: 0.1045\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0190 - mae: 0.1518 - val_loss: 0.0183 - val_mae: 0.1032\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0186 - mae: 0.1540 - val_loss: 0.0181 - val_mae: 0.1021\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0145 - mae: 0.1359 - val_loss: 0.0180 - val_mae: 0.1008\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0151 - mae: 0.1373 - val_loss: 0.0179 - val_mae: 0.0997\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0145 - mae: 0.1363 - val_loss: 0.0179 - val_mae: 0.0986\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0155 - mae: 0.1322 - val_loss: 0.0178 - val_mae: 0.0974\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0142 - mae: 0.1320 - val_loss: 0.0177 - val_mae: 0.0962\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0151 - mae: 0.1390 - val_loss: 0.0177 - val_mae: 0.0953\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1315 - val_loss: 0.0176 - val_mae: 0.0944\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0137 - mae: 0.1344 - val_loss: 0.0176 - val_mae: 0.0937\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - mae: 0.1344 - val_loss: 0.0175 - val_mae: 0.0930\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - mae: 0.1111 - val_loss: 0.0174 - val_mae: 0.0925\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0124 - mae: 0.1230 - val_loss: 0.0174 - val_mae: 0.0920\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0110 - mae: 0.1177 - val_loss: 0.0173 - val_mae: 0.0916\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0102 - mae: 0.1112 - val_loss: 0.0173 - val_mae: 0.0912\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0102 - mae: 0.1118 - val_loss: 0.0172 - val_mae: 0.0908\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0109 - mae: 0.1151 - val_loss: 0.0172 - val_mae: 0.0905\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0116 - mae: 0.1173 - val_loss: 0.0172 - val_mae: 0.0903\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0094 - mae: 0.1106 - val_loss: 0.0171 - val_mae: 0.0903\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0100 - mae: 0.1139 - val_loss: 0.0171 - val_mae: 0.0901\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0087 - mae: 0.1049 - val_loss: 0.0171 - val_mae: 0.0901\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0171 - val_mae: 0.0900\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.1055 - val_loss: 0.0171 - val_mae: 0.0900\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0171 - val_mae: 0.0900\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0084 - mae: 0.1026 - val_loss: 0.0171 - val_mae: 0.0899\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - mae: 0.1039 - val_loss: 0.0172 - val_mae: 0.0898\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0172 - val_mae: 0.0898\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0172 - val_mae: 0.0897\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - mae: 0.0951 - val_loss: 0.0173 - val_mae: 0.0898\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - mae: 0.0999 - val_loss: 0.0173 - val_mae: 0.0898\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0085 - mae: 0.1022 - val_loss: 0.0173 - val_mae: 0.0898\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - mae: 0.0947 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0070 - mae: 0.0934 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0069 - mae: 0.0913 - val_loss: 0.0174 - val_mae: 0.0899\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0175 - val_mae: 0.0900\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0960 - val_loss: 0.0175 - val_mae: 0.0901\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0995 - val_loss: 0.0175 - val_mae: 0.0902\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0071 - mae: 0.0910 - val_loss: 0.0175 - val_mae: 0.0901\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0903 - val_loss: 0.0176 - val_mae: 0.0901\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0075 - mae: 0.0946 - val_loss: 0.0176 - val_mae: 0.0901\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0080 - mae: 0.0979 - val_loss: 0.0176 - val_mae: 0.0900\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0948 - val_loss: 0.0177 - val_mae: 0.0899\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0983 - val_loss: 0.0177 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.0985 - val_loss: 0.0177 - val_mae: 0.0898\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0915 - val_loss: 0.0177 - val_mae: 0.0897\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0073 - mae: 0.0917 - val_loss: 0.0177 - val_mae: 0.0897\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.0999 - val_loss: 0.0177 - val_mae: 0.0895\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0061 - mae: 0.0852 - val_loss: 0.0177 - val_mae: 0.0895\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0986 - val_loss: 0.0178 - val_mae: 0.0894\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0075 - mae: 0.0981 - val_loss: 0.0178 - val_mae: 0.0893\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0960 - val_loss: 0.0178 - val_mae: 0.0891\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0894 - val_loss: 0.0178 - val_mae: 0.0890\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0848 - val_loss: 0.0178 - val_mae: 0.0889\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0064 - mae: 0.0888 - val_loss: 0.0178 - val_mae: 0.0889\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0880 - val_loss: 0.0178 - val_mae: 0.0888\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0813 - val_loss: 0.0177 - val_mae: 0.0888\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0852 - val_loss: 0.0177 - val_mae: 0.0887\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0856 - val_loss: 0.0177 - val_mae: 0.0886\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0855 - val_loss: 0.0176 - val_mae: 0.0886\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0053 - mae: 0.0790 - val_loss: 0.0176 - val_mae: 0.0885\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0176 - val_mae: 0.0884\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - mae: 0.0790 - val_loss: 0.0176 - val_mae: 0.0883\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0795 - val_loss: 0.0176 - val_mae: 0.0882\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0784 - val_loss: 0.0175 - val_mae: 0.0881\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - mae: 0.0828 - val_loss: 0.0175 - val_mae: 0.0879\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0816 - val_loss: 0.0175 - val_mae: 0.0878\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0794 - val_loss: 0.0175 - val_mae: 0.0876\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0815 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - mae: 0.0792 - val_loss: 0.0175 - val_mae: 0.0873\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0774 - val_loss: 0.0175 - val_mae: 0.0871\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0771 - val_loss: 0.0175 - val_mae: 0.0870\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0758 - val_loss: 0.0175 - val_mae: 0.0869\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0771 - val_loss: 0.0175 - val_mae: 0.0867\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0825 - val_loss: 0.0175 - val_mae: 0.0866\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0772 - val_loss: 0.0175 - val_mae: 0.0865\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0759 - val_loss: 0.0175 - val_mae: 0.0864\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0780 - val_loss: 0.0175 - val_mae: 0.0863\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.0863\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0742 - val_loss: 0.0175 - val_mae: 0.0863\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mae: 0.0823 - val_loss: 0.0175 - val_mae: 0.0863\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0712 - val_loss: 0.0174 - val_mae: 0.0863\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0756 - val_loss: 0.0174 - val_mae: 0.0863\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0724 - val_loss: 0.0174 - val_mae: 0.0864\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0723 - val_loss: 0.0174 - val_mae: 0.0864\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0731 - val_loss: 0.0174 - val_mae: 0.0864\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0758 - val_loss: 0.0174 - val_mae: 0.0865\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0732 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0801 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0767 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mae: 0.0703 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0726 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0716 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - mae: 0.0689 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0737 - val_loss: 0.0173 - val_mae: 0.0868\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0704 - val_loss: 0.0174 - val_mae: 0.0868\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0696 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0724 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0688 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0867\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0699 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0714 - val_loss: 0.0175 - val_mae: 0.0866\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0771 - val_loss: 0.0175 - val_mae: 0.0865\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0705 - val_loss: 0.0175 - val_mae: 0.0864\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - mae: 0.0699 - val_loss: 0.0175 - val_mae: 0.0862\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0674 - val_loss: 0.0176 - val_mae: 0.0861\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0176 - val_mae: 0.0860\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - mae: 0.0741 - val_loss: 0.0176 - val_mae: 0.0859\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0616 - val_loss: 0.0176 - val_mae: 0.0857\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0632 - val_loss: 0.0176 - val_mae: 0.0856\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0687 - val_loss: 0.0177 - val_mae: 0.0856\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0177 - val_mae: 0.0856\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0684 - val_loss: 0.0177 - val_mae: 0.0856\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0700 - val_loss: 0.0177 - val_mae: 0.0857\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0662 - val_loss: 0.0177 - val_mae: 0.0858\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - mae: 0.0702 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0691 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0649 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0641 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0653 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0176 - val_mae: 0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:30:45,742] Trial 0 finished with value: 0.08586855977773666 and parameters: {'learning_rate': 0.00011964593156586885, 'weight_decay': 1.14361878517486e-05}. Best is trial 0 with value: 0.08586855977773666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0763 - mae: 0.3147 - val_loss: 0.0258 - val_mae: 0.1334\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0449 - mae: 0.2445 - val_loss: 0.0251 - val_mae: 0.1361\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0341 - mae: 0.2115 - val_loss: 0.0257 - val_mae: 0.1417\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0363 - mae: 0.2186 - val_loss: 0.0254 - val_mae: 0.1375\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0245 - mae: 0.1765 - val_loss: 0.0256 - val_mae: 0.1390\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0213 - mae: 0.1623 - val_loss: 0.0252 - val_mae: 0.1373\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0234 - mae: 0.1715 - val_loss: 0.0242 - val_mae: 0.1331\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0223 - mae: 0.1618 - val_loss: 0.0229 - val_mae: 0.1251\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0158 - mae: 0.1369 - val_loss: 0.0215 - val_mae: 0.1162\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0131 - mae: 0.1296 - val_loss: 0.0205 - val_mae: 0.1067\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0138 - mae: 0.1313 - val_loss: 0.0197 - val_mae: 0.0998\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0108 - mae: 0.1159 - val_loss: 0.0193 - val_mae: 0.0946\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0191 - val_mae: 0.0910\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - mae: 0.1062 - val_loss: 0.0191 - val_mae: 0.0891\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0091 - mae: 0.1072 - val_loss: 0.0193 - val_mae: 0.0888\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - mae: 0.0933 - val_loss: 0.0194 - val_mae: 0.0894\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0960 - val_loss: 0.0196 - val_mae: 0.0899\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0960 - val_loss: 0.0198 - val_mae: 0.0903\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0913 - val_loss: 0.0200 - val_mae: 0.0903\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0069 - mae: 0.0900 - val_loss: 0.0202 - val_mae: 0.0898\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0870 - val_loss: 0.0203 - val_mae: 0.0891\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mae: 0.0831 - val_loss: 0.0203 - val_mae: 0.0883\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0811 - val_loss: 0.0204 - val_mae: 0.0876\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0814 - val_loss: 0.0203 - val_mae: 0.0869\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0747 - val_loss: 0.0203 - val_mae: 0.0862\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0718 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - mae: 0.0776 - val_loss: 0.0201 - val_mae: 0.0852\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0722 - val_loss: 0.0199 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0050 - mae: 0.0745 - val_loss: 0.0197 - val_mae: 0.0837\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - mae: 0.0680 - val_loss: 0.0194 - val_mae: 0.0830\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0677 - val_loss: 0.0191 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - mae: 0.0676 - val_loss: 0.0187 - val_mae: 0.0831\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0670 - val_loss: 0.0184 - val_mae: 0.0836\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0728 - val_loss: 0.0182 - val_mae: 0.0841\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0846\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0666 - val_loss: 0.0177 - val_mae: 0.0850\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0849\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0612 - val_loss: 0.0176 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0176 - val_mae: 0.0836\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0611 - val_loss: 0.0177 - val_mae: 0.0830\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0635 - val_loss: 0.0178 - val_mae: 0.0824\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0643 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0178 - val_mae: 0.0819\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0176 - val_mae: 0.0822\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0539 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0833\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0569 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0024 - mae: 0.0514 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0498 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0523 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0456 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0471 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0165 - val_mae: 0.0849\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0165 - val_mae: 0.0850\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0164 - val_mae: 0.0852\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0164 - val_mae: 0.0855\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0163 - val_mae: 0.0860\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - mae: 0.0459 - val_loss: 0.0162 - val_mae: 0.0869\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0162 - val_mae: 0.0871\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0457 - val_loss: 0.0162 - val_mae: 0.0869\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0438 - val_loss: 0.0162 - val_mae: 0.0865\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0438 - val_loss: 0.0163 - val_mae: 0.0859\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0016 - mae: 0.0448 - val_loss: 0.0164 - val_mae: 0.0847\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0164 - val_mae: 0.0842\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0164 - val_mae: 0.0847\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0411 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0162 - val_mae: 0.0865\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0429 - val_loss: 0.0161 - val_mae: 0.0877\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0160 - val_mae: 0.0883\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0160 - val_mae: 0.0881\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0412 - val_loss: 0.0161 - val_mae: 0.0870\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0451 - val_loss: 0.0162 - val_mae: 0.0853\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0163 - val_mae: 0.0845\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0408 - val_loss: 0.0162 - val_mae: 0.0866\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.0875\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0162 - val_mae: 0.0881\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0162 - val_mae: 0.0884\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0353 - val_loss: 0.0163 - val_mae: 0.0887\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0417 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0404 - val_loss: 0.0163 - val_mae: 0.0882\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0163 - val_mae: 0.0879\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0400 - val_loss: 0.0162 - val_mae: 0.0877\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0427 - val_loss: 0.0162 - val_mae: 0.0873\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0161 - val_mae: 0.0878\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0161 - val_mae: 0.0880\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0887\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0371 - val_loss: 0.0160 - val_mae: 0.0888\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0348 - val_loss: 0.0160 - val_mae: 0.0886\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0391 - val_loss: 0.0162 - val_mae: 0.0868\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0162 - val_mae: 0.0861\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0163 - val_mae: 0.0854\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0348 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0162 - val_mae: 0.0858\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0161 - val_mae: 0.0868\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0344 - val_loss: 0.0160 - val_mae: 0.0881\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0159 - val_mae: 0.0897\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0377 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0349 - val_loss: 0.0158 - val_mae: 0.0922\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0159 - val_mae: 0.0906\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0160 - val_mae: 0.0887\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0355 - val_loss: 0.0161 - val_mae: 0.0877\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0371 - val_loss: 0.0162 - val_mae: 0.0867\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0163 - val_mae: 0.0862\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0162 - val_mae: 0.0871\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0161 - val_mae: 0.0886\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0160 - val_mae: 0.0892\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0160 - val_mae: 0.0902\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0159 - val_mae: 0.0918\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.1336e-04 - mae: 0.0353 - val_loss: 0.0159 - val_mae: 0.0914\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0159 - val_mae: 0.0898\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0391 - val_loss: 0.0161 - val_mae: 0.0876\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 0.0162 - val_mae: 0.0867\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4292e-04 - mae: 0.0328 - val_loss: 0.0163 - val_mae: 0.0865\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0162 - val_mae: 0.0878\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0160 - val_mae: 0.0906\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.3093e-04 - mae: 0.0323 - val_loss: 0.0159 - val_mae: 0.0930\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0158 - val_mae: 0.0936\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0159 - val_mae: 0.0924\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8563e-04 - mae: 0.0332 - val_loss: 0.0159 - val_mae: 0.0914\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0160 - val_mae: 0.0902\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.2737e-04 - mae: 0.0316 - val_loss: 0.0162 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0163 - val_mae: 0.0884\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.3179e-04 - mae: 0.0320 - val_loss: 0.0163 - val_mae: 0.0882\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0344 - val_loss: 0.0162 - val_mae: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:30:57,199] Trial 1 finished with value: 0.08882240206003189 and parameters: {'learning_rate': 0.0006612999981289683, 'weight_decay': 2.2659734039369565e-05}. Best is trial 0 with value: 0.08586855977773666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0565 - mae: 0.2721 - val_loss: 0.0383 - val_mae: 0.1852\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0625 - mae: 0.2704 - val_loss: 0.0373 - val_mae: 0.1816\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0528 - mae: 0.2534 - val_loss: 0.0364 - val_mae: 0.1779\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0432 - mae: 0.2313 - val_loss: 0.0355 - val_mae: 0.1742\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0458 - mae: 0.2289 - val_loss: 0.0346 - val_mae: 0.1706\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0499 - mae: 0.2485 - val_loss: 0.0337 - val_mae: 0.1671\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0503 - mae: 0.2477 - val_loss: 0.0329 - val_mae: 0.1638\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0430 - mae: 0.2271 - val_loss: 0.0321 - val_mae: 0.1606\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0454 - mae: 0.2328 - val_loss: 0.0314 - val_mae: 0.1575\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0443 - mae: 0.2230 - val_loss: 0.0307 - val_mae: 0.1545\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0441 - mae: 0.2295 - val_loss: 0.0300 - val_mae: 0.1516\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0453 - mae: 0.2338 - val_loss: 0.0294 - val_mae: 0.1488\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0394 - mae: 0.2134 - val_loss: 0.0288 - val_mae: 0.1462\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0370 - mae: 0.2124 - val_loss: 0.0283 - val_mae: 0.1435\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0355 - mae: 0.2115 - val_loss: 0.0277 - val_mae: 0.1411\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0254 - mae: 0.1756 - val_loss: 0.0273 - val_mae: 0.1388\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0292 - mae: 0.1854 - val_loss: 0.0268 - val_mae: 0.1366\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0345 - mae: 0.2102 - val_loss: 0.0265 - val_mae: 0.1345\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0319 - mae: 0.1960 - val_loss: 0.0261 - val_mae: 0.1325\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0319 - mae: 0.1947 - val_loss: 0.0257 - val_mae: 0.1307\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0250 - mae: 0.1760 - val_loss: 0.0254 - val_mae: 0.1289\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0307 - mae: 0.1967 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0294 - mae: 0.1906 - val_loss: 0.0248 - val_mae: 0.1255\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0252 - mae: 0.1693 - val_loss: 0.0245 - val_mae: 0.1239\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0250 - mae: 0.1747 - val_loss: 0.0243 - val_mae: 0.1225\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0288 - mae: 0.1889 - val_loss: 0.0240 - val_mae: 0.1211\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0258 - mae: 0.1779 - val_loss: 0.0238 - val_mae: 0.1197\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0243 - mae: 0.1665 - val_loss: 0.0236 - val_mae: 0.1184\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0271 - mae: 0.1813 - val_loss: 0.0234 - val_mae: 0.1172\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0226 - mae: 0.1723 - val_loss: 0.0232 - val_mae: 0.1160\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0235 - mae: 0.1679 - val_loss: 0.0230 - val_mae: 0.1149\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0220 - mae: 0.1646 - val_loss: 0.0228 - val_mae: 0.1138\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0224 - mae: 0.1639 - val_loss: 0.0226 - val_mae: 0.1128\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0244 - mae: 0.1768 - val_loss: 0.0224 - val_mae: 0.1117\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0199 - mae: 0.1523 - val_loss: 0.0223 - val_mae: 0.1107\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0247 - mae: 0.1731 - val_loss: 0.0221 - val_mae: 0.1097\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0198 - mae: 0.1532 - val_loss: 0.0220 - val_mae: 0.1088\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0176 - mae: 0.1535 - val_loss: 0.0219 - val_mae: 0.1079\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0212 - mae: 0.1616 - val_loss: 0.0217 - val_mae: 0.1070\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0253 - mae: 0.1807 - val_loss: 0.0216 - val_mae: 0.1062\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0224 - mae: 0.1689 - val_loss: 0.0215 - val_mae: 0.1054\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0187 - mae: 0.1485 - val_loss: 0.0214 - val_mae: 0.1048\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0183 - mae: 0.1529 - val_loss: 0.0213 - val_mae: 0.1043\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0171 - mae: 0.1474 - val_loss: 0.0213 - val_mae: 0.1038\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0198 - mae: 0.1575 - val_loss: 0.0212 - val_mae: 0.1034\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0212 - mae: 0.1623 - val_loss: 0.0212 - val_mae: 0.1030\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0194 - mae: 0.1595 - val_loss: 0.0211 - val_mae: 0.1026\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0179 - mae: 0.1453 - val_loss: 0.0211 - val_mae: 0.1022\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0201 - mae: 0.1621 - val_loss: 0.0210 - val_mae: 0.1019\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0213 - mae: 0.1595 - val_loss: 0.0210 - val_mae: 0.1015\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0199 - mae: 0.1577 - val_loss: 0.0209 - val_mae: 0.1011\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0153 - mae: 0.1340 - val_loss: 0.0209 - val_mae: 0.1009\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0192 - mae: 0.1529 - val_loss: 0.0208 - val_mae: 0.1007\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - mae: 0.1408 - val_loss: 0.0208 - val_mae: 0.1006\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0162 - mae: 0.1432 - val_loss: 0.0208 - val_mae: 0.1005\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0222 - mae: 0.1633 - val_loss: 0.0208 - val_mae: 0.1004\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0223 - mae: 0.1670 - val_loss: 0.0208 - val_mae: 0.1003\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0179 - mae: 0.1484 - val_loss: 0.0208 - val_mae: 0.1002\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0152 - mae: 0.1389 - val_loss: 0.0207 - val_mae: 0.1001\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0166 - mae: 0.1428 - val_loss: 0.0207 - val_mae: 0.1000\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0157 - mae: 0.1418 - val_loss: 0.0207 - val_mae: 0.0998\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0176 - mae: 0.1451 - val_loss: 0.0207 - val_mae: 0.0997\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0150 - mae: 0.1351 - val_loss: 0.0207 - val_mae: 0.0995\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0152 - mae: 0.1390 - val_loss: 0.0206 - val_mae: 0.0992\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0157 - mae: 0.1335 - val_loss: 0.0206 - val_mae: 0.0989\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0152 - mae: 0.1341 - val_loss: 0.0206 - val_mae: 0.0986\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0156 - mae: 0.1400 - val_loss: 0.0206 - val_mae: 0.0984\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0154 - mae: 0.1382 - val_loss: 0.0206 - val_mae: 0.0981\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0135 - mae: 0.1312 - val_loss: 0.0205 - val_mae: 0.0979\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0145 - mae: 0.1331 - val_loss: 0.0205 - val_mae: 0.0977\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0156 - mae: 0.1355 - val_loss: 0.0205 - val_mae: 0.0974\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1347 - val_loss: 0.0205 - val_mae: 0.0971\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0146 - mae: 0.1383 - val_loss: 0.0204 - val_mae: 0.0969\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0134 - mae: 0.1309 - val_loss: 0.0204 - val_mae: 0.0966\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0139 - mae: 0.1300 - val_loss: 0.0203 - val_mae: 0.0964\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0153 - mae: 0.1335 - val_loss: 0.0203 - val_mae: 0.0960\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0167 - mae: 0.1464 - val_loss: 0.0202 - val_mae: 0.0956\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0156 - mae: 0.1367 - val_loss: 0.0202 - val_mae: 0.0953\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1257 - val_loss: 0.0201 - val_mae: 0.0950\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0122 - mae: 0.1241 - val_loss: 0.0201 - val_mae: 0.0946\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0119 - mae: 0.1245 - val_loss: 0.0201 - val_mae: 0.0944\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0147 - mae: 0.1343 - val_loss: 0.0200 - val_mae: 0.0941\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0148 - mae: 0.1308 - val_loss: 0.0200 - val_mae: 0.0939\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0152 - mae: 0.1339 - val_loss: 0.0199 - val_mae: 0.0936\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0144 - mae: 0.1352 - val_loss: 0.0199 - val_mae: 0.0934\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0143 - mae: 0.1329 - val_loss: 0.0198 - val_mae: 0.0931\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0124 - mae: 0.1236 - val_loss: 0.0198 - val_mae: 0.0928\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0121 - mae: 0.1207 - val_loss: 0.0197 - val_mae: 0.0926\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0155 - mae: 0.1373 - val_loss: 0.0197 - val_mae: 0.0923\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0132 - mae: 0.1341 - val_loss: 0.0196 - val_mae: 0.0922\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0128 - mae: 0.1224 - val_loss: 0.0196 - val_mae: 0.0920\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0143 - mae: 0.1329 - val_loss: 0.0196 - val_mae: 0.0919\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0132 - mae: 0.1215 - val_loss: 0.0196 - val_mae: 0.0917\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0133 - mae: 0.1317 - val_loss: 0.0195 - val_mae: 0.0916\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0109 - mae: 0.1136 - val_loss: 0.0195 - val_mae: 0.0915\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0134 - mae: 0.1310 - val_loss: 0.0195 - val_mae: 0.0913\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0139 - mae: 0.1252 - val_loss: 0.0195 - val_mae: 0.0913\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0122 - mae: 0.1254 - val_loss: 0.0195 - val_mae: 0.0912\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0126 - mae: 0.1253 - val_loss: 0.0195 - val_mae: 0.0912\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0125 - mae: 0.1168 - val_loss: 0.0195 - val_mae: 0.0912\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0115 - mae: 0.1210 - val_loss: 0.0194 - val_mae: 0.0911\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0115 - mae: 0.1197 - val_loss: 0.0194 - val_mae: 0.0911\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0125 - mae: 0.1225 - val_loss: 0.0194 - val_mae: 0.0910\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0130 - mae: 0.1287 - val_loss: 0.0194 - val_mae: 0.0910\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0117 - mae: 0.1209 - val_loss: 0.0194 - val_mae: 0.0909\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0194 - val_mae: 0.0907\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0137 - mae: 0.1305 - val_loss: 0.0194 - val_mae: 0.0906\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0193 - val_mae: 0.0905\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0131 - mae: 0.1239 - val_loss: 0.0193 - val_mae: 0.0903\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0127 - mae: 0.1194 - val_loss: 0.0193 - val_mae: 0.0903\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0116 - mae: 0.1166 - val_loss: 0.0193 - val_mae: 0.0902\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0131 - mae: 0.1293 - val_loss: 0.0193 - val_mae: 0.0903\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0117 - mae: 0.1234 - val_loss: 0.0193 - val_mae: 0.0903\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0193 - val_mae: 0.0903\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1220 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0134 - mae: 0.1311 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0115 - mae: 0.1237 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0122 - mae: 0.1202 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0129 - mae: 0.1224 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0107 - mae: 0.1137 - val_loss: 0.0192 - val_mae: 0.0904\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0104 - mae: 0.1111 - val_loss: 0.0192 - val_mae: 0.0905\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0117 - mae: 0.1193 - val_loss: 0.0192 - val_mae: 0.0905\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0192 - val_mae: 0.0905\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0103 - mae: 0.1119 - val_loss: 0.0192 - val_mae: 0.0905\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0192 - val_mae: 0.0905\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1198 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1120 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0101 - mae: 0.1077 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0088 - mae: 0.1040 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0105 - mae: 0.1172 - val_loss: 0.0191 - val_mae: 0.0905\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0096 - mae: 0.1090 - val_loss: 0.0191 - val_mae: 0.0906\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1058 - val_loss: 0.0191 - val_mae: 0.0906\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0096 - mae: 0.1109 - val_loss: 0.0191 - val_mae: 0.0906\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0118 - mae: 0.1211 - val_loss: 0.0191 - val_mae: 0.0906\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0098 - mae: 0.1106 - val_loss: 0.0191 - val_mae: 0.0906\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0191 - val_mae: 0.0905\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0094 - mae: 0.1090 - val_loss: 0.0191 - val_mae: 0.0905\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0110 - mae: 0.1134 - val_loss: 0.0191 - val_mae: 0.0904\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0191 - val_mae: 0.0903\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - mae: 0.1021 - val_loss: 0.0191 - val_mae: 0.0903\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1091 - val_loss: 0.0191 - val_mae: 0.0902\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - mae: 0.1163 - val_loss: 0.0191 - val_mae: 0.0902\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mae: 0.1133 - val_loss: 0.0191 - val_mae: 0.0901\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0191 - val_mae: 0.0901\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0087 - mae: 0.1054 - val_loss: 0.0192 - val_mae: 0.0901\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0112 - mae: 0.1170 - val_loss: 0.0192 - val_mae: 0.0901\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1084 - val_loss: 0.0192 - val_mae: 0.0900\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0107 - mae: 0.1165 - val_loss: 0.0192 - val_mae: 0.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:31:08,187] Trial 2 finished with value: 0.09001868218183517 and parameters: {'learning_rate': 3.5368899280940415e-05, 'weight_decay': 1.1459418867960801e-09}. Best is trial 0 with value: 0.08586855977773666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0743 - mae: 0.3181 - val_loss: 0.0390 - val_mae: 0.2141\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0388 - mae: 0.2200 - val_loss: 0.0270 - val_mae: 0.1627\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0254 - mae: 0.1790 - val_loss: 0.0204 - val_mae: 0.1193\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0123 - mae: 0.1251 - val_loss: 0.0203 - val_mae: 0.1091\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0111 - mae: 0.1144 - val_loss: 0.0214 - val_mae: 0.1034\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0095 - mae: 0.1093 - val_loss: 0.0216 - val_mae: 0.0988\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0215 - val_mae: 0.0966\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0899 - val_loss: 0.0211 - val_mae: 0.0937\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0065 - mae: 0.0840 - val_loss: 0.0204 - val_mae: 0.0902\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0829 - val_loss: 0.0196 - val_mae: 0.0861\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0745 - val_loss: 0.0189 - val_mae: 0.0830\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - mae: 0.0754 - val_loss: 0.0182 - val_mae: 0.0821\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0758 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mae: 0.0729 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0172 - val_mae: 0.0833\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0639 - val_loss: 0.0174 - val_mae: 0.0812\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0176 - val_mae: 0.0798\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0177 - val_mae: 0.0785\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0625 - val_loss: 0.0163 - val_mae: 0.0827\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0162 - val_mae: 0.0823\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0163 - val_mae: 0.0809\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0803\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0518 - val_loss: 0.0167 - val_mae: 0.0822\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0164 - val_mae: 0.0832\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0826\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - mae: 0.0550 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0158 - val_mae: 0.0791\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0159 - val_mae: 0.0789\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0156 - val_mae: 0.0805\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0490 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0155 - val_mae: 0.0802\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0154 - val_mae: 0.0801\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0449 - val_loss: 0.0154 - val_mae: 0.0814\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0475 - val_loss: 0.0155 - val_mae: 0.0835\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0156 - val_mae: 0.0835\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0423 - val_loss: 0.0158 - val_mae: 0.0825\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0162 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0165 - val_mae: 0.0763\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0166 - val_mae: 0.0756\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0164 - val_mae: 0.0759\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0158 - val_mae: 0.0815\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0015 - mae: 0.0422 - val_loss: 0.0159 - val_mae: 0.0813\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0159 - val_mae: 0.0808\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0158 - val_mae: 0.0812\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0158 - val_mae: 0.0817\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0381 - val_loss: 0.0157 - val_mae: 0.0829\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0158 - val_mae: 0.0825\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0162 - val_mae: 0.0792\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0166 - val_mae: 0.0769\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0168 - val_mae: 0.0765\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.7465e-04 - mae: 0.0330 - val_loss: 0.0162 - val_mae: 0.0782\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0157 - val_mae: 0.0793\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0153 - val_mae: 0.0804\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0353 - val_loss: 0.0151 - val_mae: 0.0799\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0150 - val_mae: 0.0786\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0403 - val_loss: 0.0152 - val_mae: 0.0773\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - mae: 0.0339 - val_loss: 0.0155 - val_mae: 0.0776\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0383 - val_loss: 0.0155 - val_mae: 0.0793\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0155 - val_mae: 0.0806\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0344 - val_loss: 0.0154 - val_mae: 0.0811\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0152 - val_mae: 0.0813\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0368 - val_loss: 0.0150 - val_mae: 0.0802\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0147 - val_mae: 0.0794\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.8113e-04 - mae: 0.0324 - val_loss: 0.0145 - val_mae: 0.0785\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0149 - val_mae: 0.0744\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0153 - val_mae: 0.0738\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0356 - val_loss: 0.0155 - val_mae: 0.0745\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.7684e-04 - mae: 0.0329 - val_loss: 0.0156 - val_mae: 0.0761\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3768e-04 - mae: 0.0301 - val_loss: 0.0157 - val_mae: 0.0765\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1267e-04 - mae: 0.0272 - val_loss: 0.0158 - val_mae: 0.0764\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6419e-04 - mae: 0.0316 - val_loss: 0.0157 - val_mae: 0.0757\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0153 - val_mae: 0.0754\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9723e-04 - mae: 0.0309 - val_loss: 0.0150 - val_mae: 0.0760\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6604e-04 - mae: 0.0311 - val_loss: 0.0147 - val_mae: 0.0759\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.0387e-04 - mae: 0.0291 - val_loss: 0.0145 - val_mae: 0.0753\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0142 - val_mae: 0.0757\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0342 - val_loss: 0.0142 - val_mae: 0.0748\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3474e-04 - mae: 0.0339 - val_loss: 0.0145 - val_mae: 0.0742\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.4926e-04 - mae: 0.0333 - val_loss: 0.0146 - val_mae: 0.0748\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.8353e-04 - mae: 0.0312 - val_loss: 0.0149 - val_mae: 0.0749\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3021e-04 - mae: 0.0288 - val_loss: 0.0152 - val_mae: 0.0752\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.5735e-04 - mae: 0.0284 - val_loss: 0.0153 - val_mae: 0.0766\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.3913e-04 - mae: 0.0293 - val_loss: 0.0153 - val_mae: 0.0783\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.7101e-04 - mae: 0.0288 - val_loss: 0.0153 - val_mae: 0.0786\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4475e-04 - mae: 0.0272 - val_loss: 0.0154 - val_mae: 0.0783\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4426e-04 - mae: 0.0304 - val_loss: 0.0156 - val_mae: 0.0778\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.7983e-04 - mae: 0.0286 - val_loss: 0.0155 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3360e-04 - mae: 0.0321 - val_loss: 0.0153 - val_mae: 0.0761\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.8922e-04 - mae: 0.0272 - val_loss: 0.0151 - val_mae: 0.0760\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0011e-04 - mae: 0.0300 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0149 - val_mae: 0.0762\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9955e-04 - mae: 0.0286 - val_loss: 0.0151 - val_mae: 0.0758\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4163e-04 - mae: 0.0303 - val_loss: 0.0152 - val_mae: 0.0755\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9677e-04 - mae: 0.0282 - val_loss: 0.0153 - val_mae: 0.0753\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.9708e-04 - mae: 0.0298 - val_loss: 0.0152 - val_mae: 0.0754\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.2475e-04 - mae: 0.0271 - val_loss: 0.0152 - val_mae: 0.0750\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0660e-04 - mae: 0.0285 - val_loss: 0.0153 - val_mae: 0.0740\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.3693e-04 - mae: 0.0255 - val_loss: 0.0154 - val_mae: 0.0736\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.5361e-04 - mae: 0.0283 - val_loss: 0.0154 - val_mae: 0.0739\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8605e-04 - mae: 0.0298 - val_loss: 0.0153 - val_mae: 0.0736\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7665e-04 - mae: 0.0283 - val_loss: 0.0152 - val_mae: 0.0742\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0036e-04 - mae: 0.0272 - val_loss: 0.0151 - val_mae: 0.0747\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7155e-04 - mae: 0.0277 - val_loss: 0.0149 - val_mae: 0.0744\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3232e-04 - mae: 0.0292 - val_loss: 0.0147 - val_mae: 0.0754\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6408e-04 - mae: 0.0289 - val_loss: 0.0147 - val_mae: 0.0761\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7487e-04 - mae: 0.0260 - val_loss: 0.0147 - val_mae: 0.0762\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0149 - val_mae: 0.0745\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0149 - val_mae: 0.0748\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0150 - val_mae: 0.0769\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1363e-04 - mae: 0.0292 - val_loss: 0.0151 - val_mae: 0.0776\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.3684e-04 - mae: 0.0294 - val_loss: 0.0152 - val_mae: 0.0787\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0767e-04 - mae: 0.0312 - val_loss: 0.0153 - val_mae: 0.0794\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.5570e-04 - mae: 0.0310 - val_loss: 0.0154 - val_mae: 0.0781\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0426e-04 - mae: 0.0298 - val_loss: 0.0156 - val_mae: 0.0758\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5461e-04 - mae: 0.0309 - val_loss: 0.0156 - val_mae: 0.0747\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.0543e-04 - mae: 0.0243 - val_loss: 0.0155 - val_mae: 0.0737\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.3741e-04 - mae: 0.0310 - val_loss: 0.0154 - val_mae: 0.0728\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6219e-04 - mae: 0.0309 - val_loss: 0.0151 - val_mae: 0.0736\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2701e-04 - mae: 0.0285 - val_loss: 0.0148 - val_mae: 0.0751\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1971e-04 - mae: 0.0304 - val_loss: 0.0145 - val_mae: 0.0761\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.5738e-04 - mae: 0.0279 - val_loss: 0.0144 - val_mae: 0.0773\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1151e-04 - mae: 0.0300 - val_loss: 0.0144 - val_mae: 0.0775\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9858e-04 - mae: 0.0295 - val_loss: 0.0143 - val_mae: 0.0777\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3205e-04 - mae: 0.0326 - val_loss: 0.0144 - val_mae: 0.0756\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.6616e-04 - mae: 0.0234 - val_loss: 0.0146 - val_mae: 0.0735\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.5784e-04 - mae: 0.0281 - val_loss: 0.0147 - val_mae: 0.0728\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.1122e-04 - mae: 0.0307 - val_loss: 0.0147 - val_mae: 0.0725\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.2625e-04 - mae: 0.0282 - val_loss: 0.0149 - val_mae: 0.0725\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5116e-04 - mae: 0.0285 - val_loss: 0.0149 - val_mae: 0.0732\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0331 - val_loss: 0.0150 - val_mae: 0.0732\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4484e-04 - mae: 0.0295 - val_loss: 0.0150 - val_mae: 0.0732\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1672e-04 - mae: 0.0255 - val_loss: 0.0151 - val_mae: 0.0733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:31:18,886] Trial 3 finished with value: 0.07329216599464417 and parameters: {'learning_rate': 0.0020810673148555303, 'weight_decay': 0.0006131795895763025}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0624 - mae: 0.2758 - val_loss: 0.0444 - val_mae: 0.2142\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0633 - mae: 0.2879 - val_loss: 0.0442 - val_mae: 0.2136\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0547 - mae: 0.2637 - val_loss: 0.0440 - val_mae: 0.2129\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0695 - mae: 0.3066 - val_loss: 0.0438 - val_mae: 0.2122\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2752 - val_loss: 0.0436 - val_mae: 0.2115\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0692 - mae: 0.3026 - val_loss: 0.0434 - val_mae: 0.2108\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0726 - mae: 0.2997 - val_loss: 0.0432 - val_mae: 0.2101\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0514 - mae: 0.2519 - val_loss: 0.0430 - val_mae: 0.2094\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0575 - mae: 0.2682 - val_loss: 0.0429 - val_mae: 0.2087\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0575 - mae: 0.2721 - val_loss: 0.0427 - val_mae: 0.2080\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2751 - val_loss: 0.0425 - val_mae: 0.2073\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0503 - mae: 0.2504 - val_loss: 0.0423 - val_mae: 0.2066\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0469 - mae: 0.2471 - val_loss: 0.0421 - val_mae: 0.2059\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0543 - mae: 0.2572 - val_loss: 0.0419 - val_mae: 0.2052\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0545 - mae: 0.2634 - val_loss: 0.0417 - val_mae: 0.2046\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0509 - mae: 0.2582 - val_loss: 0.0415 - val_mae: 0.2039\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0511 - mae: 0.2591 - val_loss: 0.0413 - val_mae: 0.2032\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0549 - mae: 0.2669 - val_loss: 0.0411 - val_mae: 0.2026\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0561 - mae: 0.2693 - val_loss: 0.0410 - val_mae: 0.2019\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0615 - mae: 0.2763 - val_loss: 0.0408 - val_mae: 0.2012\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0482 - mae: 0.2431 - val_loss: 0.0406 - val_mae: 0.2005\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0599 - mae: 0.2836 - val_loss: 0.0404 - val_mae: 0.1998\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0536 - mae: 0.2674 - val_loss: 0.0402 - val_mae: 0.1991\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0541 - mae: 0.2672 - val_loss: 0.0400 - val_mae: 0.1985\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0531 - mae: 0.2630 - val_loss: 0.0399 - val_mae: 0.1978\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0556 - mae: 0.2667 - val_loss: 0.0397 - val_mae: 0.1971\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0625 - mae: 0.2771 - val_loss: 0.0395 - val_mae: 0.1964\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0540 - mae: 0.2670 - val_loss: 0.0393 - val_mae: 0.1957\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0524 - mae: 0.2505 - val_loss: 0.0391 - val_mae: 0.1951\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0640 - mae: 0.2908 - val_loss: 0.0390 - val_mae: 0.1944\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0525 - mae: 0.2617 - val_loss: 0.0388 - val_mae: 0.1937\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0537 - mae: 0.2675 - val_loss: 0.0386 - val_mae: 0.1931\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0512 - mae: 0.2516 - val_loss: 0.0384 - val_mae: 0.1924\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0627 - mae: 0.2828 - val_loss: 0.0383 - val_mae: 0.1917\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0516 - mae: 0.2525 - val_loss: 0.0381 - val_mae: 0.1911\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0501 - mae: 0.2549 - val_loss: 0.0379 - val_mae: 0.1904\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0533 - mae: 0.2590 - val_loss: 0.0378 - val_mae: 0.1898\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0623 - mae: 0.2848 - val_loss: 0.0376 - val_mae: 0.1891\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0499 - mae: 0.2524 - val_loss: 0.0374 - val_mae: 0.1884\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0442 - mae: 0.2376 - val_loss: 0.0373 - val_mae: 0.1878\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0421 - mae: 0.2308 - val_loss: 0.0371 - val_mae: 0.1872\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0538 - mae: 0.2564 - val_loss: 0.0370 - val_mae: 0.1865\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0565 - mae: 0.2650 - val_loss: 0.0368 - val_mae: 0.1859\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0520 - mae: 0.2569 - val_loss: 0.0367 - val_mae: 0.1852\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0488 - mae: 0.2469 - val_loss: 0.0365 - val_mae: 0.1846\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0479 - mae: 0.2505 - val_loss: 0.0364 - val_mae: 0.1839\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0509 - mae: 0.2530 - val_loss: 0.0362 - val_mae: 0.1833\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0453 - mae: 0.2336 - val_loss: 0.0360 - val_mae: 0.1827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0502 - mae: 0.2637 - val_loss: 0.0359 - val_mae: 0.1820\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0511 - mae: 0.2550 - val_loss: 0.0357 - val_mae: 0.1814\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0433 - mae: 0.2259 - val_loss: 0.0356 - val_mae: 0.1808\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0405 - mae: 0.2278 - val_loss: 0.0355 - val_mae: 0.1802\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0508 - mae: 0.2502 - val_loss: 0.0353 - val_mae: 0.1796\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0439 - mae: 0.2429 - val_loss: 0.0352 - val_mae: 0.1790\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0420 - mae: 0.2317 - val_loss: 0.0351 - val_mae: 0.1784\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0511 - mae: 0.2487 - val_loss: 0.0349 - val_mae: 0.1778\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0508 - mae: 0.2486 - val_loss: 0.0348 - val_mae: 0.1773\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0517 - mae: 0.2540 - val_loss: 0.0347 - val_mae: 0.1767\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0440 - mae: 0.2434 - val_loss: 0.0345 - val_mae: 0.1761\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0433 - mae: 0.2404 - val_loss: 0.0344 - val_mae: 0.1756\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0401 - mae: 0.2285 - val_loss: 0.0343 - val_mae: 0.1750\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0498 - mae: 0.2463 - val_loss: 0.0342 - val_mae: 0.1745\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0443 - mae: 0.2374 - val_loss: 0.0340 - val_mae: 0.1739\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0466 - mae: 0.2476 - val_loss: 0.0339 - val_mae: 0.1734\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0502 - mae: 0.2564 - val_loss: 0.0338 - val_mae: 0.1728\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0412 - mae: 0.2354 - val_loss: 0.0337 - val_mae: 0.1723\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0447 - mae: 0.2425 - val_loss: 0.0336 - val_mae: 0.1717\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0459 - mae: 0.2378 - val_loss: 0.0334 - val_mae: 0.1712\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0414 - mae: 0.2300 - val_loss: 0.0333 - val_mae: 0.1707\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0462 - mae: 0.2479 - val_loss: 0.0332 - val_mae: 0.1702\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0475 - mae: 0.2530 - val_loss: 0.0331 - val_mae: 0.1697\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0472 - mae: 0.2476 - val_loss: 0.0330 - val_mae: 0.1692\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0578 - mae: 0.2736 - val_loss: 0.0329 - val_mae: 0.1687\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0427 - mae: 0.2374 - val_loss: 0.0327 - val_mae: 0.1682\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0392 - mae: 0.2188 - val_loss: 0.0326 - val_mae: 0.1677\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0433 - mae: 0.2403 - val_loss: 0.0325 - val_mae: 0.1672\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0391 - mae: 0.2276 - val_loss: 0.0324 - val_mae: 0.1668\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0474 - mae: 0.2444 - val_loss: 0.0323 - val_mae: 0.1663\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0440 - mae: 0.2355 - val_loss: 0.0322 - val_mae: 0.1658\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0499 - mae: 0.2586 - val_loss: 0.0321 - val_mae: 0.1653\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0449 - mae: 0.2338 - val_loss: 0.0320 - val_mae: 0.1648\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0399 - mae: 0.2178 - val_loss: 0.0319 - val_mae: 0.1643\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0525 - mae: 0.2513 - val_loss: 0.0318 - val_mae: 0.1638\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0451 - mae: 0.2393 - val_loss: 0.0317 - val_mae: 0.1633\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0351 - mae: 0.2169 - val_loss: 0.0316 - val_mae: 0.1628\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0366 - mae: 0.2158 - val_loss: 0.0315 - val_mae: 0.1623\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0378 - mae: 0.2215 - val_loss: 0.0314 - val_mae: 0.1619\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0403 - mae: 0.2249 - val_loss: 0.0313 - val_mae: 0.1614\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0446 - mae: 0.2313 - val_loss: 0.0312 - val_mae: 0.1609\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0419 - mae: 0.2292 - val_loss: 0.0311 - val_mae: 0.1605\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0458 - mae: 0.2403 - val_loss: 0.0310 - val_mae: 0.1600\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0376 - mae: 0.2184 - val_loss: 0.0309 - val_mae: 0.1595\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0402 - mae: 0.2220 - val_loss: 0.0308 - val_mae: 0.1591\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0374 - mae: 0.2237 - val_loss: 0.0307 - val_mae: 0.1586\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0409 - mae: 0.2326 - val_loss: 0.0306 - val_mae: 0.1582\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0441 - mae: 0.2371 - val_loss: 0.0305 - val_mae: 0.1577\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0348 - mae: 0.2072 - val_loss: 0.0304 - val_mae: 0.1573\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0378 - mae: 0.2217 - val_loss: 0.0303 - val_mae: 0.1568\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0396 - mae: 0.2239 - val_loss: 0.0302 - val_mae: 0.1564\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0347 - mae: 0.2138 - val_loss: 0.0302 - val_mae: 0.1560\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0436 - mae: 0.2367 - val_loss: 0.0301 - val_mae: 0.1556\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0412 - mae: 0.2284 - val_loss: 0.0300 - val_mae: 0.1552\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0354 - mae: 0.2103 - val_loss: 0.0299 - val_mae: 0.1548\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0379 - mae: 0.2187 - val_loss: 0.0298 - val_mae: 0.1544\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0353 - mae: 0.2158 - val_loss: 0.0297 - val_mae: 0.1540\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0417 - mae: 0.2302 - val_loss: 0.0297 - val_mae: 0.1535\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - mae: 0.2120 - val_loss: 0.0296 - val_mae: 0.1531\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0420 - mae: 0.2254 - val_loss: 0.0295 - val_mae: 0.1527\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0361 - mae: 0.2127 - val_loss: 0.0294 - val_mae: 0.1523\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0417 - mae: 0.2354 - val_loss: 0.0293 - val_mae: 0.1519\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0413 - mae: 0.2301 - val_loss: 0.0292 - val_mae: 0.1516\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0389 - mae: 0.2279 - val_loss: 0.0292 - val_mae: 0.1512\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0368 - mae: 0.2138 - val_loss: 0.0291 - val_mae: 0.1508\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0405 - mae: 0.2318 - val_loss: 0.0290 - val_mae: 0.1504\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0413 - mae: 0.2283 - val_loss: 0.0289 - val_mae: 0.1500\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0467 - mae: 0.2489 - val_loss: 0.0289 - val_mae: 0.1496\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0386 - mae: 0.2214 - val_loss: 0.0288 - val_mae: 0.1493\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0348 - mae: 0.2095 - val_loss: 0.0287 - val_mae: 0.1489\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0349 - mae: 0.2127 - val_loss: 0.0286 - val_mae: 0.1485\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0361 - mae: 0.2132 - val_loss: 0.0285 - val_mae: 0.1481\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0325 - mae: 0.2053 - val_loss: 0.0285 - val_mae: 0.1478\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0409 - mae: 0.2264 - val_loss: 0.0284 - val_mae: 0.1474\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0417 - mae: 0.2303 - val_loss: 0.0283 - val_mae: 0.1471\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0355 - mae: 0.2144 - val_loss: 0.0283 - val_mae: 0.1467\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0322 - mae: 0.2043 - val_loss: 0.0282 - val_mae: 0.1463\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0374 - mae: 0.2181 - val_loss: 0.0281 - val_mae: 0.1460\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0380 - mae: 0.2253 - val_loss: 0.0280 - val_mae: 0.1457\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0348 - mae: 0.2036 - val_loss: 0.0280 - val_mae: 0.1453\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0419 - mae: 0.2249 - val_loss: 0.0279 - val_mae: 0.1450\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0381 - mae: 0.2204 - val_loss: 0.0278 - val_mae: 0.1446\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0467 - mae: 0.2396 - val_loss: 0.0278 - val_mae: 0.1442\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0406 - mae: 0.2242 - val_loss: 0.0277 - val_mae: 0.1439\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0340 - mae: 0.2103 - val_loss: 0.0276 - val_mae: 0.1435\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0361 - mae: 0.2109 - val_loss: 0.0276 - val_mae: 0.1432\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0359 - mae: 0.2099 - val_loss: 0.0275 - val_mae: 0.1428\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0349 - mae: 0.2127 - val_loss: 0.0274 - val_mae: 0.1425\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0363 - mae: 0.2146 - val_loss: 0.0274 - val_mae: 0.1421\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0355 - mae: 0.2169 - val_loss: 0.0273 - val_mae: 0.1418\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0351 - mae: 0.2089 - val_loss: 0.0272 - val_mae: 0.1414\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0418 - mae: 0.2251 - val_loss: 0.0272 - val_mae: 0.1411\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0400 - mae: 0.2256 - val_loss: 0.0271 - val_mae: 0.1408\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0338 - mae: 0.2151 - val_loss: 0.0271 - val_mae: 0.1405\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0393 - mae: 0.2218 - val_loss: 0.0270 - val_mae: 0.1401\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0348 - mae: 0.2174 - val_loss: 0.0270 - val_mae: 0.1398\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0364 - mae: 0.2127 - val_loss: 0.0269 - val_mae: 0.1395\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0365 - mae: 0.2101 - val_loss: 0.0268 - val_mae: 0.1391\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0403 - mae: 0.2298 - val_loss: 0.0268 - val_mae: 0.1388\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0286 - mae: 0.1922 - val_loss: 0.0267 - val_mae: 0.1384\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0356 - mae: 0.2104 - val_loss: 0.0267 - val_mae: 0.1381\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0355 - mae: 0.2074 - val_loss: 0.0266 - val_mae: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:31:29,580] Trial 4 finished with value: 0.13778768479824066 and parameters: {'learning_rate': 4.28043769639752e-06, 'weight_decay': 7.257684125878767e-06}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0708 - mae: 0.2942 - val_loss: 0.0463 - val_mae: 0.2273\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0727 - mae: 0.3055 - val_loss: 0.0458 - val_mae: 0.2257\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0727 - mae: 0.2892 - val_loss: 0.0453 - val_mae: 0.2241\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0652 - mae: 0.2811 - val_loss: 0.0448 - val_mae: 0.2223\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0711 - mae: 0.2902 - val_loss: 0.0442 - val_mae: 0.2205\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0749 - mae: 0.2965 - val_loss: 0.0436 - val_mae: 0.2187\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0740 - mae: 0.2941 - val_loss: 0.0431 - val_mae: 0.2169\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0735 - mae: 0.2883 - val_loss: 0.0425 - val_mae: 0.2151\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0660 - mae: 0.2865 - val_loss: 0.0420 - val_mae: 0.2133\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0762 - mae: 0.3074 - val_loss: 0.0415 - val_mae: 0.2114\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0740 - mae: 0.2950 - val_loss: 0.0410 - val_mae: 0.2096\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0726 - mae: 0.2943 - val_loss: 0.0405 - val_mae: 0.2078\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0657 - mae: 0.2843 - val_loss: 0.0400 - val_mae: 0.2060\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0656 - mae: 0.2752 - val_loss: 0.0395 - val_mae: 0.2043\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0608 - mae: 0.2594 - val_loss: 0.0390 - val_mae: 0.2026\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0611 - mae: 0.2709 - val_loss: 0.0385 - val_mae: 0.2009\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0674 - mae: 0.2813 - val_loss: 0.0381 - val_mae: 0.1992\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0563 - mae: 0.2739 - val_loss: 0.0376 - val_mae: 0.1976\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0492 - mae: 0.2419 - val_loss: 0.0372 - val_mae: 0.1960\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0668 - mae: 0.2819 - val_loss: 0.0368 - val_mae: 0.1944\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0634 - mae: 0.2773 - val_loss: 0.0364 - val_mae: 0.1928\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0587 - mae: 0.2704 - val_loss: 0.0360 - val_mae: 0.1912\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0607 - mae: 0.2619 - val_loss: 0.0356 - val_mae: 0.1896\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0558 - mae: 0.2637 - val_loss: 0.0352 - val_mae: 0.1880\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0560 - mae: 0.2609 - val_loss: 0.0348 - val_mae: 0.1864\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0483 - mae: 0.2483 - val_loss: 0.0344 - val_mae: 0.1849\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0523 - mae: 0.2542 - val_loss: 0.0341 - val_mae: 0.1834\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0485 - mae: 0.2364 - val_loss: 0.0337 - val_mae: 0.1819\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0474 - mae: 0.2349 - val_loss: 0.0334 - val_mae: 0.1804\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0528 - mae: 0.2570 - val_loss: 0.0330 - val_mae: 0.1790\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0531 - mae: 0.2604 - val_loss: 0.0327 - val_mae: 0.1776\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0492 - mae: 0.2499 - val_loss: 0.0324 - val_mae: 0.1762\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0528 - mae: 0.2409 - val_loss: 0.0320 - val_mae: 0.1749\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0503 - mae: 0.2494 - val_loss: 0.0317 - val_mae: 0.1736\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0515 - mae: 0.2493 - val_loss: 0.0314 - val_mae: 0.1722\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0507 - mae: 0.2416 - val_loss: 0.0311 - val_mae: 0.1709\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0569 - mae: 0.2600 - val_loss: 0.0308 - val_mae: 0.1696\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0534 - mae: 0.2468 - val_loss: 0.0305 - val_mae: 0.1684\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0444 - mae: 0.2364 - val_loss: 0.0302 - val_mae: 0.1673\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0503 - mae: 0.2427 - val_loss: 0.0300 - val_mae: 0.1661\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0491 - mae: 0.2506 - val_loss: 0.0297 - val_mae: 0.1650\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0569 - mae: 0.2554 - val_loss: 0.0294 - val_mae: 0.1639\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0426 - mae: 0.2339 - val_loss: 0.0292 - val_mae: 0.1629\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0415 - mae: 0.2178 - val_loss: 0.0289 - val_mae: 0.1619\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0465 - mae: 0.2381 - val_loss: 0.0287 - val_mae: 0.1609\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0462 - mae: 0.2295 - val_loss: 0.0285 - val_mae: 0.1599\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0526 - mae: 0.2521 - val_loss: 0.0282 - val_mae: 0.1589\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0483 - mae: 0.2332 - val_loss: 0.0280 - val_mae: 0.1579\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0460 - mae: 0.2303 - val_loss: 0.0278 - val_mae: 0.1570\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0471 - mae: 0.2393 - val_loss: 0.0276 - val_mae: 0.1560\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0387 - mae: 0.2170 - val_loss: 0.0274 - val_mae: 0.1551\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0402 - mae: 0.2274 - val_loss: 0.0271 - val_mae: 0.1541\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0388 - mae: 0.2154 - val_loss: 0.0269 - val_mae: 0.1532\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0419 - mae: 0.2334 - val_loss: 0.0268 - val_mae: 0.1522\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0373 - mae: 0.2117 - val_loss: 0.0266 - val_mae: 0.1513\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0399 - mae: 0.2177 - val_loss: 0.0264 - val_mae: 0.1503\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0408 - mae: 0.2172 - val_loss: 0.0262 - val_mae: 0.1494\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0453 - mae: 0.2390 - val_loss: 0.0260 - val_mae: 0.1486\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0391 - mae: 0.2165 - val_loss: 0.0259 - val_mae: 0.1477\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0355 - mae: 0.2104 - val_loss: 0.0257 - val_mae: 0.1469\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0496 - mae: 0.2513 - val_loss: 0.0255 - val_mae: 0.1460\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0402 - mae: 0.2194 - val_loss: 0.0254 - val_mae: 0.1452\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0450 - mae: 0.2296 - val_loss: 0.0252 - val_mae: 0.1443\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0407 - mae: 0.2246 - val_loss: 0.0250 - val_mae: 0.1435\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0374 - mae: 0.2192 - val_loss: 0.0249 - val_mae: 0.1427\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0414 - mae: 0.2342 - val_loss: 0.0247 - val_mae: 0.1418\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0445 - mae: 0.2321 - val_loss: 0.0246 - val_mae: 0.1410\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0388 - mae: 0.2081 - val_loss: 0.0244 - val_mae: 0.1402\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0375 - mae: 0.2116 - val_loss: 0.0243 - val_mae: 0.1395\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0394 - mae: 0.2156 - val_loss: 0.0242 - val_mae: 0.1387\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0448 - mae: 0.2198 - val_loss: 0.0240 - val_mae: 0.1380\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0408 - mae: 0.2254 - val_loss: 0.0239 - val_mae: 0.1372\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0408 - mae: 0.2209 - val_loss: 0.0238 - val_mae: 0.1365\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0400 - mae: 0.2189 - val_loss: 0.0236 - val_mae: 0.1358\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0314 - mae: 0.1936 - val_loss: 0.0235 - val_mae: 0.1351\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0334 - mae: 0.2078 - val_loss: 0.0234 - val_mae: 0.1345\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0440 - mae: 0.2355 - val_loss: 0.0233 - val_mae: 0.1339\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0460 - mae: 0.2386 - val_loss: 0.0232 - val_mae: 0.1332\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0392 - mae: 0.2189 - val_loss: 0.0231 - val_mae: 0.1327\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0414 - mae: 0.2360 - val_loss: 0.0230 - val_mae: 0.1321\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0392 - mae: 0.2218 - val_loss: 0.0229 - val_mae: 0.1315\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0407 - mae: 0.2271 - val_loss: 0.0228 - val_mae: 0.1309\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0412 - mae: 0.2248 - val_loss: 0.0227 - val_mae: 0.1303\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0339 - mae: 0.2050 - val_loss: 0.0227 - val_mae: 0.1297\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0322 - mae: 0.2005 - val_loss: 0.0226 - val_mae: 0.1291\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0350 - mae: 0.1996 - val_loss: 0.0225 - val_mae: 0.1286\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0439 - mae: 0.2246 - val_loss: 0.0224 - val_mae: 0.1279\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0373 - mae: 0.2216 - val_loss: 0.0223 - val_mae: 0.1273\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0403 - mae: 0.2169 - val_loss: 0.0222 - val_mae: 0.1267\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0383 - mae: 0.2035 - val_loss: 0.0221 - val_mae: 0.1261\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0411 - mae: 0.2326 - val_loss: 0.0220 - val_mae: 0.1255\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0299 - mae: 0.1906 - val_loss: 0.0219 - val_mae: 0.1249\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0314 - mae: 0.1993 - val_loss: 0.0218 - val_mae: 0.1243\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0383 - mae: 0.2230 - val_loss: 0.0218 - val_mae: 0.1238\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0418 - mae: 0.2221 - val_loss: 0.0217 - val_mae: 0.1232\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0284 - mae: 0.1880 - val_loss: 0.0216 - val_mae: 0.1227\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0343 - mae: 0.2055 - val_loss: 0.0215 - val_mae: 0.1222\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0273 - mae: 0.1847 - val_loss: 0.0215 - val_mae: 0.1217\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0378 - mae: 0.2073 - val_loss: 0.0214 - val_mae: 0.1213\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0329 - mae: 0.1955 - val_loss: 0.0213 - val_mae: 0.1208\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0339 - mae: 0.1966 - val_loss: 0.0212 - val_mae: 0.1203\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0295 - mae: 0.1912 - val_loss: 0.0212 - val_mae: 0.1199\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0343 - mae: 0.2063 - val_loss: 0.0211 - val_mae: 0.1194\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0316 - mae: 0.1921 - val_loss: 0.0210 - val_mae: 0.1190\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0391 - mae: 0.2189 - val_loss: 0.0209 - val_mae: 0.1186\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0317 - mae: 0.1883 - val_loss: 0.0209 - val_mae: 0.1181\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0360 - mae: 0.2135 - val_loss: 0.0208 - val_mae: 0.1177\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0365 - mae: 0.2082 - val_loss: 0.0208 - val_mae: 0.1173\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0395 - mae: 0.2158 - val_loss: 0.0207 - val_mae: 0.1169\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0357 - mae: 0.2004 - val_loss: 0.0206 - val_mae: 0.1165\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0331 - mae: 0.1992 - val_loss: 0.0206 - val_mae: 0.1161\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0296 - mae: 0.1887 - val_loss: 0.0205 - val_mae: 0.1157\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0343 - mae: 0.2088 - val_loss: 0.0205 - val_mae: 0.1154\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0360 - mae: 0.2053 - val_loss: 0.0205 - val_mae: 0.1150\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0299 - mae: 0.1899 - val_loss: 0.0204 - val_mae: 0.1147\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0311 - mae: 0.1947 - val_loss: 0.0204 - val_mae: 0.1144\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0327 - mae: 0.1996 - val_loss: 0.0203 - val_mae: 0.1140\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0315 - mae: 0.2016 - val_loss: 0.0203 - val_mae: 0.1137\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0307 - mae: 0.1925 - val_loss: 0.0202 - val_mae: 0.1134\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0347 - mae: 0.2035 - val_loss: 0.0202 - val_mae: 0.1130\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0355 - mae: 0.2149 - val_loss: 0.0202 - val_mae: 0.1127\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0279 - mae: 0.1883 - val_loss: 0.0201 - val_mae: 0.1123\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0261 - mae: 0.1801 - val_loss: 0.0201 - val_mae: 0.1120\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0324 - mae: 0.1988 - val_loss: 0.0201 - val_mae: 0.1116\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0258 - mae: 0.1774 - val_loss: 0.0200 - val_mae: 0.1113\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0259 - mae: 0.1819 - val_loss: 0.0200 - val_mae: 0.1110\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0250 - mae: 0.1746 - val_loss: 0.0200 - val_mae: 0.1107\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0351 - mae: 0.2039 - val_loss: 0.0199 - val_mae: 0.1104\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0288 - mae: 0.1853 - val_loss: 0.0199 - val_mae: 0.1101\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0355 - mae: 0.2011 - val_loss: 0.0199 - val_mae: 0.1098\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0235 - mae: 0.1691 - val_loss: 0.0198 - val_mae: 0.1096\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0363 - mae: 0.2114 - val_loss: 0.0198 - val_mae: 0.1093\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0351 - mae: 0.2101 - val_loss: 0.0198 - val_mae: 0.1090\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0279 - mae: 0.1887 - val_loss: 0.0198 - val_mae: 0.1088\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0245 - mae: 0.1715 - val_loss: 0.0197 - val_mae: 0.1085\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0327 - mae: 0.2020 - val_loss: 0.0197 - val_mae: 0.1082\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0295 - mae: 0.1908 - val_loss: 0.0197 - val_mae: 0.1079\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0303 - mae: 0.1884 - val_loss: 0.0196 - val_mae: 0.1076\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0287 - mae: 0.1874 - val_loss: 0.0196 - val_mae: 0.1074\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0309 - mae: 0.1901 - val_loss: 0.0196 - val_mae: 0.1071\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0295 - mae: 0.1953 - val_loss: 0.0196 - val_mae: 0.1069\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0245 - mae: 0.1764 - val_loss: 0.0195 - val_mae: 0.1066\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0278 - mae: 0.1906 - val_loss: 0.0195 - val_mae: 0.1064\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0279 - mae: 0.1824 - val_loss: 0.0195 - val_mae: 0.1062\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0339 - mae: 0.1991 - val_loss: 0.0195 - val_mae: 0.1059\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0299 - mae: 0.1890 - val_loss: 0.0194 - val_mae: 0.1057\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0307 - mae: 0.1952 - val_loss: 0.0194 - val_mae: 0.1054\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0287 - mae: 0.1878 - val_loss: 0.0194 - val_mae: 0.1051\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0270 - mae: 0.1810 - val_loss: 0.0194 - val_mae: 0.1049\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0322 - mae: 0.1954 - val_loss: 0.0194 - val_mae: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:31:40,346] Trial 5 finished with value: 0.10462262481451035 and parameters: {'learning_rate': 1.0929284706409042e-05, 'weight_decay': 4.07092266472996e-09}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0641 - mae: 0.2851 - val_loss: 0.0250 - val_mae: 0.1272\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0229 - mae: 0.1644 - val_loss: 0.0265 - val_mae: 0.1388\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0206 - mae: 0.1553 - val_loss: 0.0251 - val_mae: 0.1369\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0187 - mae: 0.1607 - val_loss: 0.0221 - val_mae: 0.1275\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0132 - mae: 0.1285 - val_loss: 0.0198 - val_mae: 0.1137\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0119 - mae: 0.1217 - val_loss: 0.0185 - val_mae: 0.1009\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0181 - val_mae: 0.0903\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0954 - val_loss: 0.0178 - val_mae: 0.0868\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0178 - val_mae: 0.0860\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - mae: 0.0829 - val_loss: 0.0178 - val_mae: 0.0852\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0764 - val_loss: 0.0178 - val_mae: 0.0842\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0782 - val_loss: 0.0178 - val_mae: 0.0829\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mae: 0.0717 - val_loss: 0.0176 - val_mae: 0.0818\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0740 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mae: 0.0729 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0696 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0689 - val_loss: 0.0161 - val_mae: 0.0812\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0158 - val_mae: 0.0816\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0673 - val_loss: 0.0155 - val_mae: 0.0813\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0625 - val_loss: 0.0153 - val_mae: 0.0806\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0152 - val_mae: 0.0794\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0606 - val_loss: 0.0152 - val_mae: 0.0778\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0154 - val_mae: 0.0768\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0593 - val_loss: 0.0155 - val_mae: 0.0765\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0155 - val_mae: 0.0766\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0768\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0154 - val_mae: 0.0775\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0153 - val_mae: 0.0783\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0152 - val_mae: 0.0793\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0152 - val_mae: 0.0804\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0151 - val_mae: 0.0816\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0520 - val_loss: 0.0151 - val_mae: 0.0828\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0510 - val_loss: 0.0151 - val_mae: 0.0839\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0151 - val_mae: 0.0845\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0455 - val_loss: 0.0151 - val_mae: 0.0851\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0522 - val_loss: 0.0152 - val_mae: 0.0841\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0152 - val_mae: 0.0833\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0474 - val_loss: 0.0153 - val_mae: 0.0830\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0153 - val_mae: 0.0827\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0152 - val_mae: 0.0829\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0456 - val_loss: 0.0151 - val_mae: 0.0842\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0149 - val_mae: 0.0862\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0148 - val_mae: 0.0877\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0147 - val_mae: 0.0897\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0480 - val_loss: 0.0147 - val_mae: 0.0910\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0147 - val_mae: 0.0907\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0147 - val_mae: 0.0903\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0147 - val_mae: 0.0906\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0147 - val_mae: 0.0906\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0147 - val_mae: 0.0890\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0147 - val_mae: 0.0866\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0147 - val_mae: 0.0852\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0418 - val_loss: 0.0147 - val_mae: 0.0856\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0147 - val_mae: 0.0865\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0146 - val_mae: 0.0877\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0412 - val_loss: 0.0147 - val_mae: 0.0879\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0147 - val_mae: 0.0881\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0147 - val_mae: 0.0884\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0148 - val_mae: 0.0882\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0147 - val_mae: 0.0874\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0418 - val_loss: 0.0146 - val_mae: 0.0872\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0145 - val_mae: 0.0882\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0894\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0410 - val_loss: 0.0144 - val_mae: 0.0901\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0914\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0145 - val_mae: 0.0906\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0146 - val_mae: 0.0900\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0146 - val_mae: 0.0902\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0146 - val_mae: 0.0910\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0404 - val_loss: 0.0147 - val_mae: 0.0909\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0147 - val_mae: 0.0908\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0148 - val_mae: 0.0917\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0148 - val_mae: 0.0916\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0402 - val_loss: 0.0147 - val_mae: 0.0921\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0147 - val_mae: 0.0921\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0384 - val_loss: 0.0148 - val_mae: 0.0916\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0340 - val_loss: 0.0148 - val_mae: 0.0915\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0148 - val_mae: 0.0914\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0147 - val_mae: 0.0914\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0146 - val_mae: 0.0921\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0145 - val_mae: 0.0921\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0363 - val_loss: 0.0144 - val_mae: 0.0915\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0144 - val_mae: 0.0923\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9146e-04 - mae: 0.0327 - val_loss: 0.0145 - val_mae: 0.0929\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0145 - val_mae: 0.0925\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0145 - val_mae: 0.0922\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9608e-04 - mae: 0.0303 - val_loss: 0.0145 - val_mae: 0.0885\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0145 - val_mae: 0.0868\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0353 - val_loss: 0.0144 - val_mae: 0.0870\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3549e-04 - mae: 0.0302 - val_loss: 0.0143 - val_mae: 0.0887\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3634e-04 - mae: 0.0280 - val_loss: 0.0143 - val_mae: 0.0915\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0342 - val_loss: 0.0144 - val_mae: 0.0931\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.2534e-04 - mae: 0.0311 - val_loss: 0.0146 - val_mae: 0.0934\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.5936e-04 - mae: 0.0297 - val_loss: 0.0148 - val_mae: 0.0936\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9928e-04 - mae: 0.0304 - val_loss: 0.0149 - val_mae: 0.0934\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5628e-04 - mae: 0.0336 - val_loss: 0.0149 - val_mae: 0.0936\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.4757e-04 - mae: 0.0302 - val_loss: 0.0149 - val_mae: 0.0935\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.3520e-04 - mae: 0.0316 - val_loss: 0.0149 - val_mae: 0.0935\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0148 - val_mae: 0.0925\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6760e-04 - mae: 0.0311 - val_loss: 0.0147 - val_mae: 0.0903\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0336 - val_loss: 0.0146 - val_mae: 0.0896\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7001e-04 - mae: 0.0294 - val_loss: 0.0145 - val_mae: 0.0897\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3104e-04 - mae: 0.0307 - val_loss: 0.0145 - val_mae: 0.0905\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9520e-04 - mae: 0.0314 - val_loss: 0.0144 - val_mae: 0.0908\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8340e-04 - mae: 0.0328 - val_loss: 0.0144 - val_mae: 0.0932\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9358e-04 - mae: 0.0313 - val_loss: 0.0145 - val_mae: 0.0957\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.3623e-04 - mae: 0.0304 - val_loss: 0.0145 - val_mae: 0.0939\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9407e-04 - mae: 0.0302 - val_loss: 0.0146 - val_mae: 0.0923\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.0669e-04 - mae: 0.0301 - val_loss: 0.0147 - val_mae: 0.0902\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5080e-04 - mae: 0.0309 - val_loss: 0.0147 - val_mae: 0.0898\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0328 - val_loss: 0.0146 - val_mae: 0.0920\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9116e-04 - mae: 0.0286 - val_loss: 0.0145 - val_mae: 0.0943\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4421e-04 - mae: 0.0264 - val_loss: 0.0145 - val_mae: 0.0961\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0010 - mae: 0.0331 - val_loss: 0.0146 - val_mae: 0.0932\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.9727e-04 - mae: 0.0289 - val_loss: 0.0147 - val_mae: 0.0903\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8712e-04 - mae: 0.0300 - val_loss: 0.0147 - val_mae: 0.0884\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6485e-04 - mae: 0.0301 - val_loss: 0.0147 - val_mae: 0.0873\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7205e-04 - mae: 0.0286 - val_loss: 0.0148 - val_mae: 0.0872\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5317e-04 - mae: 0.0269 - val_loss: 0.0148 - val_mae: 0.0884\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.4201e-04 - mae: 0.0254 - val_loss: 0.0148 - val_mae: 0.0893\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9649e-04 - mae: 0.0297 - val_loss: 0.0148 - val_mae: 0.0910\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 8.4800e-04 - mae: 0.0300 - val_loss: 0.0149 - val_mae: 0.0946\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.9617e-04 - mae: 0.0328 - val_loss: 0.0149 - val_mae: 0.0992\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7275e-04 - mae: 0.0313 - val_loss: 0.0148 - val_mae: 0.0988\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8894e-04 - mae: 0.0302 - val_loss: 0.0147 - val_mae: 0.0974\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3868e-04 - mae: 0.0276 - val_loss: 0.0147 - val_mae: 0.0961\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0324 - val_loss: 0.0147 - val_mae: 0.0929\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9330e-04 - mae: 0.0312 - val_loss: 0.0147 - val_mae: 0.0904\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.1992e-04 - mae: 0.0315 - val_loss: 0.0147 - val_mae: 0.0894\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7081e-04 - mae: 0.0306 - val_loss: 0.0146 - val_mae: 0.0905\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.5732e-04 - mae: 0.0294 - val_loss: 0.0145 - val_mae: 0.0921\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9493e-04 - mae: 0.0285 - val_loss: 0.0144 - val_mae: 0.0937\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3443e-04 - mae: 0.0288 - val_loss: 0.0142 - val_mae: 0.0944\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.3884e-04 - mae: 0.0328 - val_loss: 0.0140 - val_mae: 0.0940\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4747e-04 - mae: 0.0308 - val_loss: 0.0139 - val_mae: 0.0917\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.0649e-04 - mae: 0.0269 - val_loss: 0.0139 - val_mae: 0.0897\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7157e-04 - mae: 0.0286 - val_loss: 0.0139 - val_mae: 0.0901\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4591e-04 - mae: 0.0283 - val_loss: 0.0140 - val_mae: 0.0914\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.4576e-04 - mae: 0.0286 - val_loss: 0.0141 - val_mae: 0.0935\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7119e-04 - mae: 0.0282 - val_loss: 0.0142 - val_mae: 0.0948\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8074e-04 - mae: 0.0261 - val_loss: 0.0142 - val_mae: 0.0962\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.7261e-04 - mae: 0.0303 - val_loss: 0.0144 - val_mae: 0.0970\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8173e-04 - mae: 0.0312 - val_loss: 0.0145 - val_mae: 0.0963\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0990e-04 - mae: 0.0263 - val_loss: 0.0145 - val_mae: 0.0936\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5307e-04 - mae: 0.0278 - val_loss: 0.0146 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.4783e-04 - mae: 0.0245 - val_loss: 0.0148 - val_mae: 0.0856\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9390e-04 - mae: 0.0252 - val_loss: 0.0150 - val_mae: 0.0839\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6024e-04 - mae: 0.0269 - val_loss: 0.0150 - val_mae: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:31:50,918] Trial 6 finished with value: 0.08406682312488556 and parameters: {'learning_rate': 0.001034095268466443, 'weight_decay': 5.144853463284705e-07}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - mae: 0.2823 - val_loss: 0.1714 - val_mae: 0.4562\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2364 - mae: 0.5475 - val_loss: 0.0281 - val_mae: 0.1542\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0207 - mae: 0.1576 - val_loss: 0.0229 - val_mae: 0.1100\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0217 - val_mae: 0.0984\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0199 - val_mae: 0.0903\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0802 - val_loss: 0.0182 - val_mae: 0.0874\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0746 - val_loss: 0.0169 - val_mae: 0.0887\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0761 - val_loss: 0.0165 - val_mae: 0.0890\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0719 - val_loss: 0.0167 - val_mae: 0.0887\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0680 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0882\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0164 - val_mae: 0.0925\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0645 - val_loss: 0.0166 - val_mae: 0.0883\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0550 - val_loss: 0.0164 - val_mae: 0.0882\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0160 - val_mae: 0.0946\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0159 - val_mae: 0.0984\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0584 - val_loss: 0.0160 - val_mae: 0.0943\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0160 - val_mae: 0.0895\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0163 - val_mae: 0.0838\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0496 - val_loss: 0.0156 - val_mae: 0.0905\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0152 - val_mae: 0.0949\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0157 - val_mae: 0.0845\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0476 - val_loss: 0.0158 - val_mae: 0.0819\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0156 - val_mae: 0.0837\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0479 - val_loss: 0.0154 - val_mae: 0.0861\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0155 - val_mae: 0.0858\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0444 - val_loss: 0.0154 - val_mae: 0.0878\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0477 - val_loss: 0.0155 - val_mae: 0.0852\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0154 - val_mae: 0.0861\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0165 - val_mae: 0.0847\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0469 - val_loss: 0.0159 - val_mae: 0.0878\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0152 - val_mae: 0.0924\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0483 - val_loss: 0.0152 - val_mae: 0.0891\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0158 - val_mae: 0.0842\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0164 - val_mae: 0.0833\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0016 - mae: 0.0386 - val_loss: 0.0163 - val_mae: 0.0852\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0156 - val_mae: 0.0936\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.0156 - val_mae: 0.0913\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0159 - val_mae: 0.0856\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0158 - val_mae: 0.0863\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0157 - val_mae: 0.0881\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0161 - val_mae: 0.0867\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.0161 - val_mae: 0.0859\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0383 - val_loss: 0.0156 - val_mae: 0.0863\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0151 - val_mae: 0.0890\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0404 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0361 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0392 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0407 - val_loss: 0.0158 - val_mae: 0.0898\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0154 - val_mae: 0.0947\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0154 - val_mae: 0.0930\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0353 - val_loss: 0.0156 - val_mae: 0.0885\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0175 - val_mae: 0.0850\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0381 - val_loss: 0.0163 - val_mae: 0.0863\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0154 - val_mae: 0.0898\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0350 - val_loss: 0.0152 - val_mae: 0.0931\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0371 - val_loss: 0.0157 - val_mae: 0.0887\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0015 - mae: 0.0372 - val_loss: 0.0167 - val_mae: 0.0872\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8926e-04 - mae: 0.0295 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0334 - val_loss: 0.0165 - val_mae: 0.0879\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 0.0162 - val_mae: 0.0871\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3860e-04 - mae: 0.0304 - val_loss: 0.0157 - val_mae: 0.0914\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.8175e-04 - mae: 0.0299 - val_loss: 0.0153 - val_mae: 0.0930\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7701e-04 - mae: 0.0310 - val_loss: 0.0153 - val_mae: 0.0892\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4698e-04 - mae: 0.0313 - val_loss: 0.0156 - val_mae: 0.0860\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7898e-04 - mae: 0.0336 - val_loss: 0.0163 - val_mae: 0.0845\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5035e-04 - mae: 0.0315 - val_loss: 0.0172 - val_mae: 0.0862\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0332 - val_loss: 0.0176 - val_mae: 0.0881\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0178 - val_mae: 0.0915\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 0.0174 - val_mae: 0.0939\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7836e-04 - mae: 0.0334 - val_loss: 0.0169 - val_mae: 0.0938\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.8044e-04 - mae: 0.0323 - val_loss: 0.0166 - val_mae: 0.0940\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0163 - val_mae: 0.0932\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.5041e-04 - mae: 0.0309 - val_loss: 0.0164 - val_mae: 0.0934\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.5384e-04 - mae: 0.0318 - val_loss: 0.0164 - val_mae: 0.0914\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0388 - val_loss: 0.0172 - val_mae: 0.0878\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8385e-04 - mae: 0.0311 - val_loss: 0.0178 - val_mae: 0.0874\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2249e-04 - mae: 0.0324 - val_loss: 0.0180 - val_mae: 0.0885\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0179 - val_mae: 0.0903\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 0.0176 - val_mae: 0.0913\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7313e-04 - mae: 0.0310 - val_loss: 0.0170 - val_mae: 0.0908\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0350 - val_loss: 0.0162 - val_mae: 0.0907\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0159 - val_mae: 0.0893\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 0.0164 - val_mae: 0.0878\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 0.0167 - val_mae: 0.0876\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.4448e-04 - mae: 0.0285 - val_loss: 0.0169 - val_mae: 0.0894\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7513e-04 - mae: 0.0252 - val_loss: 0.0174 - val_mae: 0.0895\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0332 - val_loss: 0.0173 - val_mae: 0.0876\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5134e-04 - mae: 0.0299 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0163 - val_mae: 0.0890\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5311e-04 - mae: 0.0318 - val_loss: 0.0164 - val_mae: 0.0883\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9475e-04 - mae: 0.0251 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7186e-04 - mae: 0.0291 - val_loss: 0.0163 - val_mae: 0.0875\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.7923e-04 - mae: 0.0320 - val_loss: 0.0158 - val_mae: 0.0874\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.3864e-04 - mae: 0.0304 - val_loss: 0.0153 - val_mae: 0.0880\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.4456e-04 - mae: 0.0289 - val_loss: 0.0152 - val_mae: 0.0881\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 0.0154 - val_mae: 0.0883\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8408e-04 - mae: 0.0314 - val_loss: 0.0159 - val_mae: 0.0869\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.5366e-04 - mae: 0.0289 - val_loss: 0.0160 - val_mae: 0.0873\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6137e-04 - mae: 0.0302 - val_loss: 0.0163 - val_mae: 0.0858\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4895e-04 - mae: 0.0270 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9208e-04 - mae: 0.0287 - val_loss: 0.0164 - val_mae: 0.0878\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 6.2372e-04 - mae: 0.0259 - val_loss: 0.0161 - val_mae: 0.0888\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0905e-04 - mae: 0.0299 - val_loss: 0.0159 - val_mae: 0.0894\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9162e-04 - mae: 0.0303 - val_loss: 0.0164 - val_mae: 0.0892\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.8342e-04 - mae: 0.0298 - val_loss: 0.0167 - val_mae: 0.0893\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0920e-04 - mae: 0.0303 - val_loss: 0.0167 - val_mae: 0.0887\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.7917e-04 - mae: 0.0325 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.9083e-04 - mae: 0.0269 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0355 - val_loss: 0.0166 - val_mae: 0.0875\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5154e-04 - mae: 0.0324 - val_loss: 0.0159 - val_mae: 0.0876\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4584e-04 - mae: 0.0306 - val_loss: 0.0158 - val_mae: 0.0872\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0336 - val_loss: 0.0160 - val_mae: 0.0878\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.9949e-04 - mae: 0.0265 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 8.0383e-04 - mae: 0.0295 - val_loss: 0.0157 - val_mae: 0.0858\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.9723e-04 - mae: 0.0278 - val_loss: 0.0158 - val_mae: 0.0850\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 0.0160 - val_mae: 0.0843\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9521e-04 - mae: 0.0284 - val_loss: 0.0161 - val_mae: 0.0849\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6571e-04 - mae: 0.0297 - val_loss: 0.0161 - val_mae: 0.0861\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8162e-04 - mae: 0.0290 - val_loss: 0.0161 - val_mae: 0.0868\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0342 - val_loss: 0.0162 - val_mae: 0.0862\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6860e-04 - mae: 0.0272 - val_loss: 0.0163 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6421e-04 - mae: 0.0305 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.8183e-04 - mae: 0.0252 - val_loss: 0.0161 - val_mae: 0.0843\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0323 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0164 - val_mae: 0.0853\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.6406e-04 - mae: 0.0316 - val_loss: 0.0164 - val_mae: 0.0861\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.3207e-04 - mae: 0.0306 - val_loss: 0.0162 - val_mae: 0.0867\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8376e-04 - mae: 0.0264 - val_loss: 0.0160 - val_mae: 0.0887\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0368 - val_loss: 0.0158 - val_mae: 0.0905\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 0.0162 - val_mae: 0.0901\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9905e-04 - mae: 0.0246 - val_loss: 0.0164 - val_mae: 0.0896\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.5783e-04 - mae: 0.0251 - val_loss: 0.0166 - val_mae: 0.0895\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7678e-04 - mae: 0.0288 - val_loss: 0.0165 - val_mae: 0.0892\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 6.4734e-04 - mae: 0.0251 - val_loss: 0.0164 - val_mae: 0.0891\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.5551e-04 - mae: 0.0263 - val_loss: 0.0164 - val_mae: 0.0893\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.9558e-04 - mae: 0.0224 - val_loss: 0.0163 - val_mae: 0.0892\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.2460e-04 - mae: 0.0242 - val_loss: 0.0159 - val_mae: 0.0895\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3229e-04 - mae: 0.0290 - val_loss: 0.0157 - val_mae: 0.0886\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.3295e-04 - mae: 0.0267 - val_loss: 0.0156 - val_mae: 0.0864\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.8360e-04 - mae: 0.0253 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.1726e-04 - mae: 0.0253 - val_loss: 0.0161 - val_mae: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:01,649] Trial 7 finished with value: 0.08407308161258698 and parameters: {'learning_rate': 0.004901355830086318, 'weight_decay': 1.9281308696810606e-09}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0757 - mae: 0.3060 - val_loss: 0.3954 - val_mae: 0.7530\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4299 - mae: 0.8027 - val_loss: 0.0389 - val_mae: 0.1665\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0324 - mae: 0.1835 - val_loss: 0.0222 - val_mae: 0.1089\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0123 - mae: 0.1186 - val_loss: 0.0208 - val_mae: 0.0994\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0103 - mae: 0.1098 - val_loss: 0.0197 - val_mae: 0.0915\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0080 - mae: 0.0914 - val_loss: 0.0191 - val_mae: 0.0850\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0793 - val_loss: 0.0191 - val_mae: 0.0820\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0196 - val_mae: 0.0821\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0712 - val_loss: 0.0203 - val_mae: 0.0853\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0689 - val_loss: 0.0203 - val_mae: 0.0855\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0704 - val_loss: 0.0198 - val_mae: 0.0831\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mae: 0.0644 - val_loss: 0.0192 - val_mae: 0.0816\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0599 - val_loss: 0.0181 - val_mae: 0.0843\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0179 - val_mae: 0.0891\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0859\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0178 - val_mae: 0.0807\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0178 - val_mae: 0.0800\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0564 - val_loss: 0.0177 - val_mae: 0.0811\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0572 - val_loss: 0.0177 - val_mae: 0.0876\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0824\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0888\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0042 - mae: 0.0694 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0625 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0528 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0165 - val_mae: 0.0848\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0523 - val_loss: 0.0168 - val_mae: 0.0883\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0890\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0891\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0891\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0886\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0864\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0879\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0879\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0876\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0518 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0166 - val_mae: 0.0820\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0638 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0510 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0513 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0519 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0546 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0507 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0534 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0492 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0170 - val_mae: 0.0870\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0533 - val_loss: 0.0171 - val_mae: 0.0882\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0471 - val_loss: 0.0170 - val_mae: 0.0888\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0497 - val_loss: 0.0170 - val_mae: 0.0896\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0170 - val_mae: 0.0901\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0471 - val_loss: 0.0170 - val_mae: 0.0906\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0170 - val_mae: 0.0923\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0170 - val_mae: 0.0928\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0478 - val_loss: 0.0170 - val_mae: 0.0933\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0171 - val_mae: 0.0948\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0171 - val_mae: 0.0953\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0172 - val_mae: 0.0955\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0172 - val_mae: 0.0956\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0173 - val_mae: 0.0954\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0173 - val_mae: 0.0949\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0173 - val_mae: 0.0943\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0499 - val_loss: 0.0173 - val_mae: 0.0935\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0173 - val_mae: 0.0926\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0173 - val_mae: 0.0915\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0475 - val_loss: 0.0172 - val_mae: 0.0909\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0172 - val_mae: 0.0906\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0473 - val_loss: 0.0172 - val_mae: 0.0906\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0172 - val_mae: 0.0908\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0418 - val_loss: 0.0172 - val_mae: 0.0911\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0172 - val_mae: 0.0914\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0172 - val_mae: 0.0918\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0172 - val_mae: 0.0928\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0409 - val_loss: 0.0172 - val_mae: 0.0936\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0173 - val_mae: 0.0938\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0173 - val_mae: 0.0940\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0490 - val_loss: 0.0174 - val_mae: 0.0944\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0174 - val_mae: 0.0947\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0533 - val_loss: 0.0174 - val_mae: 0.0946\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0174 - val_mae: 0.0941\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0174 - val_mae: 0.0936\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0174 - val_mae: 0.0930\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0485 - val_loss: 0.0174 - val_mae: 0.0928\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0173 - val_mae: 0.0926\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0173 - val_mae: 0.0921\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0469 - val_loss: 0.0173 - val_mae: 0.0918\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0394 - val_loss: 0.0173 - val_mae: 0.0915\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0173 - val_mae: 0.0912\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0173 - val_mae: 0.0911\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0174 - val_mae: 0.0909\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0386 - val_loss: 0.0174 - val_mae: 0.0908\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0472 - val_loss: 0.0174 - val_mae: 0.0907\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0174 - val_mae: 0.0907\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0370 - val_loss: 0.0174 - val_mae: 0.0907\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0174 - val_mae: 0.0910\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0174 - val_mae: 0.0914\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0467 - val_loss: 0.0174 - val_mae: 0.0922\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0174 - val_mae: 0.0927\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0174 - val_mae: 0.0930\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0403 - val_loss: 0.0174 - val_mae: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:12,491] Trial 8 finished with value: 0.09308356046676636 and parameters: {'learning_rate': 0.006416073308314046, 'weight_decay': 1.1145025493914503e-09}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1067 - mae: 0.3606 - val_loss: 0.0407 - val_mae: 0.2090\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0569 - mae: 0.2642 - val_loss: 0.0225 - val_mae: 0.1471\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0256 - mae: 0.1854 - val_loss: 0.0208 - val_mae: 0.1038\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1211 - val_loss: 0.0244 - val_mae: 0.1169\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0111 - mae: 0.1154 - val_loss: 0.0252 - val_mae: 0.1177\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0103 - mae: 0.1094 - val_loss: 0.0240 - val_mae: 0.1089\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1014\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0075 - mae: 0.0870 - val_loss: 0.0224 - val_mae: 0.0951\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0826 - val_loss: 0.0222 - val_mae: 0.0925\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0220 - val_mae: 0.0899\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0768 - val_loss: 0.0217 - val_mae: 0.0873\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0702 - val_loss: 0.0213 - val_mae: 0.0880\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0208 - val_mae: 0.0923\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0205 - val_mae: 0.0957\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0200 - val_mae: 0.0956\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0726 - val_loss: 0.0196 - val_mae: 0.0914\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0661 - val_loss: 0.0193 - val_mae: 0.0872\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0190 - val_mae: 0.0830\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0604 - val_loss: 0.0187 - val_mae: 0.0801\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0580 - val_loss: 0.0185 - val_mae: 0.0790\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0595 - val_loss: 0.0183 - val_mae: 0.0787\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0596 - val_loss: 0.0181 - val_mae: 0.0787\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0179 - val_mae: 0.0789\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0561 - val_loss: 0.0177 - val_mae: 0.0796\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0554 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0554 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0841\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - mae: 0.0504 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0517 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - mae: 0.0515 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0517 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0529 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0506 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0506 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0507 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0487 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0481 - val_loss: 0.0170 - val_mae: 0.0860\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0169 - val_mae: 0.0870\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0170 - val_mae: 0.0873\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0173 - val_mae: 0.0877\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0426 - val_loss: 0.0172 - val_mae: 0.0872\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0172 - val_mae: 0.0867\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0172 - val_mae: 0.0866\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0173 - val_mae: 0.0878\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0172 - val_mae: 0.0880\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0170 - val_mae: 0.0875\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0171 - val_mae: 0.0876\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0172 - val_mae: 0.0880\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0494 - val_loss: 0.0173 - val_mae: 0.0880\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0461 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0173 - val_mae: 0.0876\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0403 - val_loss: 0.0173 - val_mae: 0.0875\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0174 - val_mae: 0.0880\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0175 - val_mae: 0.0882\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0175 - val_mae: 0.0884\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0398 - val_loss: 0.0176 - val_mae: 0.0887\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0432 - val_loss: 0.0175 - val_mae: 0.0879\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0380 - val_loss: 0.0172 - val_mae: 0.0858\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0379 - val_loss: 0.0172 - val_mae: 0.0859\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.0174 - val_mae: 0.0869\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0401 - val_loss: 0.0177 - val_mae: 0.0885\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0434 - val_loss: 0.0177 - val_mae: 0.0891\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0177 - val_mae: 0.0895\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0375 - val_loss: 0.0177 - val_mae: 0.0899\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0341 - val_loss: 0.0177 - val_mae: 0.0901\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0393 - val_loss: 0.0177 - val_mae: 0.0902\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0409 - val_loss: 0.0176 - val_mae: 0.0894\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0388 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0390 - val_loss: 0.0175 - val_mae: 0.0897\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0176 - val_mae: 0.0917\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0372 - val_loss: 0.0176 - val_mae: 0.0926\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0176 - val_mae: 0.0930\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0175 - val_mae: 0.0933\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0175 - val_mae: 0.0934\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0015 - mae: 0.0403 - val_loss: 0.0175 - val_mae: 0.0934\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.0175 - val_mae: 0.0932\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0176 - val_mae: 0.0927\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0393 - val_loss: 0.0174 - val_mae: 0.0914\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0384 - val_loss: 0.0175 - val_mae: 0.0913\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0395 - val_loss: 0.0176 - val_mae: 0.0915\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0382 - val_loss: 0.0177 - val_mae: 0.0913\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0352 - val_loss: 0.0178 - val_mae: 0.0921\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 0.0178 - val_mae: 0.0926\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0465 - val_loss: 0.0179 - val_mae: 0.0927\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0179 - val_mae: 0.0925\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0179 - val_mae: 0.0919\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 0.0178 - val_mae: 0.0908\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0343 - val_loss: 0.0178 - val_mae: 0.0907\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.0180 - val_mae: 0.0918\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0346 - val_loss: 0.0181 - val_mae: 0.0925\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0181 - val_mae: 0.0928\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0181 - val_mae: 0.0924\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0415 - val_loss: 0.0181 - val_mae: 0.0919\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0331 - val_loss: 0.0180 - val_mae: 0.0912\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0320 - val_loss: 0.0179 - val_mae: 0.0912\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0181 - val_mae: 0.0930\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0356 - val_loss: 0.0182 - val_mae: 0.0948\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0299 - val_loss: 0.0182 - val_mae: 0.0959\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0373 - val_loss: 0.0183 - val_mae: 0.0965\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0182 - val_mae: 0.0964\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0181 - val_mae: 0.0955\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0182 - val_mae: 0.0959\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0183 - val_mae: 0.0965\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0379 - val_loss: 0.0184 - val_mae: 0.0971\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0379 - val_loss: 0.0184 - val_mae: 0.0972\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0372 - val_loss: 0.0184 - val_mae: 0.0970\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.9726e-04 - mae: 0.0320 - val_loss: 0.0183 - val_mae: 0.0966\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 0.0184 - val_mae: 0.0974\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0334 - val_loss: 0.0184 - val_mae: 0.0975\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0355 - val_loss: 0.0184 - val_mae: 0.0973\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0396 - val_loss: 0.0185 - val_mae: 0.0979\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1682e-04 - mae: 0.0295 - val_loss: 0.0185 - val_mae: 0.0974\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5049e-04 - mae: 0.0298 - val_loss: 0.0183 - val_mae: 0.0964\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0331 - val_loss: 0.0181 - val_mae: 0.0948\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 0.0178 - val_mae: 0.0931\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 0.0179 - val_mae: 0.0940\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0182 - val_mae: 0.0959\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.7608e-04 - mae: 0.0327 - val_loss: 0.0184 - val_mae: 0.0970\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0184 - val_mae: 0.0974\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0431 - val_loss: 0.0183 - val_mae: 0.0968\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.4849e-04 - mae: 0.0309 - val_loss: 0.0182 - val_mae: 0.0959\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5533e-04 - mae: 0.0277 - val_loss: 0.0180 - val_mae: 0.0943\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7553e-04 - mae: 0.0303 - val_loss: 0.0181 - val_mae: 0.0951\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0346 - val_loss: 0.0181 - val_mae: 0.0953\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 0.0183 - val_mae: 0.0969\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.3948e-04 - mae: 0.0286 - val_loss: 0.0184 - val_mae: 0.0979\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0379 - val_loss: 0.0184 - val_mae: 0.0978\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7320e-04 - mae: 0.0312 - val_loss: 0.0184 - val_mae: 0.0982\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8044e-04 - mae: 0.0274 - val_loss: 0.0185 - val_mae: 0.0989\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0351 - val_loss: 0.0185 - val_mae: 0.0988\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6758e-04 - mae: 0.0280 - val_loss: 0.0186 - val_mae: 0.0994\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0311 - val_loss: 0.0185 - val_mae: 0.0992\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.0725e-04 - mae: 0.0282 - val_loss: 0.0185 - val_mae: 0.0995\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0397 - val_loss: 0.0189 - val_mae: 0.1013\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0189 - val_mae: 0.1017\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0370 - val_loss: 0.0188 - val_mae: 0.1009\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0190 - val_mae: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:23,170] Trial 9 finished with value: 0.10229438543319702 and parameters: {'learning_rate': 0.0025983043327137715, 'weight_decay': 0.000816563074345258}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0424 - mae: 0.2304 - val_loss: 0.0280 - val_mae: 0.1492\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0253 - mae: 0.1801 - val_loss: 0.0238 - val_mae: 0.1292\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0172 - mae: 0.1469 - val_loss: 0.0208 - val_mae: 0.1118\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0118 - mae: 0.1226 - val_loss: 0.0190 - val_mae: 0.0931\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0102 - mae: 0.1159 - val_loss: 0.0189 - val_mae: 0.0845\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0856 - val_loss: 0.0193 - val_mae: 0.0839\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0729 - val_loss: 0.0196 - val_mae: 0.0862\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - mae: 0.0763 - val_loss: 0.0196 - val_mae: 0.0883\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0763 - val_loss: 0.0193 - val_mae: 0.0888\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0715 - val_loss: 0.0187 - val_mae: 0.0877\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0693 - val_loss: 0.0180 - val_mae: 0.0859\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0727 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0821\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0699 - val_loss: 0.0168 - val_mae: 0.0813\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0497 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0551 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0489 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0510 - val_loss: 0.0167 - val_mae: 0.0782\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0481 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0796\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0446 - val_loss: 0.0164 - val_mae: 0.0811\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0166 - val_mae: 0.0811\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0435 - val_loss: 0.0168 - val_mae: 0.0804\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0420 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0415 - val_loss: 0.0168 - val_mae: 0.0802\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0395 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0435 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0166 - val_mae: 0.0797\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0166 - val_mae: 0.0802\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0164 - val_mae: 0.0809\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0163 - val_mae: 0.0825\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 0.0162 - val_mae: 0.0842\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0161 - val_mae: 0.0853\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0165 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0400 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0379 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0171 - val_mae: 0.0864\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0369 - val_loss: 0.0170 - val_mae: 0.0806\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 0.0169 - val_mae: 0.0810\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0167 - val_mae: 0.0823\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0374 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6717e-04 - mae: 0.0333 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.2741e-04 - mae: 0.0327 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.7358e-04 - mae: 0.0342 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0346 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6449e-04 - mae: 0.0330 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7134e-04 - mae: 0.0325 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.8081e-04 - mae: 0.0305 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.5980e-04 - mae: 0.0289 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.9050e-04 - mae: 0.0328 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.7420e-04 - mae: 0.0336 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4107e-04 - mae: 0.0287 - val_loss: 0.0174 - val_mae: 0.0832\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 0.0173 - val_mae: 0.0842\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6416e-04 - mae: 0.0325 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9154e-04 - mae: 0.0306 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7225e-04 - mae: 0.0314 - val_loss: 0.0171 - val_mae: 0.0857\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0426e-04 - mae: 0.0295 - val_loss: 0.0171 - val_mae: 0.0860\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6807e-04 - mae: 0.0324 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.0466e-04 - mae: 0.0324 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8260e-04 - mae: 0.0316 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6003e-04 - mae: 0.0297 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.3291e-04 - mae: 0.0305 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7467e-04 - mae: 0.0297 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5404e-04 - mae: 0.0308 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7969e-04 - mae: 0.0321 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7165e-04 - mae: 0.0276 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.5079e-04 - mae: 0.0282 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7258e-04 - mae: 0.0294 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5443e-04 - mae: 0.0319 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4722e-04 - mae: 0.0294 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9898e-04 - mae: 0.0285 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.5604e-04 - mae: 0.0297 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9435e-04 - mae: 0.0309 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8940e-04 - mae: 0.0273 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7538e-04 - mae: 0.0293 - val_loss: 0.0174 - val_mae: 0.0839\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.2525e-04 - mae: 0.0286 - val_loss: 0.0173 - val_mae: 0.0864\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1920e-04 - mae: 0.0291 - val_loss: 0.0174 - val_mae: 0.0876\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8073e-04 - mae: 0.0306 - val_loss: 0.0175 - val_mae: 0.0878\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5529e-04 - mae: 0.0274 - val_loss: 0.0174 - val_mae: 0.0879\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.6094e-04 - mae: 0.0298 - val_loss: 0.0173 - val_mae: 0.0867\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9056e-04 - mae: 0.0263 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 7.1592e-04 - mae: 0.0263 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.6922e-04 - mae: 0.0258 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5762e-04 - mae: 0.0317 - val_loss: 0.0166 - val_mae: 0.0831\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0302e-04 - mae: 0.0322 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6635e-04 - mae: 0.0298 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4400e-04 - mae: 0.0272 - val_loss: 0.0171 - val_mae: 0.0854\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 0.0171 - val_mae: 0.0867\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6512e-04 - mae: 0.0277 - val_loss: 0.0170 - val_mae: 0.0888\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8058e-04 - mae: 0.0294 - val_loss: 0.0170 - val_mae: 0.0910\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.9940e-04 - mae: 0.0289 - val_loss: 0.0170 - val_mae: 0.0907\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6791e-04 - mae: 0.0280 - val_loss: 0.0169 - val_mae: 0.0879\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5133e-04 - mae: 0.0302 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6412e-04 - mae: 0.0262 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5232e-04 - mae: 0.0266 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - mae: 0.0277 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.2768e-04 - mae: 0.0303 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9954e-04 - mae: 0.0302 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3259e-04 - mae: 0.0280 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9017e-04 - mae: 0.0312 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6389e-04 - mae: 0.0313 - val_loss: 0.0169 - val_mae: 0.0809\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.6779e-04 - mae: 0.0258 - val_loss: 0.0170 - val_mae: 0.0806\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5780e-04 - mae: 0.0251 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.2286e-04 - mae: 0.0301 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4985e-04 - mae: 0.0253 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7170e-04 - mae: 0.0263 - val_loss: 0.0173 - val_mae: 0.0835\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3007e-04 - mae: 0.0276 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.1059e-04 - mae: 0.0247 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7480e-04 - mae: 0.0240 - val_loss: 0.0177 - val_mae: 0.0805\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.9753e-04 - mae: 0.0281 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7207e-04 - mae: 0.0277 - val_loss: 0.0176 - val_mae: 0.0805\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0010 - mae: 0.0302 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 8.1351e-04 - mae: 0.0287 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.2426e-04 - mae: 0.0226 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9015e-04 - mae: 0.0310 - val_loss: 0.0173 - val_mae: 0.0834\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7177e-04 - mae: 0.0334 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1021e-04 - mae: 0.0291 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.3641e-04 - mae: 0.0278 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3675e-04 - mae: 0.0267 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6458e-04 - mae: 0.0265 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9897e-04 - mae: 0.0217 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1851e-04 - mae: 0.0278 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.7887e-04 - mae: 0.0284 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.3678e-04 - mae: 0.0281 - val_loss: 0.0169 - val_mae: 0.0808\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0302 - val_loss: 0.0168 - val_mae: 0.0805\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.7976e-04 - mae: 0.0239 - val_loss: 0.0168 - val_mae: 0.0806\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9738e-04 - mae: 0.0254 - val_loss: 0.0168 - val_mae: 0.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:33,877] Trial 10 finished with value: 0.08093073219060898 and parameters: {'learning_rate': 0.001565088898287893, 'weight_decay': 0.0049576950498849155}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1128 - mae: 0.3784 - val_loss: 0.1374 - val_mae: 0.4196\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1578 - mae: 0.4588 - val_loss: 0.0461 - val_mae: 0.2124\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0447 - mae: 0.2212 - val_loss: 0.0244 - val_mae: 0.1257\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0125 - mae: 0.1253 - val_loss: 0.0226 - val_mae: 0.1102\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0961 - val_loss: 0.0208 - val_mae: 0.1009\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0186 - val_mae: 0.0928\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0846 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0835 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0710 - val_loss: 0.0148 - val_mae: 0.0835\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0678 - val_loss: 0.0150 - val_mae: 0.0833\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0698 - val_loss: 0.0151 - val_mae: 0.0832\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mae: 0.0698 - val_loss: 0.0153 - val_mae: 0.0807\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0154 - val_mae: 0.0802\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0588 - val_loss: 0.0154 - val_mae: 0.0904\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0158 - val_mae: 0.0996\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0159 - val_mae: 0.0869\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0533 - val_loss: 0.0162 - val_mae: 0.0888\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0162 - val_mae: 0.1005\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0642 - val_loss: 0.0159 - val_mae: 0.0961\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0525 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0159 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0505 - val_loss: 0.0157 - val_mae: 0.0858\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0154 - val_mae: 0.0913\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0153 - val_mae: 0.0911\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0152 - val_mae: 0.0887\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0151 - val_mae: 0.0841\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0150 - val_mae: 0.0835\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0151 - val_mae: 0.0824\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0428 - val_loss: 0.0150 - val_mae: 0.0846\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0150 - val_mae: 0.0895\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0464 - val_loss: 0.0151 - val_mae: 0.0898\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0154 - val_mae: 0.0847\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0156 - val_mae: 0.0862\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0157 - val_mae: 0.0903\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0157 - val_mae: 0.0926\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0156 - val_mae: 0.0936\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0154 - val_mae: 0.0845\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0435 - val_loss: 0.0155 - val_mae: 0.0867\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0156 - val_mae: 0.0913\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0157 - val_mae: 0.0897\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0157 - val_mae: 0.0857\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0157 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0155 - val_mae: 0.0884\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0421 - val_loss: 0.0156 - val_mae: 0.0987\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0391 - val_loss: 0.0158 - val_mae: 0.1018\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0156 - val_mae: 0.0876\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0384 - val_loss: 0.0158 - val_mae: 0.0852\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0159 - val_mae: 0.0895\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0161 - val_mae: 0.0937\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.2686e-04 - mae: 0.0333 - val_loss: 0.0162 - val_mae: 0.0950\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0162 - val_mae: 0.0980\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0157 - val_mae: 0.0894\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9173e-04 - mae: 0.0343 - val_loss: 0.0155 - val_mae: 0.0863\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.8730e-04 - mae: 0.0315 - val_loss: 0.0155 - val_mae: 0.0892\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3407e-04 - mae: 0.0325 - val_loss: 0.0155 - val_mae: 0.0880\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0350 - val_loss: 0.0156 - val_mae: 0.0917\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7547e-04 - mae: 0.0319 - val_loss: 0.0159 - val_mae: 0.0955\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0159 - val_mae: 0.0917\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.8772e-04 - mae: 0.0326 - val_loss: 0.0161 - val_mae: 0.0936\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0160 - val_mae: 0.0879\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0159 - val_mae: 0.0892\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0367 - val_loss: 0.0158 - val_mae: 0.0912\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0163e-04 - mae: 0.0332 - val_loss: 0.0158 - val_mae: 0.0927\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0160 - val_mae: 0.0992\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9467e-04 - mae: 0.0329 - val_loss: 0.0161 - val_mae: 0.1012\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0157 - val_mae: 0.0871\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 0.0159 - val_mae: 0.0846\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0010 - mae: 0.0311 - val_loss: 0.0162 - val_mae: 0.0912\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.9220e-04 - mae: 0.0317 - val_loss: 0.0170 - val_mae: 0.1048\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0179 - val_mae: 0.1146\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0167 - val_mae: 0.0970\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0163 - val_mae: 0.0796\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0328 - val_loss: 0.0162 - val_mae: 0.0774\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0158 - val_mae: 0.0821\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.2826e-04 - mae: 0.0312 - val_loss: 0.0160 - val_mae: 0.0961\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0413e-04 - mae: 0.0318 - val_loss: 0.0165 - val_mae: 0.1060\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0162 - val_mae: 0.1008\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0158 - val_mae: 0.0832\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0372 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1330e-04 - mae: 0.0328 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0340 - val_loss: 0.0160 - val_mae: 0.0891\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 0.0164 - val_mae: 0.0990\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0165 - val_mae: 0.0978\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0372 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7849e-04 - mae: 0.0284 - val_loss: 0.0170 - val_mae: 0.0866\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0172 - val_mae: 0.0888\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0340e-04 - mae: 0.0320 - val_loss: 0.0173 - val_mae: 0.0897\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7892e-04 - mae: 0.0320 - val_loss: 0.0173 - val_mae: 0.0895\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.8956e-04 - mae: 0.0321 - val_loss: 0.0171 - val_mae: 0.0897\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.5795e-04 - mae: 0.0309 - val_loss: 0.0171 - val_mae: 0.0910\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 0.0171 - val_mae: 0.0922\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7979e-04 - mae: 0.0297 - val_loss: 0.0171 - val_mae: 0.0934\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1717e-04 - mae: 0.0310 - val_loss: 0.0169 - val_mae: 0.0951\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0351 - val_loss: 0.0165 - val_mae: 0.0946\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0161 - val_mae: 0.0873\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.2687e-04 - mae: 0.0314 - val_loss: 0.0158 - val_mae: 0.0815\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7814e-04 - mae: 0.0301 - val_loss: 0.0156 - val_mae: 0.0793\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7589e-04 - mae: 0.0288 - val_loss: 0.0155 - val_mae: 0.0807\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6897e-04 - mae: 0.0315 - val_loss: 0.0154 - val_mae: 0.0834\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6400e-04 - mae: 0.0306 - val_loss: 0.0156 - val_mae: 0.0874\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0795e-04 - mae: 0.0323 - val_loss: 0.0157 - val_mae: 0.0879\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0329 - val_loss: 0.0158 - val_mae: 0.0893\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8128e-04 - mae: 0.0257 - val_loss: 0.0160 - val_mae: 0.0897\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7470e-04 - mae: 0.0340 - val_loss: 0.0161 - val_mae: 0.0876\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9191e-04 - mae: 0.0231 - val_loss: 0.0161 - val_mae: 0.0833\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3167e-04 - mae: 0.0280 - val_loss: 0.0161 - val_mae: 0.0823\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.6786e-04 - mae: 0.0294 - val_loss: 0.0160 - val_mae: 0.0829\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0160 - val_mae: 0.0894\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2589e-04 - mae: 0.0300 - val_loss: 0.0160 - val_mae: 0.0929\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7427e-04 - mae: 0.0342 - val_loss: 0.0159 - val_mae: 0.0861\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6253e-04 - mae: 0.0271 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3379e-04 - mae: 0.0271 - val_loss: 0.0157 - val_mae: 0.0798\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0284e-04 - mae: 0.0286 - val_loss: 0.0158 - val_mae: 0.0806\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.3234e-04 - mae: 0.0316 - val_loss: 0.0158 - val_mae: 0.0823\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0329 - val_loss: 0.0159 - val_mae: 0.0844\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.4596e-04 - mae: 0.0325 - val_loss: 0.0159 - val_mae: 0.0863\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.0995e-04 - mae: 0.0266 - val_loss: 0.0161 - val_mae: 0.0899\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6077e-04 - mae: 0.0277 - val_loss: 0.0162 - val_mae: 0.0918\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3496e-04 - mae: 0.0295 - val_loss: 0.0164 - val_mae: 0.0937\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0353 - val_loss: 0.0163 - val_mae: 0.0842\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.8110e-04 - mae: 0.0303 - val_loss: 0.0164 - val_mae: 0.0810\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.3988e-04 - mae: 0.0294 - val_loss: 0.0166 - val_mae: 0.0801\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.4188e-04 - mae: 0.0285 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0342e-04 - mae: 0.0291 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.5338e-04 - mae: 0.0302 - val_loss: 0.0169 - val_mae: 0.0931\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.5433e-04 - mae: 0.0320 - val_loss: 0.0169 - val_mae: 0.0981\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0363 - val_loss: 0.0165 - val_mae: 0.0905\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.6676e-04 - mae: 0.0304 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6913e-04 - mae: 0.0259 - val_loss: 0.0163 - val_mae: 0.0783\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3365e-04 - mae: 0.0285 - val_loss: 0.0165 - val_mae: 0.0802\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.1159e-04 - mae: 0.0257 - val_loss: 0.0164 - val_mae: 0.0800\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.7557e-04 - mae: 0.0292 - val_loss: 0.0162 - val_mae: 0.0806\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4588e-04 - mae: 0.0318 - val_loss: 0.0161 - val_mae: 0.0829\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0161 - val_mae: 0.0811\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9650e-04 - mae: 0.0236 - val_loss: 0.0161 - val_mae: 0.0812\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.4767e-04 - mae: 0.0331 - val_loss: 0.0160 - val_mae: 0.0823\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.2193e-04 - mae: 0.0313 - val_loss: 0.0163 - val_mae: 0.0913\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0566e-04 - mae: 0.0332 - val_loss: 0.0167 - val_mae: 0.0950\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0331 - val_loss: 0.0168 - val_mae: 0.0949\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0166 - val_mae: 0.0921\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8742e-04 - mae: 0.0308 - val_loss: 0.0163 - val_mae: 0.0872\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8497e-04 - mae: 0.0293 - val_loss: 0.0161 - val_mae: 0.0828\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.2490e-04 - mae: 0.0275 - val_loss: 0.0160 - val_mae: 0.0818\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0982e-04 - mae: 0.0287 - val_loss: 0.0160 - val_mae: 0.0829\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1521e-04 - mae: 0.0318 - val_loss: 0.0160 - val_mae: 0.0858\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4367e-04 - mae: 0.0287 - val_loss: 0.0161 - val_mae: 0.0873\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3596e-04 - mae: 0.0319 - val_loss: 0.0162 - val_mae: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:44,558] Trial 11 finished with value: 0.08801240473985672 and parameters: {'learning_rate': 0.0029504493300632068, 'weight_decay': 0.005335930388406917}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0679 - mae: 0.2900 - val_loss: 0.0329 - val_mae: 0.1720\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0435 - mae: 0.2352 - val_loss: 0.0264 - val_mae: 0.1421\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0388 - mae: 0.2158 - val_loss: 0.0226 - val_mae: 0.1190\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0350 - mae: 0.2090 - val_loss: 0.0208 - val_mae: 0.1041\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0280 - mae: 0.1884 - val_loss: 0.0203 - val_mae: 0.1011\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0275 - mae: 0.1899 - val_loss: 0.0204 - val_mae: 0.1056\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0228 - mae: 0.1690 - val_loss: 0.0203 - val_mae: 0.1092\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0235 - mae: 0.1671 - val_loss: 0.0202 - val_mae: 0.1112\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0190 - mae: 0.1566 - val_loss: 0.0199 - val_mae: 0.1120\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0175 - mae: 0.1539 - val_loss: 0.0196 - val_mae: 0.1121\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0192 - mae: 0.1592 - val_loss: 0.0194 - val_mae: 0.1103\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0182 - mae: 0.1463 - val_loss: 0.0191 - val_mae: 0.1078\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0137 - mae: 0.1336 - val_loss: 0.0188 - val_mae: 0.1043\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0154 - mae: 0.1401 - val_loss: 0.0185 - val_mae: 0.1013\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0119 - mae: 0.1216 - val_loss: 0.0182 - val_mae: 0.0991\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0136 - mae: 0.1296 - val_loss: 0.0181 - val_mae: 0.0966\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0109 - mae: 0.1172 - val_loss: 0.0180 - val_mae: 0.0943\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0101 - mae: 0.1139 - val_loss: 0.0179 - val_mae: 0.0923\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - mae: 0.1062 - val_loss: 0.0179 - val_mae: 0.0907\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1044 - val_loss: 0.0180 - val_mae: 0.0893\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0076 - mae: 0.1022 - val_loss: 0.0181 - val_mae: 0.0880\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0078 - mae: 0.0983 - val_loss: 0.0182 - val_mae: 0.0870\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0062 - mae: 0.0857 - val_loss: 0.0183 - val_mae: 0.0863\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0923 - val_loss: 0.0184 - val_mae: 0.0857\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0942 - val_loss: 0.0184 - val_mae: 0.0849\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mae: 0.0844 - val_loss: 0.0185 - val_mae: 0.0842\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0185 - val_mae: 0.0834\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0075 - mae: 0.0949 - val_loss: 0.0185 - val_mae: 0.0826\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0069 - mae: 0.0913 - val_loss: 0.0185 - val_mae: 0.0819\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0826 - val_loss: 0.0184 - val_mae: 0.0814\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0782 - val_loss: 0.0184 - val_mae: 0.0808\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0184 - val_mae: 0.0803\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0056 - mae: 0.0790 - val_loss: 0.0183 - val_mae: 0.0800\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - mae: 0.0807 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mae: 0.0772 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0062 - mae: 0.0812 - val_loss: 0.0182 - val_mae: 0.0794\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - mae: 0.0803 - val_loss: 0.0181 - val_mae: 0.0794\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0738 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0747 - val_loss: 0.0180 - val_mae: 0.0796\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0705 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mae: 0.0743 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0728 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - mae: 0.0714 - val_loss: 0.0179 - val_mae: 0.0804\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0179 - val_mae: 0.0805\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0705 - val_loss: 0.0179 - val_mae: 0.0806\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0682 - val_loss: 0.0179 - val_mae: 0.0808\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0809\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0178 - val_mae: 0.0810\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0178 - val_mae: 0.0811\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0042 - mae: 0.0684 - val_loss: 0.0178 - val_mae: 0.0811\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0811\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0178 - val_mae: 0.0812\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0664 - val_loss: 0.0178 - val_mae: 0.0813\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0178 - val_mae: 0.0812\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0640 - val_loss: 0.0177 - val_mae: 0.0811\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0810\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0177 - val_mae: 0.0809\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0176 - val_mae: 0.0808\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0041 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0807\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0633 - val_loss: 0.0176 - val_mae: 0.0806\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0175 - val_mae: 0.0805\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0802\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0636 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0683 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0175 - val_mae: 0.0800\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0583 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0175 - val_mae: 0.0800\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0175 - val_mae: 0.0802\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0175 - val_mae: 0.0804\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0805\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0175 - val_mae: 0.0806\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0585 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0175 - val_mae: 0.0812\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0592 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0583 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0504 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0562 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0558 - val_loss: 0.0176 - val_mae: 0.0822\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0176 - val_mae: 0.0820\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0552 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0534 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0490 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0511 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0514 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0514 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0524 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0176 - val_mae: 0.0829\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0176 - val_mae: 0.0831\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0481 - val_loss: 0.0176 - val_mae: 0.0833\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0176 - val_mae: 0.0834\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0519 - val_loss: 0.0176 - val_mae: 0.0835\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0175 - val_mae: 0.0835\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0175 - val_mae: 0.0836\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0175 - val_mae: 0.0836\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0461 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0459 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0464 - val_loss: 0.0174 - val_mae: 0.0839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0472 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0451 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0441 - val_loss: 0.0174 - val_mae: 0.0836\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0439 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0021 - mae: 0.0495 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0440 - val_loss: 0.0176 - val_mae: 0.0830\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0442 - val_loss: 0.0176 - val_mae: 0.0829\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0441 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0446 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0416 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0451 - val_loss: 0.0174 - val_mae: 0.0836\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0471 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0175 - val_mae: 0.0837\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0175 - val_mae: 0.0837\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0433 - val_loss: 0.0175 - val_mae: 0.0838\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0175 - val_mae: 0.0839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:32:55,731] Trial 12 finished with value: 0.08389885723590851 and parameters: {'learning_rate': 0.00030097439054198284, 'weight_decay': 0.0018520764603730437}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0804 - mae: 0.3214 - val_loss: 0.8139 - val_mae: 1.2129\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8988 - mae: 1.3128 - val_loss: 0.1674 - val_mae: 0.4911\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2069 - mae: 0.5386 - val_loss: 0.0242 - val_mae: 0.1094\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0239 - val_mae: 0.1069\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0233 - val_mae: 0.1038\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0224 - val_mae: 0.0988\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0827 - val_loss: 0.0213 - val_mae: 0.0927\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0062 - mae: 0.0759 - val_loss: 0.0202 - val_mae: 0.0868\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0696 - val_loss: 0.0191 - val_mae: 0.0835\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0637 - val_loss: 0.0183 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0639 - val_loss: 0.0177 - val_mae: 0.0855\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0631 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0172 - val_mae: 0.0953\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0737 - val_loss: 0.0171 - val_mae: 0.0986\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0711 - val_loss: 0.0169 - val_mae: 0.1003\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0049 - mae: 0.0784 - val_loss: 0.0167 - val_mae: 0.1007\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0753 - val_loss: 0.0165 - val_mae: 0.1002\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0784 - val_loss: 0.0164 - val_mae: 0.0997\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0045 - mae: 0.0788 - val_loss: 0.0166 - val_mae: 0.0997\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0782 - val_loss: 0.0168 - val_mae: 0.0994\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0745 - val_loss: 0.0169 - val_mae: 0.0980\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0706 - val_loss: 0.0170 - val_mae: 0.0959\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0668 - val_loss: 0.0169 - val_mae: 0.0928\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0669 - val_loss: 0.0168 - val_mae: 0.0896\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0693 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0683 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0671 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0171 - val_mae: 0.0849\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0172 - val_mae: 0.0847\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0688 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0173 - val_mae: 0.0811\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0175 - val_mae: 0.0805\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0176 - val_mae: 0.0810\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0176 - val_mae: 0.0810\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0813\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:33:06,715] Trial 13 finished with value: 0.08502590656280518 and parameters: {'learning_rate': 0.015437727974909846, 'weight_decay': 0.0003568367027791023}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0498 - mae: 0.2540 - val_loss: 0.0352 - val_mae: 0.1792\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0506 - mae: 0.2510 - val_loss: 0.0338 - val_mae: 0.1731\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0403 - mae: 0.2294 - val_loss: 0.0323 - val_mae: 0.1668\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0525 - mae: 0.2565 - val_loss: 0.0309 - val_mae: 0.1603\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0414 - mae: 0.2398 - val_loss: 0.0296 - val_mae: 0.1540\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0390 - mae: 0.2230 - val_loss: 0.0284 - val_mae: 0.1481\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0396 - mae: 0.2227 - val_loss: 0.0274 - val_mae: 0.1429\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0330 - mae: 0.2073 - val_loss: 0.0264 - val_mae: 0.1381\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0341 - mae: 0.2110 - val_loss: 0.0256 - val_mae: 0.1335\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0303 - mae: 0.2014 - val_loss: 0.0247 - val_mae: 0.1292\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0310 - mae: 0.1860 - val_loss: 0.0240 - val_mae: 0.1251\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0395 - mae: 0.2218 - val_loss: 0.0234 - val_mae: 0.1215\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0320 - mae: 0.2065 - val_loss: 0.0228 - val_mae: 0.1183\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0280 - mae: 0.1875 - val_loss: 0.0223 - val_mae: 0.1158\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0291 - mae: 0.1894 - val_loss: 0.0219 - val_mae: 0.1136\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0269 - mae: 0.1836 - val_loss: 0.0216 - val_mae: 0.1117\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0276 - mae: 0.1853 - val_loss: 0.0212 - val_mae: 0.1100\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0260 - mae: 0.1776 - val_loss: 0.0209 - val_mae: 0.1085\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0284 - mae: 0.1874 - val_loss: 0.0207 - val_mae: 0.1072\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0239 - mae: 0.1698 - val_loss: 0.0205 - val_mae: 0.1063\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0236 - mae: 0.1762 - val_loss: 0.0203 - val_mae: 0.1056\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0203 - mae: 0.1561 - val_loss: 0.0201 - val_mae: 0.1050\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0237 - mae: 0.1735 - val_loss: 0.0200 - val_mae: 0.1047\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0242 - mae: 0.1797 - val_loss: 0.0200 - val_mae: 0.1044\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0234 - mae: 0.1734 - val_loss: 0.0199 - val_mae: 0.1043\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0283 - mae: 0.1953 - val_loss: 0.0199 - val_mae: 0.1043\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0241 - mae: 0.1712 - val_loss: 0.0199 - val_mae: 0.1042\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0205 - mae: 0.1576 - val_loss: 0.0199 - val_mae: 0.1040\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0238 - mae: 0.1756 - val_loss: 0.0198 - val_mae: 0.1037\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0201 - mae: 0.1560 - val_loss: 0.0198 - val_mae: 0.1033\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0226 - mae: 0.1630 - val_loss: 0.0197 - val_mae: 0.1029\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0271 - mae: 0.1850 - val_loss: 0.0196 - val_mae: 0.1024\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0193 - mae: 0.1526 - val_loss: 0.0195 - val_mae: 0.1021\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0171 - mae: 0.1470 - val_loss: 0.0195 - val_mae: 0.1018\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0197 - mae: 0.1541 - val_loss: 0.0194 - val_mae: 0.1015\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0198 - mae: 0.1568 - val_loss: 0.0194 - val_mae: 0.1012\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0215 - mae: 0.1576 - val_loss: 0.0194 - val_mae: 0.1011\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0190 - mae: 0.1533 - val_loss: 0.0193 - val_mae: 0.1009\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0198 - mae: 0.1551 - val_loss: 0.0193 - val_mae: 0.1007\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0207 - mae: 0.1596 - val_loss: 0.0192 - val_mae: 0.1005\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0166 - mae: 0.1419 - val_loss: 0.0192 - val_mae: 0.1004\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0174 - mae: 0.1486 - val_loss: 0.0192 - val_mae: 0.1003\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0146 - mae: 0.1386 - val_loss: 0.0192 - val_mae: 0.1002\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0191 - mae: 0.1556 - val_loss: 0.0192 - val_mae: 0.1002\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0208 - mae: 0.1635 - val_loss: 0.0192 - val_mae: 0.1001\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0201 - mae: 0.1579 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0167 - mae: 0.1436 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0173 - mae: 0.1496 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0178 - mae: 0.1543 - val_loss: 0.0191 - val_mae: 0.1001\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0188 - mae: 0.1555 - val_loss: 0.0191 - val_mae: 0.1002\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0165 - mae: 0.1384 - val_loss: 0.0192 - val_mae: 0.1003\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0187 - mae: 0.1484 - val_loss: 0.0192 - val_mae: 0.1003\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0136 - mae: 0.1285 - val_loss: 0.0192 - val_mae: 0.1003\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0160 - mae: 0.1452 - val_loss: 0.0191 - val_mae: 0.1002\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0157 - mae: 0.1370 - val_loss: 0.0191 - val_mae: 0.1001\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0186 - mae: 0.1529 - val_loss: 0.0191 - val_mae: 0.0999\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0156 - mae: 0.1389 - val_loss: 0.0191 - val_mae: 0.0998\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0152 - mae: 0.1379 - val_loss: 0.0190 - val_mae: 0.0996\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0134 - mae: 0.1328 - val_loss: 0.0190 - val_mae: 0.0994\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0138 - mae: 0.1334 - val_loss: 0.0190 - val_mae: 0.0991\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0142 - mae: 0.1348 - val_loss: 0.0190 - val_mae: 0.0989\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1375 - val_loss: 0.0190 - val_mae: 0.0987\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0142 - mae: 0.1330 - val_loss: 0.0190 - val_mae: 0.0984\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0163 - mae: 0.1419 - val_loss: 0.0190 - val_mae: 0.0981\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0136 - mae: 0.1308 - val_loss: 0.0189 - val_mae: 0.0979\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0137 - mae: 0.1302 - val_loss: 0.0189 - val_mae: 0.0977\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0146 - mae: 0.1360 - val_loss: 0.0189 - val_mae: 0.0975\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0130 - mae: 0.1273 - val_loss: 0.0189 - val_mae: 0.0973\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0135 - mae: 0.1300 - val_loss: 0.0189 - val_mae: 0.0970\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0134 - mae: 0.1338 - val_loss: 0.0189 - val_mae: 0.0967\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0147 - mae: 0.1358 - val_loss: 0.0189 - val_mae: 0.0963\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0137 - mae: 0.1329 - val_loss: 0.0189 - val_mae: 0.0960\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - mae: 0.1348 - val_loss: 0.0189 - val_mae: 0.0958\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0115 - mae: 0.1206 - val_loss: 0.0189 - val_mae: 0.0955\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0137 - mae: 0.1286 - val_loss: 0.0189 - val_mae: 0.0953\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - mae: 0.1269 - val_loss: 0.0189 - val_mae: 0.0953\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0116 - mae: 0.1224 - val_loss: 0.0190 - val_mae: 0.0952\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0146 - mae: 0.1349 - val_loss: 0.0190 - val_mae: 0.0952\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0133 - mae: 0.1292 - val_loss: 0.0190 - val_mae: 0.0952\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0111 - mae: 0.1190 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0153 - mae: 0.1332 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0107 - mae: 0.1154 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0123 - mae: 0.1232 - val_loss: 0.0190 - val_mae: 0.0952\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0124 - mae: 0.1213 - val_loss: 0.0190 - val_mae: 0.0953\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0133 - mae: 0.1253 - val_loss: 0.0190 - val_mae: 0.0954\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0119 - mae: 0.1255 - val_loss: 0.0191 - val_mae: 0.0955\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - mae: 0.1238 - val_loss: 0.0191 - val_mae: 0.0955\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0111 - mae: 0.1170 - val_loss: 0.0191 - val_mae: 0.0957\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0115 - mae: 0.1212 - val_loss: 0.0191 - val_mae: 0.0958\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0113 - mae: 0.1192 - val_loss: 0.0191 - val_mae: 0.0959\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0116 - mae: 0.1231 - val_loss: 0.0191 - val_mae: 0.0960\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0108 - mae: 0.1154 - val_loss: 0.0191 - val_mae: 0.0960\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0116 - mae: 0.1172 - val_loss: 0.0191 - val_mae: 0.0960\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0105 - mae: 0.1167 - val_loss: 0.0191 - val_mae: 0.0958\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0110 - mae: 0.1178 - val_loss: 0.0191 - val_mae: 0.0957\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0118 - mae: 0.1218 - val_loss: 0.0191 - val_mae: 0.0956\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0105 - mae: 0.1115 - val_loss: 0.0191 - val_mae: 0.0954\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0090 - mae: 0.1075 - val_loss: 0.0191 - val_mae: 0.0953\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0100 - mae: 0.1071 - val_loss: 0.0190 - val_mae: 0.0952\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0120 - mae: 0.1192 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0094 - mae: 0.1099 - val_loss: 0.0190 - val_mae: 0.0949\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - mae: 0.1093 - val_loss: 0.0190 - val_mae: 0.0947\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1070 - val_loss: 0.0190 - val_mae: 0.0946\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0189 - val_mae: 0.0944\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0189 - val_mae: 0.0942\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0095 - mae: 0.1091 - val_loss: 0.0189 - val_mae: 0.0940\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1043 - val_loss: 0.0189 - val_mae: 0.0939\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0091 - mae: 0.1012 - val_loss: 0.0188 - val_mae: 0.0937\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0188 - val_mae: 0.0935\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0101 - mae: 0.1142 - val_loss: 0.0188 - val_mae: 0.0933\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1138 - val_loss: 0.0188 - val_mae: 0.0932\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0188 - val_mae: 0.0930\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0187 - val_mae: 0.0929\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - mae: 0.1180 - val_loss: 0.0187 - val_mae: 0.0928\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0080 - mae: 0.1031 - val_loss: 0.0187 - val_mae: 0.0927\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1079 - val_loss: 0.0187 - val_mae: 0.0926\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0094 - mae: 0.1087 - val_loss: 0.0187 - val_mae: 0.0925\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1058 - val_loss: 0.0187 - val_mae: 0.0923\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - mae: 0.0998 - val_loss: 0.0187 - val_mae: 0.0922\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0187 - val_mae: 0.0921\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0187 - val_mae: 0.0920\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.1043 - val_loss: 0.0187 - val_mae: 0.0918\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.1008 - val_loss: 0.0187 - val_mae: 0.0917\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0187 - val_mae: 0.0916\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0085 - mae: 0.1000 - val_loss: 0.0187 - val_mae: 0.0915\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.1044 - val_loss: 0.0187 - val_mae: 0.0914\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0086 - mae: 0.1042 - val_loss: 0.0186 - val_mae: 0.0912\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0186 - val_mae: 0.0911\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0080 - mae: 0.0989 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - mae: 0.0983 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0995 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1062 - val_loss: 0.0185 - val_mae: 0.0910\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0078 - mae: 0.0966 - val_loss: 0.0185 - val_mae: 0.0910\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0947 - val_loss: 0.0185 - val_mae: 0.0910\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0976 - val_loss: 0.0185 - val_mae: 0.0910\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0185 - val_mae: 0.0909\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0185 - val_mae: 0.0908\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0932 - val_loss: 0.0185 - val_mae: 0.0908\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - mae: 0.1004 - val_loss: 0.0184 - val_mae: 0.0908\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0940 - val_loss: 0.0184 - val_mae: 0.0907\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - mae: 0.0975 - val_loss: 0.0184 - val_mae: 0.0906\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - mae: 0.0924 - val_loss: 0.0184 - val_mae: 0.0905\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - mae: 0.0898 - val_loss: 0.0184 - val_mae: 0.0904\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0966 - val_loss: 0.0184 - val_mae: 0.0904\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0073 - mae: 0.0934 - val_loss: 0.0184 - val_mae: 0.0903\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0928 - val_loss: 0.0184 - val_mae: 0.0902\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0074 - mae: 0.0935 - val_loss: 0.0184 - val_mae: 0.0902\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0080 - mae: 0.0990 - val_loss: 0.0184 - val_mae: 0.0901\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0063 - mae: 0.0873 - val_loss: 0.0184 - val_mae: 0.0901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:33:17,454] Trial 14 finished with value: 0.09011959284543991 and parameters: {'learning_rate': 4.961773503653476e-05, 'weight_decay': 0.00331554694816902}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0531 - mae: 0.2668 - val_loss: 0.8050 - val_mae: 1.2333\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9236 - mae: 1.3623 - val_loss: 0.0294 - val_mae: 0.1712\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0235 - mae: 0.1732 - val_loss: 0.0256 - val_mae: 0.1478\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0176 - mae: 0.1496 - val_loss: 0.0226 - val_mae: 0.1137\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0112 - mae: 0.1124 - val_loss: 0.0212 - val_mae: 0.1008\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mae: 0.0900 - val_loss: 0.0210 - val_mae: 0.1033\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0908 - val_loss: 0.0189 - val_mae: 0.0880\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0174 - val_mae: 0.0861\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0186 - val_mae: 0.1237\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0063 - mae: 0.0928 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - mae: 0.0676 - val_loss: 0.0185 - val_mae: 0.0842\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0192 - val_mae: 0.0868\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0702 - val_loss: 0.0182 - val_mae: 0.0816\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0672 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0692 - val_loss: 0.0177 - val_mae: 0.1011\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0055 - mae: 0.0825 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0181 - val_mae: 0.0843\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0654 - val_loss: 0.0173 - val_mae: 0.0845\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - mae: 0.0676 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0168 - val_mae: 0.0807\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0165 - val_mae: 0.0795\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0796\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0808\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0817\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0813\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0647 - val_loss: 0.0166 - val_mae: 0.0813\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0813\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0633 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0660 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0162 - val_mae: 0.0800\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0873\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0634 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0159 - val_mae: 0.0787\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0160 - val_mae: 0.0827\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0644 - val_loss: 0.0159 - val_mae: 0.0814\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0159 - val_mae: 0.0787\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0159 - val_mae: 0.0792\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0159 - val_mae: 0.0790\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0160 - val_mae: 0.0794\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0160 - val_mae: 0.0789\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0160 - val_mae: 0.0789\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0159 - val_mae: 0.0789\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0022 - mae: 0.0471 - val_loss: 0.0160 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - mae: 0.0499 - val_loss: 0.0161 - val_mae: 0.0859\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0558 - val_loss: 0.0158 - val_mae: 0.0819\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0159 - val_mae: 0.0841\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - mae: 0.0473 - val_loss: 0.0160 - val_mae: 0.0893\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0021 - mae: 0.0501 - val_loss: 0.0164 - val_mae: 0.0953\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0546 - val_loss: 0.0159 - val_mae: 0.0843\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0462 - val_loss: 0.0164 - val_mae: 0.0863\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0869\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0555 - val_loss: 0.0162 - val_mae: 0.0827\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0491 - val_loss: 0.0159 - val_mae: 0.0841\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0159 - val_mae: 0.0843\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0428 - val_loss: 0.0159 - val_mae: 0.0830\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0464 - val_loss: 0.0160 - val_mae: 0.0786\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0164 - val_mae: 0.0792\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0163 - val_mae: 0.0784\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0160 - val_mae: 0.0775\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0525 - val_loss: 0.0159 - val_mae: 0.0788\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0158 - val_mae: 0.0835\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0581 - val_loss: 0.0157 - val_mae: 0.0785\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0162 - val_mae: 0.0806\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0162 - val_mae: 0.0817\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0160 - val_mae: 0.0810\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0475 - val_loss: 0.0160 - val_mae: 0.0809\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0161 - val_mae: 0.0806\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0020 - mae: 0.0476 - val_loss: 0.0162 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0162 - val_mae: 0.0788\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0158 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0458 - val_loss: 0.0156 - val_mae: 0.0816\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0509 - val_loss: 0.0167 - val_mae: 0.0793\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0396 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0169 - val_mae: 0.0825\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0166 - val_mae: 0.0799\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0439 - val_loss: 0.0158 - val_mae: 0.0797\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0457 - val_loss: 0.0156 - val_mae: 0.0795\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0511 - val_loss: 0.0167 - val_mae: 0.0810\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0153 - val_mae: 0.0782\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0155 - val_mae: 0.0872\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0601 - val_loss: 0.0154 - val_mae: 0.0764\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0400 - val_loss: 0.0166 - val_mae: 0.0813\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0155 - val_mae: 0.0766\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0421 - val_loss: 0.0151 - val_mae: 0.0833\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0466 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0155 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0515 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0513 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0163 - val_mae: 0.0808\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0155 - val_mae: 0.0795\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0448 - val_loss: 0.0166 - val_mae: 0.0831\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0152 - val_mae: 0.0771\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0151 - val_mae: 0.0769\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0156 - val_mae: 0.0768\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0164 - val_mae: 0.0805\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0459 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0419 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0158 - val_mae: 0.0786\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0405 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - mae: 0.0495 - val_loss: 0.0160 - val_mae: 0.0778\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0422 - val_loss: 0.0157 - val_mae: 0.0771\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0470 - val_loss: 0.0152 - val_mae: 0.0764\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0440 - val_loss: 0.0149 - val_mae: 0.0788\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0148 - val_mae: 0.0814\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0475 - val_loss: 0.0147 - val_mae: 0.0815\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0150 - val_mae: 0.0809\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0156 - val_mae: 0.0821\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0472 - val_loss: 0.0161 - val_mae: 0.0836\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0435 - val_loss: 0.0162 - val_mae: 0.0834\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0153 - val_mae: 0.0782\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0154 - val_mae: 0.0774\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0158 - val_mae: 0.0771\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0159 - val_mae: 0.0769\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0159 - val_mae: 0.0762\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0424 - val_loss: 0.0160 - val_mae: 0.0768\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0161 - val_mae: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:33:28,447] Trial 15 finished with value: 0.07742629945278168 and parameters: {'learning_rate': 0.01033552600316748, 'weight_decay': 7.6087642875090054e-06}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - mae: 0.2733 - val_loss: 0.1258 - val_mae: 0.3928\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1908 - mae: 0.4992 - val_loss: 0.0225 - val_mae: 0.1217\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0157 - mae: 0.1378 - val_loss: 0.0232 - val_mae: 0.1120\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0099 - mae: 0.1044 - val_loss: 0.0206 - val_mae: 0.0931\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0191 - val_mae: 0.0867\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0758 - val_loss: 0.0184 - val_mae: 0.0804\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0741 - val_loss: 0.0179 - val_mae: 0.0788\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0176 - val_mae: 0.0835\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0658 - val_loss: 0.0173 - val_mae: 0.0863\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0863\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0166 - val_mae: 0.0867\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0165 - val_mae: 0.0859\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0693 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0164 - val_mae: 0.0812\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0640 - val_loss: 0.0155 - val_mae: 0.0913\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0621 - val_loss: 0.0166 - val_mae: 0.0797\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0162 - val_mae: 0.0802\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0155 - val_mae: 0.0875\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0634 - val_loss: 0.0163 - val_mae: 0.0794\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0552 - val_loss: 0.0161 - val_mae: 0.0809\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0156 - val_mae: 0.0821\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0560 - val_loss: 0.0152 - val_mae: 0.0819\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0157 - val_mae: 0.0761\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0530 - val_loss: 0.0153 - val_mae: 0.0769\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0145 - val_mae: 0.0800\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0555 - val_loss: 0.0145 - val_mae: 0.0770\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0508 - val_loss: 0.0143 - val_mae: 0.0783\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0145 - val_mae: 0.0761\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0142 - val_mae: 0.0764\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0137 - val_mae: 0.0777\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0134 - val_mae: 0.0782\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0136 - val_mae: 0.0755\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0136 - val_mae: 0.0754\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0128 - val_mae: 0.0825\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0548 - val_loss: 0.0139 - val_mae: 0.0730\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0143 - val_mae: 0.0719\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0129 - val_mae: 0.0821\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0130 - val_mae: 0.0838\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0142 - val_mae: 0.0734\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0425 - val_loss: 0.0146 - val_mae: 0.0725\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0470 - val_loss: 0.0138 - val_mae: 0.0748\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0445 - val_loss: 0.0133 - val_mae: 0.0800\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0151 - val_mae: 0.0719\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0474 - val_loss: 0.0150 - val_mae: 0.0720\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0136 - val_mae: 0.0771\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0464 - val_loss: 0.0136 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0138 - val_mae: 0.0768\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0487 - val_loss: 0.0143 - val_mae: 0.0746\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0435 - val_loss: 0.0140 - val_mae: 0.0738\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0137 - val_mae: 0.0736\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0401 - val_loss: 0.0134 - val_mae: 0.0759\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0504 - val_loss: 0.0133 - val_mae: 0.0763\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0138 - val_mae: 0.0715\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0139 - val_mae: 0.0713\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0132 - val_mae: 0.0730\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0129 - val_mae: 0.0778\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0513 - val_loss: 0.0140 - val_mae: 0.0717\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0398 - val_loss: 0.0147 - val_mae: 0.0717\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0143 - val_mae: 0.0723\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0412 - val_loss: 0.0134 - val_mae: 0.0772\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0132 - val_mae: 0.0795\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0135 - val_mae: 0.0740\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0142 - val_mae: 0.0725\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0144 - val_mae: 0.0730\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0140 - val_mae: 0.0766\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0139 - val_mae: 0.0825\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0139 - val_mae: 0.0812\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0133 - val_mae: 0.0775\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0134 - val_mae: 0.0717\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0392 - val_loss: 0.0135 - val_mae: 0.0718\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0383 - val_loss: 0.0133 - val_mae: 0.0737\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0130 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0419 - val_loss: 0.0130 - val_mae: 0.0804\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0136 - val_mae: 0.0762\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0142 - val_mae: 0.0724\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0147 - val_mae: 0.0708\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0396 - val_loss: 0.0147 - val_mae: 0.0712\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0144 - val_mae: 0.0726\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0145 - val_mae: 0.0804\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0398 - val_loss: 0.0151 - val_mae: 0.0846\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0148 - val_mae: 0.0762\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0147 - val_mae: 0.0702\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0144 - val_mae: 0.0693\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0141 - val_mae: 0.0704\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.1861e-04 - mae: 0.0324 - val_loss: 0.0139 - val_mae: 0.0752\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0139 - val_mae: 0.0780\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0415 - val_loss: 0.0140 - val_mae: 0.0782\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0329 - val_loss: 0.0140 - val_mae: 0.0769\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0148 - val_mae: 0.0753\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0146 - val_mae: 0.0730\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0138 - val_mae: 0.0743\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - mae: 0.0342 - val_loss: 0.0136 - val_mae: 0.0765\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0411 - val_loss: 0.0139 - val_mae: 0.0760\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0384 - val_loss: 0.0151 - val_mae: 0.0804\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0158 - val_mae: 0.0823\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0362 - val_loss: 0.0154 - val_mae: 0.0801\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0145 - val_mae: 0.0761\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - mae: 0.0346 - val_loss: 0.0139 - val_mae: 0.0755\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.6542e-04 - mae: 0.0340 - val_loss: 0.0138 - val_mae: 0.0778\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0459 - val_loss: 0.0139 - val_mae: 0.0810\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0145 - val_mae: 0.0806\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9245e-04 - mae: 0.0301 - val_loss: 0.0151 - val_mae: 0.0808\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0360 - val_loss: 0.0153 - val_mae: 0.0800\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0387 - val_loss: 0.0148 - val_mae: 0.0816\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0141 - val_mae: 0.0845\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0135 - val_mae: 0.0829\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0389 - val_loss: 0.0133 - val_mae: 0.0757\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0138 - val_mae: 0.0724\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.4087e-04 - mae: 0.0318 - val_loss: 0.0143 - val_mae: 0.0713\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0147 - val_mae: 0.0719\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.0148 - val_mae: 0.0751\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.3190e-04 - mae: 0.0304 - val_loss: 0.0149 - val_mae: 0.0825\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9477e-04 - mae: 0.0305 - val_loss: 0.0148 - val_mae: 0.0838\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7320e-04 - mae: 0.0341 - val_loss: 0.0148 - val_mae: 0.0810\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.5720e-04 - mae: 0.0298 - val_loss: 0.0151 - val_mae: 0.0770\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.3706e-04 - mae: 0.0320 - val_loss: 0.0153 - val_mae: 0.0772\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9990e-04 - mae: 0.0333 - val_loss: 0.0152 - val_mae: 0.0802\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0346 - val_loss: 0.0152 - val_mae: 0.0891\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0360 - val_loss: 0.0149 - val_mae: 0.0895\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0404 - val_loss: 0.0144 - val_mae: 0.0768\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0148 - val_mae: 0.0737\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6156e-04 - mae: 0.0296 - val_loss: 0.0151 - val_mae: 0.0739\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.9825e-04 - mae: 0.0332 - val_loss: 0.0151 - val_mae: 0.0738\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0147 - val_mae: 0.0750\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0146 - val_mae: 0.0815\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0145 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0417 - val_loss: 0.0143 - val_mae: 0.0752\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0141 - val_mae: 0.0742\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7982e-04 - mae: 0.0301 - val_loss: 0.0140 - val_mae: 0.0729\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 7.8078e-04 - mae: 0.0296 - val_loss: 0.0138 - val_mae: 0.0729\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9291e-04 - mae: 0.0339 - val_loss: 0.0140 - val_mae: 0.0729\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.0138 - val_mae: 0.0766\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6880e-04 - mae: 0.0337 - val_loss: 0.0137 - val_mae: 0.0798\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.4592e-04 - mae: 0.0282 - val_loss: 0.0137 - val_mae: 0.0819\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8668e-04 - mae: 0.0349 - val_loss: 0.0137 - val_mae: 0.0768\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.9038e-04 - mae: 0.0298 - val_loss: 0.0142 - val_mae: 0.0714\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.9536e-04 - mae: 0.0309 - val_loss: 0.0144 - val_mae: 0.0702\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.0144 - val_mae: 0.0713\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0367 - val_loss: 0.0141 - val_mae: 0.0755\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.2780e-04 - mae: 0.0272 - val_loss: 0.0141 - val_mae: 0.0822\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0360 - val_loss: 0.0142 - val_mae: 0.0869\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7093e-04 - mae: 0.0331 - val_loss: 0.0143 - val_mae: 0.0870\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5867e-04 - mae: 0.0296 - val_loss: 0.0146 - val_mae: 0.0804\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0331 - val_loss: 0.0149 - val_mae: 0.0774\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6859e-04 - mae: 0.0340 - val_loss: 0.0149 - val_mae: 0.0770\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0309 - val_loss: 0.0148 - val_mae: 0.0775\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0145 - val_mae: 0.0792\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5030e-04 - mae: 0.0323 - val_loss: 0.0144 - val_mae: 0.0814\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8771e-04 - mae: 0.0266 - val_loss: 0.0144 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:33:39,205] Trial 16 finished with value: 0.0840098112821579 and parameters: {'learning_rate': 0.006779873190458813, 'weight_decay': 7.490146846893542e-06}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0763 - mae: 0.3093 - val_loss: 0.4687 - val_mae: 0.8396\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5298 - mae: 0.8999 - val_loss: 0.0687 - val_mae: 0.2891\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0578 - mae: 0.2768 - val_loss: 0.0245 - val_mae: 0.1152\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0086 - mae: 0.1027 - val_loss: 0.0200 - val_mae: 0.1008\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - mae: 0.0824 - val_loss: 0.0171 - val_mae: 0.0988\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0055 - mae: 0.0814 - val_loss: 0.0195 - val_mae: 0.0892\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0799 - val_loss: 0.0191 - val_mae: 0.0885\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0726 - val_loss: 0.0177 - val_mae: 0.0890\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0199 - val_mae: 0.0912\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0677 - val_loss: 0.0165 - val_mae: 0.0993\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0983\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0206 - val_mae: 0.0966\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0691 - val_loss: 0.0195 - val_mae: 0.0924\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0659 - val_loss: 0.0176 - val_mae: 0.0877\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0162 - val_mae: 0.0937\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0801 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0669 - val_loss: 0.0165 - val_mae: 0.0852\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0670 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0627 - val_loss: 0.0171 - val_mae: 0.0873\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0657 - val_loss: 0.0176 - val_mae: 0.0889\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0177 - val_mae: 0.0893\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0664 - val_loss: 0.0175 - val_mae: 0.0883\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0669 - val_loss: 0.0172 - val_mae: 0.0864\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0663 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0164 - val_mae: 0.0829\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0165 - val_mae: 0.0818\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0825\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0636 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0165 - val_mae: 0.0853\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0165 - val_mae: 0.0855\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0165 - val_mae: 0.0855\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0860\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0866\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:33:49,882] Trial 17 finished with value: 0.0853387787938118 and parameters: {'learning_rate': 0.015215121833600909, 'weight_decay': 1.841531371496911e-05}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0989 - mae: 0.3458 - val_loss: 0.3259 - val_mae: 0.6540\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3853 - mae: 0.7327 - val_loss: 0.0409 - val_mae: 0.2204\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0354 - mae: 0.2114 - val_loss: 0.0197 - val_mae: 0.1094\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0094 - mae: 0.1019 - val_loss: 0.0230 - val_mae: 0.1316\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - mae: 0.1263 - val_loss: 0.0202 - val_mae: 0.1004\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0073 - mae: 0.0905 - val_loss: 0.0198 - val_mae: 0.1013\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0874 - val_loss: 0.0184 - val_mae: 0.0851\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0842\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0651 - val_loss: 0.0176 - val_mae: 0.0891\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0176 - val_mae: 0.1031\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0701 - val_loss: 0.0169 - val_mae: 0.0886\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0166 - val_mae: 0.0964\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0181 - val_mae: 0.1243\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - mae: 0.0804 - val_loss: 0.0165 - val_mae: 0.0795\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0165 - val_mae: 0.0797\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0165 - val_mae: 0.0802\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0822\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0171 - val_mae: 0.0857\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0173 - val_mae: 0.0876\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0175 - val_mae: 0.0893\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0177 - val_mae: 0.0907\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0177 - val_mae: 0.0916\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0917\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0175 - val_mae: 0.0914\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0660 - val_loss: 0.0173 - val_mae: 0.0906\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0893\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0880\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0644 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0165 - val_mae: 0.0850\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0587 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0165 - val_mae: 0.0839\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0166 - val_mae: 0.0827\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0166 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0827\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0850\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0831\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0832\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0849\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0863\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:00,565] Trial 18 finished with value: 0.08635930716991425 and parameters: {'learning_rate': 0.012221168533630927, 'weight_decay': 7.889049307857704e-07}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0841 - mae: 0.3181 - val_loss: 0.0294 - val_mae: 0.1549\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0364 - mae: 0.2211 - val_loss: 0.0239 - val_mae: 0.1261\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0312 - mae: 0.1943 - val_loss: 0.0253 - val_mae: 0.1411\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0298 - mae: 0.1986 - val_loss: 0.0262 - val_mae: 0.1482\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - mae: 0.1923 - val_loss: 0.0248 - val_mae: 0.1416\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0219 - mae: 0.1707 - val_loss: 0.0230 - val_mae: 0.1324\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0188 - mae: 0.1551 - val_loss: 0.0218 - val_mae: 0.1236\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - mae: 0.1468 - val_loss: 0.0206 - val_mae: 0.1124\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0129 - mae: 0.1267 - val_loss: 0.0197 - val_mae: 0.1031\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0116 - mae: 0.1190 - val_loss: 0.0192 - val_mae: 0.0973\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0107 - mae: 0.1152 - val_loss: 0.0190 - val_mae: 0.0933\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0075 - mae: 0.0985 - val_loss: 0.0189 - val_mae: 0.0881\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0072 - mae: 0.0933 - val_loss: 0.0189 - val_mae: 0.0868\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0867 - val_loss: 0.0188 - val_mae: 0.0857\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0064 - mae: 0.0845 - val_loss: 0.0188 - val_mae: 0.0850\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mae: 0.0809 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0062 - mae: 0.0799 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0056 - mae: 0.0773 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0753 - val_loss: 0.0187 - val_mae: 0.0844\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0758 - val_loss: 0.0187 - val_mae: 0.0843\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0049 - mae: 0.0717 - val_loss: 0.0185 - val_mae: 0.0841\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0184 - val_mae: 0.0843\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0701 - val_loss: 0.0183 - val_mae: 0.0845\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0181 - val_mae: 0.0851\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0856\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0661 - val_loss: 0.0178 - val_mae: 0.0860\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0662 - val_loss: 0.0176 - val_mae: 0.0866\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0175 - val_mae: 0.0869\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0174 - val_mae: 0.0872\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0875\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0881\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0172 - val_mae: 0.0886\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0895\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0898\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0898\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0897\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0630 - val_loss: 0.0169 - val_mae: 0.0891\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0169 - val_mae: 0.0888\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0884\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0168 - val_mae: 0.0883\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0168 - val_mae: 0.0886\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0166 - val_mae: 0.0910\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0166 - val_mae: 0.0919\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0165 - val_mae: 0.0927\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0165 - val_mae: 0.0932\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0919\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0164 - val_mae: 0.0911\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0165 - val_mae: 0.0900\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0891\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0165 - val_mae: 0.0884\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0165 - val_mae: 0.0878\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0165 - val_mae: 0.0878\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0509 - val_loss: 0.0164 - val_mae: 0.0882\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0164 - val_mae: 0.0892\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0537 - val_loss: 0.0163 - val_mae: 0.0903\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0516 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0162 - val_mae: 0.0914\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0162 - val_mae: 0.0913\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0162 - val_mae: 0.0908\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0492 - val_loss: 0.0162 - val_mae: 0.0905\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0506 - val_loss: 0.0162 - val_mae: 0.0897\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0467 - val_loss: 0.0162 - val_mae: 0.0892\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0162 - val_mae: 0.0891\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0162 - val_mae: 0.0887\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0496 - val_loss: 0.0162 - val_mae: 0.0887\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0499 - val_loss: 0.0162 - val_mae: 0.0888\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0162 - val_mae: 0.0890\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0471 - val_loss: 0.0162 - val_mae: 0.0895\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0162 - val_mae: 0.0905\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0467 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0162 - val_mae: 0.0918\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - mae: 0.0410 - val_loss: 0.0162 - val_mae: 0.0924\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0162 - val_mae: 0.0932\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0162 - val_mae: 0.0935\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0162 - val_mae: 0.0930\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0466 - val_loss: 0.0161 - val_mae: 0.0915\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0161 - val_mae: 0.0899\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0161 - val_mae: 0.0891\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0160 - val_mae: 0.0892\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0411 - val_loss: 0.0160 - val_mae: 0.0888\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0434 - val_loss: 0.0160 - val_mae: 0.0888\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0450 - val_loss: 0.0160 - val_mae: 0.0891\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0892\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0161 - val_mae: 0.0896\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0161 - val_mae: 0.0898\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0161 - val_mae: 0.0908\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0415 - val_loss: 0.0160 - val_mae: 0.0920\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0373 - val_loss: 0.0160 - val_mae: 0.0920\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0422 - val_loss: 0.0161 - val_mae: 0.0910\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0405 - val_loss: 0.0161 - val_mae: 0.0893\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0162 - val_mae: 0.0882\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0162 - val_mae: 0.0871\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0162 - val_mae: 0.0869\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0161 - val_mae: 0.0883\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0161 - val_mae: 0.0900\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0382 - val_loss: 0.0160 - val_mae: 0.0916\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0435 - val_loss: 0.0161 - val_mae: 0.0924\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - mae: 0.0398 - val_loss: 0.0161 - val_mae: 0.0925\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0161 - val_mae: 0.0925\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0162 - val_mae: 0.0923\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0162 - val_mae: 0.0917\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0162 - val_mae: 0.0909\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0391 - val_loss: 0.0163 - val_mae: 0.0895\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0368 - val_loss: 0.0163 - val_mae: 0.0895\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0391 - val_loss: 0.0163 - val_mae: 0.0896\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0353 - val_loss: 0.0163 - val_mae: 0.0903\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0163 - val_mae: 0.0903\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0164 - val_mae: 0.0903\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0338 - val_loss: 0.0163 - val_mae: 0.0910\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0360 - val_loss: 0.0163 - val_mae: 0.0908\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0163 - val_mae: 0.0913\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.9622e-04 - mae: 0.0337 - val_loss: 0.0162 - val_mae: 0.0910\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.9258e-04 - mae: 0.0331 - val_loss: 0.0162 - val_mae: 0.0908\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0161 - val_mae: 0.0918\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0372 - val_loss: 0.0161 - val_mae: 0.0922\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7561e-04 - mae: 0.0309 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0162 - val_mae: 0.0915\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.9020e-04 - mae: 0.0341 - val_loss: 0.0163 - val_mae: 0.0908\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.3497e-04 - mae: 0.0321 - val_loss: 0.0163 - val_mae: 0.0902\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1107e-04 - mae: 0.0324 - val_loss: 0.0163 - val_mae: 0.0901\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6924e-04 - mae: 0.0338 - val_loss: 0.0164 - val_mae: 0.0903\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0360 - val_loss: 0.0163 - val_mae: 0.0909\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 9.9577e-04 - mae: 0.0343 - val_loss: 0.0163 - val_mae: 0.0909\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.8957e-04 - mae: 0.0320 - val_loss: 0.0163 - val_mae: 0.0899\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5494e-04 - mae: 0.0319 - val_loss: 0.0164 - val_mae: 0.0889\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0343 - val_loss: 0.0163 - val_mae: 0.0888\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.7038e-04 - mae: 0.0325 - val_loss: 0.0163 - val_mae: 0.0894\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.5874e-04 - mae: 0.0321 - val_loss: 0.0162 - val_mae: 0.0904\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.8225e-04 - mae: 0.0343 - val_loss: 0.0162 - val_mae: 0.0905\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0162 - val_mae: 0.0906\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5917e-04 - mae: 0.0344 - val_loss: 0.0162 - val_mae: 0.0901\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.9115e-04 - mae: 0.0334 - val_loss: 0.0163 - val_mae: 0.0895\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - mae: 0.0354 - val_loss: 0.0163 - val_mae: 0.0895\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.5041e-04 - mae: 0.0333 - val_loss: 0.0164 - val_mae: 0.0901\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5674e-04 - mae: 0.0287 - val_loss: 0.0164 - val_mae: 0.0908\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.9923e-04 - mae: 0.0339 - val_loss: 0.0163 - val_mae: 0.0918\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1751e-04 - mae: 0.0306 - val_loss: 0.0163 - val_mae: 0.0931\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7274e-04 - mae: 0.0324 - val_loss: 0.0163 - val_mae: 0.0936\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.1273e-04 - mae: 0.0330 - val_loss: 0.0163 - val_mae: 0.0943\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7775e-04 - mae: 0.0288 - val_loss: 0.0163 - val_mae: 0.0940\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8939e-04 - mae: 0.0301 - val_loss: 0.0164 - val_mae: 0.0936\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.0476e-04 - mae: 0.0313 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.8180e-04 - mae: 0.0346 - val_loss: 0.0166 - val_mae: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:11,368] Trial 19 finished with value: 0.09028071910142899 and parameters: {'learning_rate': 0.0007011515413406798, 'weight_decay': 1.8462499325035035e-05}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1053 - mae: 0.3628 - val_loss: 0.0628 - val_mae: 0.2581\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1110 - mae: 0.3673 - val_loss: 0.0627 - val_mae: 0.2580\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0861 - mae: 0.3307 - val_loss: 0.0627 - val_mae: 0.2579\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0852 - mae: 0.3342 - val_loss: 0.0627 - val_mae: 0.2578\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1100 - mae: 0.3778 - val_loss: 0.0626 - val_mae: 0.2577\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1063 - mae: 0.3511 - val_loss: 0.0626 - val_mae: 0.2576\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1121 - mae: 0.3733 - val_loss: 0.0625 - val_mae: 0.2574\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0956 - mae: 0.3408 - val_loss: 0.0625 - val_mae: 0.2573\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1005 - mae: 0.3545 - val_loss: 0.0625 - val_mae: 0.2572\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1016 - mae: 0.3500 - val_loss: 0.0624 - val_mae: 0.2571\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1043 - mae: 0.3566 - val_loss: 0.0624 - val_mae: 0.2570\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0901 - mae: 0.3357 - val_loss: 0.0623 - val_mae: 0.2568\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1051 - mae: 0.3612 - val_loss: 0.0623 - val_mae: 0.2567\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0961 - mae: 0.3493 - val_loss: 0.0622 - val_mae: 0.2566\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1059 - mae: 0.3705 - val_loss: 0.0622 - val_mae: 0.2565\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0955 - mae: 0.3596 - val_loss: 0.0621 - val_mae: 0.2564\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1039 - mae: 0.3661 - val_loss: 0.0621 - val_mae: 0.2563\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1081 - mae: 0.3728 - val_loss: 0.0621 - val_mae: 0.2561\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0907 - mae: 0.3431 - val_loss: 0.0620 - val_mae: 0.2560\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1047 - mae: 0.3652 - val_loss: 0.0620 - val_mae: 0.2559\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0914 - mae: 0.3352 - val_loss: 0.0619 - val_mae: 0.2558\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1113 - mae: 0.3705 - val_loss: 0.0619 - val_mae: 0.2557\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0993 - mae: 0.3366 - val_loss: 0.0618 - val_mae: 0.2556\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0873 - mae: 0.3338 - val_loss: 0.0618 - val_mae: 0.2554\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1060 - mae: 0.3653 - val_loss: 0.0618 - val_mae: 0.2553\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1045 - mae: 0.3535 - val_loss: 0.0617 - val_mae: 0.2552\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0956 - mae: 0.3455 - val_loss: 0.0617 - val_mae: 0.2551\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0943 - mae: 0.3491 - val_loss: 0.0616 - val_mae: 0.2550\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0941 - mae: 0.3419 - val_loss: 0.0616 - val_mae: 0.2549\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1064 - mae: 0.3575 - val_loss: 0.0615 - val_mae: 0.2547\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0973 - mae: 0.3491 - val_loss: 0.0615 - val_mae: 0.2546\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0963 - mae: 0.3529 - val_loss: 0.0615 - val_mae: 0.2545\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1004 - mae: 0.3518 - val_loss: 0.0614 - val_mae: 0.2544\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0998 - mae: 0.3508 - val_loss: 0.0614 - val_mae: 0.2543\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1068 - mae: 0.3633 - val_loss: 0.0613 - val_mae: 0.2542\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0863 - mae: 0.3245 - val_loss: 0.0613 - val_mae: 0.2540\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1023 - mae: 0.3498 - val_loss: 0.0612 - val_mae: 0.2539\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1002 - mae: 0.3577 - val_loss: 0.0612 - val_mae: 0.2538\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0931 - mae: 0.3472 - val_loss: 0.0612 - val_mae: 0.2537\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1139 - mae: 0.3753 - val_loss: 0.0611 - val_mae: 0.2536\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0932 - mae: 0.3470 - val_loss: 0.0611 - val_mae: 0.2535\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1032 - mae: 0.3602 - val_loss: 0.0610 - val_mae: 0.2534\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1001 - mae: 0.3593 - val_loss: 0.0610 - val_mae: 0.2532\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0837 - mae: 0.3169 - val_loss: 0.0610 - val_mae: 0.2531\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1010 - mae: 0.3450 - val_loss: 0.0609 - val_mae: 0.2530\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0983 - mae: 0.3512 - val_loss: 0.0609 - val_mae: 0.2529\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0928 - mae: 0.3429 - val_loss: 0.0608 - val_mae: 0.2528\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0907 - mae: 0.3289 - val_loss: 0.0608 - val_mae: 0.2527\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1076 - mae: 0.3741 - val_loss: 0.0608 - val_mae: 0.2526\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1039 - mae: 0.3540 - val_loss: 0.0607 - val_mae: 0.2525\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1046 - mae: 0.3739 - val_loss: 0.0607 - val_mae: 0.2523\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0962 - mae: 0.3532 - val_loss: 0.0606 - val_mae: 0.2522\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0845 - mae: 0.3135 - val_loss: 0.0606 - val_mae: 0.2521\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1060 - mae: 0.3724 - val_loss: 0.0605 - val_mae: 0.2520\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0994 - mae: 0.3601 - val_loss: 0.0605 - val_mae: 0.2519\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1027 - mae: 0.3537 - val_loss: 0.0605 - val_mae: 0.2518\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0973 - mae: 0.3389 - val_loss: 0.0604 - val_mae: 0.2517\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0970 - mae: 0.3496 - val_loss: 0.0604 - val_mae: 0.2516\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0873 - mae: 0.3347 - val_loss: 0.0603 - val_mae: 0.2514\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0976 - mae: 0.3526 - val_loss: 0.0603 - val_mae: 0.2513\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1046 - mae: 0.3621 - val_loss: 0.0603 - val_mae: 0.2512\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1020 - mae: 0.3669 - val_loss: 0.0602 - val_mae: 0.2511\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1000 - mae: 0.3623 - val_loss: 0.0602 - val_mae: 0.2510\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1009 - mae: 0.3588 - val_loss: 0.0601 - val_mae: 0.2509\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1034 - mae: 0.3550 - val_loss: 0.0601 - val_mae: 0.2508\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1022 - mae: 0.3584 - val_loss: 0.0600 - val_mae: 0.2507\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0933 - mae: 0.3447 - val_loss: 0.0600 - val_mae: 0.2505\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0789 - mae: 0.3189 - val_loss: 0.0600 - val_mae: 0.2504\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0848 - mae: 0.3149 - val_loss: 0.0599 - val_mae: 0.2503\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1049 - mae: 0.3594 - val_loss: 0.0599 - val_mae: 0.2502\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1044 - mae: 0.3698 - val_loss: 0.0598 - val_mae: 0.2501\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0994 - mae: 0.3418 - val_loss: 0.0598 - val_mae: 0.2500\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1061 - mae: 0.3748 - val_loss: 0.0598 - val_mae: 0.2499\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1093 - mae: 0.3719 - val_loss: 0.0597 - val_mae: 0.2497\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0939 - mae: 0.3453 - val_loss: 0.0597 - val_mae: 0.2496\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0980 - mae: 0.3555 - val_loss: 0.0596 - val_mae: 0.2495\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1052 - mae: 0.3725 - val_loss: 0.0596 - val_mae: 0.2494\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0959 - mae: 0.3467 - val_loss: 0.0596 - val_mae: 0.2493\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0975 - mae: 0.3543 - val_loss: 0.0595 - val_mae: 0.2492\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0894 - mae: 0.3388 - val_loss: 0.0595 - val_mae: 0.2490\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0943 - mae: 0.3431 - val_loss: 0.0594 - val_mae: 0.2489\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0899 - mae: 0.3403 - val_loss: 0.0594 - val_mae: 0.2488\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0967 - mae: 0.3579 - val_loss: 0.0593 - val_mae: 0.2487\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0935 - mae: 0.3407 - val_loss: 0.0593 - val_mae: 0.2486\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1018 - mae: 0.3556 - val_loss: 0.0593 - val_mae: 0.2485\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0913 - mae: 0.3444 - val_loss: 0.0592 - val_mae: 0.2484\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0902 - mae: 0.3377 - val_loss: 0.0592 - val_mae: 0.2483\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0929 - mae: 0.3414 - val_loss: 0.0591 - val_mae: 0.2482\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0888 - mae: 0.3393 - val_loss: 0.0591 - val_mae: 0.2480\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0893 - mae: 0.3324 - val_loss: 0.0591 - val_mae: 0.2479\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1009 - mae: 0.3635 - val_loss: 0.0590 - val_mae: 0.2478\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0904 - mae: 0.3360 - val_loss: 0.0590 - val_mae: 0.2477\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1018 - mae: 0.3609 - val_loss: 0.0589 - val_mae: 0.2476\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0933 - mae: 0.3383 - val_loss: 0.0589 - val_mae: 0.2475\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0919 - mae: 0.3445 - val_loss: 0.0589 - val_mae: 0.2474\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0912 - mae: 0.3327 - val_loss: 0.0588 - val_mae: 0.2473\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0929 - mae: 0.3356 - val_loss: 0.0588 - val_mae: 0.2472\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1003 - mae: 0.3576 - val_loss: 0.0587 - val_mae: 0.2471\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1021 - mae: 0.3616 - val_loss: 0.0587 - val_mae: 0.2469\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0955 - mae: 0.3550 - val_loss: 0.0587 - val_mae: 0.2468\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0937 - mae: 0.3492 - val_loss: 0.0586 - val_mae: 0.2467\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1031 - mae: 0.3615 - val_loss: 0.0586 - val_mae: 0.2466\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0955 - mae: 0.3600 - val_loss: 0.0585 - val_mae: 0.2465\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0858 - mae: 0.3272 - val_loss: 0.0585 - val_mae: 0.2464\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0836 - mae: 0.3205 - val_loss: 0.0585 - val_mae: 0.2463\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0956 - mae: 0.3536 - val_loss: 0.0584 - val_mae: 0.2462\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1033 - mae: 0.3600 - val_loss: 0.0584 - val_mae: 0.2461\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0961 - mae: 0.3424 - val_loss: 0.0583 - val_mae: 0.2459\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1196 - mae: 0.3837 - val_loss: 0.0583 - val_mae: 0.2458\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0837 - mae: 0.3242 - val_loss: 0.0583 - val_mae: 0.2457\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0967 - mae: 0.3460 - val_loss: 0.0582 - val_mae: 0.2456\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0863 - mae: 0.3381 - val_loss: 0.0582 - val_mae: 0.2455\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0979 - mae: 0.3486 - val_loss: 0.0581 - val_mae: 0.2454\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1053 - mae: 0.3598 - val_loss: 0.0581 - val_mae: 0.2453\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0931 - mae: 0.3448 - val_loss: 0.0581 - val_mae: 0.2452\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1033 - mae: 0.3701 - val_loss: 0.0580 - val_mae: 0.2450\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0870 - mae: 0.3314 - val_loss: 0.0580 - val_mae: 0.2449\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1087 - mae: 0.3723 - val_loss: 0.0579 - val_mae: 0.2448\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1067 - mae: 0.3696 - val_loss: 0.0579 - val_mae: 0.2447\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1001 - mae: 0.3543 - val_loss: 0.0579 - val_mae: 0.2446\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0933 - mae: 0.3462 - val_loss: 0.0578 - val_mae: 0.2445\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0862 - mae: 0.3262 - val_loss: 0.0578 - val_mae: 0.2444\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0877 - mae: 0.3315 - val_loss: 0.0577 - val_mae: 0.2443\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0971 - mae: 0.3444 - val_loss: 0.0577 - val_mae: 0.2441\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0986 - mae: 0.3537 - val_loss: 0.0577 - val_mae: 0.2440\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0816 - mae: 0.3270 - val_loss: 0.0576 - val_mae: 0.2439\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1044 - mae: 0.3530 - val_loss: 0.0576 - val_mae: 0.2438\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0912 - mae: 0.3477 - val_loss: 0.0575 - val_mae: 0.2437\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1024 - mae: 0.3627 - val_loss: 0.0575 - val_mae: 0.2436\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0840 - mae: 0.3251 - val_loss: 0.0575 - val_mae: 0.2435\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0995 - mae: 0.3615 - val_loss: 0.0574 - val_mae: 0.2434\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0952 - mae: 0.3510 - val_loss: 0.0574 - val_mae: 0.2433\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0899 - mae: 0.3275 - val_loss: 0.0574 - val_mae: 0.2431\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0896 - mae: 0.3324 - val_loss: 0.0573 - val_mae: 0.2430\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0961 - mae: 0.3505 - val_loss: 0.0573 - val_mae: 0.2429\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0902 - mae: 0.3378 - val_loss: 0.0572 - val_mae: 0.2428\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0942 - mae: 0.3397 - val_loss: 0.0572 - val_mae: 0.2427\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1009 - mae: 0.3541 - val_loss: 0.0572 - val_mae: 0.2426\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0970 - mae: 0.3506 - val_loss: 0.0571 - val_mae: 0.2425\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0911 - mae: 0.3521 - val_loss: 0.0571 - val_mae: 0.2424\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0778 - mae: 0.3200 - val_loss: 0.0571 - val_mae: 0.2423\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0975 - mae: 0.3538 - val_loss: 0.0570 - val_mae: 0.2422\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1081 - mae: 0.3638 - val_loss: 0.0570 - val_mae: 0.2421\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1029 - mae: 0.3784 - val_loss: 0.0569 - val_mae: 0.2420\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0917 - mae: 0.3329 - val_loss: 0.0569 - val_mae: 0.2419\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0876 - mae: 0.3305 - val_loss: 0.0569 - val_mae: 0.2418\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0793 - mae: 0.3095 - val_loss: 0.0568 - val_mae: 0.2416\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0830 - mae: 0.3243 - val_loss: 0.0568 - val_mae: 0.2415\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0927 - mae: 0.3455 - val_loss: 0.0568 - val_mae: 0.2414\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0862 - mae: 0.3409 - val_loss: 0.0567 - val_mae: 0.2413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:22,232] Trial 20 finished with value: 0.24130910634994507 and parameters: {'learning_rate': 5.968499542001252e-07, 'weight_decay': 0.0036264558508236214}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0516 - mae: 0.2516 - val_loss: 0.0242 - val_mae: 0.1230\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0200 - mae: 0.1582 - val_loss: 0.0212 - val_mae: 0.1198\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1553 - val_loss: 0.0198 - val_mae: 0.1068\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0123 - mae: 0.1244 - val_loss: 0.0199 - val_mae: 0.0977\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0090 - mae: 0.1084 - val_loss: 0.0206 - val_mae: 0.0946\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0881 - val_loss: 0.0214 - val_mae: 0.0949\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0062 - mae: 0.0846 - val_loss: 0.0218 - val_mae: 0.0937\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0798 - val_loss: 0.0217 - val_mae: 0.0917\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0212 - val_mae: 0.0900\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0206 - val_mae: 0.0876\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0704 - val_loss: 0.0198 - val_mae: 0.0860\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0190 - val_mae: 0.0853\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0184 - val_mae: 0.0863\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0692 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0668 - val_loss: 0.0177 - val_mae: 0.0885\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0175 - val_mae: 0.0880\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0696 - val_loss: 0.0175 - val_mae: 0.0862\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0177 - val_mae: 0.0835\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0181 - val_mae: 0.0805\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0180 - val_mae: 0.0796\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0177 - val_mae: 0.0792\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0516 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0821\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0594 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0592 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0571 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0515 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0506 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0165 - val_mae: 0.0838\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0517 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0484 - val_loss: 0.0164 - val_mae: 0.0838\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0486 - val_loss: 0.0164 - val_mae: 0.0832\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0164 - val_mae: 0.0829\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0164 - val_mae: 0.0826\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0163 - val_mae: 0.0818\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0164 - val_mae: 0.0807\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0397 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0159 - val_mae: 0.0826\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0158 - val_mae: 0.0844\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0439 - val_loss: 0.0160 - val_mae: 0.0841\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0161 - val_mae: 0.0828\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0403 - val_loss: 0.0163 - val_mae: 0.0816\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0163 - val_mae: 0.0806\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0439 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0163 - val_mae: 0.0799\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0402 - val_loss: 0.0156 - val_mae: 0.0856\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0154 - val_mae: 0.0862\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0155 - val_mae: 0.0836\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0156 - val_mae: 0.0817\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0356 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0402 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0374 - val_loss: 0.0164 - val_mae: 0.0823\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0162 - val_mae: 0.0843\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0161 - val_mae: 0.0855\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0367 - val_loss: 0.0161 - val_mae: 0.0847\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.5705e-04 - mae: 0.0324 - val_loss: 0.0161 - val_mae: 0.0839\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0161 - val_mae: 0.0824\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0384 - val_loss: 0.0162 - val_mae: 0.0822\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.8719e-04 - mae: 0.0337 - val_loss: 0.0162 - val_mae: 0.0819\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0326 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 9.7080e-04 - mae: 0.0335 - val_loss: 0.0162 - val_mae: 0.0811\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1116e-04 - mae: 0.0303 - val_loss: 0.0161 - val_mae: 0.0820\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.7661e-04 - mae: 0.0307 - val_loss: 0.0159 - val_mae: 0.0834\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.6555e-04 - mae: 0.0305 - val_loss: 0.0157 - val_mae: 0.0831\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0156 - val_mae: 0.0816\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.6130e-04 - mae: 0.0344 - val_loss: 0.0158 - val_mae: 0.0785\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3261e-04 - mae: 0.0313 - val_loss: 0.0159 - val_mae: 0.0781\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9674e-04 - mae: 0.0318 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.0720e-04 - mae: 0.0327 - val_loss: 0.0158 - val_mae: 0.0822\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2760e-04 - mae: 0.0323 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9141e-04 - mae: 0.0313 - val_loss: 0.0161 - val_mae: 0.0841\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.2682e-04 - mae: 0.0347 - val_loss: 0.0163 - val_mae: 0.0825\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0164 - val_mae: 0.0805\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0165 - val_mae: 0.0792\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4985e-04 - mae: 0.0330 - val_loss: 0.0164 - val_mae: 0.0789\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7476e-04 - mae: 0.0324 - val_loss: 0.0162 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.2273e-04 - mae: 0.0318 - val_loss: 0.0161 - val_mae: 0.0822\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0161 - val_mae: 0.0821\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1612e-04 - mae: 0.0317 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.6139e-04 - mae: 0.0308 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8987e-04 - mae: 0.0310 - val_loss: 0.0160 - val_mae: 0.0820\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7312e-04 - mae: 0.0311 - val_loss: 0.0159 - val_mae: 0.0816\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.2174e-04 - mae: 0.0313 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.4663e-04 - mae: 0.0295 - val_loss: 0.0160 - val_mae: 0.0781\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0160 - val_mae: 0.0768\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2133e-04 - mae: 0.0309 - val_loss: 0.0159 - val_mae: 0.0762\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.2141e-04 - mae: 0.0302 - val_loss: 0.0158 - val_mae: 0.0762\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5838e-04 - mae: 0.0299 - val_loss: 0.0156 - val_mae: 0.0768\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0336 - val_loss: 0.0156 - val_mae: 0.0787\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6762e-04 - mae: 0.0317 - val_loss: 0.0155 - val_mae: 0.0810\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0054e-04 - mae: 0.0316 - val_loss: 0.0158 - val_mae: 0.0801\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.9737e-04 - mae: 0.0308 - val_loss: 0.0161 - val_mae: 0.0808\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.4885e-04 - mae: 0.0290 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.7589e-04 - mae: 0.0288 - val_loss: 0.0160 - val_mae: 0.0826\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0010 - mae: 0.0339 - val_loss: 0.0162 - val_mae: 0.0811\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 5.9764e-04 - mae: 0.0269 - val_loss: 0.0163 - val_mae: 0.0798\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8857e-04 - mae: 0.0308 - val_loss: 0.0163 - val_mae: 0.0793\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7803e-04 - mae: 0.0304 - val_loss: 0.0160 - val_mae: 0.0796\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.4437e-04 - mae: 0.0309 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5300e-04 - mae: 0.0302 - val_loss: 0.0155 - val_mae: 0.0830\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9149e-04 - mae: 0.0329 - val_loss: 0.0158 - val_mae: 0.0802\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3747e-04 - mae: 0.0280 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1240e-04 - mae: 0.0308 - val_loss: 0.0162 - val_mae: 0.0794\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9085e-04 - mae: 0.0237 - val_loss: 0.0163 - val_mae: 0.0792\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2527e-04 - mae: 0.0269 - val_loss: 0.0164 - val_mae: 0.0791\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.0620e-04 - mae: 0.0286 - val_loss: 0.0163 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7164e-04 - mae: 0.0307 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.2884e-04 - mae: 0.0296 - val_loss: 0.0162 - val_mae: 0.0784\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.1609e-04 - mae: 0.0224 - val_loss: 0.0163 - val_mae: 0.0781\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.6559e-04 - mae: 0.0286 - val_loss: 0.0163 - val_mae: 0.0790\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6485e-04 - mae: 0.0298 - val_loss: 0.0160 - val_mae: 0.0800\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.4134e-04 - mae: 0.0308 - val_loss: 0.0157 - val_mae: 0.0816\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.5383e-04 - mae: 0.0290 - val_loss: 0.0154 - val_mae: 0.0829\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.5917e-04 - mae: 0.0280 - val_loss: 0.0153 - val_mae: 0.0817\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5526e-04 - mae: 0.0294 - val_loss: 0.0154 - val_mae: 0.0785\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3253e-04 - mae: 0.0267 - val_loss: 0.0159 - val_mae: 0.0759\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7792e-04 - mae: 0.0256 - val_loss: 0.0164 - val_mae: 0.0755\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0336 - val_loss: 0.0167 - val_mae: 0.0763\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.2028e-04 - mae: 0.0300 - val_loss: 0.0166 - val_mae: 0.0772\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4694e-04 - mae: 0.0301 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.8613e-04 - mae: 0.0233 - val_loss: 0.0160 - val_mae: 0.0811\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.6533e-04 - mae: 0.0255 - val_loss: 0.0159 - val_mae: 0.0826\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3424e-04 - mae: 0.0263 - val_loss: 0.0159 - val_mae: 0.0829\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.1231e-04 - mae: 0.0309 - val_loss: 0.0160 - val_mae: 0.0822\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.6166e-04 - mae: 0.0235 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3970e-04 - mae: 0.0294 - val_loss: 0.0160 - val_mae: 0.0808\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 5.9396e-04 - mae: 0.0267 - val_loss: 0.0160 - val_mae: 0.0801\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.7616e-04 - mae: 0.0246 - val_loss: 0.0160 - val_mae: 0.0793\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5777e-04 - mae: 0.0263 - val_loss: 0.0159 - val_mae: 0.0787\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.7553e-04 - mae: 0.0258 - val_loss: 0.0158 - val_mae: 0.0784\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.3528e-04 - mae: 0.0291 - val_loss: 0.0157 - val_mae: 0.0788\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0309e-04 - mae: 0.0265 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7669e-04 - mae: 0.0268 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9909e-04 - mae: 0.0258 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4028e-04 - mae: 0.0273 - val_loss: 0.0160 - val_mae: 0.0789\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.0953e-04 - mae: 0.0245 - val_loss: 0.0163 - val_mae: 0.0783\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6856e-04 - mae: 0.0254 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1814e-04 - mae: 0.0278 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4786e-04 - mae: 0.0272 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7578e-04 - mae: 0.0260 - val_loss: 0.0163 - val_mae: 0.0798\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.3497e-04 - mae: 0.0273 - val_loss: 0.0160 - val_mae: 0.0813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:33,101] Trial 21 finished with value: 0.08133960515260696 and parameters: {'learning_rate': 0.001290131162696981, 'weight_decay': 0.002184440556042048}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0706 - mae: 0.2968 - val_loss: 0.4724 - val_mae: 0.8743\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6040 - mae: 1.0225 - val_loss: 0.0346 - val_mae: 0.1771\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0315 - mae: 0.1880 - val_loss: 0.0241 - val_mae: 0.1227\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0120 - mae: 0.1204 - val_loss: 0.0216 - val_mae: 0.1030\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0075 - mae: 0.0974 - val_loss: 0.0193 - val_mae: 0.0921\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0848 - val_loss: 0.0182 - val_mae: 0.0846\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0759 - val_loss: 0.0187 - val_mae: 0.0859\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0840\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0733 - val_loss: 0.0173 - val_mae: 0.0841\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0042 - mae: 0.0669 - val_loss: 0.0182 - val_mae: 0.0837\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0174 - val_mae: 0.0841\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.1005\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0685 - val_loss: 0.0166 - val_mae: 0.0889\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0675 - val_loss: 0.0183 - val_mae: 0.0831\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0183 - val_mae: 0.0833\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0649 - val_loss: 0.0180 - val_mae: 0.0818\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0809\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.1012\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0169 - val_mae: 0.0812\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0173 - val_mae: 0.0846\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0172 - val_mae: 0.0855\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0641 - val_loss: 0.0171 - val_mae: 0.0862\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0650 - val_loss: 0.0171 - val_mae: 0.0869\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0170 - val_mae: 0.0876\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0676 - val_loss: 0.0170 - val_mae: 0.0881\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0888\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0668 - val_loss: 0.0169 - val_mae: 0.0888\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0887\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0884\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0879\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0874\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0643 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0633 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0824\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0825\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:43,867] Trial 22 finished with value: 0.08478368818759918 and parameters: {'learning_rate': 0.007195005360349126, 'weight_decay': 0.007362658734089777}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - mae: 0.4222 - val_loss: 0.0638 - val_mae: 0.2744\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1077 - mae: 0.3700 - val_loss: 0.0602 - val_mae: 0.2662\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0888 - mae: 0.3301 - val_loss: 0.0567 - val_mae: 0.2573\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0984 - mae: 0.3585 - val_loss: 0.0533 - val_mae: 0.2480\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0932 - mae: 0.3491 - val_loss: 0.0501 - val_mae: 0.2386\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0773 - mae: 0.3106 - val_loss: 0.0471 - val_mae: 0.2292\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0769 - mae: 0.3085 - val_loss: 0.0442 - val_mae: 0.2200\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0720 - mae: 0.3047 - val_loss: 0.0416 - val_mae: 0.2114\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0715 - mae: 0.3030 - val_loss: 0.0391 - val_mae: 0.2028\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0830 - mae: 0.3214 - val_loss: 0.0369 - val_mae: 0.1943\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0649 - mae: 0.2856 - val_loss: 0.0349 - val_mae: 0.1865\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0557 - mae: 0.2658 - val_loss: 0.0330 - val_mae: 0.1790\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0770 - mae: 0.3096 - val_loss: 0.0313 - val_mae: 0.1717\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0587 - mae: 0.2744 - val_loss: 0.0297 - val_mae: 0.1647\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0546 - mae: 0.2666 - val_loss: 0.0283 - val_mae: 0.1586\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0515 - mae: 0.2535 - val_loss: 0.0271 - val_mae: 0.1529\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0570 - mae: 0.2679 - val_loss: 0.0260 - val_mae: 0.1477\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0564 - mae: 0.2624 - val_loss: 0.0251 - val_mae: 0.1431\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0556 - mae: 0.2717 - val_loss: 0.0243 - val_mae: 0.1390\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0542 - mae: 0.2635 - val_loss: 0.0236 - val_mae: 0.1351\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0436 - mae: 0.2360 - val_loss: 0.0229 - val_mae: 0.1317\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0519 - mae: 0.2642 - val_loss: 0.0224 - val_mae: 0.1288\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0469 - mae: 0.2470 - val_loss: 0.0219 - val_mae: 0.1265\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0510 - mae: 0.2584 - val_loss: 0.0215 - val_mae: 0.1246\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0408 - mae: 0.2263 - val_loss: 0.0212 - val_mae: 0.1229\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0478 - mae: 0.2488 - val_loss: 0.0209 - val_mae: 0.1214\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0422 - mae: 0.2288 - val_loss: 0.0206 - val_mae: 0.1199\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0442 - mae: 0.2243 - val_loss: 0.0204 - val_mae: 0.1186\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0407 - mae: 0.2249 - val_loss: 0.0203 - val_mae: 0.1176\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0377 - mae: 0.2194 - val_loss: 0.0201 - val_mae: 0.1168\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0449 - mae: 0.2422 - val_loss: 0.0200 - val_mae: 0.1158\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0409 - mae: 0.2291 - val_loss: 0.0199 - val_mae: 0.1148\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0403 - mae: 0.2237 - val_loss: 0.0198 - val_mae: 0.1138\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0405 - mae: 0.2246 - val_loss: 0.0197 - val_mae: 0.1128\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0502 - mae: 0.2527 - val_loss: 0.0197 - val_mae: 0.1119\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0439 - mae: 0.2401 - val_loss: 0.0196 - val_mae: 0.1110\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0414 - mae: 0.2223 - val_loss: 0.0195 - val_mae: 0.1102\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0332 - mae: 0.2029 - val_loss: 0.0195 - val_mae: 0.1095\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0464 - mae: 0.2368 - val_loss: 0.0194 - val_mae: 0.1091\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0348 - mae: 0.2127 - val_loss: 0.0194 - val_mae: 0.1087\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0404 - mae: 0.2226 - val_loss: 0.0194 - val_mae: 0.1082\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0426 - mae: 0.2373 - val_loss: 0.0194 - val_mae: 0.1079\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0381 - mae: 0.2260 - val_loss: 0.0193 - val_mae: 0.1076\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0414 - mae: 0.2241 - val_loss: 0.0193 - val_mae: 0.1075\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0406 - mae: 0.2164 - val_loss: 0.0193 - val_mae: 0.1073\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0376 - mae: 0.2216 - val_loss: 0.0192 - val_mae: 0.1070\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0368 - mae: 0.2166 - val_loss: 0.0192 - val_mae: 0.1067\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0372 - mae: 0.2222 - val_loss: 0.0191 - val_mae: 0.1065\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0250 - mae: 0.1748 - val_loss: 0.0191 - val_mae: 0.1064\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0318 - mae: 0.2073 - val_loss: 0.0191 - val_mae: 0.1063\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0290 - mae: 0.1963 - val_loss: 0.0191 - val_mae: 0.1061\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0364 - mae: 0.2182 - val_loss: 0.0191 - val_mae: 0.1059\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0388 - mae: 0.2197 - val_loss: 0.0190 - val_mae: 0.1055\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0319 - mae: 0.1942 - val_loss: 0.0190 - val_mae: 0.1052\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0267 - mae: 0.1787 - val_loss: 0.0189 - val_mae: 0.1047\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0286 - mae: 0.1894 - val_loss: 0.0189 - val_mae: 0.1043\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0383 - mae: 0.2205 - val_loss: 0.0188 - val_mae: 0.1038\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0306 - mae: 0.1985 - val_loss: 0.0188 - val_mae: 0.1033\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0313 - mae: 0.2000 - val_loss: 0.0188 - val_mae: 0.1028\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0328 - mae: 0.1991 - val_loss: 0.0187 - val_mae: 0.1023\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0325 - mae: 0.2067 - val_loss: 0.0187 - val_mae: 0.1018\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0288 - mae: 0.1925 - val_loss: 0.0186 - val_mae: 0.1013\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0318 - mae: 0.2064 - val_loss: 0.0186 - val_mae: 0.1007\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0302 - mae: 0.1946 - val_loss: 0.0185 - val_mae: 0.1002\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0276 - mae: 0.1885 - val_loss: 0.0184 - val_mae: 0.0997\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0249 - mae: 0.1807 - val_loss: 0.0184 - val_mae: 0.0993\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0275 - mae: 0.1905 - val_loss: 0.0183 - val_mae: 0.0989\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0346 - mae: 0.2067 - val_loss: 0.0183 - val_mae: 0.0986\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0277 - mae: 0.1892 - val_loss: 0.0182 - val_mae: 0.0983\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0319 - mae: 0.2009 - val_loss: 0.0182 - val_mae: 0.0982\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0305 - mae: 0.1981 - val_loss: 0.0182 - val_mae: 0.0980\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0271 - mae: 0.1767 - val_loss: 0.0182 - val_mae: 0.0980\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0267 - mae: 0.1825 - val_loss: 0.0181 - val_mae: 0.0980\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0321 - mae: 0.2043 - val_loss: 0.0181 - val_mae: 0.0980\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0216 - mae: 0.1696 - val_loss: 0.0180 - val_mae: 0.0980\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0306 - mae: 0.1880 - val_loss: 0.0180 - val_mae: 0.0980\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0294 - mae: 0.1888 - val_loss: 0.0179 - val_mae: 0.0979\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0227 - mae: 0.1662 - val_loss: 0.0179 - val_mae: 0.0979\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0304 - mae: 0.1945 - val_loss: 0.0179 - val_mae: 0.0980\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0320 - mae: 0.1999 - val_loss: 0.0179 - val_mae: 0.0981\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0283 - mae: 0.1907 - val_loss: 0.0178 - val_mae: 0.0983\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0292 - mae: 0.1953 - val_loss: 0.0178 - val_mae: 0.0984\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0239 - mae: 0.1792 - val_loss: 0.0178 - val_mae: 0.0984\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0262 - mae: 0.1865 - val_loss: 0.0178 - val_mae: 0.0985\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0243 - mae: 0.1761 - val_loss: 0.0178 - val_mae: 0.0987\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0236 - mae: 0.1723 - val_loss: 0.0178 - val_mae: 0.0987\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0278 - mae: 0.1885 - val_loss: 0.0178 - val_mae: 0.0988\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0266 - mae: 0.1848 - val_loss: 0.0178 - val_mae: 0.0988\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0247 - mae: 0.1768 - val_loss: 0.0178 - val_mae: 0.0987\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0248 - mae: 0.1769 - val_loss: 0.0178 - val_mae: 0.0985\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0200 - mae: 0.1614 - val_loss: 0.0178 - val_mae: 0.0983\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0215 - mae: 0.1616 - val_loss: 0.0178 - val_mae: 0.0980\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0243 - mae: 0.1704 - val_loss: 0.0178 - val_mae: 0.0978\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0248 - mae: 0.1711 - val_loss: 0.0178 - val_mae: 0.0976\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0284 - mae: 0.1863 - val_loss: 0.0178 - val_mae: 0.0975\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0220 - mae: 0.1645 - val_loss: 0.0178 - val_mae: 0.0973\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0229 - mae: 0.1714 - val_loss: 0.0178 - val_mae: 0.0973\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0260 - mae: 0.1829 - val_loss: 0.0178 - val_mae: 0.0972\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0246 - mae: 0.1815 - val_loss: 0.0178 - val_mae: 0.0972\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0248 - mae: 0.1758 - val_loss: 0.0178 - val_mae: 0.0972\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0243 - mae: 0.1708 - val_loss: 0.0178 - val_mae: 0.0971\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0233 - mae: 0.1762 - val_loss: 0.0178 - val_mae: 0.0969\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0215 - mae: 0.1622 - val_loss: 0.0179 - val_mae: 0.0969\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0201 - mae: 0.1591 - val_loss: 0.0179 - val_mae: 0.0969\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0237 - mae: 0.1719 - val_loss: 0.0179 - val_mae: 0.0969\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0230 - mae: 0.1681 - val_loss: 0.0179 - val_mae: 0.0969\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0192 - mae: 0.1539 - val_loss: 0.0179 - val_mae: 0.0969\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0257 - mae: 0.1799 - val_loss: 0.0180 - val_mae: 0.0969\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0193 - mae: 0.1612 - val_loss: 0.0180 - val_mae: 0.0970\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0211 - mae: 0.1654 - val_loss: 0.0180 - val_mae: 0.0970\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0183 - mae: 0.1499 - val_loss: 0.0180 - val_mae: 0.0971\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0214 - mae: 0.1622 - val_loss: 0.0181 - val_mae: 0.0971\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0270 - mae: 0.1846 - val_loss: 0.0181 - val_mae: 0.0971\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0191 - mae: 0.1515 - val_loss: 0.0181 - val_mae: 0.0970\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0201 - mae: 0.1646 - val_loss: 0.0181 - val_mae: 0.0970\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0207 - mae: 0.1640 - val_loss: 0.0181 - val_mae: 0.0969\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0224 - mae: 0.1724 - val_loss: 0.0182 - val_mae: 0.0967\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0210 - mae: 0.1714 - val_loss: 0.0181 - val_mae: 0.0966\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0169 - mae: 0.1474 - val_loss: 0.0181 - val_mae: 0.0964\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0192 - mae: 0.1552 - val_loss: 0.0182 - val_mae: 0.0964\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0186 - mae: 0.1567 - val_loss: 0.0182 - val_mae: 0.0963\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0232 - mae: 0.1715 - val_loss: 0.0182 - val_mae: 0.0961\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0188 - mae: 0.1535 - val_loss: 0.0182 - val_mae: 0.0959\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0199 - mae: 0.1562 - val_loss: 0.0182 - val_mae: 0.0958\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0194 - mae: 0.1534 - val_loss: 0.0182 - val_mae: 0.0955\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0216 - mae: 0.1637 - val_loss: 0.0182 - val_mae: 0.0953\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0176 - mae: 0.1507 - val_loss: 0.0182 - val_mae: 0.0950\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0167 - mae: 0.1433 - val_loss: 0.0181 - val_mae: 0.0948\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0184 - mae: 0.1495 - val_loss: 0.0181 - val_mae: 0.0946\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0186 - mae: 0.1492 - val_loss: 0.0181 - val_mae: 0.0945\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0156 - mae: 0.1419 - val_loss: 0.0181 - val_mae: 0.0944\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0164 - mae: 0.1454 - val_loss: 0.0181 - val_mae: 0.0944\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0176 - mae: 0.1503 - val_loss: 0.0181 - val_mae: 0.0944\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0183 - mae: 0.1519 - val_loss: 0.0181 - val_mae: 0.0942\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0179 - mae: 0.1478 - val_loss: 0.0181 - val_mae: 0.0940\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0189 - mae: 0.1537 - val_loss: 0.0180 - val_mae: 0.0939\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0187 - mae: 0.1461 - val_loss: 0.0180 - val_mae: 0.0936\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0169 - mae: 0.1473 - val_loss: 0.0179 - val_mae: 0.0934\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0156 - mae: 0.1464 - val_loss: 0.0179 - val_mae: 0.0932\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0149 - mae: 0.1416 - val_loss: 0.0179 - val_mae: 0.0931\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0167 - mae: 0.1430 - val_loss: 0.0179 - val_mae: 0.0931\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0149 - mae: 0.1393 - val_loss: 0.0178 - val_mae: 0.0931\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0156 - mae: 0.1406 - val_loss: 0.0178 - val_mae: 0.0930\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0140 - mae: 0.1283 - val_loss: 0.0178 - val_mae: 0.0930\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0168 - mae: 0.1512 - val_loss: 0.0178 - val_mae: 0.0930\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0186 - mae: 0.1541 - val_loss: 0.0177 - val_mae: 0.0931\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0162 - mae: 0.1426 - val_loss: 0.0177 - val_mae: 0.0932\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0146 - mae: 0.1357 - val_loss: 0.0177 - val_mae: 0.0933\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0166 - mae: 0.1444 - val_loss: 0.0177 - val_mae: 0.0934\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0155 - mae: 0.1407 - val_loss: 0.0177 - val_mae: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:34:55,479] Trial 23 finished with value: 0.09347110986709595 and parameters: {'learning_rate': 3.905946130178398e-05, 'weight_decay': 0.00013702850497814004}. Best is trial 3 with value: 0.07329216599464417.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0877 - mae: 0.3187 - val_loss: 0.0447 - val_mae: 0.2217\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0547 - mae: 0.2648 - val_loss: 0.0331 - val_mae: 0.1829\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0459 - mae: 0.2473 - val_loss: 0.0270 - val_mae: 0.1513\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0389 - mae: 0.2152 - val_loss: 0.0243 - val_mae: 0.1332\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0360 - mae: 0.2151 - val_loss: 0.0236 - val_mae: 0.1301\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0304 - mae: 0.1959 - val_loss: 0.0237 - val_mae: 0.1304\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0314 - mae: 0.1992 - val_loss: 0.0240 - val_mae: 0.1306\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0296 - mae: 0.1966 - val_loss: 0.0240 - val_mae: 0.1298\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0304 - mae: 0.1950 - val_loss: 0.0239 - val_mae: 0.1265\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0241 - mae: 0.1758 - val_loss: 0.0237 - val_mae: 0.1231\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0207 - mae: 0.1561 - val_loss: 0.0237 - val_mae: 0.1199\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0185 - mae: 0.1489 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0146 - mae: 0.1375 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0133 - mae: 0.1307 - val_loss: 0.0241 - val_mae: 0.1166\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0154 - mae: 0.1353 - val_loss: 0.0240 - val_mae: 0.1162\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0157 - mae: 0.1406 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0133 - mae: 0.1297 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0132 - mae: 0.1262 - val_loss: 0.0235 - val_mae: 0.1147\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0232 - val_mae: 0.1135\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0107 - mae: 0.1192 - val_loss: 0.0228 - val_mae: 0.1120\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0110 - mae: 0.1181 - val_loss: 0.0225 - val_mae: 0.1103\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0091 - mae: 0.1054 - val_loss: 0.0222 - val_mae: 0.1087\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - mae: 0.1016 - val_loss: 0.0219 - val_mae: 0.1072\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0968 - val_loss: 0.0216 - val_mae: 0.1059\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0084 - mae: 0.1032 - val_loss: 0.0214 - val_mae: 0.1045\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.1032\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0070 - mae: 0.0915 - val_loss: 0.0210 - val_mae: 0.1020\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0064 - mae: 0.0878 - val_loss: 0.0208 - val_mae: 0.1008\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - mae: 0.0923 - val_loss: 0.0207 - val_mae: 0.0995\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0059 - mae: 0.0828 - val_loss: 0.0205 - val_mae: 0.0982\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0860 - val_loss: 0.0204 - val_mae: 0.0970\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - mae: 0.0855 - val_loss: 0.0202 - val_mae: 0.0958\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - mae: 0.0841 - val_loss: 0.0201 - val_mae: 0.0948\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0053 - mae: 0.0789 - val_loss: 0.0200 - val_mae: 0.0940\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0199 - val_mae: 0.0932\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0784 - val_loss: 0.0199 - val_mae: 0.0926\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0051 - mae: 0.0771 - val_loss: 0.0198 - val_mae: 0.0920\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0046 - mae: 0.0723 - val_loss: 0.0197 - val_mae: 0.0914\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - mae: 0.0785 - val_loss: 0.0196 - val_mae: 0.0909\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0763 - val_loss: 0.0196 - val_mae: 0.0905\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0775 - val_loss: 0.0196 - val_mae: 0.0901\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0737 - val_loss: 0.0195 - val_mae: 0.0899\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0195 - val_mae: 0.0898\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0729 - val_loss: 0.0195 - val_mae: 0.0896\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - mae: 0.0714 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - mae: 0.0710 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0744 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0652 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - mae: 0.0684 - val_loss: 0.0194 - val_mae: 0.0897\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0700 - val_loss: 0.0194 - val_mae: 0.0898\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - mae: 0.0698 - val_loss: 0.0194 - val_mae: 0.0899\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0037 - mae: 0.0649 - val_loss: 0.0194 - val_mae: 0.0901\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0194 - val_mae: 0.0902\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0194 - val_mae: 0.0904\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0194 - val_mae: 0.0904\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0193 - val_mae: 0.0904\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0193 - val_mae: 0.0902\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0643 - val_loss: 0.0192 - val_mae: 0.0900\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0658 - val_loss: 0.0192 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0657 - val_loss: 0.0192 - val_mae: 0.0899\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0654 - val_loss: 0.0192 - val_mae: 0.0898\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0632 - val_loss: 0.0192 - val_mae: 0.0897\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0191 - val_mae: 0.0897\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0191 - val_mae: 0.0898\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0650 - val_loss: 0.0191 - val_mae: 0.0899\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0191 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0659 - val_loss: 0.0190 - val_mae: 0.0901\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0190 - val_mae: 0.0902\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0190 - val_mae: 0.0903\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0190 - val_mae: 0.0905\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0190 - val_mae: 0.0905\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0190 - val_mae: 0.0906\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0189 - val_mae: 0.0907\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0189 - val_mae: 0.0908\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0573 - val_loss: 0.0189 - val_mae: 0.0910\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0189 - val_mae: 0.0911\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0189 - val_mae: 0.0912\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0189 - val_mae: 0.0912\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0519 - val_loss: 0.0189 - val_mae: 0.0912\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0190 - val_mae: 0.0912\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0541 - val_loss: 0.0189 - val_mae: 0.0914\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0188 - val_mae: 0.0914\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0555 - val_loss: 0.0188 - val_mae: 0.0913\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0188 - val_mae: 0.0911\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0551 - val_loss: 0.0188 - val_mae: 0.0909\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0187 - val_mae: 0.0908\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0026 - mae: 0.0573 - val_loss: 0.0187 - val_mae: 0.0908\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0187 - val_mae: 0.0909\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0544 - val_loss: 0.0187 - val_mae: 0.0909\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0187 - val_mae: 0.0909\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0532 - val_loss: 0.0188 - val_mae: 0.0909\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0188 - val_mae: 0.0910\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0530 - val_loss: 0.0188 - val_mae: 0.0910\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0500 - val_loss: 0.0188 - val_mae: 0.0911\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0188 - val_mae: 0.0912\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0188 - val_mae: 0.0913\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0507 - val_loss: 0.0188 - val_mae: 0.0914\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0188 - val_mae: 0.0917\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0187 - val_mae: 0.0920\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0186 - val_mae: 0.0924\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0496 - val_loss: 0.0186 - val_mae: 0.0928\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0522 - val_loss: 0.0185 - val_mae: 0.0932\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - mae: 0.0492 - val_loss: 0.0185 - val_mae: 0.0935\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0512 - val_loss: 0.0184 - val_mae: 0.0938\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0463 - val_loss: 0.0184 - val_mae: 0.0940\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0479 - val_loss: 0.0184 - val_mae: 0.0940\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0523 - val_loss: 0.0185 - val_mae: 0.0940\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0536 - val_loss: 0.0185 - val_mae: 0.0939\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0474 - val_loss: 0.0186 - val_mae: 0.0937\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0186 - val_mae: 0.0935\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0495 - val_loss: 0.0187 - val_mae: 0.0932\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0517 - val_loss: 0.0187 - val_mae: 0.0931\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0187 - val_mae: 0.0929\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0187 - val_mae: 0.0927\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0512 - val_loss: 0.0187 - val_mae: 0.0926\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0505 - val_loss: 0.0187 - val_mae: 0.0925\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0019 - mae: 0.0463 - val_loss: 0.0187 - val_mae: 0.0925\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0187 - val_mae: 0.0925\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - mae: 0.0435 - val_loss: 0.0186 - val_mae: 0.0925\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0186 - val_mae: 0.0923\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0186 - val_mae: 0.0921\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0186 - val_mae: 0.0920\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0185 - val_mae: 0.0918\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0185 - val_mae: 0.0917\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0020 - mae: 0.0486 - val_loss: 0.0185 - val_mae: 0.0918\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0476 - val_loss: 0.0185 - val_mae: 0.0919\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0185 - val_mae: 0.0922\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0185 - val_mae: 0.0923\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0184 - val_mae: 0.0925\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0505 - val_loss: 0.0184 - val_mae: 0.0927\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0451 - val_loss: 0.0184 - val_mae: 0.0928\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0184 - val_mae: 0.0928\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0431 - val_loss: 0.0184 - val_mae: 0.0930\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0184 - val_mae: 0.0931\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0184 - val_mae: 0.0932\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0184 - val_mae: 0.0933\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0499 - val_loss: 0.0184 - val_mae: 0.0935\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0446 - val_loss: 0.0184 - val_mae: 0.0935\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0478 - val_loss: 0.0185 - val_mae: 0.0935\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0442 - val_loss: 0.0185 - val_mae: 0.0933\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0444 - val_loss: 0.0186 - val_mae: 0.0931\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0187 - val_mae: 0.0929\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0187 - val_mae: 0.0927\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0187 - val_mae: 0.0926\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0187 - val_mae: 0.0926\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0186 - val_mae: 0.0926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:35:06,598] Trial 24 finished with value: 0.09263557195663452 and parameters: {'learning_rate': 0.00031021409395484326, 'weight_decay': 1.9045653144947546e-08}. Best is trial 3 with value: 0.07329216599464417.\n",
      "[I 2023-12-05 09:35:06,639] A new study created in RDB with name: no-name-93b92d85-edc8-4874-91d6-c54414ef2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0240 - val_mae: 0.1150\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1120\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0976 - val_loss: 0.0233 - val_mae: 0.1105\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1089\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1071\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0226 - val_mae: 0.1053\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.1036\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0219 - val_mae: 0.1000\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0878 - val_loss: 0.0217 - val_mae: 0.0982\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0825 - val_loss: 0.0214 - val_mae: 0.0965\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0828 - val_loss: 0.0212 - val_mae: 0.0949\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0209 - val_mae: 0.0933\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0061 - mae: 0.0791 - val_loss: 0.0207 - val_mae: 0.0919\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0752 - val_loss: 0.0204 - val_mae: 0.0905\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0744 - val_loss: 0.0202 - val_mae: 0.0892\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0780 - val_loss: 0.0199 - val_mae: 0.0880\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0197 - val_mae: 0.0871\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0054 - mae: 0.0719 - val_loss: 0.0195 - val_mae: 0.0863\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0193 - val_mae: 0.0856\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0852\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0189 - val_mae: 0.0850\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0717 - val_loss: 0.0187 - val_mae: 0.0847\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0738 - val_loss: 0.0186 - val_mae: 0.0845\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0737 - val_loss: 0.0185 - val_mae: 0.0841\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0704 - val_loss: 0.0184 - val_mae: 0.0837\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0731 - val_loss: 0.0183 - val_mae: 0.0832\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0721 - val_loss: 0.0182 - val_mae: 0.0825\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0729 - val_loss: 0.0182 - val_mae: 0.0818\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0181 - val_mae: 0.0811\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0695 - val_loss: 0.0181 - val_mae: 0.0805\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0716 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0181 - val_mae: 0.0787\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0180 - val_mae: 0.0777\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0047 - mae: 0.0708 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0691 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0572 - val_loss: 0.0177 - val_mae: 0.0768\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0642 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0681 - val_loss: 0.0174 - val_mae: 0.0760\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0760\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0583 - val_loss: 0.0174 - val_mae: 0.0760\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0768\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0775\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0540 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0777\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0777\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0043 - mae: 0.0686 - val_loss: 0.0167 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0777\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0776\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0765\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0764\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0763\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0167 - val_mae: 0.0763\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0763\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0763\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0166 - val_mae: 0.0763\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0762\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0165 - val_mae: 0.0760\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0756\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0552 - val_loss: 0.0168 - val_mae: 0.0753\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0169 - val_mae: 0.0751\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0169 - val_mae: 0.0748\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0746\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0517 - val_loss: 0.0170 - val_mae: 0.0746\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0512 - val_loss: 0.0168 - val_mae: 0.0747\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0749\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0512 - val_loss: 0.0163 - val_mae: 0.0752\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0164 - val_mae: 0.0751\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0166 - val_mae: 0.0749\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0167 - val_mae: 0.0749\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0169 - val_mae: 0.0748\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0169 - val_mae: 0.0747\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0747\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0169 - val_mae: 0.0749\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0168 - val_mae: 0.0751\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0752\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0165 - val_mae: 0.0755\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0164 - val_mae: 0.0757\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0164 - val_mae: 0.0757\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0552 - val_loss: 0.0165 - val_mae: 0.0756\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0166 - val_mae: 0.0754\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0166 - val_mae: 0.0752\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0167 - val_mae: 0.0750\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0023 - mae: 0.0488 - val_loss: 0.0167 - val_mae: 0.0747\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0168 - val_mae: 0.0745\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0169 - val_mae: 0.0744\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0170 - val_mae: 0.0744\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0169 - val_mae: 0.0743\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0168 - val_mae: 0.0743\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0027 - mae: 0.0504 - val_loss: 0.0167 - val_mae: 0.0743\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0511 - val_loss: 0.0166 - val_mae: 0.0743\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0165 - val_mae: 0.0743\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0506 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0471 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0510 - val_loss: 0.0167 - val_mae: 0.0742\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0741\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0168 - val_mae: 0.0741\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0169 - val_mae: 0.0740\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0486 - val_loss: 0.0168 - val_mae: 0.0741\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0167 - val_mae: 0.0742\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0165 - val_mae: 0.0743\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0163 - val_mae: 0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:35:25,311] Trial 0 finished with value: 0.0744893029332161 and parameters: {'learning_rate': 0.0003264183501476943, 'weight_decay': 2.7989232480664057e-06}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1074 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1072 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0249 - val_mae: 0.1206\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1051 - val_loss: 0.0249 - val_mae: 0.1206\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1206\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0249 - val_mae: 0.1206\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1206\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1114 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1030 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1048 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1037 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1068 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1037 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1024 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1030 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1186\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1016 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1021 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0092 - mae: 0.1018 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1180\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0246 - val_mae: 0.1180\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0246 - val_mae: 0.1180\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0246 - val_mae: 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:35:43,881] Trial 1 finished with value: 0.11798563599586487 and parameters: {'learning_rate': 2.8086497476806e-06, 'weight_decay': 1.1362466592398505e-07}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1064 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0242 - val_mae: 0.1187\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1035 - val_loss: 0.0242 - val_mae: 0.1187\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0099 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1186\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1058 - val_loss: 0.0242 - val_mae: 0.1186\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0242 - val_mae: 0.1186\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0096 - mae: 0.1056 - val_loss: 0.0242 - val_mae: 0.1185\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0092 - mae: 0.1019 - val_loss: 0.0242 - val_mae: 0.1185\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.1185\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0242 - val_mae: 0.1184\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1077 - val_loss: 0.0242 - val_mae: 0.1184\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1184\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1072 - val_loss: 0.0242 - val_mae: 0.1183\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0242 - val_mae: 0.1183\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1183\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1057 - val_loss: 0.0242 - val_mae: 0.1182\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0102 - mae: 0.1094 - val_loss: 0.0242 - val_mae: 0.1182\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1182\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1056 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1052 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - mae: 0.1091 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0241 - val_mae: 0.1179\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1179\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1179\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0102 - mae: 0.1087 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0241 - val_mae: 0.1177\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1177\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0241 - val_mae: 0.1177\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1052 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0098 - mae: 0.1061 - val_loss: 0.0241 - val_mae: 0.1175\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1052 - val_loss: 0.0241 - val_mae: 0.1175\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1175\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1174\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0241 - val_mae: 0.1174\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1174\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1173\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0241 - val_mae: 0.1173\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0241 - val_mae: 0.1173\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0241 - val_mae: 0.1173\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1172\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0240 - val_mae: 0.1172\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1172\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0240 - val_mae: 0.1171\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0240 - val_mae: 0.1171\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0240 - val_mae: 0.1171\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1041 - val_loss: 0.0240 - val_mae: 0.1171\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0240 - val_mae: 0.1170\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0240 - val_mae: 0.1170\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1170\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0240 - val_mae: 0.1168\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0240 - val_mae: 0.1168\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0240 - val_mae: 0.1168\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0240 - val_mae: 0.1168\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1036 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1076 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1064 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1041 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0094 - mae: 0.1037 - val_loss: 0.0240 - val_mae: 0.1165\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1034 - val_loss: 0.0240 - val_mae: 0.1165\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0240 - val_mae: 0.1165\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1165\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0239 - val_mae: 0.1164\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0239 - val_mae: 0.1164\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1045 - val_loss: 0.0239 - val_mae: 0.1164\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1163\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1163\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0239 - val_mae: 0.1163\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0098 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1163\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1162\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0239 - val_mae: 0.1162\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1162\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1159\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1159\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1159\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1158\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1158\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0239 - val_mae: 0.1158\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1158\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1157\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0096 - mae: 0.1038 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0094 - mae: 0.1034 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0096 - mae: 0.1031 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1028 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1023 - val_loss: 0.0238 - val_mae: 0.1153\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1017 - val_loss: 0.0238 - val_mae: 0.1153\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0238 - val_mae: 0.1153\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0238 - val_mae: 0.1153\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1152\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1152\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0238 - val_mae: 0.1152\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1027 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1150\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1053 - val_loss: 0.0238 - val_mae: 0.1150\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1150\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1150\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1146\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0237 - val_mae: 0.1146\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1146\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1146\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:36:02,369] Trial 2 finished with value: 0.11442635953426361 and parameters: {'learning_rate': 5.066425145176763e-06, 'weight_decay': 0.0023890174222242363}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0819 - val_mae: 0.3541\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1031 - mae: 0.3780 - val_loss: 0.0207 - val_mae: 0.0936\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0236 - val_mae: 0.1092\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0969 - val_loss: 0.0233 - val_mae: 0.1041\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0074 - mae: 0.0908 - val_loss: 0.0221 - val_mae: 0.0947\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0205 - val_mae: 0.0913\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0192 - val_mae: 0.0932\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0051 - mae: 0.0772 - val_loss: 0.0187 - val_mae: 0.0924\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0049 - mae: 0.0733 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0700 - val_loss: 0.0180 - val_mae: 0.0893\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0044 - mae: 0.0702 - val_loss: 0.0178 - val_mae: 0.0869\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0854\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0046 - mae: 0.0708 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0659 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0666 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0531 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0858\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0860\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0855\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0870\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0607 - val_loss: 0.0165 - val_mae: 0.0870\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:36:20,820] Trial 3 finished with value: 0.08517197519540787 and parameters: {'learning_rate': 0.024023614571229392, 'weight_decay': 3.743686992432697e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0110 - mae: 0.1157 - val_loss: 0.0260 - val_mae: 0.1302\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111 - mae: 0.1179 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0114 - mae: 0.1211 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0111 - mae: 0.1156 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0115 - mae: 0.1214 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0118 - mae: 0.1210 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0117 - mae: 0.1199 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0113 - mae: 0.1176 - val_loss: 0.0260 - val_mae: 0.1301\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0112 - mae: 0.1182 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0113 - mae: 0.1172 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0111 - mae: 0.1177 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0115 - mae: 0.1203 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0110 - mae: 0.1171 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0115 - mae: 0.1184 - val_loss: 0.0260 - val_mae: 0.1300\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1116 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111 - mae: 0.1178 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0112 - mae: 0.1167 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0109 - mae: 0.1169 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1149 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0112 - mae: 0.1175 - val_loss: 0.0259 - val_mae: 0.1299\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0114 - mae: 0.1214 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0114 - mae: 0.1208 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0110 - mae: 0.1191 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0110 - mae: 0.1167 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - mae: 0.1133 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0114 - mae: 0.1196 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0114 - mae: 0.1181 - val_loss: 0.0259 - val_mae: 0.1298\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0116 - mae: 0.1205 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0115 - mae: 0.1198 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0114 - mae: 0.1195 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0109 - mae: 0.1169 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0110 - mae: 0.1165 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0115 - mae: 0.1195 - val_loss: 0.0259 - val_mae: 0.1297\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0112 - mae: 0.1160 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0111 - mae: 0.1165 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0111 - mae: 0.1184 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0114 - mae: 0.1194 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0111 - mae: 0.1183 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0112 - mae: 0.1172 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - mae: 0.1176 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0114 - mae: 0.1171 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1156 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0116 - mae: 0.1206 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0259 - val_mae: 0.1295\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0113 - mae: 0.1183 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - mae: 0.1170 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111 - mae: 0.1187 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0119 - mae: 0.1208 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0111 - mae: 0.1187 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0119 - mae: 0.1216 - val_loss: 0.0259 - val_mae: 0.1293\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - mae: 0.1164 - val_loss: 0.0258 - val_mae: 0.1293\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1151 - val_loss: 0.0258 - val_mae: 0.1293\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0112 - mae: 0.1172 - val_loss: 0.0258 - val_mae: 0.1293\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0116 - mae: 0.1201 - val_loss: 0.0258 - val_mae: 0.1293\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1147 - val_loss: 0.0258 - val_mae: 0.1293\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0113 - mae: 0.1194 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0118 - mae: 0.1210 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1164 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0115 - mae: 0.1182 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0111 - mae: 0.1175 - val_loss: 0.0258 - val_mae: 0.1292\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0109 - mae: 0.1168 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1131 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0114 - mae: 0.1196 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0108 - mae: 0.1168 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0113 - mae: 0.1191 - val_loss: 0.0258 - val_mae: 0.1291\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1176 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0114 - mae: 0.1180 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0108 - mae: 0.1148 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0108 - mae: 0.1153 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0116 - mae: 0.1200 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0111 - mae: 0.1172 - val_loss: 0.0258 - val_mae: 0.1290\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1161 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0109 - mae: 0.1146 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1152 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1136 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0116 - mae: 0.1212 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0258 - val_mae: 0.1289\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1137 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1144 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0113 - mae: 0.1175 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0114 - mae: 0.1205 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - mae: 0.1145 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0105 - mae: 0.1145 - val_loss: 0.0258 - val_mae: 0.1288\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0112 - mae: 0.1186 - val_loss: 0.0258 - val_mae: 0.1287\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - mae: 0.1152 - val_loss: 0.0258 - val_mae: 0.1287\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0112 - mae: 0.1170 - val_loss: 0.0258 - val_mae: 0.1287\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0110 - mae: 0.1180 - val_loss: 0.0257 - val_mae: 0.1287\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1151 - val_loss: 0.0257 - val_mae: 0.1287\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0113 - mae: 0.1165 - val_loss: 0.0257 - val_mae: 0.1287\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0115 - mae: 0.1189 - val_loss: 0.0257 - val_mae: 0.1287\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0114 - mae: 0.1194 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0109 - mae: 0.1145 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0114 - mae: 0.1178 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0112 - mae: 0.1175 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0113 - mae: 0.1194 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0113 - mae: 0.1176 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0111 - mae: 0.1172 - val_loss: 0.0257 - val_mae: 0.1286\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111 - mae: 0.1174 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0120 - mae: 0.1230 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1126 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0109 - mae: 0.1176 - val_loss: 0.0257 - val_mae: 0.1285\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1144 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1152 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0110 - mae: 0.1159 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - mae: 0.1167 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1153 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0116 - mae: 0.1209 - val_loss: 0.0257 - val_mae: 0.1284\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0111 - mae: 0.1155 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - mae: 0.1158 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0106 - mae: 0.1153 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1151 - val_loss: 0.0257 - val_mae: 0.1283\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108 - mae: 0.1147 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0116 - mae: 0.1193 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0109 - mae: 0.1151 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0114 - mae: 0.1206 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0113 - mae: 0.1196 - val_loss: 0.0257 - val_mae: 0.1282\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0257 - val_mae: 0.1281\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1172 - val_loss: 0.0257 - val_mae: 0.1281\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - mae: 0.1154 - val_loss: 0.0257 - val_mae: 0.1281\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0114 - mae: 0.1197 - val_loss: 0.0257 - val_mae: 0.1281\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0120 - mae: 0.1220 - val_loss: 0.0256 - val_mae: 0.1281\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0256 - val_mae: 0.1281\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0107 - mae: 0.1148 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0112 - mae: 0.1193 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0111 - mae: 0.1159 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0112 - mae: 0.1177 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0112 - mae: 0.1181 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0112 - mae: 0.1177 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0111 - mae: 0.1151 - val_loss: 0.0256 - val_mae: 0.1280\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1151 - val_loss: 0.0256 - val_mae: 0.1279\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0110 - mae: 0.1172 - val_loss: 0.0256 - val_mae: 0.1279\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1143 - val_loss: 0.0256 - val_mae: 0.1279\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0108 - mae: 0.1171 - val_loss: 0.0256 - val_mae: 0.1279\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0113 - mae: 0.1174 - val_loss: 0.0256 - val_mae: 0.1279\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1167 - val_loss: 0.0256 - val_mae: 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:36:40,035] Trial 4 finished with value: 0.1278599202632904 and parameters: {'learning_rate': 1.8132330219161598e-06, 'weight_decay': 0.004410165416048513}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1080 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1072 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1085 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1064 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1068 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1093 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1092 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1091 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1090 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1090 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1108 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1071 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:36:58,649] Trial 5 finished with value: 0.11982330679893494 and parameters: {'learning_rate': 4.491518324381263e-07, 'weight_decay': 2.9235515189362754e-06}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0232 - val_mae: 0.1129\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0232 - val_mae: 0.1124\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0973 - val_loss: 0.0231 - val_mae: 0.1119\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0231 - val_mae: 0.1114\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0230 - val_mae: 0.1109\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0979 - val_loss: 0.0230 - val_mae: 0.1104\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0229 - val_mae: 0.1099\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0229 - val_mae: 0.1094\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0228 - val_mae: 0.1088\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0228 - val_mae: 0.1083\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0227 - val_mae: 0.1078\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0227 - val_mae: 0.1073\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0226 - val_mae: 0.1068\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0226 - val_mae: 0.1064\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0225 - val_mae: 0.1059\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0225 - val_mae: 0.1055\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0929 - val_loss: 0.0225 - val_mae: 0.1050\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0224 - val_mae: 0.1045\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0224 - val_mae: 0.1041\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0223 - val_mae: 0.1036\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0223 - val_mae: 0.1032\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0941 - val_loss: 0.0222 - val_mae: 0.1027\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.1023\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0222 - val_mae: 0.1019\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0898 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0221 - val_mae: 0.1012\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0220 - val_mae: 0.1008\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0220 - val_mae: 0.1004\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.1000\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0218 - val_mae: 0.0993\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0218 - val_mae: 0.0989\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0865 - val_loss: 0.0217 - val_mae: 0.0985\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0217 - val_mae: 0.0978\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0855 - val_loss: 0.0216 - val_mae: 0.0974\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0840 - val_loss: 0.0216 - val_mae: 0.0970\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0865 - val_loss: 0.0215 - val_mae: 0.0966\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0826 - val_loss: 0.0215 - val_mae: 0.0962\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0839 - val_loss: 0.0214 - val_mae: 0.0959\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0848 - val_loss: 0.0214 - val_mae: 0.0955\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0213 - val_mae: 0.0951\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0822 - val_loss: 0.0213 - val_mae: 0.0948\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0812 - val_loss: 0.0212 - val_mae: 0.0944\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0941\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0212 - val_mae: 0.0937\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0828 - val_loss: 0.0211 - val_mae: 0.0934\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0931\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0828 - val_loss: 0.0210 - val_mae: 0.0927\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0210 - val_mae: 0.0924\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0791 - val_loss: 0.0209 - val_mae: 0.0921\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0918\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0209 - val_mae: 0.0915\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0787 - val_loss: 0.0208 - val_mae: 0.0912\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0799 - val_loss: 0.0208 - val_mae: 0.0908\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0067 - mae: 0.0810 - val_loss: 0.0207 - val_mae: 0.0905\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0207 - val_mae: 0.0902\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0206 - val_mae: 0.0900\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0777 - val_loss: 0.0206 - val_mae: 0.0897\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0779 - val_loss: 0.0206 - val_mae: 0.0894\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0205 - val_mae: 0.0891\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0800 - val_loss: 0.0205 - val_mae: 0.0888\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0064 - mae: 0.0797 - val_loss: 0.0204 - val_mae: 0.0885\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0766 - val_loss: 0.0204 - val_mae: 0.0882\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0736 - val_loss: 0.0203 - val_mae: 0.0880\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0778 - val_loss: 0.0203 - val_mae: 0.0877\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0728 - val_loss: 0.0203 - val_mae: 0.0874\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0202 - val_mae: 0.0871\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0202 - val_mae: 0.0868\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0865\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0201 - val_mae: 0.0862\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0054 - mae: 0.0740 - val_loss: 0.0201 - val_mae: 0.0859\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0056 - mae: 0.0737 - val_loss: 0.0200 - val_mae: 0.0856\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0755 - val_loss: 0.0200 - val_mae: 0.0854\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0727 - val_loss: 0.0199 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0055 - mae: 0.0734 - val_loss: 0.0199 - val_mae: 0.0849\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0735 - val_loss: 0.0199 - val_mae: 0.0847\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0738 - val_loss: 0.0198 - val_mae: 0.0845\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0198 - val_mae: 0.0842\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0743 - val_loss: 0.0198 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0057 - mae: 0.0771 - val_loss: 0.0197 - val_mae: 0.0838\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0754 - val_loss: 0.0197 - val_mae: 0.0836\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0742 - val_loss: 0.0197 - val_mae: 0.0834\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0715 - val_loss: 0.0196 - val_mae: 0.0832\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0720 - val_loss: 0.0196 - val_mae: 0.0831\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0735 - val_loss: 0.0195 - val_mae: 0.0828\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0738 - val_loss: 0.0195 - val_mae: 0.0826\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0680 - val_loss: 0.0195 - val_mae: 0.0825\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0194 - val_mae: 0.0823\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - mae: 0.0711 - val_loss: 0.0194 - val_mae: 0.0822\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0715 - val_loss: 0.0194 - val_mae: 0.0820\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0714 - val_loss: 0.0193 - val_mae: 0.0819\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0193 - val_mae: 0.0817\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0193 - val_mae: 0.0815\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0056 - mae: 0.0741 - val_loss: 0.0192 - val_mae: 0.0814\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0673 - val_loss: 0.0192 - val_mae: 0.0812\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0047 - mae: 0.0713 - val_loss: 0.0192 - val_mae: 0.0811\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0809\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0737 - val_loss: 0.0191 - val_mae: 0.0808\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0191 - val_mae: 0.0807\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0190 - val_mae: 0.0804\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0752 - val_loss: 0.0190 - val_mae: 0.0803\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0190 - val_mae: 0.0802\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0190 - val_mae: 0.0800\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0708 - val_loss: 0.0189 - val_mae: 0.0799\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0048 - mae: 0.0687 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0717 - val_loss: 0.0189 - val_mae: 0.0797\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0772 - val_loss: 0.0188 - val_mae: 0.0796\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0188 - val_mae: 0.0795\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0188 - val_mae: 0.0794\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0658 - val_loss: 0.0188 - val_mae: 0.0793\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0660 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0187 - val_mae: 0.0791\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0659 - val_loss: 0.0186 - val_mae: 0.0789\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0054 - mae: 0.0725 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0678 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0186 - val_mae: 0.0786\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0186 - val_mae: 0.0785\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0185 - val_mae: 0.0785\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0697 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0728 - val_loss: 0.0185 - val_mae: 0.0783\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0651 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0049 - mae: 0.0710 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0740 - val_loss: 0.0185 - val_mae: 0.0781\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0184 - val_mae: 0.0781\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0053 - mae: 0.0735 - val_loss: 0.0184 - val_mae: 0.0780\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0779\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0779\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0184 - val_mae: 0.0778\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0184 - val_mae: 0.0777\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0681 - val_loss: 0.0184 - val_mae: 0.0777\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0667 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0627 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0677 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0706 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0183 - val_mae: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:37:17,334] Trial 6 finished with value: 0.07733727246522903 and parameters: {'learning_rate': 7.293664818899196e-05, 'weight_decay': 0.004092888573650144}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1005 - val_loss: 0.0212 - val_mae: 0.0909\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0186 - val_mae: 0.0842\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0169 - val_mae: 0.0930\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0802 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - mae: 0.0660 - val_loss: 0.0171 - val_mae: 0.0799\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0171 - val_mae: 0.0855\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0865\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0860\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0535 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0171 - val_mae: 0.0802\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0547 - val_loss: 0.0171 - val_mae: 0.0797\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0173 - val_mae: 0.0810\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0641 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0540 - val_loss: 0.0180 - val_mae: 0.0777\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0538 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0529 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0542 - val_loss: 0.0176 - val_mae: 0.0786\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0533 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0835\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0848\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0583 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0480 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0177 - val_mae: 0.0781\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0530 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0484 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0453 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0026 - mae: 0.0512 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0477 - val_loss: 0.0177 - val_mae: 0.0826\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0178 - val_mae: 0.0831\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0179 - val_mae: 0.0831\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0179 - val_mae: 0.0832\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0179 - val_mae: 0.0827\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0022 - mae: 0.0467 - val_loss: 0.0178 - val_mae: 0.0830\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0180 - val_mae: 0.0818\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0180 - val_mae: 0.0814\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0527 - val_loss: 0.0178 - val_mae: 0.0812\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - mae: 0.0499 - val_loss: 0.0177 - val_mae: 0.0811\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0175 - val_mae: 0.0813\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0180 - val_mae: 0.0822\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0180 - val_mae: 0.0821\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0179 - val_mae: 0.0820\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0052 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0819\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0180 - val_mae: 0.0819\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0549 - val_loss: 0.0177 - val_mae: 0.0814\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0542 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0539 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0549 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0842\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0876\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0167 - val_mae: 0.0887\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0878\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0553 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0542 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0028 - mae: 0.0565 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0027 - mae: 0.0518 - val_loss: 0.0179 - val_mae: 0.0817\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0180 - val_mae: 0.0809\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0461 - val_loss: 0.0181 - val_mae: 0.0804\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0533 - val_loss: 0.0180 - val_mae: 0.0798\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - mae: 0.0494 - val_loss: 0.0179 - val_mae: 0.0795\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0178 - val_mae: 0.0796\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0434 - val_loss: 0.0177 - val_mae: 0.0799\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0176 - val_mae: 0.0807\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0445 - val_loss: 0.0176 - val_mae: 0.0811\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - mae: 0.0444 - val_loss: 0.0177 - val_mae: 0.0815\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0481 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0179 - val_mae: 0.0831\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0179 - val_mae: 0.0835\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0021 - mae: 0.0472 - val_loss: 0.0179 - val_mae: 0.0834\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0472 - val_loss: 0.0178 - val_mae: 0.0833\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0434 - val_loss: 0.0177 - val_mae: 0.0830\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0176 - val_mae: 0.0821\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0471 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0021 - mae: 0.0451 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0414 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0435 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0176 - val_mae: 0.0831\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0177 - val_mae: 0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:37:35,829] Trial 7 finished with value: 0.08339422196149826 and parameters: {'learning_rate': 0.007827988977219228, 'weight_decay': 0.0013969117271237447}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0101 - mae: 0.1092 - val_loss: 0.0252 - val_mae: 0.1209\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1183\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1171\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1027 - val_loss: 0.0243 - val_mae: 0.1159\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1135\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0238 - val_mae: 0.1123\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0987 - val_loss: 0.0236 - val_mae: 0.1112\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0974 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0232 - val_mae: 0.1082\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0080 - mae: 0.0937 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0228 - val_mae: 0.1052\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1033\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0222 - val_mae: 0.1012\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0221 - val_mae: 0.1002\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0982\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0836 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0215 - val_mae: 0.0961\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0951\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0213 - val_mae: 0.0940\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0773 - val_loss: 0.0211 - val_mae: 0.0928\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0817 - val_loss: 0.0210 - val_mae: 0.0917\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - mae: 0.0802 - val_loss: 0.0208 - val_mae: 0.0905\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0737 - val_loss: 0.0207 - val_mae: 0.0894\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0059 - mae: 0.0737 - val_loss: 0.0206 - val_mae: 0.0883\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0777 - val_loss: 0.0204 - val_mae: 0.0873\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0059 - mae: 0.0728 - val_loss: 0.0203 - val_mae: 0.0863\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0059 - mae: 0.0738 - val_loss: 0.0201 - val_mae: 0.0853\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0200 - val_mae: 0.0845\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0717 - val_loss: 0.0198 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0056 - mae: 0.0731 - val_loss: 0.0197 - val_mae: 0.0830\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0705 - val_loss: 0.0195 - val_mae: 0.0824\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0194 - val_mae: 0.0819\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0693 - val_loss: 0.0193 - val_mae: 0.0814\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0191 - val_mae: 0.0811\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0051 - mae: 0.0690 - val_loss: 0.0190 - val_mae: 0.0808\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0051 - mae: 0.0689 - val_loss: 0.0188 - val_mae: 0.0806\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0691 - val_loss: 0.0185 - val_mae: 0.0801\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0184 - val_mae: 0.0799\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0650 - val_loss: 0.0183 - val_mae: 0.0797\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - mae: 0.0659 - val_loss: 0.0180 - val_mae: 0.0791\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0179 - val_mae: 0.0789\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0678 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - mae: 0.0687 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0637 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0039 - mae: 0.0613 - val_loss: 0.0175 - val_mae: 0.0762\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0609 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0600 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0628 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0171 - val_mae: 0.0764\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0765\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0042 - mae: 0.0670 - val_loss: 0.0171 - val_mae: 0.0766\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0041 - mae: 0.0656 - val_loss: 0.0171 - val_mae: 0.0766\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0768\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0775\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0673 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0545 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0038 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0790\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0563 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0547 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0029 - mae: 0.0536 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0541 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0515 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:37:54,435] Trial 8 finished with value: 0.07821660488843918 and parameters: {'learning_rate': 0.00028329718427034834, 'weight_decay': 0.0016356097893293286}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0253 - val_mae: 0.1228\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.0253 - val_mae: 0.1228\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1102 - val_loss: 0.0253 - val_mae: 0.1227\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0253 - val_mae: 0.1227\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0253 - val_mae: 0.1227\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1227\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0253 - val_mae: 0.1226\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1089 - val_loss: 0.0253 - val_mae: 0.1226\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0253 - val_mae: 0.1226\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0253 - val_mae: 0.1225\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0253 - val_mae: 0.1225\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0252 - val_mae: 0.1225\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0252 - val_mae: 0.1224\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0252 - val_mae: 0.1224\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0252 - val_mae: 0.1224\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0252 - val_mae: 0.1223\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0252 - val_mae: 0.1223\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0104 - mae: 0.1123 - val_loss: 0.0252 - val_mae: 0.1223\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1223\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0252 - val_mae: 0.1222\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0252 - val_mae: 0.1222\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0252 - val_mae: 0.1222\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0252 - val_mae: 0.1221\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0252 - val_mae: 0.1221\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1221\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0252 - val_mae: 0.1220\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1220\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0252 - val_mae: 0.1220\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0252 - val_mae: 0.1220\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0252 - val_mae: 0.1219\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0252 - val_mae: 0.1219\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0252 - val_mae: 0.1219\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1095 - val_loss: 0.0251 - val_mae: 0.1218\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0251 - val_mae: 0.1218\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0251 - val_mae: 0.1218\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0251 - val_mae: 0.1217\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0251 - val_mae: 0.1217\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0251 - val_mae: 0.1217\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0251 - val_mae: 0.1217\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0251 - val_mae: 0.1216\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0251 - val_mae: 0.1216\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1086 - val_loss: 0.0251 - val_mae: 0.1216\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1080 - val_loss: 0.0251 - val_mae: 0.1215\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0251 - val_mae: 0.1215\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0251 - val_mae: 0.1215\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0251 - val_mae: 0.1215\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0251 - val_mae: 0.1214\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0251 - val_mae: 0.1214\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1214\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0251 - val_mae: 0.1213\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1213\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0251 - val_mae: 0.1213\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0251 - val_mae: 0.1213\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0251 - val_mae: 0.1212\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0251 - val_mae: 0.1212\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0250 - val_mae: 0.1212\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0250 - val_mae: 0.1210\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0095 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1210\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0250 - val_mae: 0.1210\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0250 - val_mae: 0.1210\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1209\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1209\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0250 - val_mae: 0.1209\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1106 - val_loss: 0.0250 - val_mae: 0.1206\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0250 - val_mae: 0.1206\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1094 - val_loss: 0.0250 - val_mae: 0.1206\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0250 - val_mae: 0.1205\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1205\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1061 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0249 - val_mae: 0.1202\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1079 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1079 - val_loss: 0.0249 - val_mae: 0.1199\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1199\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0249 - val_mae: 0.1199\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1199\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0248 - val_mae: 0.1195\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0094 - mae: 0.1078 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1192\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1192\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0248 - val_mae: 0.1192\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1192\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0092 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:38:13,623] Trial 9 finished with value: 0.11869499832391739 and parameters: {'learning_rate': 5.381566757425559e-06, 'weight_decay': 0.004207337745827954}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0118 - mae: 0.1220 - val_loss: 0.0261 - val_mae: 0.1327\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0110 - mae: 0.1203 - val_loss: 0.0259 - val_mae: 0.1312\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0117 - mae: 0.1223 - val_loss: 0.0256 - val_mae: 0.1297\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0115 - mae: 0.1220 - val_loss: 0.0254 - val_mae: 0.1281\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0252 - val_mae: 0.1266\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1155 - val_loss: 0.0250 - val_mae: 0.1252\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0248 - val_mae: 0.1238\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1225\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1212\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0243 - val_mae: 0.1199\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0242 - val_mae: 0.1187\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1075 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1165\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1143\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0235 - val_mae: 0.1133\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0992 - val_loss: 0.0234 - val_mae: 0.1123\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0084 - mae: 0.0989 - val_loss: 0.0233 - val_mae: 0.1113\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0231 - val_mae: 0.1094\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0230 - val_mae: 0.1085\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0229 - val_mae: 0.1075\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1066\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0227 - val_mae: 0.1057\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.1029\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0222 - val_mae: 0.1019\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.1010\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0220 - val_mae: 0.1001\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0218 - val_mae: 0.0983\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0847 - val_loss: 0.0217 - val_mae: 0.0974\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0216 - val_mae: 0.0966\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0858 - val_loss: 0.0215 - val_mae: 0.0957\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0829 - val_loss: 0.0214 - val_mae: 0.0949\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0212 - val_mae: 0.0941\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0211 - val_mae: 0.0933\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0925\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0209 - val_mae: 0.0916\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0208 - val_mae: 0.0908\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064 - mae: 0.0771 - val_loss: 0.0206 - val_mae: 0.0899\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0205 - val_mae: 0.0892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0803 - val_loss: 0.0204 - val_mae: 0.0886\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0061 - mae: 0.0782 - val_loss: 0.0203 - val_mae: 0.0879\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0201 - val_mae: 0.0873\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0786 - val_loss: 0.0200 - val_mae: 0.0866\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0763 - val_loss: 0.0199 - val_mae: 0.0858\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0198 - val_mae: 0.0852\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0734 - val_loss: 0.0196 - val_mae: 0.0846\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0712 - val_loss: 0.0195 - val_mae: 0.0841\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0057 - mae: 0.0727 - val_loss: 0.0194 - val_mae: 0.0836\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0744 - val_loss: 0.0193 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0827\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0730 - val_loss: 0.0190 - val_mae: 0.0822\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0189 - val_mae: 0.0818\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0055 - mae: 0.0746 - val_loss: 0.0188 - val_mae: 0.0813\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0742 - val_loss: 0.0187 - val_mae: 0.0809\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0055 - mae: 0.0729 - val_loss: 0.0186 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0727 - val_loss: 0.0185 - val_mae: 0.0804\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0184 - val_mae: 0.0803\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0706 - val_loss: 0.0183 - val_mae: 0.0802\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0671 - val_loss: 0.0182 - val_mae: 0.0801\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0733 - val_loss: 0.0181 - val_mae: 0.0800\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - mae: 0.0695 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0680 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0683 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0179 - val_mae: 0.0777\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0048 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0683 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0177 - val_mae: 0.0768\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0649 - val_loss: 0.0177 - val_mae: 0.0768\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0768\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0683 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0175 - val_mae: 0.0769\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0682 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0774\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0652 - val_loss: 0.0174 - val_mae: 0.0774\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0174 - val_mae: 0.0774\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0174 - val_mae: 0.0774\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0649 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0772\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0594 - val_loss: 0.0173 - val_mae: 0.0772\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0172 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0172 - val_mae: 0.0778\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0046 - mae: 0.0687 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0784\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0777\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0042 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0775\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0775\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0169 - val_mae: 0.0783\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0785\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0663 - val_loss: 0.0168 - val_mae: 0.0787\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0784\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:38:32,217] Trial 10 finished with value: 0.07866042852401733 and parameters: {'learning_rate': 0.00019219700663581239, 'weight_decay': 1.1107285196588993e-06}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0250 - val_mae: 0.1224\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1210\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0092 - mae: 0.1026 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0235 - val_mae: 0.1110\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0948 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0079 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.1039\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0906 - val_loss: 0.0225 - val_mae: 0.1027\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0874 - val_loss: 0.0223 - val_mae: 0.1015\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071 - mae: 0.0866 - val_loss: 0.0222 - val_mae: 0.1002\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0872 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0850 - val_loss: 0.0219 - val_mae: 0.0976\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0217 - val_mae: 0.0963\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0215 - val_mae: 0.0950\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0862 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0212 - val_mae: 0.0924\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0210 - val_mae: 0.0911\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0792 - val_loss: 0.0209 - val_mae: 0.0899\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - mae: 0.0805 - val_loss: 0.0207 - val_mae: 0.0889\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0065 - mae: 0.0806 - val_loss: 0.0205 - val_mae: 0.0879\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0058 - mae: 0.0758 - val_loss: 0.0202 - val_mae: 0.0861\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0059 - mae: 0.0744 - val_loss: 0.0200 - val_mae: 0.0852\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0753 - val_loss: 0.0198 - val_mae: 0.0844\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0755 - val_loss: 0.0196 - val_mae: 0.0837\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0057 - mae: 0.0744 - val_loss: 0.0195 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0752 - val_loss: 0.0193 - val_mae: 0.0825\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0749 - val_loss: 0.0191 - val_mae: 0.0821\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0729 - val_loss: 0.0190 - val_mae: 0.0817\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - mae: 0.0747 - val_loss: 0.0188 - val_mae: 0.0814\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0186 - val_mae: 0.0812\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0051 - mae: 0.0728 - val_loss: 0.0185 - val_mae: 0.0810\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0184 - val_mae: 0.0808\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0181 - val_mae: 0.0805\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0722 - val_loss: 0.0181 - val_mae: 0.0802\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0051 - mae: 0.0732 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0796\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0675 - val_loss: 0.0178 - val_mae: 0.0788\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0668 - val_loss: 0.0178 - val_mae: 0.0786\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0783\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - mae: 0.0754 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0176 - val_mae: 0.0774\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0598 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0175 - val_mae: 0.0768\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0622 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0766\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0047 - mae: 0.0690 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0671 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0170 - val_mae: 0.0762\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0170 - val_mae: 0.0763\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0763\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0763\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0169 - val_mae: 0.0763\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0764\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0765\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0767\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0647 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0040 - mae: 0.0651 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0775\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0776\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0777\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0778\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0653 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0778\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0782\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0167 - val_mae: 0.0782\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0785\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0787\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0788\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0788\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0788\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0788\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0787\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0168 - val_mae: 0.0787\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0521 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0791\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0167 - val_mae: 0.0793\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:38:50,854] Trial 11 finished with value: 0.0793561264872551 and parameters: {'learning_rate': 0.0002610828750363698, 'weight_decay': 0.00012780337017771005}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0088 - mae: 0.1010 - val_loss: 0.0225 - val_mae: 0.1056\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0214 - val_mae: 0.0966\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0836 - val_loss: 0.0200 - val_mae: 0.0879\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0787 - val_loss: 0.0186 - val_mae: 0.0829\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0177 - val_mae: 0.0811\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0699 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0661 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0681 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0672 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0728 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0042 - mae: 0.0683 - val_loss: 0.0175 - val_mae: 0.0786\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0177 - val_mae: 0.0786\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0172 - val_mae: 0.0813\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0810\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0552 - val_loss: 0.0173 - val_mae: 0.0810\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0530 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0518 - val_loss: 0.0165 - val_mae: 0.0859\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0165 - val_mae: 0.0863\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0164 - val_mae: 0.0870\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0166 - val_mae: 0.0850\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0163 - val_mae: 0.0841\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0510 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0178 - val_mae: 0.0794\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0517 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0463 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0158 - val_mae: 0.0822\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0519 - val_loss: 0.0160 - val_mae: 0.0830\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0480 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0455 - val_loss: 0.0177 - val_mae: 0.0842\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0177 - val_mae: 0.0842\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0423 - val_loss: 0.0176 - val_mae: 0.0846\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - mae: 0.0444 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0172 - val_mae: 0.0862\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0173 - val_mae: 0.0872\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0174 - val_mae: 0.0877\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.0173 - val_mae: 0.0867\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0858\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0173 - val_mae: 0.0846\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - mae: 0.0395 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0177 - val_mae: 0.0858\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0179 - val_mae: 0.0866\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0016 - mae: 0.0407 - val_loss: 0.0180 - val_mae: 0.0880\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0179 - val_mae: 0.0888\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0344 - val_loss: 0.0178 - val_mae: 0.0896\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0176 - val_mae: 0.0909\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0179 - val_mae: 0.0916\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0181 - val_mae: 0.0902\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0183 - val_mae: 0.0894\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - mae: 0.0398 - val_loss: 0.0184 - val_mae: 0.0896\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0184 - val_mae: 0.0901\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0430 - val_loss: 0.0185 - val_mae: 0.0913\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0187 - val_mae: 0.0938\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0188 - val_mae: 0.0962\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0010 - mae: 0.0336 - val_loss: 0.0190 - val_mae: 0.0983\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0186 - val_mae: 0.0968\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0012 - mae: 0.0386 - val_loss: 0.0181 - val_mae: 0.0938\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0179 - val_mae: 0.0913\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 0.0181 - val_mae: 0.0914\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0184 - val_mae: 0.0926\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0188 - val_mae: 0.0939\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - mae: 0.0323 - val_loss: 0.0190 - val_mae: 0.0945\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0010 - mae: 0.0340 - val_loss: 0.0190 - val_mae: 0.0940\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0190 - val_mae: 0.0938\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 0.0189 - val_mae: 0.0934\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 9.6522e-04 - mae: 0.0299 - val_loss: 0.0187 - val_mae: 0.0933\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 9.3638e-04 - mae: 0.0313 - val_loss: 0.0187 - val_mae: 0.0941\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 9.1331e-04 - mae: 0.0309 - val_loss: 0.0187 - val_mae: 0.0949\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.6165e-04 - mae: 0.0327 - val_loss: 0.0188 - val_mae: 0.0965\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0189 - val_mae: 0.0976\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0010 - mae: 0.0337 - val_loss: 0.0192 - val_mae: 0.0986\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 0.0194 - val_mae: 0.0993\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0195 - val_mae: 0.0993\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0196 - val_mae: 0.0990\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0444 - val_loss: 0.0189 - val_mae: 0.0941\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.6960e-04 - mae: 0.0336 - val_loss: 0.0186 - val_mae: 0.0914\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 8.8356e-04 - mae: 0.0311 - val_loss: 0.0186 - val_mae: 0.0906\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0356 - val_loss: 0.0184 - val_mae: 0.0890\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0185 - val_mae: 0.0885\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - mae: 0.0347 - val_loss: 0.0186 - val_mae: 0.0893\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.4757e-04 - mae: 0.0302 - val_loss: 0.0186 - val_mae: 0.0893\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0323 - val_loss: 0.0187 - val_mae: 0.0908\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0010 - mae: 0.0323 - val_loss: 0.0188 - val_mae: 0.0928\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.7124e-04 - mae: 0.0292 - val_loss: 0.0187 - val_mae: 0.0935\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0010 - mae: 0.0312 - val_loss: 0.0186 - val_mae: 0.0943\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.8494e-04 - mae: 0.0336 - val_loss: 0.0184 - val_mae: 0.0941\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0010 - mae: 0.0323 - val_loss: 0.0182 - val_mae: 0.0926\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.6044e-04 - mae: 0.0321 - val_loss: 0.0180 - val_mae: 0.0916\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0181 - val_mae: 0.0913\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0382 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0183 - val_mae: 0.0900\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0012 - mae: 0.0330 - val_loss: 0.0183 - val_mae: 0.0898\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 9.9163e-04 - mae: 0.0335 - val_loss: 0.0184 - val_mae: 0.0903\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 8.3695e-04 - mae: 0.0292 - val_loss: 0.0185 - val_mae: 0.0913\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.4677e-04 - mae: 0.0296 - val_loss: 0.0186 - val_mae: 0.0923\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 0.0187 - val_mae: 0.0931\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.5017e-04 - mae: 0.0304 - val_loss: 0.0187 - val_mae: 0.0938\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.6270e-04 - mae: 0.0285 - val_loss: 0.0188 - val_mae: 0.0945\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 7.0056e-04 - mae: 0.0278 - val_loss: 0.0189 - val_mae: 0.0954\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 9.9258e-04 - mae: 0.0325 - val_loss: 0.0186 - val_mae: 0.0933\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 9.0000e-04 - mae: 0.0297 - val_loss: 0.0184 - val_mae: 0.0911\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 7.9842e-04 - mae: 0.0296 - val_loss: 0.0183 - val_mae: 0.0892\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.8537e-04 - mae: 0.0274 - val_loss: 0.0182 - val_mae: 0.0881\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.0601e-04 - mae: 0.0262 - val_loss: 0.0181 - val_mae: 0.0874\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.9554e-04 - mae: 0.0291 - val_loss: 0.0182 - val_mae: 0.0875\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.4202e-04 - mae: 0.0292 - val_loss: 0.0182 - val_mae: 0.0884\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.5021e-04 - mae: 0.0261 - val_loss: 0.0183 - val_mae: 0.0893\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 7.3040e-04 - mae: 0.0284 - val_loss: 0.0184 - val_mae: 0.0911\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.3875e-04 - mae: 0.0271 - val_loss: 0.0184 - val_mae: 0.0915\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 6.8586e-04 - mae: 0.0273 - val_loss: 0.0183 - val_mae: 0.0911\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.0631e-04 - mae: 0.0320 - val_loss: 0.0182 - val_mae: 0.0910\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 9.1909e-04 - mae: 0.0303 - val_loss: 0.0181 - val_mae: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:39:09,408] Trial 12 finished with value: 0.09124823659658432 and parameters: {'learning_rate': 0.002080685798700524, 'weight_decay': 6.855343535906866e-06}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0240 - val_mae: 0.1163\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1162\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0240 - val_mae: 0.1160\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0240 - val_mae: 0.1158\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1156\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0239 - val_mae: 0.1155\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0239 - val_mae: 0.1153\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0239 - val_mae: 0.1151\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1149\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0238 - val_mae: 0.1147\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0998 - val_loss: 0.0238 - val_mae: 0.1145\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0238 - val_mae: 0.1143\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0238 - val_mae: 0.1141\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1137\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1133\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0979 - val_loss: 0.0237 - val_mae: 0.1131\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1129\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0236 - val_mae: 0.1127\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0236 - val_mae: 0.1125\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0236 - val_mae: 0.1123\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1119\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0235 - val_mae: 0.1115\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1113\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0234 - val_mae: 0.1111\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0234 - val_mae: 0.1107\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1105\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0233 - val_mae: 0.1103\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0967 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0950 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0081 - mae: 0.0951 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0079 - mae: 0.0925 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0928 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0934 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0906 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0904 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0942 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0228 - val_mae: 0.1057\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0909 - val_loss: 0.0228 - val_mae: 0.1051\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0228 - val_mae: 0.1049\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0082 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1039\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0226 - val_mae: 0.1035\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0226 - val_mae: 0.1033\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0078 - mae: 0.0904 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0225 - val_mae: 0.1027\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0225 - val_mae: 0.1025\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0225 - val_mae: 0.1022\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1020\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0224 - val_mae: 0.1018\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0865 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0075 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1013\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1009\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0874 - val_loss: 0.0223 - val_mae: 0.1006\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0859 - val_loss: 0.0223 - val_mae: 0.1004\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.1002\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0884 - val_loss: 0.0222 - val_mae: 0.0999\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0860 - val_loss: 0.0222 - val_mae: 0.0997\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.0995\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0221 - val_mae: 0.0992\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0078 - mae: 0.0889 - val_loss: 0.0221 - val_mae: 0.0990\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0221 - val_mae: 0.0988\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0073 - mae: 0.0865 - val_loss: 0.0220 - val_mae: 0.0985\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0220 - val_mae: 0.0983\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0220 - val_mae: 0.0981\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0220 - val_mae: 0.0978\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0219 - val_mae: 0.0976\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0219 - val_mae: 0.0974\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0857 - val_loss: 0.0219 - val_mae: 0.0972\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0219 - val_mae: 0.0969\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0866 - val_loss: 0.0218 - val_mae: 0.0967\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0218 - val_mae: 0.0965\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0846 - val_loss: 0.0218 - val_mae: 0.0962\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0217 - val_mae: 0.0960\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0850 - val_loss: 0.0217 - val_mae: 0.0958\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0072 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0956\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0843 - val_loss: 0.0216 - val_mae: 0.0954\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0070 - mae: 0.0833 - val_loss: 0.0216 - val_mae: 0.0952\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0841 - val_loss: 0.0216 - val_mae: 0.0949\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0070 - mae: 0.0822 - val_loss: 0.0216 - val_mae: 0.0947\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0067 - mae: 0.0819 - val_loss: 0.0215 - val_mae: 0.0945\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0067 - mae: 0.0828 - val_loss: 0.0215 - val_mae: 0.0943\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0829 - val_loss: 0.0215 - val_mae: 0.0941\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0214 - val_mae: 0.0939\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0827 - val_loss: 0.0214 - val_mae: 0.0935\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0803 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0213 - val_mae: 0.0930\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0213 - val_mae: 0.0928\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0807 - val_loss: 0.0212 - val_mae: 0.0926\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0820 - val_loss: 0.0212 - val_mae: 0.0924\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0817 - val_loss: 0.0212 - val_mae: 0.0922\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0920\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0211 - val_mae: 0.0918\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0211 - val_mae: 0.0913\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - mae: 0.0793 - val_loss: 0.0210 - val_mae: 0.0911\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0771 - val_loss: 0.0210 - val_mae: 0.0909\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0210 - val_mae: 0.0907\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0798 - val_loss: 0.0209 - val_mae: 0.0905\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0209 - val_mae: 0.0903\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0209 - val_mae: 0.0901\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0794 - val_loss: 0.0208 - val_mae: 0.0899\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0208 - val_mae: 0.0895\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0065 - mae: 0.0786 - val_loss: 0.0207 - val_mae: 0.0893\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0207 - val_mae: 0.0891\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0207 - val_mae: 0.0889\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0821 - val_loss: 0.0207 - val_mae: 0.0887\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0206 - val_mae: 0.0886\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0062 - mae: 0.0778 - val_loss: 0.0206 - val_mae: 0.0884\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - mae: 0.0769 - val_loss: 0.0206 - val_mae: 0.0882\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0205 - val_mae: 0.0880\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0205 - val_mae: 0.0878\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064 - mae: 0.0769 - val_loss: 0.0205 - val_mae: 0.0876\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0204 - val_mae: 0.0874\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.0873\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0059 - mae: 0.0725 - val_loss: 0.0204 - val_mae: 0.0871\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0204 - val_mae: 0.0869\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0788 - val_loss: 0.0203 - val_mae: 0.0865\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0059 - mae: 0.0738 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0748 - val_loss: 0.0202 - val_mae: 0.0860\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0202 - val_mae: 0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:39:27,994] Trial 13 finished with value: 0.08585833013057709 and parameters: {'learning_rate': 2.9990856785015154e-05, 'weight_decay': 1.4913001502053045e-05}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1149\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1128\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1083\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0080 - mae: 0.0937 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0223 - val_mae: 0.1013\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0840 - val_loss: 0.0217 - val_mae: 0.0965\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0835 - val_loss: 0.0214 - val_mae: 0.0944\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0808 - val_loss: 0.0211 - val_mae: 0.0923\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0208 - val_mae: 0.0903\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0064 - mae: 0.0801 - val_loss: 0.0204 - val_mae: 0.0888\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0745 - val_loss: 0.0201 - val_mae: 0.0872\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0060 - mae: 0.0743 - val_loss: 0.0198 - val_mae: 0.0857\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0743 - val_loss: 0.0195 - val_mae: 0.0845\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0058 - mae: 0.0724 - val_loss: 0.0192 - val_mae: 0.0835\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0724 - val_loss: 0.0190 - val_mae: 0.0827\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0821\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0049 - mae: 0.0671 - val_loss: 0.0185 - val_mae: 0.0818\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0048 - mae: 0.0660 - val_loss: 0.0182 - val_mae: 0.0816\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0180 - val_mae: 0.0814\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0179 - val_mae: 0.0811\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0177 - val_mae: 0.0809\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0176 - val_mae: 0.0808\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0175 - val_mae: 0.0805\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - mae: 0.0734 - val_loss: 0.0174 - val_mae: 0.0791\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0622 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - mae: 0.0633 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0789\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0043 - mae: 0.0673 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0038 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0798\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0170 - val_mae: 0.0800\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0807\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0168 - val_mae: 0.0809\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0810\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0168 - val_mae: 0.0810\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0810\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0810\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0810\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0812\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0813\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0817\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0167 - val_mae: 0.0819\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0815\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0809\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0806\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0806\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0806\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0809\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0812\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0170 - val_mae: 0.0814\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0817\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0169 - val_mae: 0.0818\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0816\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0541 - val_loss: 0.0167 - val_mae: 0.0812\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0165 - val_mae: 0.0814\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0814\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0165 - val_mae: 0.0812\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0165 - val_mae: 0.0810\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0165 - val_mae: 0.0806\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0803\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.0801\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0164 - val_mae: 0.0800\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0164 - val_mae: 0.0799\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0163 - val_mae: 0.0800\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0162 - val_mae: 0.0802\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0026 - mae: 0.0530 - val_loss: 0.0161 - val_mae: 0.0802\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0161 - val_mae: 0.0802\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0160 - val_mae: 0.0802\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0160 - val_mae: 0.0800\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - mae: 0.0583 - val_loss: 0.0160 - val_mae: 0.0797\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0160 - val_mae: 0.0793\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0160 - val_mae: 0.0790\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0551 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0519 - val_loss: 0.0159 - val_mae: 0.0786\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0157 - val_mae: 0.0784\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0155 - val_mae: 0.0781\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0154 - val_mae: 0.0781\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0153 - val_mae: 0.0780\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0526 - val_loss: 0.0151 - val_mae: 0.0782\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0149 - val_mae: 0.0786\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0150 - val_mae: 0.0780\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0151 - val_mae: 0.0777\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0022 - mae: 0.0473 - val_loss: 0.0152 - val_mae: 0.0774\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0151 - val_mae: 0.0775\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - mae: 0.0516 - val_loss: 0.0147 - val_mae: 0.0778\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0144 - val_mae: 0.0783\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0530 - val_loss: 0.0140 - val_mae: 0.0791\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0143 - val_mae: 0.0777\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0150 - val_mae: 0.0763\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0464 - val_loss: 0.0153 - val_mae: 0.0759\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0478 - val_loss: 0.0154 - val_mae: 0.0759\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0475 - val_loss: 0.0151 - val_mae: 0.0764\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0024 - mae: 0.0477 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0022 - mae: 0.0489 - val_loss: 0.0144 - val_mae: 0.0779\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0141 - val_mae: 0.0786\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0501 - val_loss: 0.0143 - val_mae: 0.0779\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0145 - val_mae: 0.0767\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0148 - val_mae: 0.0761\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0149 - val_mae: 0.0759\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0449 - val_loss: 0.0150 - val_mae: 0.0760\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0468 - val_loss: 0.0150 - val_mae: 0.0762\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0454 - val_loss: 0.0148 - val_mae: 0.0767\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0470 - val_loss: 0.0145 - val_mae: 0.0776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:39:46,622] Trial 14 finished with value: 0.07757825404405594 and parameters: {'learning_rate': 0.0005059987485953349, 'weight_decay': 9.358712883178077e-08}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0239 - val_mae: 0.1186\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1178\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0236 - val_mae: 0.1159\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0235 - val_mae: 0.1150\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0233 - val_mae: 0.1141\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0232 - val_mae: 0.1131\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0231 - val_mae: 0.1121\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0230 - val_mae: 0.1112\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0229 - val_mae: 0.1102\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0953 - val_loss: 0.0228 - val_mae: 0.1093\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0226 - val_mae: 0.1084\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0225 - val_mae: 0.1074\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0927 - val_loss: 0.0224 - val_mae: 0.1065\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0223 - val_mae: 0.1056\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0222 - val_mae: 0.1047\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0221 - val_mae: 0.1039\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0220 - val_mae: 0.1030\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0902 - val_loss: 0.0219 - val_mae: 0.1022\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0218 - val_mae: 0.1014\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0217 - val_mae: 0.1005\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0894 - val_loss: 0.0216 - val_mae: 0.0997\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0214 - val_mae: 0.0989\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0073 - mae: 0.0842 - val_loss: 0.0213 - val_mae: 0.0981\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0212 - val_mae: 0.0973\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0211 - val_mae: 0.0965\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0856 - val_loss: 0.0210 - val_mae: 0.0957\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0208 - val_mae: 0.0949\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0207 - val_mae: 0.0941\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0815 - val_loss: 0.0206 - val_mae: 0.0933\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0064 - mae: 0.0818 - val_loss: 0.0205 - val_mae: 0.0924\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0203 - val_mae: 0.0916\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0062 - mae: 0.0794 - val_loss: 0.0202 - val_mae: 0.0908\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0201 - val_mae: 0.0900\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0825 - val_loss: 0.0200 - val_mae: 0.0895\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064 - mae: 0.0806 - val_loss: 0.0199 - val_mae: 0.0889\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - mae: 0.0833 - val_loss: 0.0197 - val_mae: 0.0884\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0196 - val_mae: 0.0879\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0059 - mae: 0.0744 - val_loss: 0.0195 - val_mae: 0.0874\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0194 - val_mae: 0.0870\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0062 - mae: 0.0781 - val_loss: 0.0193 - val_mae: 0.0866\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0192 - val_mae: 0.0863\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0754 - val_loss: 0.0191 - val_mae: 0.0859\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0189 - val_mae: 0.0855\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0060 - mae: 0.0784 - val_loss: 0.0188 - val_mae: 0.0851\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0766 - val_loss: 0.0187 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0759 - val_loss: 0.0186 - val_mae: 0.0844\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0778 - val_loss: 0.0186 - val_mae: 0.0840\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0057 - mae: 0.0770 - val_loss: 0.0185 - val_mae: 0.0837\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0745 - val_loss: 0.0184 - val_mae: 0.0833\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0758 - val_loss: 0.0184 - val_mae: 0.0829\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0183 - val_mae: 0.0826\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0183 - val_mae: 0.0823\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0183 - val_mae: 0.0820\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0762 - val_loss: 0.0182 - val_mae: 0.0817\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0182 - val_mae: 0.0814\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0734 - val_loss: 0.0182 - val_mae: 0.0811\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0181 - val_mae: 0.0808\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - mae: 0.0753 - val_loss: 0.0181 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0058 - mae: 0.0752 - val_loss: 0.0181 - val_mae: 0.0803\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0181 - val_mae: 0.0801\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0740 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0056 - mae: 0.0753 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0180 - val_mae: 0.0793\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0789\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0178 - val_mae: 0.0788\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0685 - val_loss: 0.0178 - val_mae: 0.0786\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0708 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0048 - mae: 0.0700 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0695 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0713 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0723 - val_loss: 0.0176 - val_mae: 0.0765\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0762\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0047 - mae: 0.0668 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0679 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0698 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0629 - val_loss: 0.0171 - val_mae: 0.0763\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0171 - val_mae: 0.0763\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0764\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0171 - val_mae: 0.0764\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0042 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.0763\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0763\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041 - mae: 0.0643 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0041 - mae: 0.0628 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0757\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0172 - val_mae: 0.0757\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0172 - val_mae: 0.0757\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0681 - val_loss: 0.0172 - val_mae: 0.0756\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0756\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0756\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0754\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0171 - val_mae: 0.0755\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0046 - mae: 0.0649 - val_loss: 0.0171 - val_mae: 0.0756\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0171 - val_mae: 0.0756\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0756\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0171 - val_mae: 0.0756\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0757\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0555 - val_loss: 0.0171 - val_mae: 0.0758\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0762\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0763\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0763\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0170 - val_mae: 0.0764\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0765\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0558 - val_loss: 0.0169 - val_mae: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:40:05,552] Trial 15 finished with value: 0.0767124816775322 and parameters: {'learning_rate': 0.00012751397783410004, 'weight_decay': 4.1526561383748546e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0097 - mae: 0.1046 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1124\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0101 - mae: 0.1066 - val_loss: 0.0238 - val_mae: 0.1121\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1037 - val_loss: 0.0238 - val_mae: 0.1119\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0099 - mae: 0.1054 - val_loss: 0.0238 - val_mae: 0.1117\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1115\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1085 - val_loss: 0.0237 - val_mae: 0.1113\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1111\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1109\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.0985 - val_loss: 0.0236 - val_mae: 0.1105\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.0995 - val_loss: 0.0236 - val_mae: 0.1103\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0236 - val_mae: 0.1101\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0090 - mae: 0.1001 - val_loss: 0.0235 - val_mae: 0.1097\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0096 - mae: 0.1035 - val_loss: 0.0235 - val_mae: 0.1095\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1001 - val_loss: 0.0235 - val_mae: 0.1093\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1022 - val_loss: 0.0234 - val_mae: 0.1091\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1002 - val_loss: 0.0234 - val_mae: 0.1090\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0234 - val_mae: 0.1088\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0234 - val_mae: 0.1086\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0234 - val_mae: 0.1084\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1003 - val_loss: 0.0233 - val_mae: 0.1080\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.0994 - val_loss: 0.0233 - val_mae: 0.1078\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.0963 - val_loss: 0.0233 - val_mae: 0.1077\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0232 - val_mae: 0.1075\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0232 - val_mae: 0.1073\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1072\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1070\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0961 - val_loss: 0.0232 - val_mae: 0.1068\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0971 - val_loss: 0.0231 - val_mae: 0.1067\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0963 - val_loss: 0.0231 - val_mae: 0.1065\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0231 - val_mae: 0.1063\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0984 - val_loss: 0.0231 - val_mae: 0.1062\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0231 - val_mae: 0.1060\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.0966 - val_loss: 0.0230 - val_mae: 0.1059\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.0986 - val_loss: 0.0230 - val_mae: 0.1057\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.0966 - val_loss: 0.0230 - val_mae: 0.1055\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0087 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1054\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0087 - mae: 0.0953 - val_loss: 0.0230 - val_mae: 0.1052\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1051\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0229 - val_mae: 0.1049\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0956 - val_loss: 0.0229 - val_mae: 0.1048\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0229 - val_mae: 0.1046\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0229 - val_mae: 0.1045\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0946 - val_loss: 0.0229 - val_mae: 0.1043\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0228 - val_mae: 0.1042\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0228 - val_mae: 0.1040\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1039\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0954 - val_loss: 0.0228 - val_mae: 0.1037\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080 - mae: 0.0895 - val_loss: 0.0228 - val_mae: 0.1036\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0932 - val_loss: 0.0228 - val_mae: 0.1034\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1033\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0227 - val_mae: 0.1032\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0227 - val_mae: 0.1030\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0928 - val_loss: 0.0227 - val_mae: 0.1029\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0941 - val_loss: 0.0227 - val_mae: 0.1027\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0227 - val_mae: 0.1026\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0226 - val_mae: 0.1024\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0915 - val_loss: 0.0226 - val_mae: 0.1023\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0226 - val_mae: 0.1022\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0226 - val_mae: 0.1020\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0921 - val_loss: 0.0226 - val_mae: 0.1019\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0226 - val_mae: 0.1017\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0885 - val_loss: 0.0225 - val_mae: 0.1016\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0903 - val_loss: 0.0225 - val_mae: 0.1014\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0225 - val_mae: 0.1013\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0955 - val_loss: 0.0225 - val_mae: 0.1012\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0887 - val_loss: 0.0225 - val_mae: 0.1010\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0225 - val_mae: 0.1009\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0224 - val_mae: 0.1007\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0224 - val_mae: 0.1006\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0082 - mae: 0.0932 - val_loss: 0.0224 - val_mae: 0.1004\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0907 - val_loss: 0.0224 - val_mae: 0.1003\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0900 - val_loss: 0.0224 - val_mae: 0.1002\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.1000\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.0999\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0911 - val_loss: 0.0223 - val_mae: 0.0997\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0866 - val_loss: 0.0223 - val_mae: 0.0996\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0883 - val_loss: 0.0223 - val_mae: 0.0995\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0892 - val_loss: 0.0223 - val_mae: 0.0993\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.0992\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0888 - val_loss: 0.0223 - val_mae: 0.0991\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0222 - val_mae: 0.0989\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0892 - val_loss: 0.0222 - val_mae: 0.0988\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.0987\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0881 - val_loss: 0.0222 - val_mae: 0.0986\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0878 - val_loss: 0.0222 - val_mae: 0.0984\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0914 - val_loss: 0.0222 - val_mae: 0.0983\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0873 - val_loss: 0.0222 - val_mae: 0.0982\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0221 - val_mae: 0.0980\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0221 - val_mae: 0.0979\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0221 - val_mae: 0.0978\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0892 - val_loss: 0.0221 - val_mae: 0.0977\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0221 - val_mae: 0.0975\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0221 - val_mae: 0.0974\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0973\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0220 - val_mae: 0.0971\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0970\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0220 - val_mae: 0.0969\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0220 - val_mae: 0.0968\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0220 - val_mae: 0.0966\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0076 - mae: 0.0887 - val_loss: 0.0219 - val_mae: 0.0965\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0219 - val_mae: 0.0964\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0870 - val_loss: 0.0219 - val_mae: 0.0962\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0219 - val_mae: 0.0961\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0850 - val_loss: 0.0219 - val_mae: 0.0960\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0219 - val_mae: 0.0958\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0887 - val_loss: 0.0218 - val_mae: 0.0957\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0218 - val_mae: 0.0956\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0218 - val_mae: 0.0953\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0841 - val_loss: 0.0218 - val_mae: 0.0952\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0866 - val_loss: 0.0218 - val_mae: 0.0951\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0950\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0070 - mae: 0.0855 - val_loss: 0.0217 - val_mae: 0.0949\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0070 - mae: 0.0834 - val_loss: 0.0217 - val_mae: 0.0947\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0217 - val_mae: 0.0946\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0217 - val_mae: 0.0945\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0831 - val_loss: 0.0216 - val_mae: 0.0944\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0830 - val_loss: 0.0216 - val_mae: 0.0942\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0216 - val_mae: 0.0941\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0216 - val_mae: 0.0940\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0827 - val_loss: 0.0216 - val_mae: 0.0939\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0216 - val_mae: 0.0937\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0215 - val_mae: 0.0936\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0830 - val_loss: 0.0215 - val_mae: 0.0935\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0852 - val_loss: 0.0215 - val_mae: 0.0934\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0215 - val_mae: 0.0933\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0215 - val_mae: 0.0931\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0215 - val_mae: 0.0930\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0069 - mae: 0.0838 - val_loss: 0.0214 - val_mae: 0.0929\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0214 - val_mae: 0.0928\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0837 - val_loss: 0.0214 - val_mae: 0.0927\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0830 - val_loss: 0.0214 - val_mae: 0.0926\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0214 - val_mae: 0.0925\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0214 - val_mae: 0.0923\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064 - mae: 0.0809 - val_loss: 0.0213 - val_mae: 0.0922\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0213 - val_mae: 0.0921\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0072 - mae: 0.0850 - val_loss: 0.0213 - val_mae: 0.0920\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0840 - val_loss: 0.0213 - val_mae: 0.0919\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0834 - val_loss: 0.0213 - val_mae: 0.0918\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0065 - mae: 0.0818 - val_loss: 0.0212 - val_mae: 0.0917\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0915\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0838 - val_loss: 0.0212 - val_mae: 0.0914\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0810 - val_loss: 0.0212 - val_mae: 0.0913\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0066 - mae: 0.0832 - val_loss: 0.0212 - val_mae: 0.0912\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0801 - val_loss: 0.0212 - val_mae: 0.0910\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0211 - val_mae: 0.0909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:40:24,826] Trial 16 finished with value: 0.09091577678918839 and parameters: {'learning_rate': 3.756538001455633e-05, 'weight_decay': 2.843608515996888e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1225\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1219\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1213\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0244 - val_mae: 0.1207\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0243 - val_mae: 0.1201\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0242 - val_mae: 0.1195\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0242 - val_mae: 0.1188\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0241 - val_mae: 0.1182\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1169\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0238 - val_mae: 0.1163\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1156\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0236 - val_mae: 0.1143\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0235 - val_mae: 0.1136\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0234 - val_mae: 0.1129\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1003 - val_loss: 0.0233 - val_mae: 0.1123\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0232 - val_mae: 0.1116\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0231 - val_mae: 0.1110\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0230 - val_mae: 0.1103\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0963 - val_loss: 0.0230 - val_mae: 0.1097\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0229 - val_mae: 0.1090\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0228 - val_mae: 0.1084\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0227 - val_mae: 0.1077\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1064\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0224 - val_mae: 0.1058\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0223 - val_mae: 0.1051\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0222 - val_mae: 0.1044\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0222 - val_mae: 0.1037\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0876 - val_loss: 0.0221 - val_mae: 0.1030\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0220 - val_mae: 0.1022\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0219 - val_mae: 0.1014\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0218 - val_mae: 0.1007\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0856 - val_loss: 0.0217 - val_mae: 0.0999\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0216 - val_mae: 0.0991\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0829 - val_loss: 0.0215 - val_mae: 0.0983\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0214 - val_mae: 0.0975\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0213 - val_mae: 0.0967\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0212 - val_mae: 0.0960\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0953\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0210 - val_mae: 0.0947\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0209 - val_mae: 0.0941\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0208 - val_mae: 0.0934\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0832 - val_loss: 0.0208 - val_mae: 0.0928\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0837 - val_loss: 0.0207 - val_mae: 0.0922\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0817 - val_loss: 0.0206 - val_mae: 0.0915\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0813 - val_loss: 0.0205 - val_mae: 0.0909\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0814 - val_loss: 0.0204 - val_mae: 0.0902\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0203 - val_mae: 0.0896\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0806 - val_loss: 0.0202 - val_mae: 0.0890\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0773 - val_loss: 0.0201 - val_mae: 0.0884\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0062 - mae: 0.0763 - val_loss: 0.0200 - val_mae: 0.0878\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0063 - mae: 0.0774 - val_loss: 0.0199 - val_mae: 0.0872\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0059 - mae: 0.0766 - val_loss: 0.0198 - val_mae: 0.0867\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0197 - val_mae: 0.0861\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0739 - val_loss: 0.0196 - val_mae: 0.0855\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0765 - val_loss: 0.0195 - val_mae: 0.0849\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0735 - val_loss: 0.0194 - val_mae: 0.0843\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0748 - val_loss: 0.0193 - val_mae: 0.0838\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0192 - val_mae: 0.0833\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0758 - val_loss: 0.0191 - val_mae: 0.0828\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0063 - mae: 0.0774 - val_loss: 0.0190 - val_mae: 0.0824\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0747 - val_loss: 0.0189 - val_mae: 0.0821\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0759 - val_loss: 0.0189 - val_mae: 0.0818\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0054 - mae: 0.0717 - val_loss: 0.0188 - val_mae: 0.0815\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0812\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0766 - val_loss: 0.0186 - val_mae: 0.0809\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0760 - val_loss: 0.0186 - val_mae: 0.0807\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0185 - val_mae: 0.0805\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0184 - val_mae: 0.0800\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0054 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0798\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - mae: 0.0715 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - mae: 0.0786 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0696 - val_loss: 0.0182 - val_mae: 0.0793\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0053 - mae: 0.0743 - val_loss: 0.0181 - val_mae: 0.0788\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0181 - val_mae: 0.0787\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0641 - val_loss: 0.0181 - val_mae: 0.0785\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0181 - val_mae: 0.0784\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0181 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0181 - val_mae: 0.0782\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0707 - val_loss: 0.0181 - val_mae: 0.0781\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0702 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0703 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0702 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0716 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0777\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0691 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0180 - val_mae: 0.0775\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0720 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0641 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0045 - mae: 0.0667 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0687 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0657 - val_loss: 0.0178 - val_mae: 0.0772\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0712 - val_loss: 0.0178 - val_mae: 0.0772\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0050 - mae: 0.0691 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0690 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0646 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0671 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0718 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0684 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0670 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0760\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0679 - val_loss: 0.0175 - val_mae: 0.0759\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0759\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0629 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0629 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0039 - mae: 0.0643 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0626 - val_loss: 0.0174 - val_mae: 0.0758\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0758\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0174 - val_mae: 0.0758\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0674 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0759\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0671 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0665 - val_loss: 0.0172 - val_mae: 0.0761\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0676 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0764\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0765\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0766\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0171 - val_mae: 0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:40:43,580] Trial 17 finished with value: 0.07662992924451828 and parameters: {'learning_rate': 0.00010816240028235059, 'weight_decay': 1.4270070711038241e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0106 - mae: 0.1103 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0104 - mae: 0.1094 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1079 - val_loss: 0.0248 - val_mae: 0.1208\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0103 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0109 - mae: 0.1120 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1082 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1086 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0105 - mae: 0.1100 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0109 - mae: 0.1121 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0102 - mae: 0.1074 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0246 - val_mae: 0.1189\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1089 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1105 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1051 - val_loss: 0.0244 - val_mae: 0.1178\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0244 - val_mae: 0.1177\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1173\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1172\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0243 - val_mae: 0.1170\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1169\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1058 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0242 - val_mae: 0.1165\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1024 - val_loss: 0.0242 - val_mae: 0.1164\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1027 - val_loss: 0.0242 - val_mae: 0.1162\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0242 - val_mae: 0.1161\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1034 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0241 - val_mae: 0.1156\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1154\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0098 - mae: 0.1056 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1061 - val_loss: 0.0240 - val_mae: 0.1148\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1146\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1016 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1043 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1038 - val_loss: 0.0238 - val_mae: 0.1139\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1136\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1134\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.0998 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1131\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1130\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1128\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1127\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1015 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0236 - val_mae: 0.1123\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1028 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1120\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1008 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1037 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1115\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.0998 - val_loss: 0.0235 - val_mae: 0.1113\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1110\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0088 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1107\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0957 - val_loss: 0.0234 - val_mae: 0.1106\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0234 - val_mae: 0.1105\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0981 - val_loss: 0.0234 - val_mae: 0.1103\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0088 - mae: 0.0985 - val_loss: 0.0233 - val_mae: 0.1102\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0953 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.0997 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.0984 - val_loss: 0.0233 - val_mae: 0.1098\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1015 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0989 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0232 - val_mae: 0.1094\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0977 - val_loss: 0.0232 - val_mae: 0.1092\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1090\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0231 - val_mae: 0.1086\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0231 - val_mae: 0.1085\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.0981 - val_loss: 0.0231 - val_mae: 0.1084\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0963 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0230 - val_mae: 0.1079\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0949 - val_loss: 0.0230 - val_mae: 0.1078\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0970 - val_loss: 0.0230 - val_mae: 0.1077\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.0980 - val_loss: 0.0229 - val_mae: 0.1072\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1071\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0229 - val_mae: 0.1069\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0943 - val_loss: 0.0229 - val_mae: 0.1067\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0932 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0083 - mae: 0.0935 - val_loss: 0.0228 - val_mae: 0.1063\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1062\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0951 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1060\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0922 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0931 - val_loss: 0.0228 - val_mae: 0.1057\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0937 - val_loss: 0.0228 - val_mae: 0.1056\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0950 - val_loss: 0.0227 - val_mae: 0.1055\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0085 - mae: 0.0955 - val_loss: 0.0227 - val_mae: 0.1054\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1053\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0937 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1049\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0910 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0894 - val_loss: 0.0226 - val_mae: 0.1045\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0226 - val_mae: 0.1044\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0225 - val_mae: 0.1040\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0927 - val_loss: 0.0225 - val_mae: 0.1038\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0083 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0921 - val_loss: 0.0225 - val_mae: 0.1036\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0935 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0928 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0225 - val_mae: 0.1032\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0224 - val_mae: 0.1031\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0081 - mae: 0.0897 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1029\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0895 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0903 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0878 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0223 - val_mae: 0.1021\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0906 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0899 - val_loss: 0.0223 - val_mae: 0.1017\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1015\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0222 - val_mae: 0.1014\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0222 - val_mae: 0.1013\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079 - mae: 0.0901 - val_loss: 0.0222 - val_mae: 0.1011\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1008\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0886 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.1006\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0221 - val_mae: 0.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:41:02,280] Trial 18 finished with value: 0.1004272848367691 and parameters: {'learning_rate': 2.5836926531691035e-05, 'weight_decay': 2.3963054892342755e-07}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1135\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1040 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.0992 - val_loss: 0.0234 - val_mae: 0.1092\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1071\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0928 - val_loss: 0.0228 - val_mae: 0.1049\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0225 - val_mae: 0.1027\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0909 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0864 - val_loss: 0.0216 - val_mae: 0.0959\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0072 - mae: 0.0839 - val_loss: 0.0213 - val_mae: 0.0938\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0878 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0802 - val_loss: 0.0208 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0206 - val_mae: 0.0884\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0869\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0201 - val_mae: 0.0856\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0198 - val_mae: 0.0845\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0772 - val_loss: 0.0196 - val_mae: 0.0835\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0742 - val_loss: 0.0194 - val_mae: 0.0826\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0191 - val_mae: 0.0816\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0189 - val_mae: 0.0807\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0706 - val_loss: 0.0186 - val_mae: 0.0801\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0184 - val_mae: 0.0796\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0751 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0180 - val_mae: 0.0788\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0691 - val_loss: 0.0179 - val_mae: 0.0786\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0688 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0178 - val_mae: 0.0779\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - mae: 0.0716 - val_loss: 0.0176 - val_mae: 0.0775\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0176 - val_mae: 0.0767\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0689 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0637 - val_loss: 0.0176 - val_mae: 0.0763\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0647 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0605 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0769\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0684 - val_loss: 0.0174 - val_mae: 0.0770\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0592 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0775\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0176 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0177 - val_mae: 0.0766\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0176 - val_mae: 0.0765\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0176 - val_mae: 0.0763\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0677 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0582 - val_loss: 0.0176 - val_mae: 0.0763\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0176 - val_mae: 0.0763\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0176 - val_mae: 0.0764\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0041 - mae: 0.0606 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0174 - val_mae: 0.0769\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0770\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0174 - val_mae: 0.0769\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0174 - val_mae: 0.0768\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0624 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0176 - val_mae: 0.0763\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0540 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0176 - val_mae: 0.0761\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0175 - val_mae: 0.0762\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0175 - val_mae: 0.0762\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0768\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0169 - val_mae: 0.0765\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0496 - val_loss: 0.0169 - val_mae: 0.0764\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0762\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0167 - val_mae: 0.0762\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0521 - val_loss: 0.0166 - val_mae: 0.0762\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0527 - val_loss: 0.0162 - val_mae: 0.0764\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0024 - mae: 0.0503 - val_loss: 0.0161 - val_mae: 0.0761\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0162 - val_mae: 0.0756\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0165 - val_mae: 0.0749\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0168 - val_mae: 0.0749\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0168 - val_mae: 0.0749\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0509 - val_loss: 0.0166 - val_mae: 0.0746\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0522 - val_loss: 0.0162 - val_mae: 0.0743\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0158 - val_mae: 0.0744\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0505 - val_loss: 0.0154 - val_mae: 0.0750\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0153 - val_mae: 0.0749\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0158 - val_mae: 0.0742\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0161 - val_mae: 0.0745\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0504 - val_loss: 0.0164 - val_mae: 0.0748\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0500 - val_loss: 0.0164 - val_mae: 0.0747\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0160 - val_mae: 0.0745\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0745\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0153 - val_mae: 0.0749\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0155 - val_mae: 0.0747\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0020 - mae: 0.0445 - val_loss: 0.0157 - val_mae: 0.0746\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0025 - mae: 0.0488 - val_loss: 0.0157 - val_mae: 0.0747\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0449 - val_loss: 0.0159 - val_mae: 0.0748\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0160 - val_mae: 0.0749\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0161 - val_mae: 0.0751\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0502 - val_loss: 0.0160 - val_mae: 0.0752\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0159 - val_mae: 0.0753\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0449 - val_loss: 0.0158 - val_mae: 0.0755\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0159 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0160 - val_mae: 0.0756\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0461 - val_loss: 0.0160 - val_mae: 0.0757\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0428 - val_loss: 0.0158 - val_mae: 0.0760\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0157 - val_mae: 0.0762\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0156 - val_mae: 0.0764\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0455 - val_loss: 0.0156 - val_mae: 0.0766\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0155 - val_mae: 0.0767\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0155 - val_mae: 0.0768\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0155 - val_mae: 0.0769\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0154 - val_mae: 0.0771\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0158 - val_mae: 0.0767\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0161 - val_mae: 0.0766\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0161 - val_mae: 0.0767\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0161 - val_mae: 0.0768\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0160 - val_mae: 0.0769\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0158 - val_mae: 0.0772\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0157 - val_mae: 0.0774\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0156 - val_mae: 0.0774\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0156 - val_mae: 0.0774\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0156 - val_mae: 0.0774\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0156 - val_mae: 0.0773\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0157 - val_mae: 0.0770\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0157 - val_mae: 0.0768\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0157 - val_mae: 0.0767\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0156 - val_mae: 0.0768\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0155 - val_mae: 0.0770\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - mae: 0.0455 - val_loss: 0.0154 - val_mae: 0.0772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:41:21,061] Trial 19 finished with value: 0.07719221711158752 and parameters: {'learning_rate': 0.00045917713650341075, 'weight_decay': 1.633315948070668e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0206 - val_mae: 0.0868\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061 - mae: 0.0745 - val_loss: 0.0181 - val_mae: 0.0825\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0904\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - mae: 0.0662 - val_loss: 0.0173 - val_mae: 0.0913\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0913\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0902\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0882\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0623 - val_loss: 0.0171 - val_mae: 0.0856\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0833\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0173 - val_mae: 0.0842\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0177 - val_mae: 0.0834\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0184 - val_mae: 0.0868\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0186 - val_mae: 0.0877\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0181 - val_mae: 0.0837\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0181 - val_mae: 0.0831\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0184 - val_mae: 0.0835\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0496 - val_loss: 0.0183 - val_mae: 0.0842\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.0180 - val_mae: 0.0850\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0179 - val_mae: 0.0852\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0180 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0464 - val_loss: 0.0180 - val_mae: 0.0857\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0181 - val_mae: 0.0844\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - mae: 0.0390 - val_loss: 0.0180 - val_mae: 0.0830\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0018 - mae: 0.0396 - val_loss: 0.0181 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0443 - val_loss: 0.0186 - val_mae: 0.0870\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0188 - val_mae: 0.0884\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0473 - val_loss: 0.0192 - val_mae: 0.0885\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0021 - mae: 0.0435 - val_loss: 0.0184 - val_mae: 0.0836\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0452 - val_loss: 0.0179 - val_mae: 0.0811\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0023 - mae: 0.0454 - val_loss: 0.0176 - val_mae: 0.0820\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0451 - val_loss: 0.0176 - val_mae: 0.0857\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0179 - val_mae: 0.0872\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0187 - val_mae: 0.0907\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0451 - val_loss: 0.0192 - val_mae: 0.0927\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0191 - val_mae: 0.0902\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0432 - val_loss: 0.0185 - val_mae: 0.0846\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0421 - val_loss: 0.0183 - val_mae: 0.0819\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0181 - val_mae: 0.0808\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0181 - val_mae: 0.0803\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0460 - val_loss: 0.0181 - val_mae: 0.0801\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0502 - val_loss: 0.0180 - val_mae: 0.0801\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0460 - val_loss: 0.0179 - val_mae: 0.0807\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0178 - val_mae: 0.0821\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0178 - val_mae: 0.0848\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0179 - val_mae: 0.0883\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0181 - val_mae: 0.0914\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0183 - val_mae: 0.0933\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0186 - val_mae: 0.0950\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0188 - val_mae: 0.0945\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0433 - val_loss: 0.0191 - val_mae: 0.0945\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0188 - val_mae: 0.0904\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0014 - mae: 0.0389 - val_loss: 0.0187 - val_mae: 0.0878\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0439 - val_loss: 0.0187 - val_mae: 0.0867\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0189 - val_mae: 0.0879\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0392 - val_loss: 0.0194 - val_mae: 0.0907\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0194 - val_mae: 0.0907\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0426 - val_loss: 0.0183 - val_mae: 0.0849\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0466 - val_loss: 0.0178 - val_mae: 0.0828\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0442 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0176 - val_mae: 0.0823\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0403 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0176 - val_mae: 0.0834\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0177 - val_mae: 0.0846\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0178 - val_mae: 0.0863\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0016 - mae: 0.0410 - val_loss: 0.0180 - val_mae: 0.0885\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0016 - mae: 0.0419 - val_loss: 0.0183 - val_mae: 0.0907\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0187 - val_mae: 0.0933\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0190 - val_mae: 0.0951\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0459 - val_loss: 0.0194 - val_mae: 0.0960\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0193 - val_mae: 0.0942\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0458 - val_loss: 0.0193 - val_mae: 0.0931\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.0192 - val_mae: 0.0924\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0017 - mae: 0.0434 - val_loss: 0.0191 - val_mae: 0.0914\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.0190 - val_mae: 0.0912\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0191 - val_mae: 0.0922\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0019 - mae: 0.0408 - val_loss: 0.0193 - val_mae: 0.0936\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0384 - val_loss: 0.0191 - val_mae: 0.0920\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.5917e-04 - mae: 0.0327 - val_loss: 0.0191 - val_mae: 0.0916\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0195 - val_mae: 0.0938\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 0.0204 - val_mae: 0.0988\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0405 - val_loss: 0.0211 - val_mae: 0.1028\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 9.3280e-04 - mae: 0.0330 - val_loss: 0.0202 - val_mae: 0.0982\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 9.7793e-04 - mae: 0.0335 - val_loss: 0.0202 - val_mae: 0.0983\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0219 - val_mae: 0.1063\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0016 - mae: 0.0374 - val_loss: 0.0217 - val_mae: 0.1050\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0196 - val_mae: 0.0948\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0358 - val_loss: 0.0190 - val_mae: 0.0911\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0190 - val_mae: 0.0910\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - mae: 0.0349 - val_loss: 0.0199 - val_mae: 0.0965\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0216 - val_mae: 0.1043\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0212 - val_mae: 0.1025\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0012 - mae: 0.0329 - val_loss: 0.0198 - val_mae: 0.0952\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0017 - mae: 0.0403 - val_loss: 0.0194 - val_mae: 0.0933\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0194 - val_mae: 0.0932\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0190 - val_mae: 0.0911\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0010 - mae: 0.0324 - val_loss: 0.0190 - val_mae: 0.0912\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0193 - val_mae: 0.0938\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 0.0199 - val_mae: 0.0979\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 0.0209 - val_mae: 0.1036\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0216 - val_mae: 0.1068\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0014 - mae: 0.0356 - val_loss: 0.0217 - val_mae: 0.1069\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.4855e-04 - mae: 0.0323 - val_loss: 0.0210 - val_mae: 0.1032\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0198 - val_mae: 0.0974\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - mae: 0.0401 - val_loss: 0.0196 - val_mae: 0.0950\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0201 - val_mae: 0.0962\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0337 - val_loss: 0.0209 - val_mae: 0.0996\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0479 - val_loss: 0.0207 - val_mae: 0.0993\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0195 - val_mae: 0.0935\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0185 - val_mae: 0.0881\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0014 - mae: 0.0351 - val_loss: 0.0182 - val_mae: 0.0871\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0504 - val_loss: 0.0181 - val_mae: 0.0876\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0013 - mae: 0.0332 - val_loss: 0.0181 - val_mae: 0.0881\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0184 - val_mae: 0.0905\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0189 - val_mae: 0.0939\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.6034e-04 - mae: 0.0294 - val_loss: 0.0193 - val_mae: 0.0967\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0418 - val_loss: 0.0199 - val_mae: 0.1001\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0199 - val_mae: 0.0997\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0195 - val_mae: 0.0968\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.5241e-04 - mae: 0.0316 - val_loss: 0.0193 - val_mae: 0.0944\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 9.9348e-04 - mae: 0.0321 - val_loss: 0.0194 - val_mae: 0.0932\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.8397e-04 - mae: 0.0269 - val_loss: 0.0194 - val_mae: 0.0924\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.2372e-04 - mae: 0.0277 - val_loss: 0.0197 - val_mae: 0.0934\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0012 - mae: 0.0325 - val_loss: 0.0200 - val_mae: 0.0948\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0461 - val_loss: 0.0204 - val_mae: 0.0970\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0010 - mae: 0.0327 - val_loss: 0.0199 - val_mae: 0.0952\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.2307e-04 - mae: 0.0292 - val_loss: 0.0194 - val_mae: 0.0930\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0010 - mae: 0.0314 - val_loss: 0.0194 - val_mae: 0.0939\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0201 - val_mae: 0.0982\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0213 - val_mae: 0.1037\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0323 - val_loss: 0.0198 - val_mae: 0.0967\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0194 - val_mae: 0.0936\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.9489e-04 - mae: 0.0295 - val_loss: 0.0194 - val_mae: 0.0937\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0344 - val_loss: 0.0200 - val_mae: 0.0968\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.3552e-04 - mae: 0.0279 - val_loss: 0.0209 - val_mae: 0.1013\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.5274e-04 - mae: 0.0276 - val_loss: 0.0217 - val_mae: 0.1056\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.5671e-04 - mae: 0.0300 - val_loss: 0.0216 - val_mae: 0.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:41:39,677] Trial 20 finished with value: 0.10482659190893173 and parameters: {'learning_rate': 0.008514462263594667, 'weight_decay': 8.615441419129163e-07}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0256 - val_mae: 0.1191\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0255 - val_mae: 0.1187\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0255 - val_mae: 0.1182\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0254 - val_mae: 0.1178\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0253 - val_mae: 0.1173\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0252 - val_mae: 0.1169\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0252 - val_mae: 0.1164\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0251 - val_mae: 0.1160\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0250 - val_mae: 0.1155\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0249 - val_mae: 0.1151\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1018 - val_loss: 0.0249 - val_mae: 0.1146\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1038 - val_loss: 0.0248 - val_mae: 0.1142\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0976 - val_loss: 0.0247 - val_mae: 0.1138\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0089 - mae: 0.1001 - val_loss: 0.0247 - val_mae: 0.1133\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0246 - val_mae: 0.1129\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1003 - val_loss: 0.0245 - val_mae: 0.1125\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0245 - val_mae: 0.1120\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0244 - val_mae: 0.1116\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0243 - val_mae: 0.1111\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0243 - val_mae: 0.1107\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0242 - val_mae: 0.1102\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0241 - val_mae: 0.1098\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0241 - val_mae: 0.1094\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0240 - val_mae: 0.1089\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0240 - val_mae: 0.1085\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0239 - val_mae: 0.1080\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0238 - val_mae: 0.1076\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0238 - val_mae: 0.1071\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0237 - val_mae: 0.1067\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0928 - val_loss: 0.0237 - val_mae: 0.1063\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0236 - val_mae: 0.1058\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0926 - val_loss: 0.0235 - val_mae: 0.1054\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0912 - val_loss: 0.0235 - val_mae: 0.1049\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0905 - val_loss: 0.0234 - val_mae: 0.1045\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0234 - val_mae: 0.1040\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0080 - mae: 0.0929 - val_loss: 0.0233 - val_mae: 0.1036\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0905 - val_loss: 0.0233 - val_mae: 0.1031\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0922 - val_loss: 0.0232 - val_mae: 0.1027\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0232 - val_mae: 0.1022\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0079 - mae: 0.0912 - val_loss: 0.0231 - val_mae: 0.1018\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0230 - val_mae: 0.1014\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0230 - val_mae: 0.1010\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0229 - val_mae: 0.1005\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0884 - val_loss: 0.0229 - val_mae: 0.1001\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0228 - val_mae: 0.0997\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0228 - val_mae: 0.0993\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0227 - val_mae: 0.0989\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0227 - val_mae: 0.0985\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0226 - val_mae: 0.0981\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0226 - val_mae: 0.0977\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0843 - val_loss: 0.0225 - val_mae: 0.0972\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0225 - val_mae: 0.0968\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0225 - val_mae: 0.0964\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0224 - val_mae: 0.0960\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0858 - val_loss: 0.0224 - val_mae: 0.0956\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0223 - val_mae: 0.0952\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0839 - val_loss: 0.0223 - val_mae: 0.0948\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0222 - val_mae: 0.0944\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0810 - val_loss: 0.0222 - val_mae: 0.0940\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0221 - val_mae: 0.0936\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0825 - val_loss: 0.0221 - val_mae: 0.0933\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0220 - val_mae: 0.0929\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0802 - val_loss: 0.0220 - val_mae: 0.0925\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0810 - val_loss: 0.0219 - val_mae: 0.0922\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0819 - val_loss: 0.0219 - val_mae: 0.0918\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0218 - val_mae: 0.0914\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0834 - val_loss: 0.0218 - val_mae: 0.0911\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0787 - val_loss: 0.0217 - val_mae: 0.0907\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0217 - val_mae: 0.0903\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0789 - val_loss: 0.0216 - val_mae: 0.0900\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0748 - val_loss: 0.0216 - val_mae: 0.0896\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0215 - val_mae: 0.0893\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0215 - val_mae: 0.0889\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064 - mae: 0.0789 - val_loss: 0.0214 - val_mae: 0.0886\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0214 - val_mae: 0.0883\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0774 - val_loss: 0.0213 - val_mae: 0.0879\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0213 - val_mae: 0.0876\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0766 - val_loss: 0.0213 - val_mae: 0.0873\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0062 - mae: 0.0772 - val_loss: 0.0212 - val_mae: 0.0869\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0212 - val_mae: 0.0866\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0777 - val_loss: 0.0211 - val_mae: 0.0863\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0754 - val_loss: 0.0211 - val_mae: 0.0860\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0778 - val_loss: 0.0210 - val_mae: 0.0856\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0210 - val_mae: 0.0853\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0209 - val_mae: 0.0850\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0785 - val_loss: 0.0209 - val_mae: 0.0847\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0054 - mae: 0.0704 - val_loss: 0.0208 - val_mae: 0.0844\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0736 - val_loss: 0.0208 - val_mae: 0.0841\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0723 - val_loss: 0.0207 - val_mae: 0.0838\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0743 - val_loss: 0.0206 - val_mae: 0.0835\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0739 - val_loss: 0.0206 - val_mae: 0.0832\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0057 - mae: 0.0724 - val_loss: 0.0205 - val_mae: 0.0829\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0730 - val_loss: 0.0205 - val_mae: 0.0826\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0745 - val_loss: 0.0204 - val_mae: 0.0824\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0058 - mae: 0.0754 - val_loss: 0.0204 - val_mae: 0.0822\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0721 - val_loss: 0.0203 - val_mae: 0.0820\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0739 - val_loss: 0.0203 - val_mae: 0.0818\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0718 - val_loss: 0.0202 - val_mae: 0.0816\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0202 - val_mae: 0.0814\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0740 - val_loss: 0.0202 - val_mae: 0.0812\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0754 - val_loss: 0.0201 - val_mae: 0.0811\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0201 - val_mae: 0.0809\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0200 - val_mae: 0.0808\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0806\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0199 - val_mae: 0.0805\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0718 - val_loss: 0.0199 - val_mae: 0.0803\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0680 - val_loss: 0.0199 - val_mae: 0.0802\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0749 - val_loss: 0.0198 - val_mae: 0.0801\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0717 - val_loss: 0.0198 - val_mae: 0.0800\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0051 - mae: 0.0699 - val_loss: 0.0197 - val_mae: 0.0799\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0676 - val_loss: 0.0197 - val_mae: 0.0798\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0049 - mae: 0.0685 - val_loss: 0.0196 - val_mae: 0.0798\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0650 - val_loss: 0.0196 - val_mae: 0.0797\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0667 - val_loss: 0.0195 - val_mae: 0.0797\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0692 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0657 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0698 - val_loss: 0.0194 - val_mae: 0.0795\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0693 - val_loss: 0.0194 - val_mae: 0.0795\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0701 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0193 - val_mae: 0.0794\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0672 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0677 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0793\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0191 - val_mae: 0.0793\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0694 - val_loss: 0.0190 - val_mae: 0.0793\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0190 - val_mae: 0.0792\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0190 - val_mae: 0.0792\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0190 - val_mae: 0.0792\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0668 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0709 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - mae: 0.0690 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0188 - val_mae: 0.0790\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0635 - val_loss: 0.0188 - val_mae: 0.0790\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0188 - val_mae: 0.0790\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - mae: 0.0671 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0732 - val_loss: 0.0187 - val_mae: 0.0789\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0048 - mae: 0.0667 - val_loss: 0.0187 - val_mae: 0.0789\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0186 - val_mae: 0.0789\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0637 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.0786\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0185 - val_mae: 0.0785\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0703 - val_loss: 0.0185 - val_mae: 0.0783\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0688 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0667 - val_loss: 0.0185 - val_mae: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:41:58,211] Trial 21 finished with value: 0.07815568149089813 and parameters: {'learning_rate': 7.968540999444324e-05, 'weight_decay': 1.8347876003622134e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0242 - val_mae: 0.1154\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1153\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0242 - val_mae: 0.1153\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0107 - mae: 0.1125 - val_loss: 0.0242 - val_mae: 0.1152\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1068 - val_loss: 0.0242 - val_mae: 0.1152\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1072 - val_loss: 0.0242 - val_mae: 0.1152\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1066 - val_loss: 0.0242 - val_mae: 0.1151\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1073 - val_loss: 0.0242 - val_mae: 0.1151\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1120 - val_loss: 0.0242 - val_mae: 0.1150\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0242 - val_mae: 0.1150\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1104 - val_loss: 0.0242 - val_mae: 0.1150\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1149\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1041 - val_loss: 0.0242 - val_mae: 0.1149\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1085 - val_loss: 0.0242 - val_mae: 0.1148\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1148\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1148\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1074 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0098 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1146\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1146\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1071 - val_loss: 0.0241 - val_mae: 0.1146\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1088 - val_loss: 0.0241 - val_mae: 0.1145\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1085 - val_loss: 0.0241 - val_mae: 0.1145\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0241 - val_mae: 0.1144\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1144\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1061 - val_loss: 0.0241 - val_mae: 0.1144\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1054 - val_loss: 0.0241 - val_mae: 0.1143\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0241 - val_mae: 0.1143\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1070 - val_loss: 0.0241 - val_mae: 0.1142\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0103 - mae: 0.1071 - val_loss: 0.0241 - val_mae: 0.1142\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1082 - val_loss: 0.0241 - val_mae: 0.1142\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0241 - val_mae: 0.1141\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0241 - val_mae: 0.1141\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0095 - mae: 0.1023 - val_loss: 0.0241 - val_mae: 0.1140\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1140\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1139\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1064 - val_loss: 0.0240 - val_mae: 0.1139\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0240 - val_mae: 0.1139\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0100 - mae: 0.1075 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1062 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1094 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1035 - val_loss: 0.0240 - val_mae: 0.1137\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0240 - val_mae: 0.1137\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0240 - val_mae: 0.1136\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0240 - val_mae: 0.1136\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0240 - val_mae: 0.1136\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1070 - val_loss: 0.0240 - val_mae: 0.1135\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1052 - val_loss: 0.0240 - val_mae: 0.1135\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1134\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1046 - val_loss: 0.0240 - val_mae: 0.1134\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1036 - val_loss: 0.0240 - val_mae: 0.1134\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1043 - val_loss: 0.0240 - val_mae: 0.1133\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1011 - val_loss: 0.0240 - val_mae: 0.1133\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0240 - val_mae: 0.1132\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1132\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0108 - mae: 0.1126 - val_loss: 0.0239 - val_mae: 0.1132\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1031 - val_loss: 0.0239 - val_mae: 0.1131\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1061 - val_loss: 0.0239 - val_mae: 0.1131\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1131\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1130\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1037 - val_loss: 0.0239 - val_mae: 0.1130\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1129\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0239 - val_mae: 0.1129\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1129\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1055 - val_loss: 0.0239 - val_mae: 0.1128\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0239 - val_mae: 0.1128\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1022 - val_loss: 0.0239 - val_mae: 0.1128\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1127\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0097 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1127\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1127\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0096 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1125\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1040 - val_loss: 0.0239 - val_mae: 0.1125\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.0981 - val_loss: 0.0239 - val_mae: 0.1124\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0238 - val_mae: 0.1124\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1010 - val_loss: 0.0238 - val_mae: 0.1124\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1027 - val_loss: 0.0238 - val_mae: 0.1123\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1071 - val_loss: 0.0238 - val_mae: 0.1123\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0238 - val_mae: 0.1123\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1122\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1051 - val_loss: 0.0238 - val_mae: 0.1122\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0238 - val_mae: 0.1122\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0238 - val_mae: 0.1121\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1121\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1035 - val_loss: 0.0238 - val_mae: 0.1120\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1002 - val_loss: 0.0238 - val_mae: 0.1120\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0238 - val_mae: 0.1120\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0100 - mae: 0.1070 - val_loss: 0.0238 - val_mae: 0.1119\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1025 - val_loss: 0.0238 - val_mae: 0.1119\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0238 - val_mae: 0.1119\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0238 - val_mae: 0.1118\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1060 - val_loss: 0.0238 - val_mae: 0.1118\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0238 - val_mae: 0.1118\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1117\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1005 - val_loss: 0.0238 - val_mae: 0.1117\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1117\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1116\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1116\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1115\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1115\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0237 - val_mae: 0.1115\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0237 - val_mae: 0.1114\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0237 - val_mae: 0.1114\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0237 - val_mae: 0.1114\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1053 - val_loss: 0.0237 - val_mae: 0.1113\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1113\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1027 - val_loss: 0.0237 - val_mae: 0.1113\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1112\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1112\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1112\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0237 - val_mae: 0.1111\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1111\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1110\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0237 - val_mae: 0.1110\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1110\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1109\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1109\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.0997 - val_loss: 0.0237 - val_mae: 0.1109\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0237 - val_mae: 0.1108\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.0997 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1032 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1024 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0236 - val_mae: 0.1106\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0236 - val_mae: 0.1106\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0236 - val_mae: 0.1106\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0236 - val_mae: 0.1105\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0236 - val_mae: 0.1105\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0091 - mae: 0.1002 - val_loss: 0.0236 - val_mae: 0.1105\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0236 - val_mae: 0.1104\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1017 - val_loss: 0.0236 - val_mae: 0.1104\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1104\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0236 - val_mae: 0.1103\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0236 - val_mae: 0.1103\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1014 - val_loss: 0.0236 - val_mae: 0.1103\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0236 - val_mae: 0.1102\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1029 - val_loss: 0.0236 - val_mae: 0.1102\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1019 - val_loss: 0.0236 - val_mae: 0.1102\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1017 - val_loss: 0.0236 - val_mae: 0.1101\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0236 - val_mae: 0.1101\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1101\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0236 - val_mae: 0.1100\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1031 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1014 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.0965 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0235 - val_mae: 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:42:16,960] Trial 22 finished with value: 0.10986430943012238 and parameters: {'learning_rate': 5.527615119756687e-06, 'weight_decay': 1.0111213373849174e-09}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1066 - val_loss: 0.0240 - val_mae: 0.1187\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0238 - val_mae: 0.1166\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0235 - val_mae: 0.1145\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0232 - val_mae: 0.1124\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0230 - val_mae: 0.1102\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0227 - val_mae: 0.1079\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0930 - val_loss: 0.0224 - val_mae: 0.1054\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0221 - val_mae: 0.1029\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0218 - val_mae: 0.1003\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0215 - val_mae: 0.0978\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.0953\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0209 - val_mae: 0.0931\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0205 - val_mae: 0.0912\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0786 - val_loss: 0.0202 - val_mae: 0.0893\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0799 - val_loss: 0.0198 - val_mae: 0.0879\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0058 - mae: 0.0739 - val_loss: 0.0195 - val_mae: 0.0869\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0062 - mae: 0.0767 - val_loss: 0.0191 - val_mae: 0.0859\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0188 - val_mae: 0.0849\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0185 - val_mae: 0.0841\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0732 - val_loss: 0.0182 - val_mae: 0.0832\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0055 - mae: 0.0727 - val_loss: 0.0179 - val_mae: 0.0822\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0177 - val_mae: 0.0813\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0718 - val_loss: 0.0176 - val_mae: 0.0803\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - mae: 0.0728 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0669 - val_loss: 0.0173 - val_mae: 0.0758\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0757\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0756\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0757\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0640 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0766\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0639 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0774\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0782\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0627 - val_loss: 0.0170 - val_mae: 0.0796\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0029 - mae: 0.0530 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0806\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0542 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0775\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0529 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.0784\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0028 - mae: 0.0507 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0161 - val_mae: 0.0799\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0164 - val_mae: 0.0779\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0165 - val_mae: 0.0774\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0166 - val_mae: 0.0771\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0462 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0028 - mae: 0.0522 - val_loss: 0.0166 - val_mae: 0.0770\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0772\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0162 - val_mae: 0.0775\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0159 - val_mae: 0.0777\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0163 - val_mae: 0.0772\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0167 - val_mae: 0.0768\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0522 - val_loss: 0.0170 - val_mae: 0.0766\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0023 - mae: 0.0471 - val_loss: 0.0171 - val_mae: 0.0766\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0026 - mae: 0.0495 - val_loss: 0.0170 - val_mae: 0.0767\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0522 - val_loss: 0.0167 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0165 - val_mae: 0.0772\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0162 - val_mae: 0.0777\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0161 - val_mae: 0.0779\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0534 - val_loss: 0.0161 - val_mae: 0.0777\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0165 - val_mae: 0.0766\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0022 - mae: 0.0467 - val_loss: 0.0167 - val_mae: 0.0763\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0476 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0167 - val_mae: 0.0762\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0765\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0465 - val_loss: 0.0162 - val_mae: 0.0768\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0461 - val_loss: 0.0161 - val_mae: 0.0770\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0159 - val_mae: 0.0773\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0159 - val_mae: 0.0772\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0160 - val_mae: 0.0771\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0160 - val_mae: 0.0769\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0162 - val_mae: 0.0765\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0487 - val_loss: 0.0165 - val_mae: 0.0760\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0456 - val_loss: 0.0166 - val_mae: 0.0760\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0024 - mae: 0.0463 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0443 - val_loss: 0.0163 - val_mae: 0.0764\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0161 - val_mae: 0.0767\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0458 - val_loss: 0.0158 - val_mae: 0.0772\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0159 - val_mae: 0.0771\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0162 - val_mae: 0.0769\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0458 - val_loss: 0.0163 - val_mae: 0.0767\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0471 - val_loss: 0.0164 - val_mae: 0.0766\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0452 - val_loss: 0.0165 - val_mae: 0.0766\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0477 - val_loss: 0.0164 - val_mae: 0.0768\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0161 - val_mae: 0.0776\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0159 - val_mae: 0.0781\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0157 - val_mae: 0.0788\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0157 - val_mae: 0.0789\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0158 - val_mae: 0.0786\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0159 - val_mae: 0.0778\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0162 - val_mae: 0.0771\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0165 - val_mae: 0.0767\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0021 - mae: 0.0459 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0023 - mae: 0.0470 - val_loss: 0.0165 - val_mae: 0.0767\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0162 - val_mae: 0.0772\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0438 - val_loss: 0.0160 - val_mae: 0.0779\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0158 - val_mae: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:42:36,001] Trial 23 finished with value: 0.07843606173992157 and parameters: {'learning_rate': 0.0005810036430161862, 'weight_decay': 2.7611528612608203e-08}. Best is trial 0 with value: 0.0744893029332161.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0097 - mae: 0.1086 - val_loss: 0.0243 - val_mae: 0.1185\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0242 - val_mae: 0.1175\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0241 - val_mae: 0.1169\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0240 - val_mae: 0.1164\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1044 - val_loss: 0.0240 - val_mae: 0.1159\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1154\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0238 - val_mae: 0.1149\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0237 - val_mae: 0.1144\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1002 - val_loss: 0.0236 - val_mae: 0.1134\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1032 - val_loss: 0.0236 - val_mae: 0.1129\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0235 - val_mae: 0.1124\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0235 - val_mae: 0.1119\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0234 - val_mae: 0.1115\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1110\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0233 - val_mae: 0.1105\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0987 - val_loss: 0.0232 - val_mae: 0.1101\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1096\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1092\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0231 - val_mae: 0.1088\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0971 - val_loss: 0.0230 - val_mae: 0.1083\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0961 - val_loss: 0.0229 - val_mae: 0.1079\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0229 - val_mae: 0.1074\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1061\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0227 - val_mae: 0.1056\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0225 - val_mae: 0.1048\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0225 - val_mae: 0.1043\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0224 - val_mae: 0.1039\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0904 - val_loss: 0.0224 - val_mae: 0.1035\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0223 - val_mae: 0.1030\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0222 - val_mae: 0.1026\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0915 - val_loss: 0.0222 - val_mae: 0.1021\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0865 - val_loss: 0.0221 - val_mae: 0.1017\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0221 - val_mae: 0.1012\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0220 - val_mae: 0.1008\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0219 - val_mae: 0.1003\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0863 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0218 - val_mae: 0.0993\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0868 - val_loss: 0.0217 - val_mae: 0.0988\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0865 - val_loss: 0.0217 - val_mae: 0.0983\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0978\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0828 - val_loss: 0.0215 - val_mae: 0.0973\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0214 - val_mae: 0.0968\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0070 - mae: 0.0821 - val_loss: 0.0214 - val_mae: 0.0963\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0213 - val_mae: 0.0957\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0838 - val_loss: 0.0212 - val_mae: 0.0952\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0807 - val_loss: 0.0212 - val_mae: 0.0946\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0211 - val_mae: 0.0941\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0210 - val_mae: 0.0936\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0068 - mae: 0.0795 - val_loss: 0.0210 - val_mae: 0.0931\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0209 - val_mae: 0.0925\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0208 - val_mae: 0.0920\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0207 - val_mae: 0.0915\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0797 - val_loss: 0.0207 - val_mae: 0.0910\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0206 - val_mae: 0.0905\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0776 - val_loss: 0.0205 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0816 - val_loss: 0.0204 - val_mae: 0.0895\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0789 - val_loss: 0.0204 - val_mae: 0.0890\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0761 - val_loss: 0.0203 - val_mae: 0.0885\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0748 - val_loss: 0.0202 - val_mae: 0.0880\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0201 - val_mae: 0.0876\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0201 - val_mae: 0.0871\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0200 - val_mae: 0.0866\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0862\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0739 - val_loss: 0.0198 - val_mae: 0.0858\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0058 - mae: 0.0736 - val_loss: 0.0197 - val_mae: 0.0854\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0734 - val_loss: 0.0196 - val_mae: 0.0849\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0060 - mae: 0.0766 - val_loss: 0.0196 - val_mae: 0.0845\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0059 - mae: 0.0754 - val_loss: 0.0195 - val_mae: 0.0840\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0793 - val_loss: 0.0194 - val_mae: 0.0837\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0061 - mae: 0.0757 - val_loss: 0.0193 - val_mae: 0.0833\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0764 - val_loss: 0.0193 - val_mae: 0.0829\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0731 - val_loss: 0.0192 - val_mae: 0.0825\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0191 - val_mae: 0.0822\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0744 - val_loss: 0.0190 - val_mae: 0.0818\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0708 - val_loss: 0.0190 - val_mae: 0.0815\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0055 - mae: 0.0728 - val_loss: 0.0189 - val_mae: 0.0811\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0188 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0188 - val_mae: 0.0805\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0802\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0670 - val_loss: 0.0186 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0186 - val_mae: 0.0797\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0055 - mae: 0.0716 - val_loss: 0.0185 - val_mae: 0.0794\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0713 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0184 - val_mae: 0.0790\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0184 - val_mae: 0.0787\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0749 - val_loss: 0.0183 - val_mae: 0.0785\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0682 - val_loss: 0.0183 - val_mae: 0.0783\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0704 - val_loss: 0.0182 - val_mae: 0.0781\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0669 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0736 - val_loss: 0.0181 - val_mae: 0.0776\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0775\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0181 - val_mae: 0.0773\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0051 - mae: 0.0691 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0716 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0669 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0180 - val_mae: 0.0765\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0180 - val_mae: 0.0764\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0763\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0179 - val_mae: 0.0762\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0057 - mae: 0.0753 - val_loss: 0.0179 - val_mae: 0.0761\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0672 - val_loss: 0.0179 - val_mae: 0.0760\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0179 - val_mae: 0.0759\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0179 - val_mae: 0.0758\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0179 - val_mae: 0.0757\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0651 - val_loss: 0.0178 - val_mae: 0.0756\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0178 - val_mae: 0.0756\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0656 - val_loss: 0.0178 - val_mae: 0.0755\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0178 - val_mae: 0.0754\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0178 - val_mae: 0.0753\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0178 - val_mae: 0.0752\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0752\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0177 - val_mae: 0.0751\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0177 - val_mae: 0.0751\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0750\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0749 - val_loss: 0.0177 - val_mae: 0.0749\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0177 - val_mae: 0.0749\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0177 - val_mae: 0.0748\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0716 - val_loss: 0.0176 - val_mae: 0.0748\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0050 - mae: 0.0709 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0698 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0176 - val_mae: 0.0746\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0176 - val_mae: 0.0746\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0047 - mae: 0.0688 - val_loss: 0.0176 - val_mae: 0.0745\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0176 - val_mae: 0.0745\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - mae: 0.0693 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0176 - val_mae: 0.0743\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0743\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0176 - val_mae: 0.0743\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0743\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0176 - val_mae: 0.0743\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0175 - val_mae: 0.0742\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0742\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0605 - val_loss: 0.0175 - val_mae: 0.0743\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:42:55,532] Trial 24 finished with value: 0.07429321110248566 and parameters: {'learning_rate': 9.53308246804482e-05, 'weight_decay': 2.2151774334312568e-08}. Best is trial 24 with value: 0.07429321110248566.\n",
      "[I 2023-12-05 09:42:55,572] A new study created in RDB with name: no-name-b165e45f-04b1-4a6d-9032-d1f87459bb15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0240 - val_mae: 0.1160\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0237 - val_mae: 0.1134\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0088 - mae: 0.1012 - val_loss: 0.0234 - val_mae: 0.1110\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0231 - val_mae: 0.1087\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0926 - val_loss: 0.0226 - val_mae: 0.1045\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0900 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0074 - mae: 0.0903 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0218 - val_mae: 0.0979\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0069 - mae: 0.0851 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0821 - val_loss: 0.0210 - val_mae: 0.0909\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0207 - val_mae: 0.0886\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0062 - mae: 0.0779 - val_loss: 0.0204 - val_mae: 0.0863\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0812 - val_loss: 0.0201 - val_mae: 0.0841\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0769 - val_loss: 0.0198 - val_mae: 0.0825\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0737 - val_loss: 0.0195 - val_mae: 0.0810\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0192 - val_mae: 0.0798\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0730 - val_loss: 0.0190 - val_mae: 0.0790\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0185 - val_mae: 0.0783\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0752 - val_loss: 0.0183 - val_mae: 0.0783\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0181 - val_mae: 0.0784\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0725 - val_loss: 0.0180 - val_mae: 0.0784\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - mae: 0.0759 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0758 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0721 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0736 - val_loss: 0.0177 - val_mae: 0.0765\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0177 - val_mae: 0.0762\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0177 - val_mae: 0.0759\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0177 - val_mae: 0.0757\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0176 - val_mae: 0.0757\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0691 - val_loss: 0.0176 - val_mae: 0.0756\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0176 - val_mae: 0.0756\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0175 - val_mae: 0.0757\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0646 - val_loss: 0.0174 - val_mae: 0.0758\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0783\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0775\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0775\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0776\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0664 - val_loss: 0.0168 - val_mae: 0.0776\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0777\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0778\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0166 - val_mae: 0.0788\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0796\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0801\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0807\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0660 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.0809\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0552 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0165 - val_mae: 0.0807\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0164 - val_mae: 0.0804\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0793\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0164 - val_mae: 0.0789\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0163 - val_mae: 0.0790\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0593 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0162 - val_mae: 0.0792\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0161 - val_mae: 0.0795\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0630 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0795\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0159 - val_mae: 0.0804\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0158 - val_mae: 0.0808\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0159 - val_mae: 0.0798\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0159 - val_mae: 0.0796\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0159 - val_mae: 0.0795\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0158 - val_mae: 0.0797\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0158 - val_mae: 0.0799\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0157 - val_mae: 0.0807\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0156 - val_mae: 0.0812\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0156 - val_mae: 0.0805\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0156 - val_mae: 0.0798\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0515 - val_loss: 0.0156 - val_mae: 0.0795\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0157 - val_mae: 0.0789\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0157 - val_mae: 0.0785\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0157 - val_mae: 0.0785\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0787\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0157 - val_mae: 0.0787\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0157 - val_mae: 0.0788\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0156 - val_mae: 0.0806\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0529 - val_loss: 0.0156 - val_mae: 0.0811\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0155 - val_mae: 0.0815\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0027 - mae: 0.0533 - val_loss: 0.0155 - val_mae: 0.0817\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0155 - val_mae: 0.0817\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0154 - val_mae: 0.0816\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0524 - val_loss: 0.0154 - val_mae: 0.0818\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0153 - val_mae: 0.0825\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0152 - val_mae: 0.0825\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0152 - val_mae: 0.0822\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0500 - val_loss: 0.0151 - val_mae: 0.0828\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0151 - val_mae: 0.0832\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0520 - val_loss: 0.0150 - val_mae: 0.0835\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0150 - val_mae: 0.0830\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0501 - val_loss: 0.0150 - val_mae: 0.0829\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0150 - val_mae: 0.0826\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0150 - val_mae: 0.0824\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0151 - val_mae: 0.0812\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0151 - val_mae: 0.0806\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0151 - val_mae: 0.0808\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0151 - val_mae: 0.0811\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0025 - mae: 0.0508 - val_loss: 0.0151 - val_mae: 0.0811\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0027 - mae: 0.0521 - val_loss: 0.0151 - val_mae: 0.0818\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0151 - val_mae: 0.0833\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0150 - val_mae: 0.0849\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0149 - val_mae: 0.0854\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0149 - val_mae: 0.0841\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0149 - val_mae: 0.0826\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0490 - val_loss: 0.0148 - val_mae: 0.0827\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0534 - val_loss: 0.0147 - val_mae: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:43:10,233] Trial 0 finished with value: 0.0833246260881424 and parameters: {'learning_rate': 0.00030075697027188194, 'weight_decay': 7.263398644164309e-08}. Best is trial 0 with value: 0.0833246260881424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0106 - mae: 0.1116 - val_loss: 0.0267 - val_mae: 0.1230\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1069 - val_loss: 0.0267 - val_mae: 0.1230\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1108 - val_loss: 0.0267 - val_mae: 0.1229\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0106 - mae: 0.1119 - val_loss: 0.0267 - val_mae: 0.1229\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1104 - val_loss: 0.0267 - val_mae: 0.1228\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - mae: 0.1105 - val_loss: 0.0267 - val_mae: 0.1228\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1125 - val_loss: 0.0267 - val_mae: 0.1227\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1102 - val_loss: 0.0266 - val_mae: 0.1227\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0108 - mae: 0.1104 - val_loss: 0.0266 - val_mae: 0.1226\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0106 - mae: 0.1083 - val_loss: 0.0266 - val_mae: 0.1225\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1108 - val_loss: 0.0266 - val_mae: 0.1225\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1113 - val_loss: 0.0266 - val_mae: 0.1224\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - mae: 0.1097 - val_loss: 0.0266 - val_mae: 0.1224\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1071 - val_loss: 0.0266 - val_mae: 0.1223\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0107 - mae: 0.1124 - val_loss: 0.0266 - val_mae: 0.1223\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1093 - val_loss: 0.0266 - val_mae: 0.1222\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0110 - mae: 0.1146 - val_loss: 0.0265 - val_mae: 0.1221\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1076 - val_loss: 0.0265 - val_mae: 0.1221\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0106 - mae: 0.1116 - val_loss: 0.0265 - val_mae: 0.1220\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0110 - mae: 0.1132 - val_loss: 0.0265 - val_mae: 0.1220\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1084 - val_loss: 0.0265 - val_mae: 0.1219\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1085 - val_loss: 0.0265 - val_mae: 0.1219\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1098 - val_loss: 0.0265 - val_mae: 0.1218\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1081 - val_loss: 0.0265 - val_mae: 0.1217\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0106 - mae: 0.1100 - val_loss: 0.0265 - val_mae: 0.1217\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0264 - val_mae: 0.1216\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1109 - val_loss: 0.0264 - val_mae: 0.1216\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0105 - mae: 0.1083 - val_loss: 0.0264 - val_mae: 0.1215\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1105 - val_loss: 0.0264 - val_mae: 0.1215\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1136 - val_loss: 0.0264 - val_mae: 0.1214\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0104 - mae: 0.1088 - val_loss: 0.0264 - val_mae: 0.1214\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1121 - val_loss: 0.0264 - val_mae: 0.1213\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1111 - val_loss: 0.0264 - val_mae: 0.1212\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1093 - val_loss: 0.0264 - val_mae: 0.1212\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1052 - val_loss: 0.0263 - val_mae: 0.1211\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1105 - val_loss: 0.0263 - val_mae: 0.1211\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - mae: 0.1065 - val_loss: 0.0263 - val_mae: 0.1210\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1099 - val_loss: 0.0263 - val_mae: 0.1210\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1096 - val_loss: 0.0263 - val_mae: 0.1209\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1042 - val_loss: 0.0263 - val_mae: 0.1209\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1083 - val_loss: 0.0263 - val_mae: 0.1208\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - mae: 0.1107 - val_loss: 0.0263 - val_mae: 0.1208\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1082 - val_loss: 0.0263 - val_mae: 0.1207\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0106 - mae: 0.1106 - val_loss: 0.0262 - val_mae: 0.1207\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1083 - val_loss: 0.0262 - val_mae: 0.1206\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1104 - val_loss: 0.0262 - val_mae: 0.1205\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0107 - mae: 0.1093 - val_loss: 0.0262 - val_mae: 0.1205\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1115 - val_loss: 0.0262 - val_mae: 0.1204\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1095 - val_loss: 0.0262 - val_mae: 0.1204\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1062 - val_loss: 0.0262 - val_mae: 0.1203\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1077 - val_loss: 0.0262 - val_mae: 0.1203\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1097 - val_loss: 0.0262 - val_mae: 0.1202\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1071 - val_loss: 0.0262 - val_mae: 0.1202\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1085 - val_loss: 0.0261 - val_mae: 0.1201\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1080 - val_loss: 0.0261 - val_mae: 0.1201\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0261 - val_mae: 0.1200\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0100 - mae: 0.1058 - val_loss: 0.0261 - val_mae: 0.1200\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1072 - val_loss: 0.0261 - val_mae: 0.1199\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1071 - val_loss: 0.0261 - val_mae: 0.1198\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1076 - val_loss: 0.0261 - val_mae: 0.1198\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0105 - mae: 0.1097 - val_loss: 0.0261 - val_mae: 0.1197\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0261 - val_mae: 0.1197\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1087 - val_loss: 0.0261 - val_mae: 0.1196\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1080 - val_loss: 0.0260 - val_mae: 0.1196\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1082 - val_loss: 0.0260 - val_mae: 0.1195\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1073 - val_loss: 0.0260 - val_mae: 0.1195\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1094 - val_loss: 0.0260 - val_mae: 0.1194\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1063 - val_loss: 0.0260 - val_mae: 0.1194\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0260 - val_mae: 0.1193\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1045 - val_loss: 0.0260 - val_mae: 0.1193\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1072 - val_loss: 0.0260 - val_mae: 0.1192\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0260 - val_mae: 0.1192\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0107 - mae: 0.1090 - val_loss: 0.0260 - val_mae: 0.1191\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0107 - mae: 0.1098 - val_loss: 0.0259 - val_mae: 0.1191\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1052 - val_loss: 0.0259 - val_mae: 0.1190\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0103 - mae: 0.1084 - val_loss: 0.0259 - val_mae: 0.1190\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1063 - val_loss: 0.0259 - val_mae: 0.1189\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1072 - val_loss: 0.0259 - val_mae: 0.1189\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1069 - val_loss: 0.0259 - val_mae: 0.1188\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1083 - val_loss: 0.0259 - val_mae: 0.1188\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0104 - mae: 0.1080 - val_loss: 0.0259 - val_mae: 0.1187\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1061 - val_loss: 0.0259 - val_mae: 0.1187\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1116 - val_loss: 0.0259 - val_mae: 0.1186\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1039 - val_loss: 0.0259 - val_mae: 0.1186\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1073 - val_loss: 0.0258 - val_mae: 0.1186\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1060 - val_loss: 0.0258 - val_mae: 0.1185\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1090 - val_loss: 0.0258 - val_mae: 0.1185\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1051 - val_loss: 0.0258 - val_mae: 0.1184\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1057 - val_loss: 0.0258 - val_mae: 0.1184\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1114 - val_loss: 0.0258 - val_mae: 0.1183\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0100 - mae: 0.1076 - val_loss: 0.0258 - val_mae: 0.1183\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1062 - val_loss: 0.0258 - val_mae: 0.1182\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0258 - val_mae: 0.1182\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1076 - val_loss: 0.0258 - val_mae: 0.1181\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0258 - val_mae: 0.1181\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1089 - val_loss: 0.0257 - val_mae: 0.1180\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1069 - val_loss: 0.0257 - val_mae: 0.1180\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1021 - val_loss: 0.0257 - val_mae: 0.1179\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1093 - val_loss: 0.0257 - val_mae: 0.1179\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0257 - val_mae: 0.1178\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0257 - val_mae: 0.1178\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1090 - val_loss: 0.0257 - val_mae: 0.1177\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1096 - val_loss: 0.0257 - val_mae: 0.1177\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1096 - val_loss: 0.0257 - val_mae: 0.1176\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1066 - val_loss: 0.0257 - val_mae: 0.1176\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1078 - val_loss: 0.0257 - val_mae: 0.1176\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1034 - val_loss: 0.0256 - val_mae: 0.1175\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1048 - val_loss: 0.0256 - val_mae: 0.1175\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1077 - val_loss: 0.0256 - val_mae: 0.1174\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1043 - val_loss: 0.0256 - val_mae: 0.1174\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1084 - val_loss: 0.0256 - val_mae: 0.1173\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1052 - val_loss: 0.0256 - val_mae: 0.1173\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1030 - val_loss: 0.0256 - val_mae: 0.1172\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0099 - mae: 0.1058 - val_loss: 0.0256 - val_mae: 0.1172\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1069 - val_loss: 0.0256 - val_mae: 0.1171\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1042 - val_loss: 0.0256 - val_mae: 0.1171\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1040 - val_loss: 0.0256 - val_mae: 0.1171\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.0990 - val_loss: 0.0256 - val_mae: 0.1170\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1037 - val_loss: 0.0255 - val_mae: 0.1170\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1049 - val_loss: 0.0255 - val_mae: 0.1169\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1061 - val_loss: 0.0255 - val_mae: 0.1169\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1062 - val_loss: 0.0255 - val_mae: 0.1168\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1023 - val_loss: 0.0255 - val_mae: 0.1168\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1051 - val_loss: 0.0255 - val_mae: 0.1167\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1028 - val_loss: 0.0255 - val_mae: 0.1167\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0095 - mae: 0.1021 - val_loss: 0.0255 - val_mae: 0.1167\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1030 - val_loss: 0.0255 - val_mae: 0.1166\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1028 - val_loss: 0.0255 - val_mae: 0.1166\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1041 - val_loss: 0.0255 - val_mae: 0.1165\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1052 - val_loss: 0.0255 - val_mae: 0.1165\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0254 - val_mae: 0.1164\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1023 - val_loss: 0.0254 - val_mae: 0.1164\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1045 - val_loss: 0.0254 - val_mae: 0.1163\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1043 - val_loss: 0.0254 - val_mae: 0.1163\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0254 - val_mae: 0.1162\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0254 - val_mae: 0.1162\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1041 - val_loss: 0.0254 - val_mae: 0.1162\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1035 - val_loss: 0.0254 - val_mae: 0.1161\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1051 - val_loss: 0.0254 - val_mae: 0.1161\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1023 - val_loss: 0.0254 - val_mae: 0.1160\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1057 - val_loss: 0.0254 - val_mae: 0.1160\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1026 - val_loss: 0.0254 - val_mae: 0.1159\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0253 - val_mae: 0.1159\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1061 - val_loss: 0.0253 - val_mae: 0.1159\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1046 - val_loss: 0.0253 - val_mae: 0.1158\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1031 - val_loss: 0.0253 - val_mae: 0.1158\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0253 - val_mae: 0.1157\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1012 - val_loss: 0.0253 - val_mae: 0.1157\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1042 - val_loss: 0.0253 - val_mae: 0.1156\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0253 - val_mae: 0.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:43:24,773] Trial 1 finished with value: 0.11559619009494781 and parameters: {'learning_rate': 4.284197666764374e-06, 'weight_decay': 0.000303493556391638}. Best is trial 0 with value: 0.0833246260881424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0102 - mae: 0.1082 - val_loss: 0.0234 - val_mae: 0.1120\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0231 - val_mae: 0.1087\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0227 - val_mae: 0.1054\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0942 - val_loss: 0.0224 - val_mae: 0.1024\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0874 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0215 - val_mae: 0.0951\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0822 - val_loss: 0.0211 - val_mae: 0.0931\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0824 - val_loss: 0.0208 - val_mae: 0.0912\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0205 - val_mae: 0.0895\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0809 - val_loss: 0.0202 - val_mae: 0.0881\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0800 - val_loss: 0.0200 - val_mae: 0.0868\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0730 - val_loss: 0.0197 - val_mae: 0.0853\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - mae: 0.0751 - val_loss: 0.0194 - val_mae: 0.0838\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0191 - val_mae: 0.0825\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0188 - val_mae: 0.0816\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0186 - val_mae: 0.0807\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0718 - val_loss: 0.0184 - val_mae: 0.0801\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0727 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0716 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0710 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0622 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0760\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0692 - val_loss: 0.0173 - val_mae: 0.0757\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0754\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0752\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0752\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0661 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0172 - val_mae: 0.0753\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0755\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0759\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0765\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0168 - val_mae: 0.0775\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0658 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0786\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0774\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0164 - val_mae: 0.0771\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0164 - val_mae: 0.0770\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0163 - val_mae: 0.0772\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0775\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0162 - val_mae: 0.0777\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0162 - val_mae: 0.0775\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0626 - val_loss: 0.0163 - val_mae: 0.0774\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0163 - val_mae: 0.0774\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0163 - val_mae: 0.0776\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0528 - val_loss: 0.0163 - val_mae: 0.0779\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0783\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0160 - val_mae: 0.0796\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0158 - val_mae: 0.0795\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0158 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0159 - val_mae: 0.0785\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0159 - val_mae: 0.0782\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0160 - val_mae: 0.0781\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0160 - val_mae: 0.0781\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0159 - val_mae: 0.0782\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0159 - val_mae: 0.0784\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0158 - val_mae: 0.0785\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0157 - val_mae: 0.0794\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0155 - val_mae: 0.0803\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0658 - val_loss: 0.0155 - val_mae: 0.0806\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0155 - val_mae: 0.0803\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0155 - val_mae: 0.0801\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0155 - val_mae: 0.0797\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0155 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0156 - val_mae: 0.0789\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0155 - val_mae: 0.0788\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0155 - val_mae: 0.0786\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0027 - mae: 0.0514 - val_loss: 0.0155 - val_mae: 0.0788\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0154 - val_mae: 0.0788\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0154 - val_mae: 0.0788\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0527 - val_loss: 0.0154 - val_mae: 0.0791\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0154 - val_mae: 0.0793\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0154 - val_mae: 0.0797\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0522 - val_loss: 0.0154 - val_mae: 0.0802\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0153 - val_mae: 0.0809\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0152 - val_mae: 0.0813\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0569 - val_loss: 0.0152 - val_mae: 0.0815\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0151 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0152 - val_mae: 0.0808\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0152 - val_mae: 0.0801\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0153 - val_mae: 0.0794\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0154 - val_mae: 0.0784\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0522 - val_loss: 0.0155 - val_mae: 0.0780\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0155 - val_mae: 0.0782\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0154 - val_mae: 0.0797\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0545 - val_loss: 0.0153 - val_mae: 0.0807\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0153 - val_mae: 0.0814\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0153 - val_mae: 0.0824\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0153 - val_mae: 0.0831\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0024 - mae: 0.0509 - val_loss: 0.0153 - val_mae: 0.0836\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0153 - val_mae: 0.0837\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0154 - val_mae: 0.0827\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0154 - val_mae: 0.0819\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0155 - val_mae: 0.0814\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0154 - val_mae: 0.0813\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0153 - val_mae: 0.0816\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0152 - val_mae: 0.0821\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0151 - val_mae: 0.0832\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0150 - val_mae: 0.0843\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0149 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0518 - val_loss: 0.0149 - val_mae: 0.0860\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0149 - val_mae: 0.0870\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0149 - val_mae: 0.0864\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0536 - val_loss: 0.0151 - val_mae: 0.0845\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - mae: 0.0537 - val_loss: 0.0152 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0152 - val_mae: 0.0825\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0152 - val_mae: 0.0829\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0151 - val_mae: 0.0839\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0150 - val_mae: 0.0854\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0149 - val_mae: 0.0872\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0149 - val_mae: 0.0889\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0148 - val_mae: 0.0905\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0148 - val_mae: 0.0907\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0026 - mae: 0.0545 - val_loss: 0.0149 - val_mae: 0.0895\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0150 - val_mae: 0.0885\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0151 - val_mae: 0.0871\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0152 - val_mae: 0.0861\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0152 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0151 - val_mae: 0.0861\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0150 - val_mae: 0.0873\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0149 - val_mae: 0.0887\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0518 - val_loss: 0.0148 - val_mae: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:43:39,328] Trial 2 finished with value: 0.09023559093475342 and parameters: {'learning_rate': 0.00027981652510657444, 'weight_decay': 3.2823866720836136e-08}. Best is trial 0 with value: 0.0833246260881424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1203\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1202\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0239 - val_mae: 0.1200\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1199\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1197\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0238 - val_mae: 0.1196\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1194\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1192\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1191\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1189\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1054 - val_loss: 0.0237 - val_mae: 0.1187\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1186\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1184\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0236 - val_mae: 0.1183\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0236 - val_mae: 0.1181\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0236 - val_mae: 0.1179\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0236 - val_mae: 0.1178\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0235 - val_mae: 0.1176\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0235 - val_mae: 0.1175\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0235 - val_mae: 0.1173\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0235 - val_mae: 0.1171\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1024 - val_loss: 0.0234 - val_mae: 0.1170\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0234 - val_mae: 0.1168\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1167\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0234 - val_mae: 0.1165\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0234 - val_mae: 0.1163\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0233 - val_mae: 0.1162\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0233 - val_mae: 0.1160\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0233 - val_mae: 0.1159\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0084 - mae: 0.0976 - val_loss: 0.0233 - val_mae: 0.1157\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0233 - val_mae: 0.1156\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0232 - val_mae: 0.1154\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0232 - val_mae: 0.1153\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0971 - val_loss: 0.0232 - val_mae: 0.1151\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1149\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0231 - val_mae: 0.1148\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0997 - val_loss: 0.0231 - val_mae: 0.1146\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0231 - val_mae: 0.1145\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1143\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0231 - val_mae: 0.1142\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.1001 - val_loss: 0.0230 - val_mae: 0.1140\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - mae: 0.1005 - val_loss: 0.0230 - val_mae: 0.1139\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0230 - val_mae: 0.1137\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0230 - val_mae: 0.1136\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0230 - val_mae: 0.1134\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0964 - val_loss: 0.0229 - val_mae: 0.1133\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0956 - val_loss: 0.0229 - val_mae: 0.1131\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0229 - val_mae: 0.1130\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0229 - val_mae: 0.1128\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0972 - val_loss: 0.0228 - val_mae: 0.1127\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0972 - val_loss: 0.0228 - val_mae: 0.1125\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0228 - val_mae: 0.1124\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0991 - val_loss: 0.0228 - val_mae: 0.1122\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0228 - val_mae: 0.1120\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0980 - val_loss: 0.0227 - val_mae: 0.1119\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0227 - val_mae: 0.1117\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0227 - val_mae: 0.1116\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0990 - val_loss: 0.0227 - val_mae: 0.1114\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1001 - val_loss: 0.0227 - val_mae: 0.1113\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0226 - val_mae: 0.1112\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0226 - val_mae: 0.1110\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0947 - val_loss: 0.0226 - val_mae: 0.1109\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0226 - val_mae: 0.1108\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0226 - val_mae: 0.1106\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0225 - val_mae: 0.1105\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0225 - val_mae: 0.1103\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0225 - val_mae: 0.1102\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0225 - val_mae: 0.1101\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0225 - val_mae: 0.1099\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0225 - val_mae: 0.1098\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0224 - val_mae: 0.1097\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0224 - val_mae: 0.1095\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0224 - val_mae: 0.1094\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0967 - val_loss: 0.0224 - val_mae: 0.1092\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0224 - val_mae: 0.1091\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0915 - val_loss: 0.0223 - val_mae: 0.1090\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0223 - val_mae: 0.1088\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0223 - val_mae: 0.1087\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0079 - mae: 0.0952 - val_loss: 0.0223 - val_mae: 0.1086\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0223 - val_mae: 0.1084\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0910 - val_loss: 0.0222 - val_mae: 0.1083\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0946 - val_loss: 0.0222 - val_mae: 0.1081\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0930 - val_loss: 0.0222 - val_mae: 0.1080\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0222 - val_mae: 0.1079\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0222 - val_mae: 0.1077\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0937 - val_loss: 0.0221 - val_mae: 0.1076\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0221 - val_mae: 0.1074\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0221 - val_mae: 0.1073\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0221 - val_mae: 0.1071\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0911 - val_loss: 0.0221 - val_mae: 0.1070\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0221 - val_mae: 0.1069\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0906 - val_loss: 0.0220 - val_mae: 0.1067\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0910 - val_loss: 0.0220 - val_mae: 0.1066\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0897 - val_loss: 0.0220 - val_mae: 0.1064\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0220 - val_mae: 0.1063\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0220 - val_mae: 0.1061\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0219 - val_mae: 0.1060\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0219 - val_mae: 0.1059\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0219 - val_mae: 0.1057\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0081 - mae: 0.0931 - val_loss: 0.0219 - val_mae: 0.1056\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0219 - val_mae: 0.1055\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0879 - val_loss: 0.0218 - val_mae: 0.1053\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0895 - val_loss: 0.0218 - val_mae: 0.1052\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0218 - val_mae: 0.1050\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0218 - val_mae: 0.1049\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0218 - val_mae: 0.1047\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0901 - val_loss: 0.0218 - val_mae: 0.1046\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0900 - val_loss: 0.0217 - val_mae: 0.1044\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0892 - val_loss: 0.0217 - val_mae: 0.1043\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0893 - val_loss: 0.0217 - val_mae: 0.1042\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0217 - val_mae: 0.1040\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0071 - mae: 0.0881 - val_loss: 0.0217 - val_mae: 0.1039\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0216 - val_mae: 0.1037\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0921 - val_loss: 0.0216 - val_mae: 0.1036\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0216 - val_mae: 0.1034\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0216 - val_mae: 0.1032\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0078 - mae: 0.0891 - val_loss: 0.0216 - val_mae: 0.1031\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0076 - mae: 0.0902 - val_loss: 0.0215 - val_mae: 0.1029\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0077 - mae: 0.0908 - val_loss: 0.0215 - val_mae: 0.1028\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0215 - val_mae: 0.1026\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0215 - val_mae: 0.1025\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0892 - val_loss: 0.0215 - val_mae: 0.1024\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0910 - val_loss: 0.0214 - val_mae: 0.1022\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0910 - val_loss: 0.0214 - val_mae: 0.1021\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0214 - val_mae: 0.1019\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0214 - val_mae: 0.1018\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0895 - val_loss: 0.0214 - val_mae: 0.1016\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0871 - val_loss: 0.0213 - val_mae: 0.1015\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0874 - val_loss: 0.0213 - val_mae: 0.1013\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0855 - val_loss: 0.0213 - val_mae: 0.1012\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0213 - val_mae: 0.1010\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0213 - val_mae: 0.1008\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0868 - val_loss: 0.0213 - val_mae: 0.1007\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0212 - val_mae: 0.1005\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0212 - val_mae: 0.1004\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0212 - val_mae: 0.1002\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0212 - val_mae: 0.1001\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0212 - val_mae: 0.0999\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0211 - val_mae: 0.0998\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0846 - val_loss: 0.0211 - val_mae: 0.0996\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0864 - val_loss: 0.0211 - val_mae: 0.0995\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0887 - val_loss: 0.0211 - val_mae: 0.0993\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0873 - val_loss: 0.0211 - val_mae: 0.0992\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0210 - val_mae: 0.0990\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0210 - val_mae: 0.0989\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0859 - val_loss: 0.0210 - val_mae: 0.0988\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0210 - val_mae: 0.0986\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0873 - val_loss: 0.0210 - val_mae: 0.0984\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0853 - val_loss: 0.0209 - val_mae: 0.0983\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0209 - val_mae: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:43:53,798] Trial 3 finished with value: 0.09814151376485825 and parameters: {'learning_rate': 1.465987973817285e-05, 'weight_decay': 4.929290764555151e-07}. Best is trial 0 with value: 0.0833246260881424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0086 - mae: 0.0976 - val_loss: 0.0232 - val_mae: 0.1060\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0229 - val_mae: 0.1033\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0895 - val_loss: 0.0226 - val_mae: 0.1008\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0891 - val_loss: 0.0223 - val_mae: 0.0984\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0069 - mae: 0.0851 - val_loss: 0.0221 - val_mae: 0.0961\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0846 - val_loss: 0.0218 - val_mae: 0.0943\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0816 - val_loss: 0.0213 - val_mae: 0.0912\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0900\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0208 - val_mae: 0.0893\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0206 - val_mae: 0.0888\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0786 - val_loss: 0.0203 - val_mae: 0.0884\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0755 - val_loss: 0.0201 - val_mae: 0.0881\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0744 - val_loss: 0.0199 - val_mae: 0.0877\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0794 - val_loss: 0.0197 - val_mae: 0.0874\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0793 - val_loss: 0.0195 - val_mae: 0.0870\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0706 - val_loss: 0.0193 - val_mae: 0.0867\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0808 - val_loss: 0.0192 - val_mae: 0.0863\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0768 - val_loss: 0.0190 - val_mae: 0.0857\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0700 - val_loss: 0.0189 - val_mae: 0.0850\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0059 - mae: 0.0793 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0748 - val_loss: 0.0188 - val_mae: 0.0835\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0780 - val_loss: 0.0187 - val_mae: 0.0827\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0187 - val_mae: 0.0819\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0736 - val_loss: 0.0187 - val_mae: 0.0812\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0697 - val_loss: 0.0186 - val_mae: 0.0807\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0750 - val_loss: 0.0186 - val_mae: 0.0801\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0697 - val_loss: 0.0185 - val_mae: 0.0796\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0703 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0679 - val_loss: 0.0184 - val_mae: 0.0788\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0182 - val_mae: 0.0780\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0180 - val_mae: 0.0774\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0048 - mae: 0.0687 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0658 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0671 - val_loss: 0.0174 - val_mae: 0.0775\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0658 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0776\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0671 - val_loss: 0.0172 - val_mae: 0.0776\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0675 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0640 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0671 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0776\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0556 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0643 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0775\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0164 - val_mae: 0.0782\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0780\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0782\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0613 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0163 - val_mae: 0.0783\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0163 - val_mae: 0.0784\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0162 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0162 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0544 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0788\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0784\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0162 - val_mae: 0.0782\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0162 - val_mae: 0.0782\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0162 - val_mae: 0.0783\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0162 - val_mae: 0.0784\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0161 - val_mae: 0.0786\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0161 - val_mae: 0.0787\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - mae: 0.0597 - val_loss: 0.0161 - val_mae: 0.0787\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0787\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0161 - val_mae: 0.0786\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0160 - val_mae: 0.0786\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0160 - val_mae: 0.0781\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0568 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0159 - val_mae: 0.0782\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0540 - val_loss: 0.0159 - val_mae: 0.0786\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0158 - val_mae: 0.0792\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0158 - val_mae: 0.0797\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0157 - val_mae: 0.0802\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0157 - val_mae: 0.0802\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0157 - val_mae: 0.0802\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0157 - val_mae: 0.0802\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0798\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0158 - val_mae: 0.0793\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0158 - val_mae: 0.0791\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0158 - val_mae: 0.0788\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0158 - val_mae: 0.0785\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0158 - val_mae: 0.0785\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0790\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0156 - val_mae: 0.0803\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0155 - val_mae: 0.0807\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0155 - val_mae: 0.0800\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0156 - val_mae: 0.0789\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0157 - val_mae: 0.0780\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0157 - val_mae: 0.0776\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0156 - val_mae: 0.0776\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0156 - val_mae: 0.0777\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0778\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0536 - val_loss: 0.0154 - val_mae: 0.0787\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0153 - val_mae: 0.0799\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0152 - val_mae: 0.0807\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0152 - val_mae: 0.0813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:44:08,369] Trial 4 finished with value: 0.08132396638393402 and parameters: {'learning_rate': 0.00022635662555669326, 'weight_decay': 0.002444733492748874}. Best is trial 4 with value: 0.08132396638393402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1491\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0163 - mae: 0.1419 - val_loss: 0.0200 - val_mae: 0.0873\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0740 - val_loss: 0.0180 - val_mae: 0.0825\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0163 - val_mae: 0.0890\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0759 - val_loss: 0.0163 - val_mae: 0.0891\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0695 - val_loss: 0.0166 - val_mae: 0.0898\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0683 - val_loss: 0.0169 - val_mae: 0.0920\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.0930\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0930\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0924\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0661 - val_loss: 0.0174 - val_mae: 0.0905\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0886\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0862\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0821\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0164 - val_mae: 0.0918\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0611 - val_loss: 0.0164 - val_mae: 0.0924\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0164 - val_mae: 0.0910\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0612 - val_loss: 0.0164 - val_mae: 0.0887\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0869\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0166 - val_mae: 0.0884\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0904\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0923\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0646 - val_loss: 0.0170 - val_mae: 0.0925\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0908\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0888\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0872\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0529 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0165 - val_mae: 0.0887\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0165 - val_mae: 0.0893\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0166 - val_mae: 0.0935\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0952\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0966\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0977\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0988\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0986\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0173 - val_mae: 0.0987\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0174 - val_mae: 0.0986\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0174 - val_mae: 0.0970\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - mae: 0.0614 - val_loss: 0.0173 - val_mae: 0.0944\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0172 - val_mae: 0.0917\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0172 - val_mae: 0.0899\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0171 - val_mae: 0.0920\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0928\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0909\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0871\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0165 - val_mae: 0.0890\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0644 - val_loss: 0.0165 - val_mae: 0.0892\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0166 - val_mae: 0.0907\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0924\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0930\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0518 - val_loss: 0.0171 - val_mae: 0.0939\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0173 - val_mae: 0.0974\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0173 - val_mae: 0.0972\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0953\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0926\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0906\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0168 - val_mae: 0.0901\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0168 - val_mae: 0.0908\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0917\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0921\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0922\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0908\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0168 - val_mae: 0.0921\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0938\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0941\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0170 - val_mae: 0.0944\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0955\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0981\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0172 - val_mae: 0.1000\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0990\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0171 - val_mae: 0.0970\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0936\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0170 - val_mae: 0.0922\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0170 - val_mae: 0.0938\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0169 - val_mae: 0.0957\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0982\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0965\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0938\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0918\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0922\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0918\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0899\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0170 - val_mae: 0.0882\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0171 - val_mae: 0.0876\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0879\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0525 - val_loss: 0.0170 - val_mae: 0.0893\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0916\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0168 - val_mae: 0.0947\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0167 - val_mae: 0.0972\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0960\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0938\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0169 - val_mae: 0.0949\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0171 - val_mae: 0.0996\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0994\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0960\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0536 - val_loss: 0.0172 - val_mae: 0.0947\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0928\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0552 - val_loss: 0.0167 - val_mae: 0.0937\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0520 - val_loss: 0.0166 - val_mae: 0.0961\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0166 - val_mae: 0.0984\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0976\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.1000\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.1011\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0998\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0174 - val_mae: 0.0984\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0611 - val_loss: 0.0175 - val_mae: 0.0950\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0509 - val_loss: 0.0174 - val_mae: 0.0940\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0172 - val_mae: 0.0934\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0502 - val_loss: 0.0170 - val_mae: 0.0956\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0978\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0516 - val_loss: 0.0168 - val_mae: 0.0984\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0955\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0523 - val_loss: 0.0164 - val_mae: 0.0926\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0163 - val_mae: 0.0934\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0163 - val_mae: 0.0929\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0167 - val_mae: 0.0945\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0171 - val_mae: 0.0976\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0980\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0943\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0903\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0167 - val_mae: 0.0881\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0165 - val_mae: 0.0874\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0528 - val_loss: 0.0164 - val_mae: 0.0922\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0966\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0165 - val_mae: 0.0982\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0629 - val_loss: 0.0165 - val_mae: 0.0956\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0540 - val_loss: 0.0165 - val_mae: 0.0930\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0167 - val_mae: 0.0936\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0937\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0167 - val_mae: 0.0943\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0614 - val_loss: 0.0166 - val_mae: 0.0930\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0907\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0166 - val_mae: 0.0877\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0505 - val_loss: 0.0166 - val_mae: 0.0875\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0870\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0504 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0163 - val_mae: 0.0880\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0164 - val_mae: 0.0888\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0904\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0167 - val_mae: 0.0911\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0163 - val_mae: 0.0916\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0160 - val_mae: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:44:22,917] Trial 5 finished with value: 0.09268965572118759 and parameters: {'learning_rate': 0.012684650819279603, 'weight_decay': 7.065688888637544e-06}. Best is trial 4 with value: 0.08132396638393402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0090 - mae: 0.1027 - val_loss: 2.1295 - val_mae: 2.6130\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.8367 - mae: 3.3132 - val_loss: 0.0236 - val_mae: 0.1129\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0254 - val_mae: 0.1274\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0147 - mae: 0.1290 - val_loss: 0.0252 - val_mae: 0.1178\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - mae: 0.1121 - val_loss: 0.0201 - val_mae: 0.0902\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0240 - val_mae: 0.1651\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0184 - mae: 0.1561 - val_loss: 0.0201 - val_mae: 0.1180\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0938 - val_loss: 0.0203 - val_mae: 0.1159\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0930 - val_loss: 0.0204 - val_mae: 0.1200\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0064 - mae: 0.0907 - val_loss: 0.0194 - val_mae: 0.1091\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0849 - val_loss: 0.0188 - val_mae: 0.0975\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0946 - val_loss: 0.0183 - val_mae: 0.0965\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0844 - val_loss: 0.0181 - val_mae: 0.0974\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0893 - val_loss: 0.0177 - val_mae: 0.0899\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0797 - val_loss: 0.0172 - val_mae: 0.0868\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0789 - val_loss: 0.0166 - val_mae: 0.0974\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0842 - val_loss: 0.0169 - val_mae: 0.0878\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0808 - val_loss: 0.0177 - val_mae: 0.0836\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0850 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0744 - val_loss: 0.0165 - val_mae: 0.0946\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0772 - val_loss: 0.0166 - val_mae: 0.1023\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0817 - val_loss: 0.0164 - val_mae: 0.0881\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0692 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0685 - val_loss: 0.0173 - val_mae: 0.0752\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0649 - val_loss: 0.0165 - val_mae: 0.0805\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0712 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0718 - val_loss: 0.0164 - val_mae: 0.0835\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0744 - val_loss: 0.0163 - val_mae: 0.0929\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0785 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0668 - val_loss: 0.0165 - val_mae: 0.0850\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0713 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0682 - val_loss: 0.0166 - val_mae: 0.0883\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0654 - val_loss: 0.0167 - val_mae: 0.0882\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0683 - val_loss: 0.0168 - val_mae: 0.0900\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mae: 0.0721 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0752 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0664 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0922\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0717 - val_loss: 0.0167 - val_mae: 0.0964\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0777 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0657 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0678 - val_loss: 0.0177 - val_mae: 0.0800\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0692 - val_loss: 0.0167 - val_mae: 0.0912\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0642 - val_loss: 0.0166 - val_mae: 0.0956\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0706 - val_loss: 0.0166 - val_mae: 0.0926\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0682 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0166 - val_mae: 0.0911\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0660 - val_loss: 0.0166 - val_mae: 0.0931\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0656 - val_loss: 0.0167 - val_mae: 0.0889\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0669 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0658 - val_loss: 0.0176 - val_mae: 0.0773\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0746 - val_loss: 0.0165 - val_mae: 0.0882\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0643 - val_loss: 0.0165 - val_mae: 0.0892\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0692 - val_loss: 0.0165 - val_mae: 0.0885\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0167 - val_mae: 0.0826\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0700 - val_loss: 0.0168 - val_mae: 0.0816\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0166 - val_mae: 0.0864\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0642 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0868\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0661 - val_loss: 0.0166 - val_mae: 0.0907\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0681 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0892\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0696 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0890\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0040 - mae: 0.0684 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0797\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0165 - val_mae: 0.0866\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0165 - val_mae: 0.0896\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0634 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0818\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0166 - val_mae: 0.0896\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0689 - val_loss: 0.0165 - val_mae: 0.0915\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0689 - val_loss: 0.0165 - val_mae: 0.0876\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0722 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0806\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0164 - val_mae: 0.0865\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0694 - val_loss: 0.0168 - val_mae: 0.0801\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0813\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0918\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0675 - val_loss: 0.0167 - val_mae: 0.0929\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0691 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0176 - val_mae: 0.0794\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0864\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0920\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0934\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0719 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0836\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0681 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0031 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0032 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0957\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0621 - val_loss: 0.0166 - val_mae: 0.0956\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0748 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0676 - val_loss: 0.0166 - val_mae: 0.0933\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.1021\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0730 - val_loss: 0.0166 - val_mae: 0.0920\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0045 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0951\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0688 - val_loss: 0.0165 - val_mae: 0.0887\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0565 - val_loss: 0.0167 - val_mae: 0.0825\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0164 - val_mae: 0.0917\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0722 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0637 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0906\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0897\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0661 - val_loss: 0.0175 - val_mae: 0.0821\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0858\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0171 - val_mae: 0.0904\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0665 - val_loss: 0.0170 - val_mae: 0.0882\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0863\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0164 - val_mae: 0.0885\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0705 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:44:37,431] Trial 6 finished with value: 0.0817723199725151 and parameters: {'learning_rate': 0.023920893273295548, 'weight_decay': 0.0003439743322811436}. Best is trial 4 with value: 0.08132396638393402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0108 - mae: 0.1174 - val_loss: 0.0242 - val_mae: 0.1230\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0240 - val_mae: 0.1215\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0238 - val_mae: 0.1200\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0235 - val_mae: 0.1171\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0234 - val_mae: 0.1157\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0232 - val_mae: 0.1143\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0231 - val_mae: 0.1131\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1118\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0229 - val_mae: 0.1106\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0228 - val_mae: 0.1095\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0080 - mae: 0.0959 - val_loss: 0.0227 - val_mae: 0.1084\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0226 - val_mae: 0.1073\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0225 - val_mae: 0.1062\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0920 - val_loss: 0.0224 - val_mae: 0.1051\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0915 - val_loss: 0.0223 - val_mae: 0.1041\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0222 - val_mae: 0.1031\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0221 - val_mae: 0.1021\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0220 - val_mae: 0.1011\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0219 - val_mae: 0.1001\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0875 - val_loss: 0.0218 - val_mae: 0.0992\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0069 - mae: 0.0851 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0216 - val_mae: 0.0972\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0214 - val_mae: 0.0963\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0833 - val_loss: 0.0213 - val_mae: 0.0953\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0847 - val_loss: 0.0212 - val_mae: 0.0943\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0825 - val_loss: 0.0210 - val_mae: 0.0934\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0069 - mae: 0.0838 - val_loss: 0.0209 - val_mae: 0.0926\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0786 - val_loss: 0.0208 - val_mae: 0.0917\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0794 - val_loss: 0.0206 - val_mae: 0.0909\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0818 - val_loss: 0.0205 - val_mae: 0.0901\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0798 - val_loss: 0.0203 - val_mae: 0.0893\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0825 - val_loss: 0.0202 - val_mae: 0.0886\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0200 - val_mae: 0.0878\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0199 - val_mae: 0.0872\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0781 - val_loss: 0.0198 - val_mae: 0.0866\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0197 - val_mae: 0.0860\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0766 - val_loss: 0.0195 - val_mae: 0.0855\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0742 - val_loss: 0.0194 - val_mae: 0.0851\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0771 - val_loss: 0.0193 - val_mae: 0.0848\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0692 - val_loss: 0.0192 - val_mae: 0.0843\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0190 - val_mae: 0.0839\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0057 - mae: 0.0759 - val_loss: 0.0189 - val_mae: 0.0835\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0188 - val_mae: 0.0830\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0187 - val_mae: 0.0826\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0737 - val_loss: 0.0186 - val_mae: 0.0822\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0722 - val_loss: 0.0185 - val_mae: 0.0818\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0709 - val_loss: 0.0185 - val_mae: 0.0814\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0769 - val_loss: 0.0184 - val_mae: 0.0809\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0183 - val_mae: 0.0805\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0048 - mae: 0.0668 - val_loss: 0.0183 - val_mae: 0.0801\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0752 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0718 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0182 - val_mae: 0.0787\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0679 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0182 - val_mae: 0.0775\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0721 - val_loss: 0.0181 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0761\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0044 - mae: 0.0610 - val_loss: 0.0180 - val_mae: 0.0759\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0651 - val_loss: 0.0180 - val_mae: 0.0758\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0049 - mae: 0.0672 - val_loss: 0.0179 - val_mae: 0.0758\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0179 - val_mae: 0.0757\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0178 - val_mae: 0.0757\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0758\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0177 - val_mae: 0.0758\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0758\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0176 - val_mae: 0.0758\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0176 - val_mae: 0.0758\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0175 - val_mae: 0.0758\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0759\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0174 - val_mae: 0.0760\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0174 - val_mae: 0.0760\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0659 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0640 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0171 - val_mae: 0.0758\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0758\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0663 - val_loss: 0.0171 - val_mae: 0.0759\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0762\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0169 - val_mae: 0.0762\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0759\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0764\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0765\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0666 - val_loss: 0.0167 - val_mae: 0.0768\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0770\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0770\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0771\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0770\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0769\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0768\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0769\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0770\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0164 - val_mae: 0.0769\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0164 - val_mae: 0.0768\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0164 - val_mae: 0.0767\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0040 - mae: 0.0648 - val_loss: 0.0164 - val_mae: 0.0765\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0164 - val_mae: 0.0763\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0763\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0164 - val_mae: 0.0762\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0534 - val_loss: 0.0164 - val_mae: 0.0763\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0164 - val_mae: 0.0764\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0765\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0163 - val_mae: 0.0766\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0163 - val_mae: 0.0768\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0163 - val_mae: 0.0770\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0163 - val_mae: 0.0770\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0163 - val_mae: 0.0772\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0772\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0584 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0770\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0163 - val_mae: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:44:52,997] Trial 7 finished with value: 0.07697930932044983 and parameters: {'learning_rate': 0.0001353156461955834, 'weight_decay': 1.1362819900870463e-06}. Best is trial 7 with value: 0.07697930932044983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1031 - val_loss: 0.0251 - val_mae: 0.1167\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0250 - val_mae: 0.1159\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0248 - val_mae: 0.1151\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1142\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0245 - val_mae: 0.1134\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0244 - val_mae: 0.1126\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0989 - val_loss: 0.0243 - val_mae: 0.1118\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0966 - val_loss: 0.0241 - val_mae: 0.1110\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0943 - val_loss: 0.0240 - val_mae: 0.1102\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0239 - val_mae: 0.1094\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0930 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0236 - val_mae: 0.1079\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0235 - val_mae: 0.1072\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0234 - val_mae: 0.1065\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0233 - val_mae: 0.1058\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0232 - val_mae: 0.1051\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0231 - val_mae: 0.1044\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0230 - val_mae: 0.1037\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0900 - val_loss: 0.0229 - val_mae: 0.1031\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0883 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0227 - val_mae: 0.1018\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0876 - val_loss: 0.0226 - val_mae: 0.1012\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0879 - val_loss: 0.0225 - val_mae: 0.1006\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0224 - val_mae: 0.1000\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0868 - val_loss: 0.0223 - val_mae: 0.0993\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0222 - val_mae: 0.0988\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0221 - val_mae: 0.0982\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0220 - val_mae: 0.0976\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0843 - val_loss: 0.0218 - val_mae: 0.0964\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0958\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0952\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0946\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0806 - val_loss: 0.0215 - val_mae: 0.0940\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0813 - val_loss: 0.0214 - val_mae: 0.0934\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0064 - mae: 0.0831 - val_loss: 0.0213 - val_mae: 0.0928\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0212 - val_mae: 0.0922\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0211 - val_mae: 0.0916\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0793 - val_loss: 0.0210 - val_mae: 0.0910\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0817 - val_loss: 0.0209 - val_mae: 0.0905\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0208 - val_mae: 0.0899\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0781 - val_loss: 0.0207 - val_mae: 0.0894\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0775 - val_loss: 0.0206 - val_mae: 0.0889\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0205 - val_mae: 0.0884\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0204 - val_mae: 0.0879\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0204 - val_mae: 0.0875\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0770 - val_loss: 0.0203 - val_mae: 0.0870\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0742 - val_loss: 0.0202 - val_mae: 0.0865\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0202 - val_mae: 0.0861\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0720 - val_loss: 0.0201 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0200 - val_mae: 0.0853\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0199 - val_mae: 0.0849\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0199 - val_mae: 0.0845\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0198 - val_mae: 0.0841\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0197 - val_mae: 0.0837\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0724 - val_loss: 0.0196 - val_mae: 0.0832\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0195 - val_mae: 0.0826\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0752 - val_loss: 0.0194 - val_mae: 0.0822\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0742 - val_loss: 0.0194 - val_mae: 0.0820\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0746 - val_loss: 0.0193 - val_mae: 0.0817\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0740 - val_loss: 0.0192 - val_mae: 0.0814\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0699 - val_loss: 0.0192 - val_mae: 0.0811\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0692 - val_loss: 0.0191 - val_mae: 0.0808\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0721 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0190 - val_mae: 0.0803\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0746 - val_loss: 0.0189 - val_mae: 0.0800\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0189 - val_mae: 0.0797\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0188 - val_mae: 0.0795\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0684 - val_loss: 0.0188 - val_mae: 0.0793\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0702 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0185 - val_mae: 0.0786\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0184 - val_mae: 0.0783\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0184 - val_mae: 0.0781\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0183 - val_mae: 0.0780\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - mae: 0.0619 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0182 - val_mae: 0.0776\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0662 - val_loss: 0.0181 - val_mae: 0.0775\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0181 - val_mae: 0.0774\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0180 - val_mae: 0.0773\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0668 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0689 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0646 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0637 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0679 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0705 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0700 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - mae: 0.0590 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - mae: 0.0646 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0675 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0768\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0775\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0168 - val_mae: 0.0784\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:45:07,744] Trial 8 finished with value: 0.07831127941608429 and parameters: {'learning_rate': 0.00010280170072454091, 'weight_decay': 3.8084257954048516e-07}. Best is trial 7 with value: 0.07697930932044983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0087 - mae: 0.1000 - val_loss: 25.7131 - val_mae: 26.2131\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 23.3221 - mae: 23.8161 - val_loss: 0.0730 - val_mae: 0.2685\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0933 - mae: 0.3400 - val_loss: 0.0304 - val_mae: 0.1619\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0157 - mae: 0.1455 - val_loss: 0.0240 - val_mae: 0.1262\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1148 - val_loss: 0.0185 - val_mae: 0.1037\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0986 - val_loss: 0.0177 - val_mae: 0.1145\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1061 - val_loss: 0.0177 - val_mae: 0.1177\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0080 - mae: 0.1057 - val_loss: 0.0183 - val_mae: 0.1232\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.1053 - val_loss: 0.0180 - val_mae: 0.1109\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0914 - val_loss: 0.0220 - val_mae: 0.1101\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0977 - val_loss: 0.0180 - val_mae: 0.0926\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0796 - val_loss: 0.0168 - val_mae: 0.1005\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0785 - val_loss: 0.0166 - val_mae: 0.0999\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0856 - val_loss: 0.0168 - val_mae: 0.0875\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0728 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0798 - val_loss: 0.0176 - val_mae: 0.0861\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0052 - mae: 0.0756 - val_loss: 0.0169 - val_mae: 0.0876\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0750 - val_loss: 0.0167 - val_mae: 0.0899\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0735 - val_loss: 0.0166 - val_mae: 0.0949\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0826 - val_loss: 0.0167 - val_mae: 0.0984\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0058 - mae: 0.0867 - val_loss: 0.0169 - val_mae: 0.0900\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0049 - mae: 0.0760 - val_loss: 0.0177 - val_mae: 0.0829\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mae: 0.0716 - val_loss: 0.0183 - val_mae: 0.0818\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0171 - val_mae: 0.0925\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0779 - val_loss: 0.0172 - val_mae: 0.0868\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0713 - val_loss: 0.0181 - val_mae: 0.0812\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0715 - val_loss: 0.0183 - val_mae: 0.0810\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0721 - val_loss: 0.0170 - val_mae: 0.0870\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0743 - val_loss: 0.0169 - val_mae: 0.0868\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0733 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0723 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0761 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0738 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0724 - val_loss: 0.0164 - val_mae: 0.0855\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0664 - val_loss: 0.0163 - val_mae: 0.0881\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0669 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0696 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0654 - val_loss: 0.0167 - val_mae: 0.0868\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0668 - val_loss: 0.0167 - val_mae: 0.0864\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0654 - val_loss: 0.0166 - val_mae: 0.0903\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0663 - val_loss: 0.0166 - val_mae: 0.0916\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0691 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0682 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0646 - val_loss: 0.0166 - val_mae: 0.0900\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0682 - val_loss: 0.0165 - val_mae: 0.0926\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0711 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - mae: 0.0723 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0684 - val_loss: 0.0167 - val_mae: 0.0877\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0973\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0986\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0771 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0187 - val_mae: 0.0827\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0622 - val_loss: 0.0182 - val_mae: 0.0805\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0636 - val_loss: 0.0167 - val_mae: 0.1017\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0043 - mae: 0.0765 - val_loss: 0.0165 - val_mae: 0.0952\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0721 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0165 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0163 - val_mae: 0.0894\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0728 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0679 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0928\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0694 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0689 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0165 - val_mae: 0.0942\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0749 - val_loss: 0.0164 - val_mae: 0.0954\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0801 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0176 - val_mae: 0.0805\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0164 - val_mae: 0.0971\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0740 - val_loss: 0.0164 - val_mae: 0.0918\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0744 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0178 - val_mae: 0.0800\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0908\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0694 - val_loss: 0.0168 - val_mae: 0.0922\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0690 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0176 - val_mae: 0.0803\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0649 - val_loss: 0.0166 - val_mae: 0.0934\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0769 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0166 - val_mae: 0.0887\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0659 - val_loss: 0.0166 - val_mae: 0.0946\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0681 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0036 - mae: 0.0642 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0170 - val_mae: 0.0872\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0869\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0708 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0876\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0650 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0685 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0163 - val_mae: 0.0864\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0662 - val_loss: 0.0164 - val_mae: 0.0811\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0165 - val_mae: 0.0845\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0663 - val_loss: 0.0172 - val_mae: 0.0844\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0640 - val_loss: 0.0176 - val_mae: 0.0821\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0868\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0898\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0040 - mae: 0.0696 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0866\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0663 - val_loss: 0.0168 - val_mae: 0.0916\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0688 - val_loss: 0.0168 - val_mae: 0.0899\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0842\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0168 - val_mae: 0.0877\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0639 - val_loss: 0.0166 - val_mae: 0.0945\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0715 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0678 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0167 - val_mae: 0.0812\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0161 - val_mae: 0.1029\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0737 - val_loss: 0.0177 - val_mae: 0.0794\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0180 - val_mae: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:45:22,421] Trial 9 finished with value: 0.07931284606456757 and parameters: {'learning_rate': 0.02529087404861221, 'weight_decay': 2.1783509228033363e-07}. Best is trial 7 with value: 0.07697930932044983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0082 - mae: 0.0976 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0946 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0973 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0953 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0088 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1083\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0232 - val_mae: 0.1083\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0084 - mae: 0.0948 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0950 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0968 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0966 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0946 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0084 - mae: 0.0959 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0970 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0931 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0950 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0086 - mae: 0.0972 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0937 - val_loss: 0.0231 - val_mae: 0.1073\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0231 - val_mae: 0.1073\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0947 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - mae: 0.0946 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0966 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0933 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0934 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0080 - mae: 0.0933 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0938 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0230 - val_mae: 0.1065\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0230 - val_mae: 0.1065\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0230 - val_mae: 0.1065\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0933 - val_loss: 0.0230 - val_mae: 0.1065\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0083 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1064\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0230 - val_mae: 0.1064\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1064\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0930 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0938 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0962 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0085 - mae: 0.0952 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0915 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0933 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0921 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0081 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0932 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0927 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0945 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0228 - val_mae: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:45:36,923] Trial 10 finished with value: 0.10534623265266418 and parameters: {'learning_rate': 3.3595563412196834e-06, 'weight_decay': 4.035411872961367e-09}. Best is trial 7 with value: 0.07697930932044983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0095 - mae: 0.1077 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1147\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0238 - val_mae: 0.1140\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0236 - val_mae: 0.1132\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0235 - val_mae: 0.1124\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0985 - val_loss: 0.0233 - val_mae: 0.1102\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1095\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0231 - val_mae: 0.1088\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0230 - val_mae: 0.1082\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0229 - val_mae: 0.1076\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0228 - val_mae: 0.1064\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1054\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0932 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0225 - val_mae: 0.1043\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0935 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0224 - val_mae: 0.1031\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0077 - mae: 0.0938 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0908 - val_loss: 0.0222 - val_mae: 0.1019\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0073 - mae: 0.0895 - val_loss: 0.0222 - val_mae: 0.1013\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0876 - val_loss: 0.0220 - val_mae: 0.1001\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0893 - val_loss: 0.0219 - val_mae: 0.0994\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0873 - val_loss: 0.0219 - val_mae: 0.0988\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0874 - val_loss: 0.0218 - val_mae: 0.0982\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0859 - val_loss: 0.0217 - val_mae: 0.0977\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0216 - val_mae: 0.0971\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0216 - val_mae: 0.0965\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0215 - val_mae: 0.0959\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0214 - val_mae: 0.0954\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0213 - val_mae: 0.0949\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0069 - mae: 0.0858 - val_loss: 0.0213 - val_mae: 0.0943\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.0938\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0211 - val_mae: 0.0933\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0211 - val_mae: 0.0928\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0812 - val_loss: 0.0210 - val_mae: 0.0923\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0827 - val_loss: 0.0209 - val_mae: 0.0919\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0821 - val_loss: 0.0209 - val_mae: 0.0915\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0068 - mae: 0.0868 - val_loss: 0.0208 - val_mae: 0.0911\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0817 - val_loss: 0.0207 - val_mae: 0.0907\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0793 - val_loss: 0.0206 - val_mae: 0.0903\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0816 - val_loss: 0.0206 - val_mae: 0.0900\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0059 - mae: 0.0789 - val_loss: 0.0205 - val_mae: 0.0896\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0204 - val_mae: 0.0893\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0816 - val_loss: 0.0204 - val_mae: 0.0890\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0887\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0783 - val_loss: 0.0202 - val_mae: 0.0883\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0202 - val_mae: 0.0881\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0793 - val_loss: 0.0201 - val_mae: 0.0878\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0800 - val_loss: 0.0201 - val_mae: 0.0875\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0741 - val_loss: 0.0200 - val_mae: 0.0872\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0800 - val_loss: 0.0199 - val_mae: 0.0870\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0199 - val_mae: 0.0867\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0784 - val_loss: 0.0198 - val_mae: 0.0864\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0745 - val_loss: 0.0198 - val_mae: 0.0861\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0197 - val_mae: 0.0858\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0758 - val_loss: 0.0196 - val_mae: 0.0855\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0054 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.0852\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0195 - val_mae: 0.0849\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0195 - val_mae: 0.0846\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0755 - val_loss: 0.0194 - val_mae: 0.0843\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0057 - mae: 0.0772 - val_loss: 0.0194 - val_mae: 0.0840\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0729 - val_loss: 0.0193 - val_mae: 0.0838\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0713 - val_loss: 0.0193 - val_mae: 0.0836\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0745 - val_loss: 0.0192 - val_mae: 0.0833\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0192 - val_mae: 0.0831\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0804 - val_loss: 0.0192 - val_mae: 0.0828\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0055 - mae: 0.0757 - val_loss: 0.0191 - val_mae: 0.0825\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0191 - val_mae: 0.0822\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0191 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0741 - val_loss: 0.0190 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0780 - val_loss: 0.0190 - val_mae: 0.0814\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0752 - val_loss: 0.0189 - val_mae: 0.0812\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0189 - val_mae: 0.0810\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0189 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - mae: 0.0714 - val_loss: 0.0188 - val_mae: 0.0805\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0188 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0187 - val_mae: 0.0801\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0775 - val_loss: 0.0187 - val_mae: 0.0799\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0187 - val_mae: 0.0798\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0186 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0727 - val_loss: 0.0186 - val_mae: 0.0796\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0049 - mae: 0.0716 - val_loss: 0.0185 - val_mae: 0.0794\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0738 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0185 - val_mae: 0.0791\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0665 - val_loss: 0.0184 - val_mae: 0.0790\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0738 - val_loss: 0.0184 - val_mae: 0.0789\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0704 - val_loss: 0.0184 - val_mae: 0.0788\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0787\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0689 - val_loss: 0.0183 - val_mae: 0.0785\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0183 - val_mae: 0.0783\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0183 - val_mae: 0.0781\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0744 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0707 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0681 - val_loss: 0.0182 - val_mae: 0.0776\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0182 - val_mae: 0.0774\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0705 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0182 - val_mae: 0.0772\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0182 - val_mae: 0.0771\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0182 - val_mae: 0.0770\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0633 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0696 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0180 - val_mae: 0.0769\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0180 - val_mae: 0.0769\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0048 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0770\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0649 - val_loss: 0.0179 - val_mae: 0.0771\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0644 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0649 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0693 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0668 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0645 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0626 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0640 - val_loss: 0.0174 - val_mae: 0.0759\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0174 - val_mae: 0.0758\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0624 - val_loss: 0.0174 - val_mae: 0.0757\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0700 - val_loss: 0.0174 - val_mae: 0.0757\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0173 - val_mae: 0.0757\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0757\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0173 - val_mae: 0.0758\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0758\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0759\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0759\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:45:51,407] Trial 11 finished with value: 0.076032355427742 and parameters: {'learning_rate': 7.299829255384803e-05, 'weight_decay': 1.6091561003023187e-06}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0241 - val_mae: 0.1181\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0240 - val_mae: 0.1177\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1170\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1167\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0238 - val_mae: 0.1163\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0238 - val_mae: 0.1159\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1155\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1152\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1018 - val_loss: 0.0236 - val_mae: 0.1148\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0235 - val_mae: 0.1136\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0235 - val_mae: 0.1133\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0994 - val_loss: 0.0234 - val_mae: 0.1129\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0233 - val_mae: 0.1121\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0233 - val_mae: 0.1118\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0232 - val_mae: 0.1114\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0972 - val_loss: 0.0232 - val_mae: 0.1110\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1106\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0231 - val_mae: 0.1102\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0230 - val_mae: 0.1099\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0230 - val_mae: 0.1095\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1091\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0229 - val_mae: 0.1087\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0229 - val_mae: 0.1084\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1080\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0947 - val_loss: 0.0228 - val_mae: 0.1076\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0227 - val_mae: 0.1073\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0227 - val_mae: 0.1070\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0952 - val_loss: 0.0226 - val_mae: 0.1066\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0226 - val_mae: 0.1063\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0226 - val_mae: 0.1060\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0225 - val_mae: 0.1056\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0225 - val_mae: 0.1053\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0224 - val_mae: 0.1050\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0224 - val_mae: 0.1046\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0223 - val_mae: 0.1043\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0223 - val_mae: 0.1039\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0222 - val_mae: 0.1036\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0910 - val_loss: 0.0222 - val_mae: 0.1033\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0905 - val_loss: 0.0222 - val_mae: 0.1029\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0221 - val_mae: 0.1026\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0221 - val_mae: 0.1022\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0220 - val_mae: 0.1019\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0911 - val_loss: 0.0220 - val_mae: 0.1016\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0219 - val_mae: 0.1012\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0219 - val_mae: 0.1009\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0218 - val_mae: 0.1005\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0218 - val_mae: 0.1002\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0073 - mae: 0.0884 - val_loss: 0.0218 - val_mae: 0.0998\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0217 - val_mae: 0.0994\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0217 - val_mae: 0.0991\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0073 - mae: 0.0864 - val_loss: 0.0216 - val_mae: 0.0987\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0216 - val_mae: 0.0983\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0868 - val_loss: 0.0215 - val_mae: 0.0980\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0215 - val_mae: 0.0976\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0214 - val_mae: 0.0972\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0858 - val_loss: 0.0214 - val_mae: 0.0969\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0861 - val_loss: 0.0213 - val_mae: 0.0965\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0854 - val_loss: 0.0213 - val_mae: 0.0962\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0212 - val_mae: 0.0958\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0073 - mae: 0.0838 - val_loss: 0.0212 - val_mae: 0.0954\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0211 - val_mae: 0.0951\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0069 - mae: 0.0853 - val_loss: 0.0211 - val_mae: 0.0947\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0210 - val_mae: 0.0944\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0069 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0941\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0799 - val_loss: 0.0209 - val_mae: 0.0937\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066 - mae: 0.0793 - val_loss: 0.0209 - val_mae: 0.0934\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0208 - val_mae: 0.0931\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0826 - val_loss: 0.0208 - val_mae: 0.0928\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0925\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0207 - val_mae: 0.0923\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0069 - mae: 0.0805 - val_loss: 0.0206 - val_mae: 0.0920\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0792 - val_loss: 0.0206 - val_mae: 0.0917\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0068 - mae: 0.0826 - val_loss: 0.0205 - val_mae: 0.0915\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0912\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0062 - mae: 0.0795 - val_loss: 0.0204 - val_mae: 0.0910\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0204 - val_mae: 0.0908\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0203 - val_mae: 0.0905\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0775 - val_loss: 0.0203 - val_mae: 0.0903\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0787 - val_loss: 0.0202 - val_mae: 0.0901\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0803 - val_loss: 0.0202 - val_mae: 0.0898\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0201 - val_mae: 0.0896\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0794 - val_loss: 0.0201 - val_mae: 0.0893\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0200 - val_mae: 0.0890\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0059 - mae: 0.0743 - val_loss: 0.0200 - val_mae: 0.0888\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0768 - val_loss: 0.0199 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0756 - val_loss: 0.0199 - val_mae: 0.0883\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0198 - val_mae: 0.0881\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0198 - val_mae: 0.0878\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0819 - val_loss: 0.0197 - val_mae: 0.0876\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0811 - val_loss: 0.0197 - val_mae: 0.0873\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0197 - val_mae: 0.0871\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0769 - val_loss: 0.0196 - val_mae: 0.0869\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0058 - mae: 0.0742 - val_loss: 0.0196 - val_mae: 0.0866\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0789 - val_loss: 0.0196 - val_mae: 0.0864\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0742 - val_loss: 0.0195 - val_mae: 0.0861\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0755 - val_loss: 0.0195 - val_mae: 0.0859\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0780 - val_loss: 0.0194 - val_mae: 0.0856\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0194 - val_mae: 0.0854\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0785 - val_loss: 0.0194 - val_mae: 0.0851\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0193 - val_mae: 0.0849\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0193 - val_mae: 0.0847\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0058 - mae: 0.0756 - val_loss: 0.0193 - val_mae: 0.0845\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0192 - val_mae: 0.0843\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0192 - val_mae: 0.0840\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0767 - val_loss: 0.0191 - val_mae: 0.0838\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0758 - val_loss: 0.0191 - val_mae: 0.0836\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0748 - val_loss: 0.0191 - val_mae: 0.0834\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0190 - val_mae: 0.0833\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0057 - mae: 0.0720 - val_loss: 0.0190 - val_mae: 0.0831\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0190 - val_mae: 0.0830\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0736 - val_loss: 0.0189 - val_mae: 0.0829\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0189 - val_mae: 0.0827\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0189 - val_mae: 0.0826\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0720 - val_loss: 0.0188 - val_mae: 0.0825\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0188 - val_mae: 0.0823\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0711 - val_loss: 0.0188 - val_mae: 0.0822\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0187 - val_mae: 0.0820\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0187 - val_mae: 0.0819\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0777 - val_loss: 0.0187 - val_mae: 0.0817\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0187 - val_mae: 0.0816\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0186 - val_mae: 0.0814\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0186 - val_mae: 0.0813\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0186 - val_mae: 0.0811\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0186 - val_mae: 0.0810\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0186 - val_mae: 0.0808\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0757 - val_loss: 0.0185 - val_mae: 0.0807\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0185 - val_mae: 0.0805\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0185 - val_mae: 0.0804\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0185 - val_mae: 0.0803\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0729 - val_loss: 0.0184 - val_mae: 0.0801\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0184 - val_mae: 0.0800\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0184 - val_mae: 0.0799\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0798\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0059 - mae: 0.0721 - val_loss: 0.0184 - val_mae: 0.0797\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0183 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0706 - val_loss: 0.0183 - val_mae: 0.0793\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0757 - val_loss: 0.0183 - val_mae: 0.0792\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0710 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0055 - mae: 0.0747 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0707 - val_loss: 0.0182 - val_mae: 0.0789\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0182 - val_mae: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:46:06,030] Trial 12 finished with value: 0.07887998968362808 and parameters: {'learning_rate': 4.241015521951006e-05, 'weight_decay': 2.114426138777562e-05}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1151\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.1130\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1111\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1092\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0235 - val_mae: 0.1073\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0232 - val_mae: 0.1054\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0902 - val_loss: 0.0230 - val_mae: 0.1036\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0891 - val_loss: 0.0228 - val_mae: 0.1018\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0880 - val_loss: 0.0225 - val_mae: 0.1000\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0223 - val_mae: 0.0982\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0835 - val_loss: 0.0221 - val_mae: 0.0964\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0218 - val_mae: 0.0945\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0767 - val_loss: 0.0213 - val_mae: 0.0908\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0841 - val_loss: 0.0211 - val_mae: 0.0890\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0766 - val_loss: 0.0209 - val_mae: 0.0872\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0792 - val_loss: 0.0206 - val_mae: 0.0854\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0724 - val_loss: 0.0204 - val_mae: 0.0837\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0202 - val_mae: 0.0824\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0811\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0722 - val_loss: 0.0198 - val_mae: 0.0801\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0699 - val_loss: 0.0196 - val_mae: 0.0793\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0056 - mae: 0.0696 - val_loss: 0.0194 - val_mae: 0.0786\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0192 - val_mae: 0.0781\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0190 - val_mae: 0.0776\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0188 - val_mae: 0.0773\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0731 - val_loss: 0.0186 - val_mae: 0.0771\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0692 - val_loss: 0.0185 - val_mae: 0.0770\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0183 - val_mae: 0.0771\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0644 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0775\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0649 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0671 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0693 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0177 - val_mae: 0.0781\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0654 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0176 - val_mae: 0.0780\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0780\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0646 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0618 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0790\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0536 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0167 - val_mae: 0.0796\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0029 - mae: 0.0518 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0802\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0806\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0807\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0545 - val_loss: 0.0166 - val_mae: 0.0806\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0805\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0166 - val_mae: 0.0805\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0572 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0803\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0163 - val_mae: 0.0805\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0163 - val_mae: 0.0806\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0163 - val_mae: 0.0808\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0162 - val_mae: 0.0811\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0162 - val_mae: 0.0814\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0162 - val_mae: 0.0817\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0544 - val_loss: 0.0161 - val_mae: 0.0821\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0515 - val_loss: 0.0161 - val_mae: 0.0828\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0161 - val_mae: 0.0830\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0160 - val_mae: 0.0835\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0159 - val_mae: 0.0838\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0159 - val_mae: 0.0833\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0519 - val_loss: 0.0159 - val_mae: 0.0831\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0159 - val_mae: 0.0830\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0158 - val_mae: 0.0827\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0158 - val_mae: 0.0822\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0550 - val_loss: 0.0157 - val_mae: 0.0821\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0498 - val_loss: 0.0157 - val_mae: 0.0826\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0156 - val_mae: 0.0830\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0155 - val_mae: 0.0826\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0155 - val_mae: 0.0823\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0032 - mae: 0.0525 - val_loss: 0.0155 - val_mae: 0.0823\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0155 - val_mae: 0.0824\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0154 - val_mae: 0.0826\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0517 - val_loss: 0.0154 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0153 - val_mae: 0.0839\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0153 - val_mae: 0.0847\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0152 - val_mae: 0.0853\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0515 - val_loss: 0.0152 - val_mae: 0.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:46:20,784] Trial 13 finished with value: 0.08603313565254211 and parameters: {'learning_rate': 0.00022835386284539104, 'weight_decay': 8.079162776084182e-06}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0087 - mae: 0.0965 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0979 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0972 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.0987 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.0997 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0945 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0089 - mae: 0.0972 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.0998 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0961 - val_loss: 0.0243 - val_mae: 0.1094\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0933 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.0996 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0970 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1003 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0966 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0973 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.0985 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0961 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0950 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.0972 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0088 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1093\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0089 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0083 - mae: 0.0932 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0088 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0090 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0940 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0977 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0960 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0968 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0973 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0243 - val_mae: 0.1092\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0945 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0955 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0953 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0979 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0090 - mae: 0.0993 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0969 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0997 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0975 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0091 - mae: 0.0995 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0936 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0972 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1091\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0991 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.0986 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0967 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.0993 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0094 - mae: 0.1013 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0997 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0993 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0989 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0958 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0969 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0979 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0940 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0930 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0979 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.0986 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0961 - val_loss: 0.0243 - val_mae: 0.1090\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0087 - mae: 0.0975 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0984 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0987 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1002 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0953 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0962 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0946 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0973 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0959 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0977 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0959 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0954 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0945 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0243 - val_mae: 0.1089\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0946 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.0992 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0978 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0940 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0960 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0090 - mae: 0.0998 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0964 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0980 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - mae: 0.0957 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0986 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0958 - val_loss: 0.0243 - val_mae: 0.1088\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0243 - val_mae: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:46:35,426] Trial 14 finished with value: 0.10875514894723892 and parameters: {'learning_rate': 3.1644800639472844e-07, 'weight_decay': 1.1883819405483118e-05}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0204 - val_mae: 0.0943\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - mae: 0.0849 - val_loss: 0.0187 - val_mae: 0.0842\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0056 - mae: 0.0786 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0724 - val_loss: 0.0176 - val_mae: 0.0756\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0175 - val_mae: 0.0774\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0625 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0169 - val_mae: 0.0818\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0659 - val_loss: 0.0171 - val_mae: 0.0802\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0797\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0812\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0818\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0162 - val_mae: 0.0834\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0161 - val_mae: 0.0838\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0594 - val_loss: 0.0164 - val_mae: 0.0824\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0162 - val_mae: 0.0821\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0629 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0162 - val_mae: 0.0811\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0603 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0157 - val_mae: 0.0824\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0570 - val_loss: 0.0161 - val_mae: 0.0813\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0161 - val_mae: 0.0808\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0152 - val_mae: 0.0824\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0575 - val_loss: 0.0152 - val_mae: 0.0819\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0160 - val_mae: 0.0795\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0163 - val_mae: 0.0790\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0161 - val_mae: 0.0788\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0154 - val_mae: 0.0794\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0145 - val_mae: 0.0845\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0141 - val_mae: 0.0898\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0142 - val_mae: 0.0869\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0151 - val_mae: 0.0777\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0499 - val_loss: 0.0159 - val_mae: 0.0754\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0529 - val_loss: 0.0161 - val_mae: 0.0752\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0503 - val_loss: 0.0158 - val_mae: 0.0754\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0515 - val_loss: 0.0150 - val_mae: 0.0784\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0145 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0142 - val_mae: 0.0878\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0143 - val_mae: 0.0856\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0542 - val_loss: 0.0146 - val_mae: 0.0818\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0150 - val_mae: 0.0787\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - mae: 0.0508 - val_loss: 0.0153 - val_mae: 0.0775\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0154 - val_mae: 0.0771\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0151 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0146 - val_mae: 0.0797\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0146 - val_mae: 0.0790\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0486 - val_loss: 0.0147 - val_mae: 0.0778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0476 - val_loss: 0.0145 - val_mae: 0.0786\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0510 - val_loss: 0.0140 - val_mae: 0.0804\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0136 - val_mae: 0.0835\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0136 - val_mae: 0.0840\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0138 - val_mae: 0.0824\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0483 - val_loss: 0.0139 - val_mae: 0.0813\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0138 - val_mae: 0.0818\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0137 - val_mae: 0.0823\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0148 - val_mae: 0.0784\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0495 - val_loss: 0.0145 - val_mae: 0.0803\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0140 - val_mae: 0.0834\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0134 - val_mae: 0.0882\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0136 - val_mae: 0.0841\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0147 - val_mae: 0.0781\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0507 - val_loss: 0.0147 - val_mae: 0.0784\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0140 - val_mae: 0.0822\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0489 - val_loss: 0.0136 - val_mae: 0.0881\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0532 - val_loss: 0.0140 - val_mae: 0.0826\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0146 - val_mae: 0.0789\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0148 - val_mae: 0.0794\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0144 - val_mae: 0.0837\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0140 - val_mae: 0.0883\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0467 - val_loss: 0.0139 - val_mae: 0.0895\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0516 - val_loss: 0.0143 - val_mae: 0.0826\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0148 - val_mae: 0.0787\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0444 - val_loss: 0.0148 - val_mae: 0.0787\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0027 - mae: 0.0489 - val_loss: 0.0144 - val_mae: 0.0823\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0495 - val_loss: 0.0139 - val_mae: 0.0881\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0509 - val_loss: 0.0136 - val_mae: 0.0907\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0136 - val_mae: 0.0906\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0457 - val_loss: 0.0136 - val_mae: 0.0853\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0137 - val_mae: 0.0834\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0138 - val_mae: 0.0829\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0443 - val_loss: 0.0139 - val_mae: 0.0828\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0442 - val_loss: 0.0141 - val_mae: 0.0816\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0141 - val_mae: 0.0826\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0139 - val_mae: 0.0833\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - mae: 0.0459 - val_loss: 0.0137 - val_mae: 0.0853\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0457 - val_loss: 0.0135 - val_mae: 0.0854\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0134 - val_mae: 0.0833\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0134 - val_mae: 0.0807\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0132 - val_mae: 0.0812\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0133 - val_mae: 0.0790\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0442 - val_loss: 0.0138 - val_mae: 0.0769\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0412 - val_loss: 0.0140 - val_mae: 0.0785\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0140 - val_mae: 0.0822\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0402 - val_loss: 0.0138 - val_mae: 0.0828\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0135 - val_mae: 0.0822\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0135 - val_mae: 0.0800\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0397 - val_loss: 0.0135 - val_mae: 0.0798\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0410 - val_loss: 0.0136 - val_mae: 0.0806\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0136 - val_mae: 0.0828\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0138 - val_mae: 0.0833\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0429 - val_loss: 0.0136 - val_mae: 0.0836\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0135 - val_mae: 0.0802\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0438 - val_loss: 0.0134 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - mae: 0.0383 - val_loss: 0.0131 - val_mae: 0.0787\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - mae: 0.0445 - val_loss: 0.0130 - val_mae: 0.0825\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0130 - val_mae: 0.0861\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - mae: 0.0466 - val_loss: 0.0135 - val_mae: 0.0795\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0412 - val_loss: 0.0151 - val_mae: 0.0778\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0157 - val_mae: 0.0774\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0433 - val_loss: 0.0158 - val_mae: 0.0906\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0161 - val_mae: 0.0969\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0158 - val_mae: 0.0929\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0151 - val_mae: 0.0851\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - mae: 0.0395 - val_loss: 0.0147 - val_mae: 0.0805\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0413 - val_loss: 0.0143 - val_mae: 0.0798\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 0.0140 - val_mae: 0.0811\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0138 - val_mae: 0.0837\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - mae: 0.0350 - val_loss: 0.0137 - val_mae: 0.0867\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0433 - val_loss: 0.0137 - val_mae: 0.0904\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0401 - val_loss: 0.0138 - val_mae: 0.0956\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0137 - val_mae: 0.0944\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0137 - val_mae: 0.0891\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0139 - val_mae: 0.0852\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 0.0140 - val_mae: 0.0815\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0139 - val_mae: 0.0806\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0137 - val_mae: 0.0818\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0136 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0417 - val_loss: 0.0136 - val_mae: 0.0840\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0412 - val_loss: 0.0139 - val_mae: 0.0837\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0146 - val_mae: 0.0808\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - mae: 0.0329 - val_loss: 0.0149 - val_mae: 0.0800\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0374 - val_loss: 0.0145 - val_mae: 0.0819\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.9637e-04 - mae: 0.0314 - val_loss: 0.0140 - val_mae: 0.0857\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - mae: 0.0349 - val_loss: 0.0138 - val_mae: 0.0897\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0138 - val_mae: 0.0933\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0440 - val_loss: 0.0141 - val_mae: 0.0843\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0148 - val_mae: 0.0798\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mae: 0.0390 - val_loss: 0.0148 - val_mae: 0.0765\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0143 - val_mae: 0.0789\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - mae: 0.0386 - val_loss: 0.0140 - val_mae: 0.0818\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - mae: 0.0380 - val_loss: 0.0140 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0140 - val_mae: 0.0881\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0426 - val_loss: 0.0141 - val_mae: 0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:46:50,113] Trial 15 finished with value: 0.0896311104297638 and parameters: {'learning_rate': 0.0022772446356281607, 'weight_decay': 1.4482863492232255e-09}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0082 - mae: 0.0912 - val_loss: 0.0215 - val_mae: 0.0953\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0205 - val_mae: 0.0882\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0196 - val_mae: 0.0824\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0699 - val_loss: 0.0177 - val_mae: 0.0800\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0849 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0683 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0643 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0686 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0811\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0679 - val_loss: 0.0175 - val_mae: 0.0812\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0808\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0165 - val_mae: 0.0813\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0816\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0163 - val_mae: 0.0816\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0646 - val_loss: 0.0163 - val_mae: 0.0810\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0163 - val_mae: 0.0800\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0163 - val_mae: 0.0793\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0163 - val_mae: 0.0789\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0162 - val_mae: 0.0788\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0160 - val_mae: 0.0793\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0157 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0157 - val_mae: 0.0813\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0160 - val_mae: 0.0798\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0160 - val_mae: 0.0796\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0158 - val_mae: 0.0798\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0806\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0155 - val_mae: 0.0819\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0153 - val_mae: 0.0827\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0154 - val_mae: 0.0817\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0154 - val_mae: 0.0818\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0551 - val_loss: 0.0154 - val_mae: 0.0816\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0153 - val_mae: 0.0823\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0153 - val_mae: 0.0819\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0152 - val_mae: 0.0824\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0151 - val_mae: 0.0826\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0551 - val_loss: 0.0149 - val_mae: 0.0836\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0542 - val_loss: 0.0147 - val_mae: 0.0844\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0145 - val_mae: 0.0854\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0144 - val_mae: 0.0857\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0144 - val_mae: 0.0842\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0143 - val_mae: 0.0850\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0506 - val_loss: 0.0140 - val_mae: 0.0887\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0139 - val_mae: 0.0936\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0524 - val_loss: 0.0138 - val_mae: 0.0921\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0519 - val_loss: 0.0140 - val_mae: 0.0869\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0512 - val_loss: 0.0145 - val_mae: 0.0802\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0149 - val_mae: 0.0781\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0147 - val_mae: 0.0794\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0143 - val_mae: 0.0834\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0140 - val_mae: 0.0894\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0138 - val_mae: 0.0940\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0524 - val_loss: 0.0138 - val_mae: 0.0912\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0553 - val_loss: 0.0140 - val_mae: 0.0852\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0472 - val_loss: 0.0142 - val_mae: 0.0817\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0492 - val_loss: 0.0143 - val_mae: 0.0806\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0143 - val_mae: 0.0819\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0488 - val_loss: 0.0141 - val_mae: 0.0861\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0140 - val_mae: 0.0921\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0507 - val_loss: 0.0141 - val_mae: 0.0906\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0143 - val_mae: 0.0862\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0482 - val_loss: 0.0145 - val_mae: 0.0840\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0147 - val_mae: 0.0833\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - mae: 0.0476 - val_loss: 0.0146 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0144 - val_mae: 0.0870\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0475 - val_loss: 0.0142 - val_mae: 0.0903\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0141 - val_mae: 0.0914\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0141 - val_mae: 0.0886\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0141 - val_mae: 0.0882\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0448 - val_loss: 0.0141 - val_mae: 0.0884\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0141 - val_mae: 0.0877\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0141 - val_mae: 0.0882\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0144 - val_mae: 0.0871\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0145 - val_mae: 0.0890\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0148 - val_mae: 0.0913\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0150 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0429 - val_loss: 0.0150 - val_mae: 0.0929\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0413 - val_loss: 0.0149 - val_mae: 0.0906\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0401 - val_loss: 0.0148 - val_mae: 0.0861\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0147 - val_mae: 0.0852\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0146 - val_mae: 0.0879\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - mae: 0.0434 - val_loss: 0.0147 - val_mae: 0.0889\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0422 - val_loss: 0.0147 - val_mae: 0.0876\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0147 - val_mae: 0.0894\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0146 - val_mae: 0.0920\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0143 - val_mae: 0.0910\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0399 - val_loss: 0.0142 - val_mae: 0.0900\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0434 - val_loss: 0.0146 - val_mae: 0.0872\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0156 - val_mae: 0.0880\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - mae: 0.0437 - val_loss: 0.0163 - val_mae: 0.0918\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0166 - val_mae: 0.0893\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0405 - val_loss: 0.0163 - val_mae: 0.0877\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0162 - val_mae: 0.0850\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0158 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0156 - val_mae: 0.0876\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0154 - val_mae: 0.0914\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0154 - val_mae: 0.0925\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0399 - val_loss: 0.0152 - val_mae: 0.0931\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0154 - val_mae: 0.0940\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0150 - val_mae: 0.0891\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - mae: 0.0396 - val_loss: 0.0149 - val_mae: 0.0874\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0151 - val_mae: 0.0889\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0155 - val_mae: 0.0910\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0163 - val_mae: 0.0948\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - mae: 0.0367 - val_loss: 0.0161 - val_mae: 0.0943\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - mae: 0.0387 - val_loss: 0.0151 - val_mae: 0.0909\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0012 - mae: 0.0387 - val_loss: 0.0147 - val_mae: 0.0896\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0385 - val_loss: 0.0149 - val_mae: 0.0896\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0154 - val_mae: 0.0916\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0165 - val_mae: 0.0962\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0173 - val_mae: 0.0980\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0176 - val_mae: 0.0992\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0172 - val_mae: 0.0999\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0419 - val_loss: 0.0150 - val_mae: 0.0924\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0140 - val_mae: 0.0840\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - mae: 0.0389 - val_loss: 0.0139 - val_mae: 0.0803\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.0138 - val_mae: 0.0802\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0383 - val_loss: 0.0139 - val_mae: 0.0828\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.0142 - val_mae: 0.0881\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0146 - val_mae: 0.0916\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0152 - val_mae: 0.0938\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0155 - val_mae: 0.0919\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - mae: 0.0383 - val_loss: 0.0157 - val_mae: 0.0906\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0158 - val_mae: 0.0885\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0158 - val_mae: 0.0880\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0155 - val_mae: 0.0888\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - mae: 0.0402 - val_loss: 0.0153 - val_mae: 0.0906\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - mae: 0.0349 - val_loss: 0.0150 - val_mae: 0.0926\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0387 - val_loss: 0.0146 - val_mae: 0.0933\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0143 - val_mae: 0.0938\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0142 - val_mae: 0.0950\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0143 - val_mae: 0.0966\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0149 - val_mae: 0.0998\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0155 - val_mae: 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:47:04,668] Trial 16 finished with value: 0.10237571597099304 and parameters: {'learning_rate': 0.000978058457033226, 'weight_decay': 2.794408213340807e-06}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0116 - mae: 0.1196 - val_loss: 0.0256 - val_mae: 0.1257\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0112 - mae: 0.1167 - val_loss: 0.0256 - val_mae: 0.1255\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0256 - val_mae: 0.1254\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1161 - val_loss: 0.0256 - val_mae: 0.1253\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1251\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1157 - val_loss: 0.0255 - val_mae: 0.1250\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1176 - val_loss: 0.0255 - val_mae: 0.1248\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1176 - val_loss: 0.0255 - val_mae: 0.1247\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1245\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1213 - val_loss: 0.0254 - val_mae: 0.1244\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1098 - val_loss: 0.0254 - val_mae: 0.1242\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1138 - val_loss: 0.0254 - val_mae: 0.1241\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1135 - val_loss: 0.0254 - val_mae: 0.1239\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0114 - mae: 0.1179 - val_loss: 0.0254 - val_mae: 0.1238\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0107 - mae: 0.1132 - val_loss: 0.0253 - val_mae: 0.1236\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1143 - val_loss: 0.0253 - val_mae: 0.1235\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0253 - val_mae: 0.1233\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1144 - val_loss: 0.0253 - val_mae: 0.1232\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1167 - val_loss: 0.0253 - val_mae: 0.1230\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1229\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0252 - val_mae: 0.1227\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1129 - val_loss: 0.0252 - val_mae: 0.1226\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0105 - mae: 0.1109 - val_loss: 0.0252 - val_mae: 0.1224\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1132 - val_loss: 0.0252 - val_mae: 0.1223\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0252 - val_mae: 0.1222\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1152 - val_loss: 0.0251 - val_mae: 0.1220\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1125 - val_loss: 0.0251 - val_mae: 0.1219\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0110 - mae: 0.1138 - val_loss: 0.0251 - val_mae: 0.1217\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1136 - val_loss: 0.0251 - val_mae: 0.1216\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1115 - val_loss: 0.0251 - val_mae: 0.1214\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1094 - val_loss: 0.0250 - val_mae: 0.1213\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1129 - val_loss: 0.0250 - val_mae: 0.1211\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1140 - val_loss: 0.0250 - val_mae: 0.1210\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1124 - val_loss: 0.0250 - val_mae: 0.1208\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1095 - val_loss: 0.0250 - val_mae: 0.1207\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0250 - val_mae: 0.1206\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1114 - val_loss: 0.0249 - val_mae: 0.1204\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0249 - val_mae: 0.1203\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1122 - val_loss: 0.0249 - val_mae: 0.1201\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0249 - val_mae: 0.1200\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0249 - val_mae: 0.1198\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0249 - val_mae: 0.1197\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1194\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1193\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1190\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0247 - val_mae: 0.1187\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1106 - val_loss: 0.0247 - val_mae: 0.1186\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1184\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1119 - val_loss: 0.0247 - val_mae: 0.1183\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0106 - mae: 0.1101 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1180\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1178\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1177\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1176\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0246 - val_mae: 0.1174\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1173\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0246 - val_mae: 0.1172\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0246 - val_mae: 0.1170\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1169\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0092 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1167\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1166\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1164\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1163\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1094 - val_loss: 0.0245 - val_mae: 0.1162\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1160\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1159\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0244 - val_mae: 0.1157\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1156\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1155\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1045 - val_loss: 0.0244 - val_mae: 0.1153\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0244 - val_mae: 0.1152\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0100 - mae: 0.1050 - val_loss: 0.0243 - val_mae: 0.1150\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0243 - val_mae: 0.1149\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0243 - val_mae: 0.1148\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1146\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0243 - val_mae: 0.1145\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - mae: 0.1047 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0243 - val_mae: 0.1142\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1141\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0242 - val_mae: 0.1139\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0242 - val_mae: 0.1138\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0242 - val_mae: 0.1137\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1026 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1134\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1133\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1003 - val_loss: 0.0241 - val_mae: 0.1131\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0241 - val_mae: 0.1130\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1128\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1127\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1126\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1124\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.1020 - val_loss: 0.0241 - val_mae: 0.1123\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0240 - val_mae: 0.1122\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0240 - val_mae: 0.1120\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1119\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0240 - val_mae: 0.1118\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0088 - mae: 0.1012 - val_loss: 0.0240 - val_mae: 0.1116\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0240 - val_mae: 0.1115\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0090 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1114\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0239 - val_mae: 0.1112\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0239 - val_mae: 0.1111\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0239 - val_mae: 0.1110\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.0990 - val_loss: 0.0239 - val_mae: 0.1108\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0239 - val_mae: 0.1107\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1105\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0239 - val_mae: 0.1104\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0239 - val_mae: 0.1103\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1101\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0983 - val_loss: 0.0238 - val_mae: 0.1100\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0238 - val_mae: 0.1099\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0238 - val_mae: 0.1098\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1096\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0238 - val_mae: 0.1094\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0237 - val_mae: 0.1092\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0237 - val_mae: 0.1091\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1005 - val_loss: 0.0237 - val_mae: 0.1090\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0237 - val_mae: 0.1088\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0091 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1086\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1083\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0236 - val_mae: 0.1081\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1080\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0954 - val_loss: 0.0236 - val_mae: 0.1079\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0236 - val_mae: 0.1077\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0236 - val_mae: 0.1076\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0236 - val_mae: 0.1075\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0929 - val_loss: 0.0236 - val_mae: 0.1073\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0974 - val_loss: 0.0235 - val_mae: 0.1072\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0997 - val_loss: 0.0235 - val_mae: 0.1071\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1069\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0974 - val_loss: 0.0235 - val_mae: 0.1068\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0235 - val_mae: 0.1067\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0235 - val_mae: 0.1065\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0082 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1064\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1063\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0234 - val_mae: 0.1061\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0971 - val_loss: 0.0234 - val_mae: 0.1060\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0234 - val_mae: 0.1059\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0234 - val_mae: 0.1057\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0234 - val_mae: 0.1056\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1055\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1054\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0928 - val_loss: 0.0234 - val_mae: 0.1052\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0081 - mae: 0.0946 - val_loss: 0.0233 - val_mae: 0.1051\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0921 - val_loss: 0.0233 - val_mae: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:47:20,657] Trial 17 finished with value: 0.10494958609342575 and parameters: {'learning_rate': 1.1367983248070303e-05, 'weight_decay': 3.1797409145551354e-06}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0102 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1151\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0104 - mae: 0.1092 - val_loss: 0.0250 - val_mae: 0.1150\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1043 - val_loss: 0.0250 - val_mae: 0.1150\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1150\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1061 - val_loss: 0.0250 - val_mae: 0.1150\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0250 - val_mae: 0.1149\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1067 - val_loss: 0.0250 - val_mae: 0.1149\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1055 - val_loss: 0.0250 - val_mae: 0.1149\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1050 - val_loss: 0.0250 - val_mae: 0.1149\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0250 - val_mae: 0.1148\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1036 - val_loss: 0.0250 - val_mae: 0.1148\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1054 - val_loss: 0.0250 - val_mae: 0.1148\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1051 - val_loss: 0.0250 - val_mae: 0.1147\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0250 - val_mae: 0.1147\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1036 - val_loss: 0.0250 - val_mae: 0.1147\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1023 - val_loss: 0.0250 - val_mae: 0.1147\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1146\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1057 - val_loss: 0.0249 - val_mae: 0.1146\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0096 - mae: 0.1056 - val_loss: 0.0249 - val_mae: 0.1146\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1146\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1145\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0100 - mae: 0.1053 - val_loss: 0.0249 - val_mae: 0.1145\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0249 - val_mae: 0.1145\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1042 - val_loss: 0.0249 - val_mae: 0.1144\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1144\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1021 - val_loss: 0.0249 - val_mae: 0.1144\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1050 - val_loss: 0.0249 - val_mae: 0.1144\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1039 - val_loss: 0.0249 - val_mae: 0.1143\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0249 - val_mae: 0.1143\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1064 - val_loss: 0.0249 - val_mae: 0.1143\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1027 - val_loss: 0.0249 - val_mae: 0.1143\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1045 - val_loss: 0.0249 - val_mae: 0.1142\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1068 - val_loss: 0.0249 - val_mae: 0.1142\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1142\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1035 - val_loss: 0.0248 - val_mae: 0.1141\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0248 - val_mae: 0.1141\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1035 - val_loss: 0.0248 - val_mae: 0.1141\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1141\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1008 - val_loss: 0.0248 - val_mae: 0.1140\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1140\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1140\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0248 - val_mae: 0.1140\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0094 - mae: 0.1020 - val_loss: 0.0248 - val_mae: 0.1139\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0099 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1139\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0248 - val_mae: 0.1139\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0248 - val_mae: 0.1139\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1138\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1138\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1037 - val_loss: 0.0248 - val_mae: 0.1138\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1041 - val_loss: 0.0248 - val_mae: 0.1138\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1008 - val_loss: 0.0248 - val_mae: 0.1137\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1137\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0247 - val_mae: 0.1137\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1137\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1137\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1136\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1136\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1032 - val_loss: 0.0247 - val_mae: 0.1136\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1025 - val_loss: 0.0247 - val_mae: 0.1136\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1135\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1135\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1135\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1135\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0247 - val_mae: 0.1134\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1134\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0247 - val_mae: 0.1134\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0247 - val_mae: 0.1134\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1133\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0247 - val_mae: 0.1133\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1133\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0246 - val_mae: 0.1133\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1132\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1132\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0246 - val_mae: 0.1132\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0246 - val_mae: 0.1132\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0246 - val_mae: 0.1131\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1131\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1131\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0246 - val_mae: 0.1131\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0092 - mae: 0.1024 - val_loss: 0.0246 - val_mae: 0.1130\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1130\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1009 - val_loss: 0.0246 - val_mae: 0.1130\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1130\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0246 - val_mae: 0.1129\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1129\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1018 - val_loss: 0.0246 - val_mae: 0.1129\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1129\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093 - mae: 0.1016 - val_loss: 0.0246 - val_mae: 0.1128\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.0992 - val_loss: 0.0246 - val_mae: 0.1128\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1023 - val_loss: 0.0246 - val_mae: 0.1128\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1128\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1019 - val_loss: 0.0245 - val_mae: 0.1127\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1127\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1127\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1127\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1126\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1126\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1126\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1126\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1053 - val_loss: 0.0245 - val_mae: 0.1126\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1125\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1125\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1125\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1018 - val_loss: 0.0245 - val_mae: 0.1125\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1124\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0094 - mae: 0.1022 - val_loss: 0.0245 - val_mae: 0.1124\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0987 - val_loss: 0.0245 - val_mae: 0.1124\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1017 - val_loss: 0.0245 - val_mae: 0.1124\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1123\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0245 - val_mae: 0.1123\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1019 - val_loss: 0.0245 - val_mae: 0.1123\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1123\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1123\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.0994 - val_loss: 0.0244 - val_mae: 0.1122\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1020 - val_loss: 0.0244 - val_mae: 0.1122\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1122\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1005 - val_loss: 0.0244 - val_mae: 0.1122\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0978 - val_loss: 0.0244 - val_mae: 0.1121\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1009 - val_loss: 0.0244 - val_mae: 0.1121\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0244 - val_mae: 0.1121\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1007 - val_loss: 0.0244 - val_mae: 0.1121\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1121\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1056 - val_loss: 0.0244 - val_mae: 0.1120\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0244 - val_mae: 0.1120\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0096 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1120\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.0989 - val_loss: 0.0244 - val_mae: 0.1120\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1119\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0244 - val_mae: 0.1119\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1119\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0244 - val_mae: 0.1119\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1033 - val_loss: 0.0244 - val_mae: 0.1119\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0244 - val_mae: 0.1118\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0244 - val_mae: 0.1118\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1005 - val_loss: 0.0244 - val_mae: 0.1118\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0092 - mae: 0.1024 - val_loss: 0.0244 - val_mae: 0.1118\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.0989 - val_loss: 0.0244 - val_mae: 0.1117\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1007 - val_loss: 0.0244 - val_mae: 0.1117\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1005 - val_loss: 0.0243 - val_mae: 0.1117\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.0979 - val_loss: 0.0243 - val_mae: 0.1117\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1050 - val_loss: 0.0243 - val_mae: 0.1116\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0243 - val_mae: 0.1116\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0243 - val_mae: 0.1116\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1116\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0091 - mae: 0.0991 - val_loss: 0.0243 - val_mae: 0.1116\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1002 - val_loss: 0.0243 - val_mae: 0.1115\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0091 - mae: 0.1002 - val_loss: 0.0243 - val_mae: 0.1115\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1014 - val_loss: 0.0243 - val_mae: 0.1115\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.0998 - val_loss: 0.0243 - val_mae: 0.1115\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1114\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0243 - val_mae: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:47:35,381] Trial 18 finished with value: 0.11142735183238983 and parameters: {'learning_rate': 2.7079355069701723e-06, 'weight_decay': 1.532289917982443e-07}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0117 - mae: 0.1200 - val_loss: 0.0269 - val_mae: 0.1328\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1194 - val_loss: 0.0269 - val_mae: 0.1327\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - mae: 0.1186 - val_loss: 0.0269 - val_mae: 0.1327\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0110 - mae: 0.1171 - val_loss: 0.0268 - val_mae: 0.1326\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1186 - val_loss: 0.0268 - val_mae: 0.1326\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0108 - mae: 0.1146 - val_loss: 0.0268 - val_mae: 0.1325\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0116 - mae: 0.1206 - val_loss: 0.0268 - val_mae: 0.1325\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - mae: 0.1187 - val_loss: 0.0268 - val_mae: 0.1324\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1191 - val_loss: 0.0268 - val_mae: 0.1324\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - mae: 0.1200 - val_loss: 0.0268 - val_mae: 0.1323\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0113 - mae: 0.1191 - val_loss: 0.0268 - val_mae: 0.1323\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0115 - mae: 0.1190 - val_loss: 0.0268 - val_mae: 0.1322\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0118 - mae: 0.1216 - val_loss: 0.0268 - val_mae: 0.1322\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0268 - val_mae: 0.1321\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0114 - mae: 0.1195 - val_loss: 0.0267 - val_mae: 0.1321\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0267 - val_mae: 0.1320\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0113 - mae: 0.1193 - val_loss: 0.0267 - val_mae: 0.1319\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0105 - mae: 0.1143 - val_loss: 0.0267 - val_mae: 0.1319\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0114 - mae: 0.1192 - val_loss: 0.0267 - val_mae: 0.1318\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1174 - val_loss: 0.0267 - val_mae: 0.1318\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1165 - val_loss: 0.0267 - val_mae: 0.1317\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0118 - mae: 0.1214 - val_loss: 0.0267 - val_mae: 0.1317\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1151 - val_loss: 0.0267 - val_mae: 0.1316\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - mae: 0.1167 - val_loss: 0.0267 - val_mae: 0.1316\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0267 - val_mae: 0.1315\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - mae: 0.1187 - val_loss: 0.0266 - val_mae: 0.1315\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1165 - val_loss: 0.0266 - val_mae: 0.1314\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - mae: 0.1189 - val_loss: 0.0266 - val_mae: 0.1314\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1174 - val_loss: 0.0266 - val_mae: 0.1313\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - mae: 0.1162 - val_loss: 0.0266 - val_mae: 0.1313\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1194 - val_loss: 0.0266 - val_mae: 0.1312\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0113 - mae: 0.1183 - val_loss: 0.0266 - val_mae: 0.1312\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - mae: 0.1172 - val_loss: 0.0266 - val_mae: 0.1311\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - mae: 0.1185 - val_loss: 0.0266 - val_mae: 0.1311\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0266 - val_mae: 0.1310\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1188 - val_loss: 0.0266 - val_mae: 0.1310\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - mae: 0.1175 - val_loss: 0.0265 - val_mae: 0.1309\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1180 - val_loss: 0.0265 - val_mae: 0.1309\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1164 - val_loss: 0.0265 - val_mae: 0.1308\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1176 - val_loss: 0.0265 - val_mae: 0.1307\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0110 - mae: 0.1155 - val_loss: 0.0265 - val_mae: 0.1307\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1176 - val_loss: 0.0265 - val_mae: 0.1306\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1168 - val_loss: 0.0265 - val_mae: 0.1306\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0108 - mae: 0.1167 - val_loss: 0.0265 - val_mae: 0.1305\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0108 - mae: 0.1163 - val_loss: 0.0265 - val_mae: 0.1305\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0115 - mae: 0.1194 - val_loss: 0.0265 - val_mae: 0.1304\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0114 - mae: 0.1199 - val_loss: 0.0265 - val_mae: 0.1304\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1147 - val_loss: 0.0265 - val_mae: 0.1303\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1158 - val_loss: 0.0264 - val_mae: 0.1303\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0111 - mae: 0.1182 - val_loss: 0.0264 - val_mae: 0.1302\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0117 - mae: 0.1199 - val_loss: 0.0264 - val_mae: 0.1302\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1154 - val_loss: 0.0264 - val_mae: 0.1301\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1178 - val_loss: 0.0264 - val_mae: 0.1301\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1166 - val_loss: 0.0264 - val_mae: 0.1300\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1183 - val_loss: 0.0264 - val_mae: 0.1300\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0109 - mae: 0.1163 - val_loss: 0.0264 - val_mae: 0.1299\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1149 - val_loss: 0.0264 - val_mae: 0.1299\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1151 - val_loss: 0.0264 - val_mae: 0.1298\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0264 - val_mae: 0.1298\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1148 - val_loss: 0.0263 - val_mae: 0.1297\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - mae: 0.1163 - val_loss: 0.0263 - val_mae: 0.1297\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1142 - val_loss: 0.0263 - val_mae: 0.1296\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0108 - mae: 0.1142 - val_loss: 0.0263 - val_mae: 0.1296\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1150 - val_loss: 0.0263 - val_mae: 0.1295\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1159 - val_loss: 0.0263 - val_mae: 0.1295\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0263 - val_mae: 0.1294\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1171 - val_loss: 0.0263 - val_mae: 0.1294\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1154 - val_loss: 0.0263 - val_mae: 0.1293\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0263 - val_mae: 0.1293\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1148 - val_loss: 0.0263 - val_mae: 0.1292\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0108 - mae: 0.1171 - val_loss: 0.0263 - val_mae: 0.1292\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1132 - val_loss: 0.0262 - val_mae: 0.1291\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0262 - val_mae: 0.1291\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1170 - val_loss: 0.0262 - val_mae: 0.1290\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1154 - val_loss: 0.0262 - val_mae: 0.1290\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1139 - val_loss: 0.0262 - val_mae: 0.1289\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1136 - val_loss: 0.0262 - val_mae: 0.1289\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1147 - val_loss: 0.0262 - val_mae: 0.1289\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1146 - val_loss: 0.0262 - val_mae: 0.1288\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0105 - mae: 0.1138 - val_loss: 0.0262 - val_mae: 0.1288\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0107 - mae: 0.1148 - val_loss: 0.0262 - val_mae: 0.1287\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1179 - val_loss: 0.0262 - val_mae: 0.1287\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1149 - val_loss: 0.0262 - val_mae: 0.1286\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0108 - mae: 0.1139 - val_loss: 0.0262 - val_mae: 0.1286\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0105 - mae: 0.1145 - val_loss: 0.0261 - val_mae: 0.1285\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0261 - val_mae: 0.1285\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1126 - val_loss: 0.0261 - val_mae: 0.1284\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1159 - val_loss: 0.0261 - val_mae: 0.1284\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0261 - val_mae: 0.1283\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1174 - val_loss: 0.0261 - val_mae: 0.1283\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0106 - mae: 0.1140 - val_loss: 0.0261 - val_mae: 0.1282\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0261 - val_mae: 0.1282\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1123 - val_loss: 0.0261 - val_mae: 0.1282\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0261 - val_mae: 0.1281\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0261 - val_mae: 0.1281\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0261 - val_mae: 0.1280\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - mae: 0.1151 - val_loss: 0.0261 - val_mae: 0.1280\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - mae: 0.1149 - val_loss: 0.0260 - val_mae: 0.1279\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0260 - val_mae: 0.1279\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1147 - val_loss: 0.0260 - val_mae: 0.1278\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - mae: 0.1132 - val_loss: 0.0260 - val_mae: 0.1278\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0104 - mae: 0.1123 - val_loss: 0.0260 - val_mae: 0.1277\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1131 - val_loss: 0.0260 - val_mae: 0.1277\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0106 - mae: 0.1142 - val_loss: 0.0260 - val_mae: 0.1276\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0260 - val_mae: 0.1276\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0260 - val_mae: 0.1275\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0104 - mae: 0.1122 - val_loss: 0.0260 - val_mae: 0.1275\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1137 - val_loss: 0.0260 - val_mae: 0.1275\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0260 - val_mae: 0.1274\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1136 - val_loss: 0.0260 - val_mae: 0.1274\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1147 - val_loss: 0.0259 - val_mae: 0.1273\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0259 - val_mae: 0.1273\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1145 - val_loss: 0.0259 - val_mae: 0.1272\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1136 - val_loss: 0.0259 - val_mae: 0.1272\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0111 - mae: 0.1189 - val_loss: 0.0259 - val_mae: 0.1271\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0105 - mae: 0.1122 - val_loss: 0.0259 - val_mae: 0.1271\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0102 - mae: 0.1131 - val_loss: 0.0259 - val_mae: 0.1270\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1138 - val_loss: 0.0259 - val_mae: 0.1270\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1108 - val_loss: 0.0259 - val_mae: 0.1269\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0107 - mae: 0.1143 - val_loss: 0.0259 - val_mae: 0.1269\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0259 - val_mae: 0.1269\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1158 - val_loss: 0.0259 - val_mae: 0.1268\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1123 - val_loss: 0.0259 - val_mae: 0.1268\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0258 - val_mae: 0.1267\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0105 - mae: 0.1131 - val_loss: 0.0258 - val_mae: 0.1267\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0258 - val_mae: 0.1266\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0105 - mae: 0.1127 - val_loss: 0.0258 - val_mae: 0.1266\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0258 - val_mae: 0.1265\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1129 - val_loss: 0.0258 - val_mae: 0.1265\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1116 - val_loss: 0.0258 - val_mae: 0.1264\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1141 - val_loss: 0.0258 - val_mae: 0.1264\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1125 - val_loss: 0.0258 - val_mae: 0.1263\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0105 - mae: 0.1124 - val_loss: 0.0258 - val_mae: 0.1263\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1107 - val_loss: 0.0258 - val_mae: 0.1263\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0258 - val_mae: 0.1262\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0103 - mae: 0.1109 - val_loss: 0.0258 - val_mae: 0.1262\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1106 - val_loss: 0.0258 - val_mae: 0.1261\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1138 - val_loss: 0.0257 - val_mae: 0.1261\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1118 - val_loss: 0.0257 - val_mae: 0.1260\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0257 - val_mae: 0.1260\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1154 - val_loss: 0.0257 - val_mae: 0.1259\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1106 - val_loss: 0.0257 - val_mae: 0.1259\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0105 - mae: 0.1131 - val_loss: 0.0257 - val_mae: 0.1258\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0257 - val_mae: 0.1258\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0257 - val_mae: 0.1257\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0257 - val_mae: 0.1257\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0257 - val_mae: 0.1257\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1083 - val_loss: 0.0257 - val_mae: 0.1256\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0257 - val_mae: 0.1256\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0257 - val_mae: 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:47:50,012] Trial 19 finished with value: 0.1255246251821518 and parameters: {'learning_rate': 3.969261528532409e-06, 'weight_decay': 0.006682765634309023}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0232 - val_mae: 0.1125\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0229 - val_mae: 0.1089\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0225 - val_mae: 0.1052\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0221 - val_mae: 0.1016\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0886 - val_loss: 0.0216 - val_mae: 0.0977\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0211 - val_mae: 0.0938\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0205 - val_mae: 0.0901\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0818 - val_loss: 0.0199 - val_mae: 0.0871\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - mae: 0.0806 - val_loss: 0.0194 - val_mae: 0.0843\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0190 - val_mae: 0.0820\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0759 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0708 - val_loss: 0.0181 - val_mae: 0.0788\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0730 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0719 - val_loss: 0.0171 - val_mae: 0.0772\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0676 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0704 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0768\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0173 - val_mae: 0.0770\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0776\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0784\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0808\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0645 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0804\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0790\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0797\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0161 - val_mae: 0.0821\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0159 - val_mae: 0.0828\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0158 - val_mae: 0.0828\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0158 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0159 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0540 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0552 - val_loss: 0.0160 - val_mae: 0.0788\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0517 - val_loss: 0.0158 - val_mae: 0.0794\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0157 - val_mae: 0.0799\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0534 - val_loss: 0.0155 - val_mae: 0.0806\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0154 - val_mae: 0.0813\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0584 - val_loss: 0.0152 - val_mae: 0.0821\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0152 - val_mae: 0.0830\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0151 - val_mae: 0.0836\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0024 - mae: 0.0526 - val_loss: 0.0150 - val_mae: 0.0840\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0150 - val_mae: 0.0841\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0605 - val_loss: 0.0150 - val_mae: 0.0830\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0150 - val_mae: 0.0823\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0149 - val_mae: 0.0819\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0149 - val_mae: 0.0815\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0149 - val_mae: 0.0813\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0148 - val_mae: 0.0812\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0147 - val_mae: 0.0815\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0146 - val_mae: 0.0823\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0506 - val_loss: 0.0144 - val_mae: 0.0839\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0142 - val_mae: 0.0850\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0519 - val_loss: 0.0141 - val_mae: 0.0863\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0142 - val_mae: 0.0857\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0509 - val_loss: 0.0143 - val_mae: 0.0849\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0142 - val_mae: 0.0854\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0142 - val_mae: 0.0869\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0141 - val_mae: 0.0882\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0492 - val_loss: 0.0141 - val_mae: 0.0891\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0140 - val_mae: 0.0907\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0141 - val_mae: 0.0904\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0141 - val_mae: 0.0890\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0529 - val_loss: 0.0141 - val_mae: 0.0887\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0141 - val_mae: 0.0878\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0140 - val_mae: 0.0875\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0140 - val_mae: 0.0883\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.0138 - val_mae: 0.0903\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0138 - val_mae: 0.0921\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0137 - val_mae: 0.0913\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0467 - val_loss: 0.0138 - val_mae: 0.0865\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0139 - val_mae: 0.0847\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0138 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0137 - val_mae: 0.0877\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0464 - val_loss: 0.0136 - val_mae: 0.0913\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0136 - val_mae: 0.0931\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0520 - val_loss: 0.0137 - val_mae: 0.0921\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0531 - val_loss: 0.0139 - val_mae: 0.0897\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0140 - val_mae: 0.0878\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0141 - val_mae: 0.0870\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0525 - val_loss: 0.0141 - val_mae: 0.0869\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0504 - val_loss: 0.0140 - val_mae: 0.0887\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0139 - val_mae: 0.0922\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0139 - val_mae: 0.0944\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0459 - val_loss: 0.0139 - val_mae: 0.0948\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0471 - val_loss: 0.0140 - val_mae: 0.0948\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0140 - val_mae: 0.0953\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0140 - val_mae: 0.0954\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0140 - val_mae: 0.0939\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0139 - val_mae: 0.0931\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0138 - val_mae: 0.0951\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0139 - val_mae: 0.0934\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0140 - val_mae: 0.0920\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0139 - val_mae: 0.0934\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0446 - val_loss: 0.0139 - val_mae: 0.0964\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0138 - val_mae: 0.0984\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0457 - val_loss: 0.0138 - val_mae: 0.0979\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0539 - val_loss: 0.0139 - val_mae: 0.0963\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0498 - val_loss: 0.0140 - val_mae: 0.0938\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0445 - val_loss: 0.0141 - val_mae: 0.0920\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0141 - val_mae: 0.0926\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0142 - val_mae: 0.0939\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0142 - val_mae: 0.0941\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0142 - val_mae: 0.0952\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0435 - val_loss: 0.0143 - val_mae: 0.0958\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0143 - val_mae: 0.0965\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0143 - val_mae: 0.0980\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0143 - val_mae: 0.0991\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0141 - val_mae: 0.0949\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0142 - val_mae: 0.0887\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0142 - val_mae: 0.0872\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0142 - val_mae: 0.0890\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0142 - val_mae: 0.0937\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0144 - val_mae: 0.0968\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0489 - val_loss: 0.0145 - val_mae: 0.0990\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0146 - val_mae: 0.0975\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0146 - val_mae: 0.0940\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0146 - val_mae: 0.0924\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0145 - val_mae: 0.0940\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0014 - mae: 0.0395 - val_loss: 0.0145 - val_mae: 0.0964\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0410 - val_loss: 0.0146 - val_mae: 0.1001\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0148 - val_mae: 0.1044\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0015 - mae: 0.0419 - val_loss: 0.0147 - val_mae: 0.1031\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0014 - mae: 0.0426 - val_loss: 0.0145 - val_mae: 0.0983\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0145 - val_mae: 0.0954\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0417 - val_loss: 0.0145 - val_mae: 0.0940\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0144 - val_mae: 0.0946\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0145 - val_mae: 0.0967\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.0148 - val_mae: 0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:48:04,640] Trial 20 finished with value: 0.10122295469045639 and parameters: {'learning_rate': 0.0005074611704006582, 'weight_decay': 0.00017821336730939325}. Best is trial 11 with value: 0.076032355427742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0236 - val_mae: 0.1142\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0236 - val_mae: 0.1135\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1128\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1002 - val_loss: 0.0234 - val_mae: 0.1121\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0989 - val_loss: 0.0234 - val_mae: 0.1114\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0986 - val_loss: 0.0233 - val_mae: 0.1107\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1101\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0232 - val_mae: 0.1094\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0974 - val_loss: 0.0231 - val_mae: 0.1087\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0943 - val_loss: 0.0230 - val_mae: 0.1081\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0926 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0931 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1049\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0907 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0909 - val_loss: 0.0225 - val_mae: 0.1024\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0224 - val_mae: 0.1018\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.1012\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1005\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.0999\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0222 - val_mae: 0.0992\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0221 - val_mae: 0.0986\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0220 - val_mae: 0.0980\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0220 - val_mae: 0.0973\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0844 - val_loss: 0.0219 - val_mae: 0.0967\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0218 - val_mae: 0.0960\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0954\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0217 - val_mae: 0.0948\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0216 - val_mae: 0.0942\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0832 - val_loss: 0.0215 - val_mae: 0.0936\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0215 - val_mae: 0.0931\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0832 - val_loss: 0.0214 - val_mae: 0.0926\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0839 - val_loss: 0.0213 - val_mae: 0.0921\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0212 - val_mae: 0.0917\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0069 - mae: 0.0850 - val_loss: 0.0212 - val_mae: 0.0912\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0211 - val_mae: 0.0907\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0817 - val_loss: 0.0210 - val_mae: 0.0902\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0070 - mae: 0.0822 - val_loss: 0.0209 - val_mae: 0.0898\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0209 - val_mae: 0.0893\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0208 - val_mae: 0.0888\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0207 - val_mae: 0.0883\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0770 - val_loss: 0.0206 - val_mae: 0.0878\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0206 - val_mae: 0.0873\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0788 - val_loss: 0.0205 - val_mae: 0.0868\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.0863\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0755 - val_loss: 0.0204 - val_mae: 0.0858\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0801 - val_loss: 0.0203 - val_mae: 0.0853\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0202 - val_mae: 0.0849\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0797 - val_loss: 0.0201 - val_mae: 0.0844\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0809 - val_loss: 0.0201 - val_mae: 0.0839\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0767 - val_loss: 0.0200 - val_mae: 0.0835\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0794 - val_loss: 0.0199 - val_mae: 0.0831\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0199 - val_mae: 0.0827\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - mae: 0.0745 - val_loss: 0.0198 - val_mae: 0.0824\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0198 - val_mae: 0.0820\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0751 - val_loss: 0.0197 - val_mae: 0.0817\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0702 - val_loss: 0.0196 - val_mae: 0.0814\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0196 - val_mae: 0.0811\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0808\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0754 - val_loss: 0.0195 - val_mae: 0.0806\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0194 - val_mae: 0.0803\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0193 - val_mae: 0.0801\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0193 - val_mae: 0.0799\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0710 - val_loss: 0.0192 - val_mae: 0.0796\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0742 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0742 - val_loss: 0.0191 - val_mae: 0.0792\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0761 - val_loss: 0.0191 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0190 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0190 - val_mae: 0.0786\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0724 - val_loss: 0.0189 - val_mae: 0.0784\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0189 - val_mae: 0.0782\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0723 - val_loss: 0.0189 - val_mae: 0.0781\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0758 - val_loss: 0.0188 - val_mae: 0.0779\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0697 - val_loss: 0.0188 - val_mae: 0.0777\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0047 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0774\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0748 - val_loss: 0.0187 - val_mae: 0.0773\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0187 - val_mae: 0.0771\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0186 - val_mae: 0.0770\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0186 - val_mae: 0.0768\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0729 - val_loss: 0.0186 - val_mae: 0.0767\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0185 - val_mae: 0.0766\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0185 - val_mae: 0.0764\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0185 - val_mae: 0.0763\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0714 - val_loss: 0.0184 - val_mae: 0.0762\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0761\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0760\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0688 - val_loss: 0.0183 - val_mae: 0.0759\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - mae: 0.0695 - val_loss: 0.0183 - val_mae: 0.0757\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0729 - val_loss: 0.0183 - val_mae: 0.0756\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0707 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0677 - val_loss: 0.0182 - val_mae: 0.0754\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0753\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0182 - val_mae: 0.0752\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - mae: 0.0693 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0749\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0677 - val_loss: 0.0181 - val_mae: 0.0749\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0181 - val_mae: 0.0749\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0181 - val_mae: 0.0748\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0638 - val_loss: 0.0180 - val_mae: 0.0748\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0702 - val_loss: 0.0180 - val_mae: 0.0748\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0180 - val_mae: 0.0748\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0692 - val_loss: 0.0179 - val_mae: 0.0748\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0179 - val_mae: 0.0748\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0051 - mae: 0.0692 - val_loss: 0.0178 - val_mae: 0.0749\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0676 - val_loss: 0.0178 - val_mae: 0.0748\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0178 - val_mae: 0.0748\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0666 - val_loss: 0.0178 - val_mae: 0.0748\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0177 - val_mae: 0.0748\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0043 - mae: 0.0682 - val_loss: 0.0177 - val_mae: 0.0748\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0046 - mae: 0.0668 - val_loss: 0.0177 - val_mae: 0.0748\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0677 - val_loss: 0.0177 - val_mae: 0.0748\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0687 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0747\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0176 - val_mae: 0.0746\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0176 - val_mae: 0.0746\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0745\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0745\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0673 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0744\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0745\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0671 - val_loss: 0.0175 - val_mae: 0.0745\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0175 - val_mae: 0.0745\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0175 - val_mae: 0.0746\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0746\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0175 - val_mae: 0.0746\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0747\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0580 - val_loss: 0.0174 - val_mae: 0.0747\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0174 - val_mae: 0.0748\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0649 - val_loss: 0.0174 - val_mae: 0.0749\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0749\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0042 - mae: 0.0678 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0751\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0752\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0753\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0753\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0683 - val_loss: 0.0171 - val_mae: 0.0754\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:48:19,249] Trial 21 finished with value: 0.07538589835166931 and parameters: {'learning_rate': 6.86345949649877e-05, 'weight_decay': 1.1193398900230798e-06}. Best is trial 21 with value: 0.07538589835166931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1093 - val_loss: 0.0245 - val_mae: 0.1194\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1191\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0242 - val_mae: 0.1177\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1012 - val_loss: 0.0241 - val_mae: 0.1170\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1164\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0240 - val_mae: 0.1160\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1006 - val_loss: 0.0240 - val_mae: 0.1157\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0239 - val_mae: 0.1153\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0239 - val_mae: 0.1150\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0238 - val_mae: 0.1146\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1143\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0238 - val_mae: 0.1139\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0237 - val_mae: 0.1132\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1128\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1125\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0994 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1118\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0234 - val_mae: 0.1107\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0234 - val_mae: 0.1101\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0233 - val_mae: 0.1094\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0930 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0230 - val_mae: 0.1063\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0229 - val_mae: 0.1055\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0080 - mae: 0.0920 - val_loss: 0.0228 - val_mae: 0.1050\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0227 - val_mae: 0.1042\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0227 - val_mae: 0.1038\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0226 - val_mae: 0.1034\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0881 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0226 - val_mae: 0.1026\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0890 - val_loss: 0.0225 - val_mae: 0.1022\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0225 - val_mae: 0.1018\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0224 - val_mae: 0.1014\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0075 - mae: 0.0874 - val_loss: 0.0224 - val_mae: 0.1010\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0223 - val_mae: 0.1006\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0880 - val_loss: 0.0223 - val_mae: 0.1003\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.0999\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0222 - val_mae: 0.0995\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0840 - val_loss: 0.0221 - val_mae: 0.0991\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0221 - val_mae: 0.0987\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0860 - val_loss: 0.0220 - val_mae: 0.0983\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0220 - val_mae: 0.0979\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0219 - val_mae: 0.0974\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0828 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0838 - val_loss: 0.0218 - val_mae: 0.0966\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0826 - val_loss: 0.0218 - val_mae: 0.0962\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0958\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0217 - val_mae: 0.0953\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0814 - val_loss: 0.0216 - val_mae: 0.0949\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0215 - val_mae: 0.0945\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0215 - val_mae: 0.0941\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0064 - mae: 0.0786 - val_loss: 0.0214 - val_mae: 0.0933\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0213 - val_mae: 0.0929\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0213 - val_mae: 0.0925\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0921\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0212 - val_mae: 0.0917\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0913\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0909\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0806 - val_loss: 0.0210 - val_mae: 0.0905\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0773 - val_loss: 0.0209 - val_mae: 0.0902\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0768 - val_loss: 0.0209 - val_mae: 0.0898\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0068 - mae: 0.0810 - val_loss: 0.0208 - val_mae: 0.0895\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0208 - val_mae: 0.0891\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0766 - val_loss: 0.0207 - val_mae: 0.0888\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0768 - val_loss: 0.0207 - val_mae: 0.0885\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0206 - val_mae: 0.0883\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0776 - val_loss: 0.0206 - val_mae: 0.0880\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0204 - val_mae: 0.0875\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0204 - val_mae: 0.0872\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0061 - mae: 0.0771 - val_loss: 0.0203 - val_mae: 0.0869\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0759 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0791 - val_loss: 0.0202 - val_mae: 0.0865\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0805 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0771 - val_loss: 0.0201 - val_mae: 0.0860\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0758 - val_loss: 0.0201 - val_mae: 0.0858\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0200 - val_mae: 0.0856\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0755 - val_loss: 0.0200 - val_mae: 0.0854\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0199 - val_mae: 0.0852\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0745 - val_loss: 0.0199 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0755 - val_loss: 0.0198 - val_mae: 0.0849\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0197 - val_mae: 0.0847\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0775 - val_loss: 0.0197 - val_mae: 0.0845\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0196 - val_mae: 0.0843\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0779 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0195 - val_mae: 0.0839\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0733 - val_loss: 0.0195 - val_mae: 0.0837\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0056 - mae: 0.0727 - val_loss: 0.0195 - val_mae: 0.0836\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0194 - val_mae: 0.0834\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0706 - val_loss: 0.0194 - val_mae: 0.0832\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0776 - val_loss: 0.0193 - val_mae: 0.0831\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0724 - val_loss: 0.0193 - val_mae: 0.0829\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0061 - mae: 0.0769 - val_loss: 0.0193 - val_mae: 0.0827\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0726 - val_loss: 0.0192 - val_mae: 0.0825\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0192 - val_mae: 0.0824\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0192 - val_mae: 0.0823\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0745 - val_loss: 0.0191 - val_mae: 0.0821\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0723 - val_loss: 0.0191 - val_mae: 0.0820\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0691 - val_loss: 0.0191 - val_mae: 0.0818\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0686 - val_loss: 0.0190 - val_mae: 0.0817\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0740 - val_loss: 0.0190 - val_mae: 0.0816\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0707 - val_loss: 0.0190 - val_mae: 0.0814\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0189 - val_mae: 0.0813\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0189 - val_mae: 0.0812\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0189 - val_mae: 0.0810\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0188 - val_mae: 0.0809\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0188 - val_mae: 0.0807\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0693 - val_loss: 0.0188 - val_mae: 0.0806\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0708 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0051 - mae: 0.0693 - val_loss: 0.0187 - val_mae: 0.0803\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0187 - val_mae: 0.0802\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0747 - val_loss: 0.0186 - val_mae: 0.0800\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0186 - val_mae: 0.0799\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0186 - val_mae: 0.0798\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0185 - val_mae: 0.0797\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0185 - val_mae: 0.0796\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0185 - val_mae: 0.0795\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0184 - val_mae: 0.0795\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0719 - val_loss: 0.0184 - val_mae: 0.0795\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0667 - val_loss: 0.0184 - val_mae: 0.0795\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0642 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0665 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0684 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0182 - val_mae: 0.0795\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0181 - val_mae: 0.0796\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0181 - val_mae: 0.0796\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0796\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0717 - val_loss: 0.0181 - val_mae: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:48:33,896] Trial 22 finished with value: 0.07953941822052002 and parameters: {'learning_rate': 4.801562911405928e-05, 'weight_decay': 2.261271882718787e-06}. Best is trial 21 with value: 0.07538589835166931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0235 - val_mae: 0.1108\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0226 - val_mae: 0.1034\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0218 - val_mae: 0.0959\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0865 - val_loss: 0.0211 - val_mae: 0.0897\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0204 - val_mae: 0.0851\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0765 - val_loss: 0.0197 - val_mae: 0.0824\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0712 - val_loss: 0.0190 - val_mae: 0.0805\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0185 - val_mae: 0.0798\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0056 - mae: 0.0765 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0168 - val_mae: 0.0769\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0165 - val_mae: 0.0787\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0163 - val_mae: 0.0794\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0163 - val_mae: 0.0800\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0162 - val_mae: 0.0803\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0162 - val_mae: 0.0805\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0649 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0163 - val_mae: 0.0802\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0565 - val_loss: 0.0163 - val_mae: 0.0804\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0161 - val_mae: 0.0819\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0161 - val_mae: 0.0824\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0159 - val_mae: 0.0842\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0159 - val_mae: 0.0853\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0158 - val_mae: 0.0848\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0159 - val_mae: 0.0838\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0159 - val_mae: 0.0827\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0159 - val_mae: 0.0823\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0160 - val_mae: 0.0818\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0160 - val_mae: 0.0818\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0159 - val_mae: 0.0827\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0158 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0157 - val_mae: 0.0846\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0156 - val_mae: 0.0857\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0156 - val_mae: 0.0865\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0862\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0155 - val_mae: 0.0847\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0155 - val_mae: 0.0846\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0154 - val_mae: 0.0849\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0154 - val_mae: 0.0853\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0154 - val_mae: 0.0856\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0154 - val_mae: 0.0858\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0540 - val_loss: 0.0153 - val_mae: 0.0861\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0530 - val_loss: 0.0152 - val_mae: 0.0869\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0151 - val_mae: 0.0878\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0151 - val_mae: 0.0885\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0150 - val_mae: 0.0900\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0150 - val_mae: 0.0918\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0539 - val_loss: 0.0149 - val_mae: 0.0939\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0149 - val_mae: 0.0965\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0149 - val_mae: 0.0968\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0148 - val_mae: 0.0953\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0512 - val_loss: 0.0148 - val_mae: 0.0925\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0148 - val_mae: 0.0895\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0148 - val_mae: 0.0887\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0148 - val_mae: 0.0887\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0147 - val_mae: 0.0900\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0147 - val_mae: 0.0932\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0147 - val_mae: 0.0964\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - mae: 0.0511 - val_loss: 0.0147 - val_mae: 0.0989\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0146 - val_mae: 0.0979\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0146 - val_mae: 0.0958\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0145 - val_mae: 0.0948\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0497 - val_loss: 0.0145 - val_mae: 0.0960\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0497 - val_loss: 0.0144 - val_mae: 0.0968\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0144 - val_mae: 0.0977\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0143 - val_mae: 0.0963\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0535 - val_loss: 0.0143 - val_mae: 0.0905\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0143 - val_mae: 0.0891\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0142 - val_mae: 0.0909\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0141 - val_mae: 0.0928\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0141 - val_mae: 0.0940\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0141 - val_mae: 0.0992\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0141 - val_mae: 0.0975\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0142 - val_mae: 0.0932\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0477 - val_loss: 0.0143 - val_mae: 0.0882\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0489 - val_loss: 0.0145 - val_mae: 0.0869\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0145 - val_mae: 0.0870\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0146 - val_mae: 0.0887\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0496 - val_loss: 0.0145 - val_mae: 0.0912\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0146 - val_mae: 0.0961\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.1000\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0148 - val_mae: 0.1032\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0149 - val_mae: 0.1026\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0148 - val_mae: 0.0971\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0019 - mae: 0.0460 - val_loss: 0.0149 - val_mae: 0.0932\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0150 - val_mae: 0.0921\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0149 - val_mae: 0.0934\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0149 - val_mae: 0.0959\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0484 - val_loss: 0.0148 - val_mae: 0.0963\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0147 - val_mae: 0.0963\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0022 - mae: 0.0473 - val_loss: 0.0146 - val_mae: 0.0970\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0146 - val_mae: 0.0944\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.0938\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0145 - val_mae: 0.0934\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0146 - val_mae: 0.0950\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0474 - val_loss: 0.0146 - val_mae: 0.0964\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0457 - val_loss: 0.0146 - val_mae: 0.0943\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0459 - val_loss: 0.0147 - val_mae: 0.0952\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - mae: 0.0448 - val_loss: 0.0148 - val_mae: 0.0966\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0419 - val_loss: 0.0149 - val_mae: 0.0957\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - mae: 0.0423 - val_loss: 0.0148 - val_mae: 0.0935\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0019 - mae: 0.0460 - val_loss: 0.0148 - val_mae: 0.0941\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0146 - val_mae: 0.0936\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0144 - val_mae: 0.0950\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0420 - val_loss: 0.0143 - val_mae: 0.0939\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0022 - mae: 0.0481 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0141 - val_mae: 0.0894\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0141 - val_mae: 0.0865\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0141 - val_mae: 0.0861\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0141 - val_mae: 0.0863\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0142 - val_mae: 0.0879\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0143 - val_mae: 0.0911\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0398 - val_loss: 0.0144 - val_mae: 0.0923\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0145 - val_mae: 0.0944\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0146 - val_mae: 0.0942\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0146 - val_mae: 0.0913\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0146 - val_mae: 0.0903\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0012 - mae: 0.0371 - val_loss: 0.0147 - val_mae: 0.0894\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - mae: 0.0384 - val_loss: 0.0146 - val_mae: 0.0880\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0145 - val_mae: 0.0887\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0145 - val_mae: 0.0884\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - mae: 0.0382 - val_loss: 0.0146 - val_mae: 0.0858\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0398 - val_loss: 0.0148 - val_mae: 0.0850\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0149 - val_mae: 0.0874\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0148 - val_mae: 0.0916\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0149 - val_mae: 0.0952\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0458 - val_loss: 0.0148 - val_mae: 0.0947\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - mae: 0.0428 - val_loss: 0.0148 - val_mae: 0.0896\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0148 - val_mae: 0.0849\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0148 - val_mae: 0.0830\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0146 - val_mae: 0.0841\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0014 - mae: 0.0376 - val_loss: 0.0143 - val_mae: 0.0875\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0142 - val_mae: 0.0911\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0143 - val_mae: 0.0932\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0144 - val_mae: 0.0909\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0147 - val_mae: 0.0893\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0151 - val_mae: 0.0877\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0154 - val_mae: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:48:48,503] Trial 23 finished with value: 0.08790098130702972 and parameters: {'learning_rate': 0.0007443516940647256, 'weight_decay': 4.823698529764882e-07}. Best is trial 21 with value: 0.07538589835166931.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1163\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1161\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1159\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1157\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0243 - val_mae: 0.1155\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1152\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0243 - val_mae: 0.1150\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1051 - val_loss: 0.0243 - val_mae: 0.1148\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0242 - val_mae: 0.1146\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0242 - val_mae: 0.1144\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0242 - val_mae: 0.1142\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1023 - val_loss: 0.0241 - val_mae: 0.1140\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0995 - val_loss: 0.0241 - val_mae: 0.1137\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1135\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0241 - val_mae: 0.1133\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1131\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1129\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1127\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0240 - val_mae: 0.1125\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1123\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0239 - val_mae: 0.1121\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0239 - val_mae: 0.1119\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0239 - val_mae: 0.1117\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0238 - val_mae: 0.1115\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0238 - val_mae: 0.1113\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0967 - val_loss: 0.0238 - val_mae: 0.1111\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0238 - val_mae: 0.1109\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0237 - val_mae: 0.1107\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1105\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0237 - val_mae: 0.1103\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0237 - val_mae: 0.1101\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0236 - val_mae: 0.1099\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0236 - val_mae: 0.1097\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0952 - val_loss: 0.0236 - val_mae: 0.1095\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0974 - val_loss: 0.0236 - val_mae: 0.1094\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0236 - val_mae: 0.1092\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0235 - val_mae: 0.1090\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1088\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0959 - val_loss: 0.0235 - val_mae: 0.1086\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0235 - val_mae: 0.1084\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1083\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0234 - val_mae: 0.1081\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0234 - val_mae: 0.1079\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0234 - val_mae: 0.1077\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0234 - val_mae: 0.1075\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1073\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0951 - val_loss: 0.0233 - val_mae: 0.1071\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1069\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0233 - val_mae: 0.1067\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0233 - val_mae: 0.1065\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0232 - val_mae: 0.1063\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0232 - val_mae: 0.1061\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0955 - val_loss: 0.0232 - val_mae: 0.1059\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0921 - val_loss: 0.0232 - val_mae: 0.1057\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0232 - val_mae: 0.1055\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0231 - val_mae: 0.1053\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0080 - mae: 0.0949 - val_loss: 0.0231 - val_mae: 0.1051\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0080 - mae: 0.0917 - val_loss: 0.0231 - val_mae: 0.1049\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0930 - val_loss: 0.0231 - val_mae: 0.1047\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0231 - val_mae: 0.1045\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0079 - mae: 0.0918 - val_loss: 0.0230 - val_mae: 0.1043\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0230 - val_mae: 0.1041\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0230 - val_mae: 0.1038\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0230 - val_mae: 0.1036\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0230 - val_mae: 0.1035\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0075 - mae: 0.0900 - val_loss: 0.0229 - val_mae: 0.1032\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0229 - val_mae: 0.1030\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1028\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0919 - val_loss: 0.0229 - val_mae: 0.1026\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0229 - val_mae: 0.1024\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0075 - mae: 0.0900 - val_loss: 0.0228 - val_mae: 0.1022\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1021\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0890 - val_loss: 0.0228 - val_mae: 0.1019\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0228 - val_mae: 0.1017\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1015\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0075 - mae: 0.0891 - val_loss: 0.0227 - val_mae: 0.1013\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0227 - val_mae: 0.1012\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0227 - val_mae: 0.1010\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0227 - val_mae: 0.1008\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0902 - val_loss: 0.0226 - val_mae: 0.1006\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0226 - val_mae: 0.1004\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0873 - val_loss: 0.0226 - val_mae: 0.1002\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0860 - val_loss: 0.0226 - val_mae: 0.1000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.0999\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0895 - val_loss: 0.0225 - val_mae: 0.0997\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0225 - val_mae: 0.0995\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0071 - mae: 0.0856 - val_loss: 0.0225 - val_mae: 0.0994\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0073 - mae: 0.0886 - val_loss: 0.0225 - val_mae: 0.0992\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0225 - val_mae: 0.0990\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0224 - val_mae: 0.0989\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0224 - val_mae: 0.0987\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0224 - val_mae: 0.0986\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0224 - val_mae: 0.0984\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.0982\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0223 - val_mae: 0.0981\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0864 - val_loss: 0.0223 - val_mae: 0.0979\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.0978\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.0976\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0854 - val_loss: 0.0222 - val_mae: 0.0974\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0222 - val_mae: 0.0973\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0834 - val_loss: 0.0222 - val_mae: 0.0971\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0875 - val_loss: 0.0222 - val_mae: 0.0969\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0222 - val_mae: 0.0968\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0221 - val_mae: 0.0966\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0221 - val_mae: 0.0965\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0867 - val_loss: 0.0221 - val_mae: 0.0963\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0221 - val_mae: 0.0961\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0220 - val_mae: 0.0960\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0220 - val_mae: 0.0958\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0220 - val_mae: 0.0956\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0220 - val_mae: 0.0955\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0834 - val_loss: 0.0219 - val_mae: 0.0953\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0069 - mae: 0.0813 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0841 - val_loss: 0.0219 - val_mae: 0.0950\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0799 - val_loss: 0.0219 - val_mae: 0.0949\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0824 - val_loss: 0.0218 - val_mae: 0.0947\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0218 - val_mae: 0.0946\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0834 - val_loss: 0.0218 - val_mae: 0.0944\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0820 - val_loss: 0.0218 - val_mae: 0.0942\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0218 - val_mae: 0.0941\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0217 - val_mae: 0.0939\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0830 - val_loss: 0.0217 - val_mae: 0.0938\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0850 - val_loss: 0.0217 - val_mae: 0.0936\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0217 - val_mae: 0.0935\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0216 - val_mae: 0.0933\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0821 - val_loss: 0.0216 - val_mae: 0.0932\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0799 - val_loss: 0.0216 - val_mae: 0.0931\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0216 - val_mae: 0.0929\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0782 - val_loss: 0.0216 - val_mae: 0.0928\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0215 - val_mae: 0.0927\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0215 - val_mae: 0.0925\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0215 - val_mae: 0.0924\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0215 - val_mae: 0.0923\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0214 - val_mae: 0.0921\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0214 - val_mae: 0.0920\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0806 - val_loss: 0.0214 - val_mae: 0.0918\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0214 - val_mae: 0.0917\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0814 - val_loss: 0.0213 - val_mae: 0.0916\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0822 - val_loss: 0.0213 - val_mae: 0.0914\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0213 - val_mae: 0.0913\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0213 - val_mae: 0.0911\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0212 - val_mae: 0.0910\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0212 - val_mae: 0.0909\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0212 - val_mae: 0.0907\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0771 - val_loss: 0.0212 - val_mae: 0.0906\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0904\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0903\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0785 - val_loss: 0.0211 - val_mae: 0.0902\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0777 - val_loss: 0.0211 - val_mae: 0.0900\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0767 - val_loss: 0.0210 - val_mae: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 09:49:03,156] Trial 24 finished with value: 0.08989766240119934 and parameters: {'learning_rate': 2.589502797458983e-05, 'weight_decay': 1.4375305504229323e-08}. Best is trial 21 with value: 0.07538589835166931.\n"
     ]
    }
   ],
   "source": [
    "cnn_study = create_study(model_fun=cnn_model,\n",
    "                         train=train_df,\n",
    "                         val=val_df,\n",
    "                         n_steps=N_STEPS,\n",
    "                         n_horizon=N_HORIZON,\n",
    "                         n_features=N_FEATURES)\n",
    "lstm_study = create_study(model_fun=lstm_model,\n",
    "                          train=train_df,\n",
    "                          val=val_df,\n",
    "                          n_steps=N_STEPS,\n",
    "                          n_horizon=N_HORIZON,\n",
    "                          n_features=N_FEATURES)\n",
    "stacked_study = create_study(model_fun=lstm_cnn_model,\n",
    "                             train=train_df,\n",
    "                             val=val_df,\n",
    "                             n_steps=N_STEPS,\n",
    "                             n_horizon=N_HORIZON,\n",
    "                             n_features=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07329216599464417\n",
      "\n",
      "LSTM Study Results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07429321110248566\n",
      "\n",
      "LSTM-CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07538589835166931\n"
     ]
    }
   ],
   "source": [
    "print('CNN Study Results')\n",
    "cnn_params = get_optimized_parameters(cnn_study)\n",
    "print('\\nLSTM Study Results')\n",
    "lstm_params = get_optimized_parameters(lstm_study)\n",
    "print('\\nLSTM-CNN Study Results')\n",
    "stacked_params = get_optimized_parameters(stacked_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = dict()\n",
    "path = './src/rv_sentiment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Compile Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            2368      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               123008    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140824 (550.09 KB)\n",
      "Trainable params: 140824 (550.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_model(cnn_params['learning_rate'], cnn_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 72, 72)            22752     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55352 (216.22 KB)\n",
      "Trainable params: 55352 (216.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(lstm_params['learning_rate'], lstm_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            2368      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 72)            39456     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86776 (338.97 KB)\n",
      "Trainable params: 86776 (338.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked = lstm_cnn_model(stacked_params['learning_rate'], stacked_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0519 - mae: 0.2560 - val_loss: 0.0463 - val_mae: 0.2140\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0559 - mae: 0.2540 - val_loss: 0.0238 - val_mae: 0.1405\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0216 - mae: 0.1616 - val_loss: 0.0183 - val_mae: 0.1088\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0119 - mae: 0.1183 - val_loss: 0.0181 - val_mae: 0.1014\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - mae: 0.1013 - val_loss: 0.0183 - val_mae: 0.0970\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0872 - val_loss: 0.0182 - val_mae: 0.0919\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - mae: 0.0793 - val_loss: 0.0182 - val_mae: 0.0891\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - mae: 0.0787 - val_loss: 0.0180 - val_mae: 0.0879\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0051 - mae: 0.0727 - val_loss: 0.0177 - val_mae: 0.0880\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0705 - val_loss: 0.0175 - val_mae: 0.0901\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0690 - val_loss: 0.0174 - val_mae: 0.0932\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0953\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0970\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0962\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0953\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0941\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0165 - val_mae: 0.0933\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0164 - val_mae: 0.0919\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0163 - val_mae: 0.0922\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0163 - val_mae: 0.0929\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0162 - val_mae: 0.0952\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0163 - val_mae: 0.0961\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0164 - val_mae: 0.0949\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0166 - val_mae: 0.0945\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0167 - val_mae: 0.0955\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0168 - val_mae: 0.0963\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0988\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0167 - val_mae: 0.1006\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0166 - val_mae: 0.1036\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0522 - val_loss: 0.0165 - val_mae: 0.1002\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0164 - val_mae: 0.0973\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0163 - val_mae: 0.0969\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0494 - val_loss: 0.0162 - val_mae: 0.0969\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0160 - val_mae: 0.0983\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0159 - val_mae: 0.1008\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0158 - val_mae: 0.1013\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0158 - val_mae: 0.0966\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0159 - val_mae: 0.0926\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0159 - val_mae: 0.0913\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.0159 - val_mae: 0.0925\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0456 - val_loss: 0.0158 - val_mae: 0.0976\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0157 - val_mae: 0.0987\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0465 - val_loss: 0.0156 - val_mae: 0.0981\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0982\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - mae: 0.0412 - val_loss: 0.0158 - val_mae: 0.0965\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0160 - val_mae: 0.0933\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.0161 - val_mae: 0.0930\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0160 - val_mae: 0.0959\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0160 - val_mae: 0.0983\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0160 - val_mae: 0.1013\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0159 - val_mae: 0.1037\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0158 - val_mae: 0.0977\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0158 - val_mae: 0.0907\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0160 - val_mae: 0.0882\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0160 - val_mae: 0.0904\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0159 - val_mae: 0.0952\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0160 - val_mae: 0.0996\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0162 - val_mae: 0.1039\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0360 - val_loss: 0.0163 - val_mae: 0.1059\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0162 - val_mae: 0.1034\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0161 - val_mae: 0.0988\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0162 - val_mae: 0.0977\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0164 - val_mae: 0.0976\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0165 - val_mae: 0.0978\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0379 - val_loss: 0.0166 - val_mae: 0.0990\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0166 - val_mae: 0.1042\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.4094e-04 - mae: 0.0328 - val_loss: 0.0167 - val_mae: 0.1080\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0165 - val_mae: 0.1076\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0163 - val_mae: 0.1046\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0163 - val_mae: 0.1000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0164 - val_mae: 0.1002\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 9.0963e-04 - mae: 0.0303 - val_loss: 0.0166 - val_mae: 0.1016\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0167 - val_mae: 0.1045\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0168 - val_mae: 0.1056\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8333e-04 - mae: 0.0339 - val_loss: 0.0167 - val_mae: 0.1049\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8672e-04 - mae: 0.0331 - val_loss: 0.0167 - val_mae: 0.1070\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.3222e-04 - mae: 0.0307 - val_loss: 0.0166 - val_mae: 0.1086\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.9853e-04 - mae: 0.0290 - val_loss: 0.0165 - val_mae: 0.1097\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.5097e-04 - mae: 0.0331 - val_loss: 0.0165 - val_mae: 0.1069\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.7387e-04 - mae: 0.0317 - val_loss: 0.0165 - val_mae: 0.1033\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.3550e-04 - mae: 0.0318 - val_loss: 0.0165 - val_mae: 0.1022\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9.5386e-04 - mae: 0.0329 - val_loss: 0.0166 - val_mae: 0.1010\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.5984e-04 - mae: 0.0289 - val_loss: 0.0167 - val_mae: 0.1018\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.3761e-04 - mae: 0.0294 - val_loss: 0.0169 - val_mae: 0.1023\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3959e-04 - mae: 0.0316 - val_loss: 0.0171 - val_mae: 0.1042\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6485e-04 - mae: 0.0278 - val_loss: 0.0170 - val_mae: 0.1049\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.8838e-04 - mae: 0.0310 - val_loss: 0.0169 - val_mae: 0.1054\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.6916e-04 - mae: 0.0287 - val_loss: 0.0167 - val_mae: 0.1031\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.2181e-04 - mae: 0.0329 - val_loss: 0.0167 - val_mae: 0.1025\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1993e-04 - mae: 0.0283 - val_loss: 0.0168 - val_mae: 0.1023\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.4468e-04 - mae: 0.0308 - val_loss: 0.0168 - val_mae: 0.1008\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.8901e-04 - mae: 0.0292 - val_loss: 0.0170 - val_mae: 0.1016\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5581e-04 - mae: 0.0265 - val_loss: 0.0172 - val_mae: 0.1007\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.7163e-04 - mae: 0.0295 - val_loss: 0.0174 - val_mae: 0.1013\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 8.2553e-04 - mae: 0.0298 - val_loss: 0.0173 - val_mae: 0.1024\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6243e-04 - mae: 0.0293 - val_loss: 0.0171 - val_mae: 0.1041\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4790e-04 - mae: 0.0274 - val_loss: 0.0167 - val_mae: 0.1035\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.1147e-04 - mae: 0.0293 - val_loss: 0.0165 - val_mae: 0.1024\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.6896e-04 - mae: 0.0330 - val_loss: 0.0164 - val_mae: 0.0976\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.6784e-04 - mae: 0.0266 - val_loss: 0.0166 - val_mae: 0.0971\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0219e-04 - mae: 0.0268 - val_loss: 0.0167 - val_mae: 0.0976\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.5223e-04 - mae: 0.0277 - val_loss: 0.0168 - val_mae: 0.0989\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.5167e-04 - mae: 0.0250 - val_loss: 0.0168 - val_mae: 0.1000\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7.3046e-04 - mae: 0.0275 - val_loss: 0.0167 - val_mae: 0.1000\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.2351e-04 - mae: 0.0271 - val_loss: 0.0167 - val_mae: 0.0996\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0116e-04 - mae: 0.0289 - val_loss: 0.0166 - val_mae: 0.0983\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.6222e-04 - mae: 0.0272 - val_loss: 0.0167 - val_mae: 0.0984\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.6591e-04 - mae: 0.0301 - val_loss: 0.0169 - val_mae: 0.1004\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5037e-04 - mae: 0.0275 - val_loss: 0.0173 - val_mae: 0.1036\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.6435e-04 - mae: 0.0294 - val_loss: 0.0177 - val_mae: 0.1072\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.2805e-04 - mae: 0.0271 - val_loss: 0.0178 - val_mae: 0.1088\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3256e-04 - mae: 0.0289 - val_loss: 0.0176 - val_mae: 0.1079\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9404e-04 - mae: 0.0285 - val_loss: 0.0173 - val_mae: 0.1068\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9847e-04 - mae: 0.0273 - val_loss: 0.0171 - val_mae: 0.1074\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9781e-04 - mae: 0.0273 - val_loss: 0.0170 - val_mae: 0.1095\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.5126e-04 - mae: 0.0313 - val_loss: 0.0170 - val_mae: 0.1061\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.3712e-04 - mae: 0.0307 - val_loss: 0.0171 - val_mae: 0.1019\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0015e-04 - mae: 0.0271 - val_loss: 0.0174 - val_mae: 0.1011\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.5604e-04 - mae: 0.0236 - val_loss: 0.0176 - val_mae: 0.1008\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.7595e-04 - mae: 0.0299 - val_loss: 0.0177 - val_mae: 0.1017\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.6924e-04 - mae: 0.0283 - val_loss: 0.0176 - val_mae: 0.1050\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6695e-04 - mae: 0.0255 - val_loss: 0.0172 - val_mae: 0.1038\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8180e-04 - mae: 0.0245 - val_loss: 0.0169 - val_mae: 0.1058\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0344 - val_loss: 0.0168 - val_mae: 0.1046\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.7645e-04 - mae: 0.0300 - val_loss: 0.0169 - val_mae: 0.1012\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.9222e-04 - mae: 0.0283 - val_loss: 0.0171 - val_mae: 0.1016\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.3865e-04 - mae: 0.0244 - val_loss: 0.0173 - val_mae: 0.1030\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4842e-04 - mae: 0.0268 - val_loss: 0.0173 - val_mae: 0.1033\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.7222e-04 - mae: 0.0293 - val_loss: 0.0171 - val_mae: 0.1037\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.0069e-04 - mae: 0.0285 - val_loss: 0.0168 - val_mae: 0.1033\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4089e-04 - mae: 0.0258 - val_loss: 0.0164 - val_mae: 0.0994\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.9854e-04 - mae: 0.0290 - val_loss: 0.0163 - val_mae: 0.0972\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6797e-04 - mae: 0.0256 - val_loss: 0.0163 - val_mae: 0.0962\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.7532e-04 - mae: 0.0280 - val_loss: 0.0165 - val_mae: 0.0980\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8470e-04 - mae: 0.0280 - val_loss: 0.0169 - val_mae: 0.1026\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.0824e-04 - mae: 0.0226 - val_loss: 0.0173 - val_mae: 0.1071\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9646e-04 - mae: 0.0268 - val_loss: 0.0175 - val_mae: 0.1084\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.8634e-04 - mae: 0.0233 - val_loss: 0.0177 - val_mae: 0.1095\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6334e-04 - mae: 0.0227 - val_loss: 0.0180 - val_mae: 0.1108\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1537e-04 - mae: 0.0299 - val_loss: 0.0180 - val_mae: 0.1104\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.3233e-04 - mae: 0.0245 - val_loss: 0.0174 - val_mae: 0.1056\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.3145e-04 - mae: 0.0283 - val_loss: 0.0172 - val_mae: 0.1048\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.3898e-04 - mae: 0.0289 - val_loss: 0.0173 - val_mae: 0.1075\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8500e-04 - mae: 0.0283 - val_loss: 0.0176 - val_mae: 0.1105\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4363e-04 - mae: 0.0252 - val_loss: 0.0176 - val_mae: 0.1100\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7689e-04 - mae: 0.0239 - val_loss: 0.0174 - val_mae: 0.1073\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5.8161e-04 - mae: 0.0254 - val_loss: 0.0171 - val_mae: 0.1033\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.6259e-04 - mae: 0.0271 - val_loss: 0.0170 - val_mae: 0.1013\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.5736e-04 - mae: 0.0209 - val_loss: 0.0169 - val_mae: 0.1002\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.2021e-04 - mae: 0.0262 - val_loss: 0.0170 - val_mae: 0.1028\n",
      "--- Training LSTM ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0377 - mae: 0.2098 - val_loss: 0.0263 - val_mae: 0.1424\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0330 - mae: 0.2032 - val_loss: 0.0246 - val_mae: 0.1329\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - mae: 0.2067 - val_loss: 0.0231 - val_mae: 0.1234\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0315 - mae: 0.2005 - val_loss: 0.0219 - val_mae: 0.1156\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0275 - mae: 0.1789 - val_loss: 0.0208 - val_mae: 0.1095\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0241 - mae: 0.1729 - val_loss: 0.0200 - val_mae: 0.1045\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0283 - mae: 0.1863 - val_loss: 0.0194 - val_mae: 0.1004\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0208 - mae: 0.1623 - val_loss: 0.0189 - val_mae: 0.0973\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0199 - mae: 0.1522 - val_loss: 0.0186 - val_mae: 0.0955\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0217 - mae: 0.1672 - val_loss: 0.0182 - val_mae: 0.0946\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0190 - mae: 0.1531 - val_loss: 0.0180 - val_mae: 0.0941\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0245 - mae: 0.1772 - val_loss: 0.0178 - val_mae: 0.0939\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1536 - val_loss: 0.0176 - val_mae: 0.0938\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0195 - mae: 0.1543 - val_loss: 0.0175 - val_mae: 0.0934\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0152 - mae: 0.1410 - val_loss: 0.0173 - val_mae: 0.0931\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0182 - mae: 0.1459 - val_loss: 0.0172 - val_mae: 0.0929\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0172 - mae: 0.1430 - val_loss: 0.0171 - val_mae: 0.0926\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0166 - mae: 0.1462 - val_loss: 0.0170 - val_mae: 0.0922\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0169 - mae: 0.1457 - val_loss: 0.0170 - val_mae: 0.0918\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0179 - mae: 0.1471 - val_loss: 0.0169 - val_mae: 0.0914\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0138 - mae: 0.1317 - val_loss: 0.0168 - val_mae: 0.0910\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0137 - mae: 0.1285 - val_loss: 0.0167 - val_mae: 0.0906\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0133 - mae: 0.1298 - val_loss: 0.0167 - val_mae: 0.0902\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0138 - mae: 0.1283 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1308 - val_loss: 0.0166 - val_mae: 0.0898\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0125 - mae: 0.1236 - val_loss: 0.0166 - val_mae: 0.0894\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1344 - val_loss: 0.0165 - val_mae: 0.0889\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0122 - mae: 0.1183 - val_loss: 0.0165 - val_mae: 0.0886\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0124 - mae: 0.1257 - val_loss: 0.0164 - val_mae: 0.0885\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0118 - mae: 0.1183 - val_loss: 0.0164 - val_mae: 0.0883\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0097 - mae: 0.1140 - val_loss: 0.0164 - val_mae: 0.0879\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0111 - mae: 0.1142 - val_loss: 0.0164 - val_mae: 0.0877\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0106 - mae: 0.1142 - val_loss: 0.0164 - val_mae: 0.0876\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0102 - mae: 0.1084 - val_loss: 0.0164 - val_mae: 0.0875\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0111 - mae: 0.1168 - val_loss: 0.0164 - val_mae: 0.0875\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0107 - mae: 0.1151 - val_loss: 0.0164 - val_mae: 0.0875\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - mae: 0.1062 - val_loss: 0.0164 - val_mae: 0.0875\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0083 - mae: 0.1008 - val_loss: 0.0164 - val_mae: 0.0875\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0107 - mae: 0.1126 - val_loss: 0.0164 - val_mae: 0.0874\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0089 - mae: 0.1057 - val_loss: 0.0163 - val_mae: 0.0873\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0163 - val_mae: 0.0872\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0074 - mae: 0.0977 - val_loss: 0.0163 - val_mae: 0.0870\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0085 - mae: 0.1017 - val_loss: 0.0163 - val_mae: 0.0869\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0095 - mae: 0.1077 - val_loss: 0.0163 - val_mae: 0.0866\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0163 - val_mae: 0.0864\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0078 - mae: 0.0941 - val_loss: 0.0162 - val_mae: 0.0861\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0077 - mae: 0.0959 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0076 - mae: 0.0955 - val_loss: 0.0162 - val_mae: 0.0858\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.1006 - val_loss: 0.0162 - val_mae: 0.0857\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0064 - mae: 0.0857 - val_loss: 0.0161 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - mae: 0.0988 - val_loss: 0.0161 - val_mae: 0.0856\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0086 - mae: 0.1014 - val_loss: 0.0160 - val_mae: 0.0855\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0077 - mae: 0.0923 - val_loss: 0.0160 - val_mae: 0.0855\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - mae: 0.0937 - val_loss: 0.0160 - val_mae: 0.0855\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - mae: 0.0926 - val_loss: 0.0159 - val_mae: 0.0855\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - mae: 0.0942 - val_loss: 0.0159 - val_mae: 0.0855\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0068 - mae: 0.0927 - val_loss: 0.0159 - val_mae: 0.0855\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0068 - mae: 0.0919 - val_loss: 0.0158 - val_mae: 0.0855\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0854 - val_loss: 0.0158 - val_mae: 0.0855\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0061 - mae: 0.0839 - val_loss: 0.0158 - val_mae: 0.0856\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0842 - val_loss: 0.0158 - val_mae: 0.0857\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - mae: 0.0914 - val_loss: 0.0157 - val_mae: 0.0857\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0059 - mae: 0.0838 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0056 - mae: 0.0840 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0058 - mae: 0.0848 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - mae: 0.0877 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0056 - mae: 0.0794 - val_loss: 0.0157 - val_mae: 0.0855\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - mae: 0.0950 - val_loss: 0.0157 - val_mae: 0.0855\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0760 - val_loss: 0.0157 - val_mae: 0.0854\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - mae: 0.0779 - val_loss: 0.0157 - val_mae: 0.0854\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - mae: 0.0859 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - mae: 0.0773 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - mae: 0.0727 - val_loss: 0.0157 - val_mae: 0.0852\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0793 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0053 - mae: 0.0778 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - mae: 0.0832 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - mae: 0.0758 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0784 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0752 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - mae: 0.0744 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0058 - mae: 0.0806 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0787 - val_loss: 0.0157 - val_mae: 0.0852\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0726 - val_loss: 0.0157 - val_mae: 0.0852\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0730 - val_loss: 0.0157 - val_mae: 0.0853\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - mae: 0.0790 - val_loss: 0.0157 - val_mae: 0.0854\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - mae: 0.0689 - val_loss: 0.0157 - val_mae: 0.0854\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0042 - mae: 0.0706 - val_loss: 0.0157 - val_mae: 0.0855\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0689 - val_loss: 0.0157 - val_mae: 0.0855\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - mae: 0.0744 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0746 - val_loss: 0.0157 - val_mae: 0.0857\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - mae: 0.0750 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0043 - mae: 0.0732 - val_loss: 0.0157 - val_mae: 0.0856\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0724 - val_loss: 0.0157 - val_mae: 0.0855\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - mae: 0.0765 - val_loss: 0.0156 - val_mae: 0.0853\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - mae: 0.0754 - val_loss: 0.0156 - val_mae: 0.0851\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - mae: 0.0720 - val_loss: 0.0156 - val_mae: 0.0849\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0709 - val_loss: 0.0156 - val_mae: 0.0848\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - mae: 0.0757 - val_loss: 0.0156 - val_mae: 0.0846\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0731 - val_loss: 0.0156 - val_mae: 0.0846\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0651 - val_loss: 0.0156 - val_mae: 0.0845\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0680 - val_loss: 0.0156 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0713 - val_loss: 0.0156 - val_mae: 0.0843\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0624 - val_loss: 0.0156 - val_mae: 0.0842\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0040 - mae: 0.0697 - val_loss: 0.0156 - val_mae: 0.0841\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0652 - val_loss: 0.0156 - val_mae: 0.0841\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0700 - val_loss: 0.0155 - val_mae: 0.0840\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0639 - val_loss: 0.0155 - val_mae: 0.0841\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0155 - val_mae: 0.0843\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0612 - val_loss: 0.0155 - val_mae: 0.0845\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0689 - val_loss: 0.0155 - val_mae: 0.0847\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0048 - mae: 0.0753 - val_loss: 0.0155 - val_mae: 0.0849\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0649 - val_loss: 0.0155 - val_mae: 0.0851\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0658 - val_loss: 0.0155 - val_mae: 0.0854\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0637 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.0155 - val_mae: 0.0857\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - mae: 0.0656 - val_loss: 0.0155 - val_mae: 0.0858\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0625 - val_loss: 0.0155 - val_mae: 0.0858\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0626 - val_loss: 0.0155 - val_mae: 0.0858\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0681 - val_loss: 0.0155 - val_mae: 0.0858\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0155 - val_mae: 0.0859\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0638 - val_loss: 0.0155 - val_mae: 0.0861\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0154 - val_mae: 0.0862\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0154 - val_mae: 0.0864\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0656 - val_loss: 0.0154 - val_mae: 0.0866\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0154 - val_mae: 0.0868\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0603 - val_loss: 0.0154 - val_mae: 0.0870\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0647 - val_loss: 0.0154 - val_mae: 0.0872\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - mae: 0.0614 - val_loss: 0.0154 - val_mae: 0.0874\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0628 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0618 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mae: 0.0570 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0640 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0597 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0538 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0634 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0153 - val_mae: 0.0876\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mae: 0.0590 - val_loss: 0.0153 - val_mae: 0.0875\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - mae: 0.0592 - val_loss: 0.0153 - val_mae: 0.0875\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0874\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0618 - val_loss: 0.0153 - val_mae: 0.0873\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0153 - val_mae: 0.0870\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0619 - val_loss: 0.0153 - val_mae: 0.0867\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - mae: 0.0597 - val_loss: 0.0153 - val_mae: 0.0865\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0153 - val_mae: 0.0862\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mae: 0.0560 - val_loss: 0.0153 - val_mae: 0.0860\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0153 - val_mae: 0.0859\n",
      "--- Training LSTM-CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0769 - mae: 0.3073 - val_loss: 0.0543 - val_mae: 0.2258\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0870 - mae: 0.3321 - val_loss: 0.0506 - val_mae: 0.2161\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0729 - mae: 0.2927 - val_loss: 0.0471 - val_mae: 0.2060\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0614 - mae: 0.2818 - val_loss: 0.0438 - val_mae: 0.1959\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0615 - mae: 0.2693 - val_loss: 0.0408 - val_mae: 0.1862\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0448 - mae: 0.2380 - val_loss: 0.0382 - val_mae: 0.1772\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0534 - mae: 0.2599 - val_loss: 0.0358 - val_mae: 0.1690\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0463 - mae: 0.2444 - val_loss: 0.0336 - val_mae: 0.1611\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0522 - mae: 0.2504 - val_loss: 0.0317 - val_mae: 0.1537\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0449 - mae: 0.2405 - val_loss: 0.0299 - val_mae: 0.1468\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0428 - mae: 0.2256 - val_loss: 0.0285 - val_mae: 0.1408\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0385 - mae: 0.2268 - val_loss: 0.0271 - val_mae: 0.1348\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0384 - mae: 0.2240 - val_loss: 0.0259 - val_mae: 0.1292\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0334 - mae: 0.1968 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0365 - mae: 0.2091 - val_loss: 0.0240 - val_mae: 0.1190\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0291 - mae: 0.1912 - val_loss: 0.0232 - val_mae: 0.1150\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0268 - mae: 0.1804 - val_loss: 0.0225 - val_mae: 0.1115\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0343 - mae: 0.2087 - val_loss: 0.0219 - val_mae: 0.1086\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0245 - mae: 0.1718 - val_loss: 0.0215 - val_mae: 0.1068\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0255 - mae: 0.1804 - val_loss: 0.0210 - val_mae: 0.1051\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0299 - mae: 0.1944 - val_loss: 0.0206 - val_mae: 0.1035\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0216 - mae: 0.1619 - val_loss: 0.0203 - val_mae: 0.1022\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0246 - mae: 0.1770 - val_loss: 0.0200 - val_mae: 0.1009\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0279 - mae: 0.1831 - val_loss: 0.0197 - val_mae: 0.0995\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0243 - mae: 0.1774 - val_loss: 0.0195 - val_mae: 0.0985\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0254 - mae: 0.1769 - val_loss: 0.0193 - val_mae: 0.0976\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0241 - mae: 0.1702 - val_loss: 0.0192 - val_mae: 0.0970\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0245 - mae: 0.1766 - val_loss: 0.0190 - val_mae: 0.0964\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0194 - mae: 0.1546 - val_loss: 0.0189 - val_mae: 0.0958\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0209 - mae: 0.1602 - val_loss: 0.0188 - val_mae: 0.0951\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0216 - mae: 0.1644 - val_loss: 0.0187 - val_mae: 0.0944\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0201 - mae: 0.1610 - val_loss: 0.0186 - val_mae: 0.0937\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0174 - mae: 0.1502 - val_loss: 0.0186 - val_mae: 0.0931\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0206 - mae: 0.1608 - val_loss: 0.0185 - val_mae: 0.0925\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0201 - mae: 0.1557 - val_loss: 0.0185 - val_mae: 0.0921\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0222 - mae: 0.1679 - val_loss: 0.0184 - val_mae: 0.0917\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0195 - mae: 0.1564 - val_loss: 0.0184 - val_mae: 0.0914\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0172 - mae: 0.1409 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0182 - mae: 0.1549 - val_loss: 0.0183 - val_mae: 0.0910\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0192 - mae: 0.1531 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0196 - mae: 0.1556 - val_loss: 0.0183 - val_mae: 0.0908\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0169 - mae: 0.1417 - val_loss: 0.0183 - val_mae: 0.0906\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0149 - mae: 0.1379 - val_loss: 0.0183 - val_mae: 0.0904\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0161 - mae: 0.1413 - val_loss: 0.0183 - val_mae: 0.0903\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0220 - mae: 0.1669 - val_loss: 0.0183 - val_mae: 0.0902\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1446 - val_loss: 0.0183 - val_mae: 0.0901\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0157 - mae: 0.1456 - val_loss: 0.0183 - val_mae: 0.0899\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0168 - mae: 0.1467 - val_loss: 0.0183 - val_mae: 0.0898\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1408 - val_loss: 0.0183 - val_mae: 0.0897\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0151 - mae: 0.1331 - val_loss: 0.0184 - val_mae: 0.0896\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0165 - mae: 0.1437 - val_loss: 0.0184 - val_mae: 0.0896\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1339 - val_loss: 0.0185 - val_mae: 0.0896\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0153 - mae: 0.1406 - val_loss: 0.0185 - val_mae: 0.0896\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0136 - mae: 0.1310 - val_loss: 0.0186 - val_mae: 0.0896\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1363 - val_loss: 0.0186 - val_mae: 0.0897\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1244 - val_loss: 0.0187 - val_mae: 0.0897\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0142 - mae: 0.1363 - val_loss: 0.0187 - val_mae: 0.0897\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0147 - mae: 0.1329 - val_loss: 0.0187 - val_mae: 0.0898\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0142 - mae: 0.1387 - val_loss: 0.0188 - val_mae: 0.0899\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - mae: 0.1488 - val_loss: 0.0188 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0106 - mae: 0.1174 - val_loss: 0.0188 - val_mae: 0.0901\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0136 - mae: 0.1346 - val_loss: 0.0189 - val_mae: 0.0901\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0139 - mae: 0.1327 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0110 - mae: 0.1145 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0125 - mae: 0.1206 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0118 - mae: 0.1222 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0123 - mae: 0.1293 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0106 - mae: 0.1157 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0124 - mae: 0.1232 - val_loss: 0.0189 - val_mae: 0.0902\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0122 - mae: 0.1254 - val_loss: 0.0189 - val_mae: 0.0901\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0106 - mae: 0.1164 - val_loss: 0.0189 - val_mae: 0.0901\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0128 - mae: 0.1182 - val_loss: 0.0188 - val_mae: 0.0901\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0114 - mae: 0.1190 - val_loss: 0.0188 - val_mae: 0.0900\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0188 - val_mae: 0.0900\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0124 - mae: 0.1235 - val_loss: 0.0188 - val_mae: 0.0900\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0117 - mae: 0.1186 - val_loss: 0.0188 - val_mae: 0.0899\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0115 - mae: 0.1219 - val_loss: 0.0188 - val_mae: 0.0899\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0118 - mae: 0.1167 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0109 - mae: 0.1150 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0101 - mae: 0.1131 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1028 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0113 - mae: 0.1165 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0088 - mae: 0.1054 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0107 - mae: 0.1180 - val_loss: 0.0187 - val_mae: 0.0898\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0113 - mae: 0.1174 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0088 - mae: 0.1067 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - mae: 0.0965 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1159 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - mae: 0.1004 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0092 - mae: 0.1080 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - mae: 0.0975 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0107 - mae: 0.1149 - val_loss: 0.0187 - val_mae: 0.0900\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0084 - mae: 0.1000 - val_loss: 0.0186 - val_mae: 0.0900\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0075 - mae: 0.0955 - val_loss: 0.0186 - val_mae: 0.0899\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0186 - val_mae: 0.0899\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0088 - mae: 0.1040 - val_loss: 0.0186 - val_mae: 0.0899\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0076 - mae: 0.0975 - val_loss: 0.0186 - val_mae: 0.0898\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0081 - mae: 0.0993 - val_loss: 0.0186 - val_mae: 0.0898\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0092 - mae: 0.1063 - val_loss: 0.0186 - val_mae: 0.0897\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0186 - val_mae: 0.0897\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - mae: 0.0971 - val_loss: 0.0186 - val_mae: 0.0896\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0186 - val_mae: 0.0896\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0089 - mae: 0.1069 - val_loss: 0.0186 - val_mae: 0.0896\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - mae: 0.0916 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0081 - mae: 0.0986 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - mae: 0.0952 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0997 - val_loss: 0.0186 - val_mae: 0.0896\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - mae: 0.0965 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0083 - mae: 0.1007 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0080 - mae: 0.0998 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0073 - mae: 0.0962 - val_loss: 0.0186 - val_mae: 0.0894\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0077 - mae: 0.0946 - val_loss: 0.0186 - val_mae: 0.0894\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0063 - mae: 0.0870 - val_loss: 0.0186 - val_mae: 0.0893\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0881 - val_loss: 0.0186 - val_mae: 0.0893\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0062 - mae: 0.0873 - val_loss: 0.0186 - val_mae: 0.0892\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - mae: 0.0943 - val_loss: 0.0186 - val_mae: 0.0892\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0070 - mae: 0.0955 - val_loss: 0.0186 - val_mae: 0.0892\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0075 - mae: 0.0918 - val_loss: 0.0186 - val_mae: 0.0891\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0077 - mae: 0.0956 - val_loss: 0.0186 - val_mae: 0.0891\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0065 - mae: 0.0907 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0936 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - mae: 0.0906 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - mae: 0.0840 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - mae: 0.0903 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0933 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0066 - mae: 0.0885 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0073 - mae: 0.0926 - val_loss: 0.0186 - val_mae: 0.0889\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - mae: 0.0870 - val_loss: 0.0186 - val_mae: 0.0889\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - mae: 0.0921 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0844 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - mae: 0.0882 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0843 - val_loss: 0.0186 - val_mae: 0.0887\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - mae: 0.0870 - val_loss: 0.0186 - val_mae: 0.0887\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - mae: 0.0843 - val_loss: 0.0186 - val_mae: 0.0886\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0065 - mae: 0.0859 - val_loss: 0.0186 - val_mae: 0.0885\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - mae: 0.0871 - val_loss: 0.0186 - val_mae: 0.0884\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - mae: 0.0877 - val_loss: 0.0186 - val_mae: 0.0884\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0059 - mae: 0.0829 - val_loss: 0.0186 - val_mae: 0.0883\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - mae: 0.0880 - val_loss: 0.0186 - val_mae: 0.0882\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0063 - mae: 0.0850 - val_loss: 0.0186 - val_mae: 0.0882\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0057 - mae: 0.0852 - val_loss: 0.0186 - val_mae: 0.0881\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - mae: 0.0825 - val_loss: 0.0186 - val_mae: 0.0881\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - mae: 0.0859 - val_loss: 0.0186 - val_mae: 0.0881\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0059 - mae: 0.0845 - val_loss: 0.0186 - val_mae: 0.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 6), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--- Training CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=cnn_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)\n",
    "print('--- Training LSTM ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=lstm_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)\n",
    "print('--- Training LSTM-CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM-CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=stacked_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Training/Validation Results\n",
    "\n",
    "Loss curves across the models are fairly stable. All models show a decreasing validation curve with different epoch thresholds for when the model stops learning against the validation set. The LSTM appears to begin to have the slowest learning curve, while the CNN takes around 20 epochs to reach a loss close to 0. Some options to help improve this are to introduce learning rate decline, or train on longer input sequences.\n",
    "\n",
    "Plots of the MAE show a similar pattern to the loss plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB+EAAAHWCAYAAACogPtYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hb9dn/8c+RZEnee2Q4ew8SCBQSKFAIJGzK3qOFtjxltOlDaYBSKKW0fVoKLRQKP2hpSyhlBcoIhZQwwwxZEEK2s2zHduJty5b0++OcI0te8ZAj2X6/rkuXZOno6DgO5OvzOfd9G8FgMCgAAAAAAAAAAAAAANBrjlgfAAAAAAAAAAAAAAAAAwUhPAAAAAAAAAAAAAAAUUIIDwAAAAAAAAAAAABAlBDCAwAAAAAAAAAAAAAQJYTwAAAAAAAAAAAAAABECSE8AAAAAAAAAAAAAABRQggPAAAAAAAAAAAAAECUEMIDAAAAAAAAAAAAABAlhPAAAAAAAAAAAAAAAEQJITwAAAAAAAAAAAAAAFFCCA8AUbRp0yZ997vf1ZgxY+T1epWWlqYjjzxS9913n+rr6yVJo0aNkmEYuu6669q8f9myZTIMQ88880zoub/+9a8yDENer1c7d+5s855jjz1W06ZN67tvCgAAAP2KvX785JNPOtxmz549uuGGGzRp0iQlJiYqLy9PX/va13TTTTeppqYmtC7tyi38Mw3D0Lvvvtvm84LBoAoLC2UYhk499dQ++94BAAAQXQNpbVlVVaU77rhDM2bMUEpKihITEzVt2jTddNNN2rVrV2i7K664QoZh6KCDDlIwGGyzH8MwdO2114a+3rp1a+h4n3322Tbb33777TIMQ2VlZV0+VgD9nyvWBwAAA8XLL7+sc889Vx6PR5dddpmmTZsmn8+nd999VzfeeKM+//xzPfzww6HtH3nkES1cuFBDhw7t0v4bGxv1q1/9Sn/84x/76lsAAADAIFBRUaFDDz1UVVVV+ta3vqVJkyapvLxcq1ev1oMPPqhrrrlGkydP1t///veI9y1cuFApKSm65ZZbOty31+vVokWLdNRRR0U8/9Zbb2nHjh3yeDx98j0BAAAgNvrL2nLz5s2aO3euioqKdO655+o73/mO3G63Vq9erUcffVTPP/+8vvrqq4j3rFmzRs8995zOPvvsLn/Oz3/+c5111lmhCwoADF6E8AAQBVu2bNEFF1ygkSNH6r///a+GDBkSeu373/++Nm7cqJdffjn03NSpU7V+/Xr96le/0h/+8IcufcbMmTO7HdwDAAAArT366KMqKirSe++9pzlz5kS8VlVVJbfbLa/Xq0suuSTitV/96lfKyclp83y4k08+WU8//bT+8Ic/yOVqOeWwaNEizZo1i+ofAACAAaY/rC2bm5t11llnqaSkRMuWLWsT6t9111369a9/HfFcYmKiCgsLuxWqz5w5UytXrtTzzz+vs846q0vHBmDgoh09AETBb37zG9XU1OjRRx+NCOBt48aN0w033BD6etSoUbrsssv0yCOPRLQ66szNN98sv9+vX/3qV1E7bgAAAAw+mzZtktPp1BFHHNHmtbS0NHm93h7v+8ILL1R5eblef/310HM+n0/PPPOMLrrooh7vFwAAAPGpP6wtn332Wa1atUq33HJLmwDePs677ror4jmHw6Fbb71Vq1ev1vPPP9+lz7ngggs0YcIE/fznP2+3jT2AwYUQHgCi4N///rfGjBnT5mrPztxyyy1qbm7ucqg+evTobgf3AAAAQGsjR46U3+9v0xI0GkaNGqXZs2frySefDD336quvqrKyUhdccEHUPw8AAACx1R/Wli+++KIk6dJLL+3W51900UUaP358l0N1p9OpW2+9VatWrepycA9g4CKEB4Beqqqq0s6dOzV9+vRuvW/MmDG69NJL9cgjj2j37t1deo8d3LdujwQAAAB01be+9S3l5ubqiiuu0OTJk3XNNdfoySefVGVlZVT2f9FFF2nx4sWqr6+XJD3xxBM65phjGKkEAAAwAPWHteW6deuUnp6uwsLCbn12eKi+ePHiLh9vd4J7AAMXITwA9FJVVZUkKTU1tdvvvfXWW7tVDW8H9w8//HCXg3sAAAAgXH5+vlatWqXvfe972rt3rx566CFddNFFysvL05133tnrk4XnnXee6uvr9dJLL6m6ulovvfQSregBAAAGqP6wtqyqqurRuVtJuvjii3tcDd/V4B7AwEQIDwC9lJaWJkmqrq7u9nt7Eqp3N7gHAAAAWhsyZIgefPBB7d69W+vXr9cf/vAH5ebm6rbbbtOjjz7aq33n5uZq7ty5WrRokZ577jn5/X6dc845UTpyAAAAxJt4WVvu2bNHxcXFoVtNTY0k8/xtT87dSi2h+sqVK7scql988cUaN24c1fDAIEcIDwC9lJaWpqFDh2rt2rU9en93W8yPGTNGl1xyCdXwAAAA6DXDMDRhwgRdd911evvtt+VwOPTEE0/0er8XXXSRXn31VT300EM66aSTlJGR0fuDBQAAQFyL9drysMMO05AhQ0K33/72t5KkSZMmqbKyUtu3b+/R53c3VA8P7l944YUefSaA/o8QHgCi4NRTT9WmTZu0fPnybr937NixuuSSS/TnP/+529XwzIYHAABAtIwZM0aZmZlRudDzm9/8phwOhz744ANa0QMAAAxCsVhbPvHEE3r99ddDt8suu0ySdNppp0mS/vGPf/To83sSql9yySUaN26c7rjjDqrhgUGKEB4AouDHP/6xkpOTddVVV6mkpKTN65s2bdJ9993X4ftvvfVWNTU16Te/+U2XPi88uC8uLu7xcQMAAGDw+fDDD1VbW9vm+Y8++kjl5eWaOHFirz8jJSVFDz74oG6//fbQSU8AAAAMPPG0tjzyyCM1d+7c0G3MmDGSpHPOOUfTp0/XXXfd1W4RVXV1tW655ZZOjyE8VO+K8OD+xRdf7NJ7AAwsrlgfAAAMBGPHjtWiRYt0/vnna/Lkybrssss0bdo0+Xw+vf/++3r66ad1xRVXdPr+Sy65RI8//niXP/OWW27R3//+d61fv15Tp06NwncBAACAgeSxxx7TkiVL2jy/ZcsWPffcc/rmN7+pWbNmye12a926dXrsscfk9Xp18803R+XzL7/88qjsBwAAALHXn9eWCQkJeu655zR37lwdffTROu+883TkkUcqISFBn3/+uRYtWqTMzEzdddddHe7D6XTqlltu0ZVXXtnlz7344ot15513auXKlT0+dgD9FyE8AETJ6aefrtWrV+v//u//9MILL+jBBx+Ux+PRQQcdpN/97ne6+uqrO33/rbfeqn/84x/y+/1d+rxx48Z1O7gHAADA4PHggw+2+/zbb7+t7OxsLV26VC+88IKqqqqUm5urE088UQsXLtTBBx98gI8UAAAA8a6/ry3HjRunlStX6ve//72ef/55LV68WIFAQOPGjdNVV12l66+/fr/7uOSSS/SLX/xCmzZt6tJnulwu3Xrrrd0K7gEMHEaQYRQAAAAAAAAAAAAAAEQFM+EBAAAAAAAAAAAAAIgSQngAAAAAAAAAAAAAAKKEEB4AAAAAAAAAAAAAgCiJixD+gQce0KhRo+T1enX44Yfro48+6nT7p59+WpMmTZLX69X06dP1yiuvRLx+xRVXyDCMiNv8+fP78lsAAADAAMVaFQAAAPGM9SoAAED8iXkI/9RTT2nBggX62c9+phUrVmjGjBmaN2+eSktL293+/fff14UXXqhvf/vb+uyzz3TmmWfqzDPP1Nq1ayO2mz9/vnbv3h26Pfnkkwfi2wEAAMAAwloVAAAA8Yz1KgAAQHwygsFgMJYHcPjhh+uwww7T/fffL0kKBAIqLCzUddddp5/85Cdttj///PNVW1url156KfTcEUccoZkzZ+qhhx6SZF6tuW/fPi1evPiAfA8AAAAYmFirAgAAIJ6xXgUAAIhPrlh+uM/n06effqqFCxeGnnM4HJo7d66WL1/e7nuWL1+uBQsWRDw3b968NovCZcuWKS8vT5mZmTruuOP0i1/8QtnZ2e3us7GxUY2NjaGvA4GAKioqlJ2dLcMwevjdAQAAxJ9gMKjq6moNHTpUDkfMmyLFtXhZq0qsVwEAwODBerXrWK8CAAAceF1dr8Y0hC8rK5Pf71d+fn7E8/n5+fryyy/bfU9xcXG72xcXF4e+nj9/vs466yyNHj1amzZt0s0336yTTjpJy5cvl9PpbLPPu+++W3fccUcUviMAAID+Yfv27Ro+fHisDyOuxctaVWK9CgAABh/Wq/vHehUAACB29rdejWkI31cuuOCC0OPp06froIMO0tixY7Vs2TIdf/zxbbZfuHBhxBWglZWVGjFihLZv3660tLQDcszN/oBm/vx1SdI7P/6GMpPdB+RzAQDA4FJVVaXCwkKlpqbG+lAGre6uVaX4WK8CAAAcCKxXY6/frlfLNkiPfENKSJF+tE7aTwX+rn31OvH3byvB5dDSHx6to/9vmSRp5W0n6KwH39fmPbV69PJDNSY3Wd/47VtyGNL3jhmrPy3bpHNmDdftp089AN8UAACIN11dr8Y0hM/JyZHT6VRJSUnE8yUlJSooKGj3PQUFBd3aXpLGjBmjnJwcbdy4sd2FosfjkcfjafN8WlraAVskBoNBOTxJkqTk1FSlpbQ9HgAAgGihJeT+xctaVYqP9SoAAMCBxHp1/1ivtpI4RfIYkmqlBL+UlNXp5o2GRw5PkvySDE+SHJ4kJSY4lZWZoayMdG2tCsrvSpTflSiHJ0lZyW7l52TK4UlSo8PDOhwAgEFuf+vVmA5WcrvdmjVrlpYuXRp6LhAIaOnSpZo9e3a775k9e3bE9pL0+uuvd7i9JO3YsUPl5eUaMmRIdA68DxiGIYf1s/IHgrE9GAAAALBWBQAAQFxjvdpKQqKUYrXa37t1v5u7XS2nxvfVNUmSkj1mzVpaYoIkqaqhSRW1PklSRlKC0rzW8/VN0TpqAAAwQMU0hJekBQsW6JFHHtHjjz+udevW6ZprrlFtba2uvPJKSdJll12mhQsXhra/4YYbtGTJEv3ud7/Tl19+qdtvv12ffPKJrr32WklSTU2NbrzxRn3wwQfaunWrli5dqjPOOEPjxo3TvHnzYvI9dpXTSuEJ4QEAAOIDa1UAAADEM9arrWSMNO/3bdvvpp6wEN4O2lO9VggfFrbvqzNfy0xyh8L56obmqB0yAAAYmGI+E/7888/Xnj17dNttt6m4uFgzZ87UkiVLlJ9vXrVYVFQkh6NlQTRnzhwtWrRIt956q26++WaNHz9eixcv1rRp0yRJTqdTq1ev1uOPP659+/Zp6NChOvHEE3XnnXe22xIpnjgdhpr8QUJ4AACAOMFaFQAAAPGM9WormSOlHR9Je/cfwrudbUP4ZI9TkpSe2BLC77Wq4zOT3KGQvqqBSngAANC5mIfwknTttdeGrrZsbdmyZW2eO/fcc3Xuuee2u31iYqJee+21aB7eAeM0qIQHAPQvfr9fTU2cfIgnTqdTLpeLGZpRxFoVAID+KRgMqrm5WX6/P9aHgjCsV6OP9WqYblTCOxyGXA5DzYFgKIRPCbWjt8P2Znlq7Ur48Hb0VMIDAHqP9Wp8itZ6NS5CeJgcdjv6ICE8ACD+1dTUaMeOHQry71bcSUpK0pAhQ+R2u2N9KAAAADHh8/m0e/du1dXVxfpQ0A7Wq+gzmVYI34VKeMmcC9/s86uirlUIH9aOPsFpnrPNTHaHwvlqKuEBAL3EejW+RWO9SggfR1xWCB+gEh4AEOf8fr927NihpKQk5ebmUsUSJ4LBoHw+n/bs2aMtW7Zo/PjxEa0nAQAABoNAIKAtW7bI6XRq6NChcrvdrFfjBOtV9LluVMJLZghf5/OroqZ1JbwVwjc0hf7/YbajN59vbA6oockvb4IzmkcPABgkWK/Gr2iuVwnh44jTCuGbCeEBAHGuqalJwWBQubm5SkxMjPXhIExiYqISEhK0bds2+Xw+eb3eWB8SAADAAeXz+RQIBFRYWKikpKRYHw5aYb2KPmVXwu8rkgIBaT8nze258HYlfHKbSvhm2c3fMpMSlOpxyTCkYFCqbmgmhAcA9Ajr1fgWrfUql5rGETuEZyY8AKC/4ArN+EQ1EQAAAGuieMbPBn0mbbhkOCW/T6op3u/mbpcVwtsz4b1mCJ8eVgm/1wroM5LccjiMULU8LekBAL3Fmih+ReNnw083jjgNQngAAAAAAAAA6BGnS0ofZj7uwlx4O4Tfa4fwbrsdvXlfWd+kvXVm2J6VbM6EDVXJNzRH77gBAMCAQwgfRxx2JXyQEB4AAAAAAAAAui1zlHnfhbnwrdvR25XwLe3oWyrhM5PM51KtbarqqYQHAAAdI4SPIy4rhA9QCQ8AQJ849thj9YMf/CDWhwEAAAC0i/UqEAUZ1lz4LlTCe6xK+EorUA/NhLfa0df6/KHXMpLcEa9VUwkPABiEWK92HSF8HLEr4ZsJ4QEAAAAAAACg+zKtEL4rlfBWCG83Jk21Qni72j38tQyrEj7NroRnJjwAAOgEIXwcsWfCUwkPAAAAAAAAAD2QMcq878ZMeJtdCZ/gdCjZ7Qw9n+p1KcFqXR/eqh4AAKAjhPBxxMlMeABAPxUMBlXna47JLdjDfzf37t2ryy67TJmZmUpKStJJJ52kDRs2hF7ftm2bTjvtNGVmZio5OVlTp07VK6+8EnrvxRdfrNzcXCUmJmr8+PH6y1/+EpU/SwAAAEQf61XWqxhEulEJbwfrtpSwCni77bwkZVqt6MOfpx09ACCaWK8OvPWqa/+b4EBx0o4eANBP1Tf5NeW212Ly2V/8fJ6S3N1f0lxxxRXasGGDXnzxRaWlpemmm27SySefrC+++EIJCQn6/ve/L5/Pp7ffflvJycn64osvlJKSIkn66U9/qi+++EKvvvqqcnJytHHjRtXX10f7WwMAAECUsF5lvYpBxJ4JX7VT8jdJzoQON3W3DuE9YSG8N0G7KxskSZnJLSF8Ku3oAQB9gPXqwFuvEsLHEZeDdvQAABwI9uLwvffe05w5cyRJTzzxhAoLC7V48WKde+65Kioq0tlnn63p06dLksaMGRN6f1FRkQ4++GAdeuihkqRRo0Yd8O8BAAAAAxfrVaAXUvIkV6LUXC9VbpeyxnS4aet29BEhfGLL48ykliCfdvQAALBe7QpC+DjioBIeANBPJSY49cXP58Xss7tr3bp1crlcOvzww0PPZWdna+LEiVq3bp0k6frrr9c111yj//znP5o7d67OPvtsHXTQQZKka665RmeffbZWrFihE088UWeeeWZosQkAAID4w3qV9SoGEcOQMkZIZevNufDdCOGTW1XC27Ii2tGb29COHgAQTaxXB956lZnwccRpUAkPAOifDMNQktsVk5th/fsZbVdddZU2b96sSy+9VGvWrNGhhx6qP/7xj5Kkk046Sdu2bdMPf/hD7dq1S8cff7z+93//t0+OAwAAAL3HepX1KgaZLs6F93RSCZ8eNhM+Iym8Hb1VCU87egBAFLFeHXjrVUL4OGLPhPcHCeEBAOhLkydPVnNzsz788MPQc+Xl5Vq/fr2mTJkSeq6wsFDf+9739Nxzz+lHP/qRHnnkkdBrubm5uvzyy/WPf/xD9957rx5++OED+j0AAABg4GK9CvSSPRd+79ZONwufCZ+Y4Aydn5WktLAQvv129FTCAwAGL9ar+0c7+jgSCuGphAcAoE+NHz9eZ5xxhq6++mr9+c9/Vmpqqn7yk59o2LBhOuOMMyRJP/jBD3TSSSdpwoQJ2rt3r958801NnjxZknTbbbdp1qxZmjp1qhobG/XSSy+FXgMAAAB6i/Uq0EuZo8z7/YXwYZXwKd7IU+VpYV9nJrfXjp5KeADA4MV6df+ohI8jhPAAABw4f/nLXzRr1iydeuqpmj17toLBoF555RUlJJhVDX6/X9///vc1efJkzZ8/XxMmTNCf/vQnSZLb7dbChQt10EEH6eijj5bT6dQ///nPWH47AAAAGGBYrwK9kDXavK/Y0ulmESG8p1UIH1EJ3147eirhAQCDG+vVzlEJH0cI4QEA6FvLli0LPc7MzNTf/va3Dre15xO159Zbb9Wtt94azUMDAAAAWK8C0ZJphfB79xPCO52hx21CeG9H7ejN7Woam+UPBCNa2AMAMNCxXu06KuHjiNMghAcAAAAAAACAXrHb0TdUSnUVHW4WXgmf7HFGvBZRCZ/cthJekmqohgcAAB0ghI8joUr4ICE8AAAAAAAAAPSIO0lKHWI+7qQaPrIdfULEa/bsdymyHb3b5ZA3wXxfFXPhAQBABwjhY2VfkfSLAunuwtBTdggfoBIeAAAAAAAAAHouc/9z4SND+FaV8GEV7xlJCe2+VllPCA8AANpHCB8rhlNqrpea6kJPOawQvpkQHgAAAAAAAAB6Lmv/IbzHGRbCeyNnwueneWUYUk6KW96E9lvVV9OOHgAAdMC1/03QJ5xWC6NAsxQMSoYhl4OZ8AAAAAAAAADQa3YlfBfb0Sd7Ik+V56Z69Milhyorxd36bUq1Anva0QMAgI4QwseKM+yPPtAsORPkNAjhAQAAAAAAAKDXulAJHx7Cp3raniqfOyW/3ffZ7eiraEcPAAA6QDv6WHGEzRHym4s1ux29P0gIDwAAAAAAAAA91oVK+ARnx5XwnaEdPQAA2B9C+FhxhoXwATOEt9vRB6iEBwAAAAAAAICesyvhq3dLTfXtbtJZO/rO0I4eAADsDyF8rERUwptXTNqV8M2E8AAAAAAAAADQc4mZkifdfLx3a7ubuJ2dt6PvSEs7eirhAQBA+wjhY8XhkAzrj59KeAAA+oVRo0bp3nvv7dK2hmFo8eLFfXo8AAAAQDjWq0AYw5CyRpmPO5gL39NK+LREc9tqKuEBAOiWwbReJYSPJbsa3p4JbzATHgAAAAAAAACiYj9z4T1hIXyKtzvt6K1KeEJ4AADQAUL4WLLnwvt95pe0owcAAAAAAACA6MgaY95XbG735fBK+JRutaO3ZsLTjh4AAHSAED6W7BA+YC7WaEcPAOi3gkHJVxubWxc7yDz88MMaOnSoAoFAxPNnnHGGvvWtb2nTpk0644wzlJ+fr5SUFB122GF64403ovZHtGbNGh133HFKTExUdna2vvOd76impib0+rJly/S1r31NycnJysjI0JFHHqlt27ZJklatWqVvfOMbSk1NVVpammbNmqVPPvkkascGAAAw4LFe3S/WqxiQsqxK+I7a0Tt7GMInmud1qxuphAcARAnr1f3qb+vVrq8sEH2t29FTCQ8A6K+a6qRfDo3NZ9+8S3In73ezc889V9ddd53efPNNHX/88ZKkiooKLVmyRK+88opqamp08skn66677pLH49Hf/vY3nXbaaVq/fr1GjBjRq0Osra3VvHnzNHv2bH388ccqLS3VVVddpWuvvVZ//etf1dzcrDPPPFNXX321nnzySfl8Pn300UcyrFE1F198sQ4++GA9+OCDcjqdWrlypRISEnp1TAAAAIMK69VOsV7FgLWfdvQ9nglPJTwAINpYr3aqP65XCeFjKVQJb4bwToNKeAAA+kpmZqZOOukkLVq0KLRIfOaZZ5STk6NvfOMbcjgcmjFjRmj7O++8U88//7xefPFFXXvttb367EWLFqmhoUF/+9vflJxsLmjvv/9+nXbaafr1r3+thIQEVVZW6tRTT9XYsWMlSZMnTw69v6ioSDfeeKMmTZokSRo/fnyvjgcAAADxh/Uq0AfsSvh9RZK/WXJGng5PdptfJzgNJbudXd5tbopXklRc1SBfcyAizAcAYKBivdo9hPCx5LD++P3mFZP2THh/F9s+AAAQNxKSzCsmY/XZXXTxxRfr6quv1p/+9Cd5PB498cQTuuCCC+RwOFRTU6Pbb79dL7/8snbv3q3m5mbV19erqKio14e4bt06zZgxI7RAlKQjjzxSgUBA69ev19FHH60rrrhC8+bN0wknnKC5c+fqvPPO05AhQyRJCxYs0FVXXaW///3vmjt3rs4999zQYhIAAABdwHq1U6xXMWClDpWcHsnfKFXtkDJHRbycnpSg206dohSvSy5n14P0wqxEZSQlaF9dk77YXaWZhRnRPW4AwODDerVT/XG9yiV6sdS6Et4O4amEBwD0N4ZhtiyKxc3qJNMVp512moLBoF5++WVt375d77zzji6++GJJ0v/+7//q+eef1y9/+Uu98847WrlypaZPny6fz9dXf2oR/vKXv2j58uWaM2eOnnrqKU2YMEEffPCBJOn222/X559/rlNOOUX//e9/NWXKFD3//PMH5LgAAAAGBNarvcZ6Ff2SwyFljjQfdzAX/ltHjdZ5hxZ2a7eGYehgK3j/rGhvb44QAAAT69Vei7f1KiF8LLWaCU8IDwBA3/J6vTrrrLP0xBNP6Mknn9TEiRN1yCGHSJLee+89XXHFFfrmN7+p6dOnq6CgQFu3bo3K506ePFmrVq1SbW1t6Ln33ntPDodDEydODD138MEHa+HChXr//fc1bdo0LVq0KPTahAkT9MMf/lD/+c9/dNZZZ+kvf/lLVI4NAAAA8YP1KtAH9jMXvqcOGZEpSVpRtC+q+wUAIJ6xXu06QvhYsmcQtamEj9UBAQAw8F188cV6+eWX9dhjj4Wu0pTMOUDPPfecVq5cqVWrVumiiy5SIBCdf5Qvvvhieb1eXX755Vq7dq3efPNNXXfddbr00kuVn5+vLVu2aOHChVq+fLm2bdum//znP9qwYYMmT56s+vp6XXvttVq2bJm2bdum9957Tx9//HHETCMAAAAMHKxXgSiz58J3UAnfU4eMtEL4bVTCAwAGF9arXcNM+FhqXQlv2CE8KTwAAH3luOOOU1ZWltavX6+LLroo9Pw999yjb33rW5ozZ45ycnJ00003qaqqKiqfmZSUpNdee0033HCDDjvsMCUlJenss8/WPffcE3r9yy+/1OOPP67y8nINGTJE3//+9/Xd735Xzc3NKi8v12WXXaaSkhLl5OTorLPO0h133BGVYwMAAEB8Yb0KRFkfVcLPKMyQYUg799WrtKpBeWneqO4fAIB4xXq1a4xgMEjv81aqqqqUnp6uyspKpaWl9d0HPTpP2v6BdN7fpSmn67F3t+jnL32h02YM1R8vPLjvPhcAgF5qaGjQli1bNHr0aHm9nGiIN539fA7YOgd9ip8jAAAdY60a/1ivDnxx9XP86jVp0XlS/jTpmveiuuv5976tL4ur9dAlszR/WkFU9w0AGLhYr8a/aKxXaUcfS06rEr5VO/oAM+EBAAAAAAAAoPcyw9rRR7ke7WBrLvxnRbSkBwAAkQjhY8lhTQPwN5tfWiF8M+3oAQCIa0888YRSUlLavU2dOjXWhwcAAIBBjvUqECZzpGQ4pKZaqaY0qrs+ZESGJGkFITwAAN0yGNarzISPpVaV8C6HPRM+VgcEAAC64vTTT9fhhx/e7msJCQkH+GgAAACASKxXgTAuj5ReKO3bJpVvlFLzo7brQ0aalfCrd1TK1xyQ20XNGwAAXTEY1quE8LHksP4S+a129IYdwpPCAwAQz1JTU5WamhrrwwAAAADaxXoVaCVnfEsIP+rIqO12dHay0hMTVFnfpC+Lq3TQ8Iyo7RsAgIFsMKxXuTQvlpzWNRCByHb0fkbCAwD6iWCU5+khOvi5AAAAsCaKZ/xscMBljzPvyzdEdbcOh6GD7Zb022hJDwDoHtZE8SsaPxtC+FhqVQlvt6MPBPiPDgAQ35xOpyTJ5/PF+EjQnrq6OkkDp3UTAABAd9hrIHtNhPjDehUHXCiE3xT1XR8ywmxJv6JoX9T3DQAYmFivxr9orFdpRx9L9kx4vxlg2JXwzbSjBwDEOZfLpaSkJO3Zs0cJCQlyOLiuLx4Eg0HV1dWptLRUGRkZoYslAAAABhOn06mMjAyVlpZKkpKSkmRYIwARW6xXETOhEH5j1HcdqoQvohIeANA1rFfjVzTXq4TwsWSH8IHWlfCxOiAAALrGMAwNGTJEW7Zs0bZt22J9OGglIyNDBQUFsT4MAACAmLHXQvaJTcQX1qs44OwQvmKL5G9uGRMaBTMLM2QY0o699SqtblBeqjdq+wYADFysV+NbNNarhPCxFGpHb82EN+yZ8LSjBwDEP7fbrfHjx9OSPs4kJCRQUQQAAAY9+6LRvLw8NTU1xfpwEIb1KmIibZjkSpSa66V926TssVHbdao3QRPyUrW+pFqfFe3TvKlcYAIA2D/Wq/ErWutVQvhYalUJ7wy1oyeEBwD0Dw6HQ14vV/kDAAAgPjmdTgJfAJLDYQbvJWvNufBRDOElaWKBGcIXlTPbFwDQPaxXBy4GuMaSw7oGwt+6HT0hPAAAAAAAAABEjR2898Fc+IJ08+L04qqGqO8bAAD0T4TwsRSqhLfa0VMJDwAAAAAAAADRZ8+FL98Q9V3npxHCAwCASITwsRSaCW+1ozeohAcAAAAAAACAqMseb973RSW8FcKXVBLCAwAAEyF8LNmV8H6f+aVVCe8PEsIDAAAAAAAAQNSEKuE3RX3X+WkeSVJJNSE8AAAwEcLHkj0T3mpHHwrhqYQHAAAAAAAAgOixZ8JX7ZR8tVHdtd2OvqSqUUEKrAAAgAjhY8vpNu/tdvSE8AAAAAAAAAAQfUlZUmKW+TjK1fB2CO9rDmhvXVNU9w0AAPonQvhYstvRBwjhAQAAAAAAAKBP5fTNXHi3y6HsZLPgqpi58AAAQITwsWW3o7cr4Q1CeAAAAAAAAADoE304Fz4v1JKeEB4AABDCx1aoEr7VTHjmBgEAAAAAAABAdNlz4cs3RH3XBWkeSYTwAADARAgfSw4rhG81Ez5AJTwAAAAAAAAARFd237Sjl6SCdLMSvpgQHgAAiBA+ttrMhDe/bCaEBwAAAAAAAIDoCrWj3yhFuRtpPu3oAQBAGEL4WGo9E95h/jiohAcAAAAAAACAKMsaLcmQGiqluvKo7toO4YsrCeEBAAAhfGw5W7WjN8x29FTCAwAAAAAAAECUJSRKGYXm47LozoUvCFXCN0Z1vwAAoH8ihI8lp9u8t9vRO80Q3h/lVkgAAAAAAAAAAEW2pI8i2tEDAIBwhPCxFGpH3yyppRKedvQAAAAAAAAA0AfsEL7sq6jutiDdDOHLa31qbPZHdd8AAKD/IYSPJbsdvVUJb42Epx09AAAAAAAAAPSF3Enm/Z4vo7rbzKQEuZ3mCd5SWtIDADDoEcLHkiNyJrzL0fLjoBoeAAAAAAAAAKIsb4p5X7ouqrs1DEN5aR5z19W0pAcAYLCLixD+gQce0KhRo+T1enX44Yfro48+6nT7p59+WpMmTZLX69X06dP1yiuvdLjt9773PRmGoXvvvTfKRx0FTqsdfSCyHb3EXHgAAIB4MWjXqgAAAOgXWK92U55VCV+5XWqoiuquC6y58MWVVMIDADDYxTyEf+qpp7RgwQL97Gc/04oVKzRjxgzNmzdPpaWl7W7//vvv68ILL9S3v/1tffbZZzrzzDN15plnau3atW22ff755/XBBx9o6NChff1t9EyrSviwQnj5qYQHAACIuUG9VgUAAEDcY73aA4mZUqr1PUW5JX2+NRe+uIpKeAAABruYh/D33HOPrr76al155ZWaMmWKHnroISUlJemxxx5rd/v77rtP8+fP14033qjJkyfrzjvv1CGHHKL7778/YrudO3fquuuu0xNPPKGEhIQD8a10nz0T3u+TFNmOnhAeAAAg9gb1WhUAAABxj/VqD+VNNu9Lv4jqbu1K+BJCeAAABr2YhvA+n0+ffvqp5s6dG3rO4XBo7ty5Wr58ebvvWb58ecT2kjRv3ryI7QOBgC699FLdeOONmjp16n6Po7GxUVVVVRG3A8KuhLfa0YdXwjcTwgMAAMRUvKxVpRiuVwEAABC3WK/2QiiEj3IlvDUTnhAeAADENIQvKyuT3+9Xfn5+xPP5+fkqLi5u9z3FxcX73f7Xv/61XC6Xrr/++i4dx91336309PTQrbCwsJvfSQ85I9vRh1fCBwjhAQAAYipe1qpSDNerAAAAiFusV3uhjyrh80Mz4QnhAQAY7GLejj7aPv30U913333661//KsMwuvSehQsXqrKyMnTbvn17Hx+lxQ7hA9ZM+LDD9QcJ4QEAAAaanqxVpRiuVwEAADCoDJr1aiiEXxfV3dKOHgAA2GIawufk5MjpdKqkpCTi+ZKSEhUUFLT7noKCgk63f+edd1RaWqoRI0bI5XLJ5XJp27Zt+tGPfqRRo0a1u0+Px6O0tLSI2wER3o4+GJRhGKEgnpnwAAAAsRUva1UphutVAAAAxC3Wq72QO8m8ry2VasuittuCdKsSvqpBQYqsAAAY1GIawrvdbs2aNUtLly4NPRcIBLR06VLNnj273ffMnj07YntJev3110PbX3rppVq9erVWrlwZug0dOlQ33nijXnvttb77ZnrC6Wp5bM2Ft1vSE8IDAADE1qBfqwIAACCusV7tBXeylDnKfBzFani7HX1DU0BV9c1R2y8AAOh/XPvfpG8tWLBAl19+uQ499FB97Wtf07333qva2lpdeeWVkqTLLrtMw4YN09133y1JuuGGG3TMMcfod7/7nU455RT985//1CeffKKHH35YkpSdna3s7OyIz0hISFBBQYEmTpx4YL+5/bEr4SVzLrwzQQ6HJD8hPAAAQDwY1GtVAAAAxD3Wq72QN0Xau9UM4Ud/PSq79CY4lZ6YoMr6JpVUNyg9KWH/bwIAAANSzEP4888/X3v27NFtt92m4uJizZw5U0uWLFF+fr4kqaioSA5HS8H+nDlztGjRIt166626+eabNX78eC1evFjTpk2L1bfQc86wRZg1F95pzVoihAcAAIi9Qb1WBQAAQNxjvdoLeZOl9a9IpV9EdbcFaV5V1jepuLJBE/JTo7pvAADQfxhBhtO0UVVVpfT0dFVWVvbt/KJAQPp5pvn4xk1Sco4Ouv01VTU0a+mPjtHY3JS++2wAADAoHbB1DvoUP0cAADBQsc4ZGPrFz3HNM9Kz35YKj5C+Hb1W+5c99pHe/mqPfnPOQTrv0MKo7RcAAMSHrq5zYjoTftBzOCTD+hH4rUp4h1kJH6ASHgAAAAAAAAD6Ru4k8750nRTFOrWCNI8kqaSyIWr7BAAA/Q8hfKw53ea93Y7eag/VTAgPAAAAAAAAAH0jZ7xkOKXGSql6d9R2m5/mlSSVVBPCAwAwmBHCx5rDmgsfqoS3viSEBwAAAAAAAIC+4fJI2ePMx1GcC2+H8MWVjVHbJwAA6H8I4WPN6TLvA83ml4bZjp4QHgAAAAAAAAD6UN5k8750XdR2WWCF8J8V7dWflm3UiqK9avIHorZ/AADQP7hifQCDXutKeKcVwkdxDhEAAAAAAAAAoJW8KdIXi6Mawk8akiqXw1B5rU+/WbJekpSV7NZz18zRqJzkqH0OAACIb1TCx5rTCuHtmfBWJXyASngAAAAAAAAA6DuhSvjotaMfnpmkNxYco9tPm6L5UwuU7Haqotanj7ZURO0zAABA/COEjzWH1YzAb7ajdzjMEL6ZEB4AAAAAAAAA+k7eFPO+9Esp4I/abkflJOuKI0froUtn6aTpQyRJe2qYEQ8AwGBCCB9rdiW83ydJcjmohAcAAAAAAACAPpc1WnIlSs31UsXmPvmInBSPJKmMEB4AgEGFED7WHJHt6B0GM+EBAAAAAAAAoM85nFL+VPPx7lV98hE5KW5JUlmNr0/2DwAA4hMhfKyFKuHNdvRO2tEDAAAgDpRWNejVNbv15pelsT4UAAAAoO8MOci8L17dJ7vPTbUq4auphAcAYDAhhI81Z2QlPO3oAQAAEA9WFO3TNU+s0B/+uyHWhwIAAAD0nQI7hF/TJ7unHT0AAIMTIXys2e3o/VY7eirhAQAAEAfy0syThaVVnCwEAADAAGaH8LtXS30wIpQQHgCAwYkQPtaohAcAAEAcyrPaZu6pblSwD05GAgAAAHEhf4pkOKW6Mql6d9R3b8+E31vXpCZ/IOr7BwAA8YkQPtYcLvPemgnvMMwQ3s+JTgAAAMSQPbvS5w+osr4pxkcDAAAA9JGERClngvm4D1rSZya55bQKrypqfVHfPwAAiE+E8LHWqhLeXpD5qYQHAABADHlcTmUkmWvV0mpaZwIAAGAAK5hu3u9eHfVdOxyGspLNavg9rKsBABg0COFjLTQT3rwKkhAeAAAA8cJuSc9ceAAAAAxoQ6y58MXRD+El5sIDADAYEcLHmjOyHT0hPAAAAOJFXqpXklRa3RDjIwEAAAD6UEFfh/BmJXxZDe3oAQAYLAjhY81pLsBC7egNQngAAADEh1AlPG0zAQAAMJDZ7ej3bpUaKqO++1wq4QEAGHQI4WMt1I6+1Uz4ICE8AAAAYis3jXb0AAAAGASSsqT0QvNx8dqo7z7Huri1rNXFrVvKarX4s50KUJAFAMCAQwgfa3Y7+kBkCM/CCwAAALFGO3oAAAAMGn3Ykr6lHX1kCH/TM6v1g6dW6uOtFVH/TAAAEFuE8LEWqoSPnAnfTAgPAACAGKMdPQAAAAYNuyX97r4I4e129C0z4YPBoNYVV0mSiqu46BUAgIGGED7WnFYI36oSnpnwAAAAiDU7hN9DCA8AAICBbohdCb8m6rvOaWcmfEWtT9UNZmFWVX1T1D8TAADEFiF8rDmsdvT2THiDEB4AAADxIS/NakdPZQ4AAAAGOrsd/Z51UnN0L0JtL4TfWl4XelxlhfEAAGDgIISPNbsS3t+qEj5ICA8AAIDYsivha31+1TZyYhAAAAADWPpwyZshBZql0nVR3XVOqjkTvqLWFyq+2lpWG3q9qoFKeAAABhpC+Fhzmguw1u3oA1TCAwAAIMaSPS4lu52SmAsPAACAAc4wwlrSR3cufFaSW4YhBYJmEC9JW8tbQvhqKuEBABhwCOFjzRFZCe+wQvhmQngAAADEAVrSAwAAYNAYMsO837Uyqrt1OR3KSjKLseyW9FvCK+GZCQ8AwIBDCB9rTmsmfMC82tFFJTwAAADiSK7Vkp5KeAAAAAx4Qw8x73etiPquW8+F3xY2E55KeAAABh5C+FhrXQlvMBMeAAAA8SOPEB4AAACDxbBZ5n3xWqk5uutfey58WU2jgsEgM+EBABjgCOFjzWmF8NZMeBft6AEAABBH8lKtdvTVtKMHAADAAJcxQkrKNs/VFq+N6q7tSvg91Y0qr/WpurGl+p129AAADDyE8LHmsNrRW5XwTtrRAwAAII7kpVknC6uohAcAAMAAZxgt1fA7P43qrlva0fsiquAl2tEDADAQEcLHmrNVO3oq4QEAABBHaEcPAACAQaWP5sKHQvjqRm215sGPyEqSRDt6AAAGIkL4WHO0346eSngAAADEA9rRAwAAYFAZZoXwUa+EN2fC76lpDFXCHzQ8XZLU0BSQrzkQ1c8DAACxRQgfa60r4Q0zhPcHCeEBAAAQe3Y7eirhAQAAMCjYlfBlG6SGyqjtNie1pR39lnIzhJ82LD30ejXV8AAADCiE8LFmh/ABc+6PPRPeTyU8AAAA4oDdjn5fXZMam/0xPhoAAACgj6XkSukjJAWlXSujttvc0Ez4lkr4sbkpSnY7JTEXHgCAgYYQPtYckZXwhPAAAACIJ+mJCXK7zF8b9lANDwAAgMFgWPTnwtsz4StqfaEQfnROktISzfPDzIUHAGBgIYSPNWfkTPiWED5WBwQAAAC0MAwjVLVDS3oAAAAMCn0wFz7bmgnvDwRV6/PLYUiFWUlK85rnhzurhA8Gg9pQUq2GJjpTAQDQXxDCx5rDZd77zUWWKxTCk8IDAAAgPoTmwlcRwgMAAGAQGDbLvN/5WdR2meB0KCMpIfT10IxEeVxOpXrN88NV9R1Xwn+0pUIn/P5t/eyFz6N2PAAAoG8Rwsdaq0p4h2GF8HSjBwAAQJyw58LvqW6I8ZEAAAAAB8CQGZIMqWqHVF0Std3aLeklaVR2siSF2tF3Vgm/obRGkrTFamMPAADiHyF8rIVmwvsktbSjDzATHgAAAHEiL9UriXb0AAAAGCQ8qVLuJPNxVOfCu0OPR+UkSVJLJXwnM+HtgL7W13FQDwAA4gshfKw5I9vR2yF8M+3oAQAAECdyU2lHDwAAgEGmD+bCt1sJb82Er+qkEt4O6Ot9zIQHAKC/IISPNad19aPVjt4ZmgkfqwMCAAAAItnt6EutdvSl1Q264Z+faem66LXmBAAAAOJKKISPZiV8Swg/OscM4bsyE77aCuGphAcAoP9wxfoABr1QO3orhLdnwlMJDwAAgDiRl2aH8I0KBoO68enVeuurPVpfXK3jJ+fH+OgAAACAPjA0rBI+EJAcva9nsztMSdLIVjPhO2tHX1Vvhu91jVTCAwDQX1AJH2tOK4QPRLaj9zMSHgAAAHEifCb8kx9t11tf7ZEkbSitUUMTJwIBAAAwAOVPk1yJUsM+qXxDVHZpz4R3GNKIrMiZ8NWdtKMPr4QPBjlxDABAf0AIH2sOeyZ8ZDv6QIDFFAAAAOKD3Y6+vKZRv3j5i9Dz/kBQ63ZXxeqwAAAAgL7jckvDZpmPiz6Iyi7tSvhhmYlyu8xT86GZ8J22ozcD+kBQamymgyoAAP0BIXyshSrhI0P4ZtrRAwAAIE5kp3jkMMyTfnU+vw4fnaVjJuRKktbsrIzx0QEAAAB9ZMTh5v32D6OyuyPGZOvEKfm67rjxoee6Ugkf3qq+tpG58AAA9AeE8LHmCGtHHwyGVcLH8JgAAACAME6HoewUs2on2e3Ub8+doRnD0yVJq3cQwgMAAGCAKjzCvC9aHpXdJbldeviyQ3XeoYWh57oyEz48oK/zMQ4KAID+gBA+1pyulsf+JjkMeyY87egBAAAQPybkp0iSfnrqFBVmJWn68AxJ0loq4QEAADBQFR4myZAqNks1pX3yEXY7+k4r4cNa1RPCAwDQP7j2vwn6lF0JL0mBJrlC7egJ4QEAABA/7jlvpraW1erwMdmSpIOsSvivSqpV7/Mr0e2M5eEBAAAA0ZeYKeVNlkq/MFvSTz4t6h+RFmpH36RgMCjDKtKy+QNB1YYF77U+2tEDANAfUAkfa053y2N/U1g7ekJ4AAAAxI/8NG8ogLe/zk31KBCUvthNNTwAAAAGqEJrLnzRB32ye7sdfSCoiLDdVtOqQr6ukUp4AAD6A0L4WHOGV8I3y0ElPAAAAPqJg4YxFx4AAAAD3IjZ5n0fhfAel0MJTvOccHjbeVvrWfFUwgMA0D8QwseaYUiG1brT39KOnkp4AAAAxLtpVgi/hrnwAAAAGKhGWJXwu1dJTfVR371hGJ3OhW8dwtczEx4AgH6BED4e2NXwgSY5rJk//iAhPAAAAOKbPRd+DZXwAAAAGKgyRkopBVKgSdq5ok8+ItWaC986cJekqvrIYJ5KeAAA+gdC+HjgsEJ4f5NcVushP5XwAAAAiHPTrUr4jXtqVNvIyUAAAAAMQIbRUg1ftLxPPsKeC1/dTgjf+jlmwgMA0D8QwscDp3mlowLNLZXwhPAAAACIc3lpXuWneRQMSl/sror14QAAAAB9w54Lv/3DPtl9qBK+vu2Fra1b1FMJDwBA/0AIHw9ClfA+OR2E8AAAAOg/pg/LkCStpiU9AAAABqpCqxJ++4dSIBD13dsz4dttR9+6Ep6Z8AAA9AuE8PHAGdaOnhAeAAAA/UjLXPh9sT0QAAAAoK8UTJcSkqSGSqlsfdR3b1fCt656b++5OirhAQDoFwjh44Edwoe3ow8SwgMAACD+2XPh1+ykEh4AAAADlDNBGn6o+Xjb+1HffagSvr6dSnjrObt4i5nwAAD0D4Tw8cDRUglvt6MPUAkPAACAfmCaFcJvLqtVdTvtMwEAAIABYeRR5v3Wd6K+67REux19x5XweakeScyEBwCgvyCEjwehSviWEL6ZEB4AAAD9QG6qRwVpXgWD0vri6lgfDgAAANA3Rh9t3m95O+pz4e129O3NhK9uNJ/LT/dKYiY8AAD9BSF8PHCYiyz5m6mEBwAAQL8zIitJkrRzX32MjwQAAADoI8NmSQnJUl25VPpFVHdtt6NvbyZ8Vb35XEGaGcLXNlIJDwBAf0AIHw/CK+ENKuEBAADQvwzJME8I7q5siPGRAAAAAH3E5ZZGzjYfb3krqrsOVcK3MxPeHvmUn0YlPAAA/QkhfDwInwnvNEN4f5AQHgAAAP3DkPRESdJuKuEBAAAwkI0+xrzf8nZUd2vPhK9upx29PSd+CO3oAQDoVwjh44FdCe/3hSrhaUcPAACA/mKoVQm/i0p4AAAADGT2XPit70n+6LWFb5kJ33afdjBfEArhaUcPAEB/QAgfD+yZ8IGWmfC0owcAAEB/EaqEr6QSHgAAAANYwUFSYqbkq5Z2fRa13bbMhG+nEt6aCZ8fmglPJTwAAP0BIXw8cLrNe39TKISXqIYHAABA/2C3xty9j0p4AAAADGAOhzTq6+bjLcuitls7hG9oCsjXHAg939Dkl89vfl1ghfD1TX75OW8MAEDcI4SPB3Y7+kBTqB29xFx4AAAA9A9DM8xK+PJanxqaqMwBAADAAGa3pI/iXPgUqx29FFkNX221pzcMKS/NE3q+njU3AABxLy5C+AceeECjRo2S1+vV4Ycfro8++qjT7Z9++mlNmjRJXq9X06dP1yuvvBLx+u23365JkyYpOTlZmZmZmjt3rj788MO+/BZ6x25H72+W0xkWwnNFIwAAQMwN+rVqF2QmJcibYP5qUcxceAAAgAOK9eoBNuZY877oQ6kpOuOYnA5DKZ62c+GrrEA+xeNSYoJTdhNV5sIDABD/Yh7CP/XUU1qwYIF+9rOfacWKFZoxY4bmzZun0tLSdrd///33deGFF+rb3/62PvvsM5155pk688wztXbt2tA2EyZM0P333681a9bo3Xff1ahRo3TiiSdqz549B+rb6p6OKuEJ4QEAAGKKtWrXGIahodZc+F3MhQcAADhgWK/GQPY4KXWI5G+Utkfv4oQ0qxq+qr5tJXyaN0GGYSjZbW5Tx1x4AADiXsxD+HvuuUdXX321rrzySk2ZMkUPPfSQkpKS9Nhjj7W7/X333af58+frxhtv1OTJk3XnnXfqkEMO0f333x/a5qKLLtLcuXM1ZswYTZ06Vffcc4+qqqq0evXqA/VtdY/DCuH9TXKE/USaCeEBAABiirVq1w3JYC48AADAgcZ6NQYMQxp9jPk4ii3pU6258NXhlfBWIJ9qBfSJbqckqZZKeAAA4l5MQ3ifz6dPP/1Uc+fODT3ncDg0d+5cLV++vN33LF++PGJ7SZo3b16H2/t8Pj388MNKT0/XjBkz2t2msbFRVVVVEbcDymm1ow80yRWWwgcI4QEAAGImXtaqUhysV7tgiFUJv5tKeAAAgAOC9WoM2XPhN78VtV2mJdrt6NuvhJekZKtlfZ2v40r4ilqftpXXRu24AABAz8Q0hC8rK5Pf71d+fn7E8/n5+SouLm73PcXFxV3a/qWXXlJKSoq8Xq9+//vf6/XXX1dOTk67+7z77ruVnp4euhUWFvbiu+qB8Er4lm708gcJ4QEAAGIlXtaqUhysV7tgaLpZCb+LmfAAAAAHBOvVGLLnwu9aIdWWRWWXaaFK+PAQPrISPsmuhG/suBL+woc/0An3vK29tb6oHBcAAOiZmLej7yvf+MY3tHLlSr3//vuaP3++zjvvvA5nIS1cuFCVlZWh2/bt2w/swTpbQnjDMOS0knhmwgMAAAxM3VmrSnGwXu2CIRlWJfw+KuEBAAD6u4G4Xo2q9GFSwUFSMCBt+E9Udpkamgkf1o7eCuHTEq1KeGsmfH0HlfBN/oDWl1TL5w9oJ+tyAABiKqYhfE5OjpxOp0pKSiKeLykpUUFBQbvvKSgo6NL2ycnJGjdunI444gg9+uijcrlcevTRR9vdp8fjUVpaWsTtgLJD+IC5qHIahPAAAACxFi9rVSkO1qtdMMSqhN9NJTwAAMABwXo1xiaebN6vfyUqu7OD9up22tGHKuE99kz49kP4PdWNbd4LAABiI6YhvNvt1qxZs7R06dLQc4FAQEuXLtXs2bPbfc/s2bMjtpek119/vcPtw/fb2NjY6TYxE2pHby6M7LHwhPAAAACxw1q1e4ZalfC7qLgBAAA4IFivxtjE+eb9xv9KTb2/EDVUCR8WnlfVW5Xw3shK+Dpf+wF7cVXLcdR00rIeAAD0PVesD2DBggW6/PLLdeihh+prX/ua7r33XtXW1urKK6+UJF122WUaNmyY7r77bknSDTfcoGOOOUa/+93vdMopp+if//ynPvnkEz388MOSpNraWt111106/fTTNWTIEJWVlemBBx7Qzp07de6558bs++xUq0p4l8MhKUAIDwAAEGOsVbvOroSvamhWbWOzkj0x/1UDAABgwGO9GkNDZkqpQ6Tq3dLWd6Xxc3u1Oztor+qkEj4xNBO+/Ur40rAQvrO58QAAoO/F/MzY+eefrz179ui2225TcXGxZs6cqSVLlig/P1+SVFRUJIejpWB/zpw5WrRokW699VbdfPPNGj9+vBYvXqxp06ZJkpxOp7788ks9/vjjKisrU3Z2tg477DC98847mjp1aky+x/1ytMyElyRrJLz8QUJ4AACAWGKt2nWp3gSlelyqbmzW7sp6jctLjfUhAQAADHisV2PIMKSJJ0mfPGa2pO9lCJ9qh/ARM+GbI15LtkL4jirhS6rC2tETwgMAEFMxD+El6dprr9W1117b7mvLli1r89y5557b4ZWXXq9Xzz33XDQPr+85rR9DwFwYOa0UPkAlPAAAQMwN+rVqNwzJ8Kq6pEa79jUQwgMAABwgrFdjaIIdwr8qnfI7M5jvobREqx19fUslvF0Vb7+W5LHb0bdfCV8S3o6emfAAAMRUTGfCwxKqhPdJkpzW1anNhPAAAADoR4akm3Phd1cyFx4AAACDwOijpYQkqXqXtHtVr3ZVmJkkSdq4p0ZBq0NqdTcr4SNnwje1uw0AADgwCOHjgTOyHb3T+qkwEx4AAAD9ydAMcy78rn0N+9kSAAAAGAASvNLY48zHXy3p1a4mFqTK6TBUUevT7kpzPW1XxadZM+GT3OZ9xzPhW9rRUwkPAEBsEcLHA0dkO3qXVQlPCA8AAID+hEp4AAAADDoTTzbv17/Sq914E5wan5ciSVq7s1KSVG21o7cr4ZP2OxO+5WJYZsIDABBbhPDxwOk2761KeIddCR8khAcAAED/MSTdrIS3K3cAAACAAW/8iZIMsx195c5e7Wr6sHRJ0tpdVQoEgqqxgvRQJbyn80p4ZsIDABA/COHjgd2OPmC1ozcM80sq4QEAANCPDM0wK+F37eu4En57RR3rXAAAAAwcKblS4dfMx1++3KtdTbNC+M93VqrW1yx72ZyWuP+Z8PU+v6rCgvcaKuEBAIgpQvh4YLejD82EN0P4Zk5OAgAAoB8Jr4QPttPV6Y0vSvT137yp3/5n/YE+NAAAAKDvTDnDvP/8uV7tZtqwNEnS2l2VqrYC9QSnIY/LPI1vz4Sv87WthA+vgpcI4QEAiDVC+HgQqoQ3F0Z2CE+FEAAAAPoTeyZ8nc+vqvq2J/1W7dgnSVpfXH0gDwsAAADoW1O/KcmQipZLlTt6vJvJQ9JkGFJJVaM27amRJKV5E2RYnVOTPXYlfBdCeNrRAwAQU4Tw8cBhhfD2THhrUcVMeAAAAPQniW6nMpPMte2uyrYt6YutWfFVDU0H9LgAAACAPpU2VBp5pPn48+d7vJskt0tjc1MkScs3lUuSUq158ObrZghf2047+mIrhLfnx1dTCQ8AQEwRwscDuxLe75MkuZy0owcAAED/ZFfD724vhLdODFZTlQMAAICBZtpZ5v2aZ3q3m6FmS/rlm+0QPiH0WqgdfWPbSvjSqkZJ0tg8M8TfXyX8xtIaXfX4J1q1fV+vjhcAALSPED4e2DPh7Xb0Bu3oAQAA0D8NzTDnwu/a19DmtRJCeAAAAAxUU86QDKe0e6VUvqnHu5k2LF2StHpHpSQpLbGlEj7ZCuF9/oCa/IGI99lrbbuSvr7JL38n55f/9cl2vbGuRH9bvq3HxwoAADpGCB8PnJHt6O2Z8FTCAwAAoL/ptBLebkdfTzt6AAAADDDJOdKYY83Ha5/r8W7sEN4O0FM9LZXwiVY7eqntXPiSarMSfkxucui5mk5a0m8tq5Uk7dhb1+NjBQAAHSOEjwdOt3kfiAzhqYQHAABAfzM0wwrhW1XC1/maVWVVwNf4mlnrAgAAYOCZfo55v/bZHu9iitWO3hZeCe92OeR2mqf061rNhS+xLngtzEyS22Vu01kIv63cDN937G178SwAAOg9Qvh4YLej95uLIofVjt4f5MQkAAAA+he7Hf2OfZEn8+wqeEkKBs0gHgAAABhQJp1iFlztWSeVfNGjXaR5EzQqOyn0dfhMeElK8pjV8LWNrSvhzfV2QbpXqR7zfHNHc+GDwaC2VZiV8MVVDWpu1doeAAD0HiF8PLDb0VuV8C6nFcJTHQQAAIB+ZkSWecJwR0VkW8viqsjKeFrSAwAAYMDxpkvjTzQfr32mx7uZarWkl6RUryvitaQEM4QPr4QPBoOhmfD5qV6lWO+paWx/zV1a3aiGJjN49weC2l3Z0O52AACg5wjh44EjciZ8qBKeEB4AAAD9TKEVwu+ualBjc0t1TkmrEL66g6ocAAAAoF+bdrZ5v+YZKdCzCvPpYSF8WptKeDNgD6+Er2poDoXqeWkepVjbdLTmtlvR27YzFx4AgKgjhI8HoUp4c1Fkz4QnhAcAAEB/k53sVpLbqWBQ2hk2X7K4sjFiO0J4AAAADEgT5kvuVGnfNqloeY92MW1ox5XwyW6zEr6+qWU9bV/wmp6YIG+CMxTCdzQTfmt5bcTXzIUHACD6COHjQWgmvE+S5CKEBwAAQD9lGEaoJX1RWEv61pXwtKMHAADAgOROkqZ903y8clGPdjF1aFrocVpiq0p4d9tKeHutXZDmldQS3Hc0E76oVSU8ITwAANFHCB8PnB20ow8SwgMAAKD/sVvSbw8L4XdXRp7Yq+5gPiUAAADQ78282Lz//Hmpsabbb89MdqswK1GS2WkqXLKn7Uz4kiqz61RemkeSulwJn2Xtewft6AEAiDpC+Hhgz4QP+qVgUC6nGcIHqIQHAABAP1SYaYXw4e3orRODbqf5Kwjt6AEAADBgFR4uZY2Rmmqldf/u0S5+ddZB+uHcCTp4RGbE84mdVMLnW5XwKd7OZ8LbHavmjM2WRCU8AAB9gRA+HjjDWgr5m0KV8M2E8AAAAOiHRlhVO+FtLksqzRODY3KTJdGOHgAAAAOYYUgzLzIfr3yiR7s4clyObpg7Xk5rdKnNngkfWQlvh/BmJXxyJ5XwwWBQW8rMSvijxuVIknZUUAkPAEC0EcLHg/AQPtAUWlgxEx4AAAAxU/Sh9NQl0mu3dPutI7IjZ8L7A0HtqTEr4Sfkp0qiEh4AAAAD3EEXSDKkre9Ie7dFbbehmfC+TmbCezqeCb+vrim0Fp8z1gzhi6sa5GsORO0YAQAAIXx8cERWwhPCAwAAIOYaq8zWmV+8KAW7ty4dETYTPhgMqqymUf5AUE6HodE5ViU8ITwAAAAGsoxCacwx5uNV/4zabu2Z8PURIbw9E95qR2+H8L62a+5t1oWy+WkeFWYlyuNyKBCUiq3OVQAAIDp6FMI//vjjevnll0Nf//jHP1ZGRobmzJmjbduid1XfoBFRCd8sp9WO3t/Nk50AAAAwsV6NghGzzYtFK4ukvVu69dbh1kz46sZm7atr0m7rhF5eqkfpiebat6qBdvQAAGDwYr06SMwIa0kfiE6leagSvrG9dvT2THhzzd1eJfy2crMV/cjsZBmGoWGZ5iipHXtpSQ8AQDT1KIT/5S9/qcRE8x/n5cuX64EHHtBvfvMb5eTk6Ic//GFUD3BQMAzJMK9gDK+ED1AJDwAA0COsV6PAkyINP8x8vHlZt97qTXAqL9WcR7l9b12oqiY/zas0K4SnHT0AABjMWK8OEpNPldyp0r5t0rb3orJLuxK+zqqEDwSCKq02K+HtmfApncyE31Zuhu0jre5V9gW0O/bWR+X4AACAydWTN23fvl3jxo2TJC1evFhnn322vvOd7+jII4/UscceG83jGzycCVKzX/L7QiF8MyE8AABAj7BejZIxx0pF70ub35IO/Va33joiK0ml1Y0qqqhTeY1PkjmjMtVr/gpSTSU8AAAYxFivDhLuZGn62dKnf5U+fkQa/fVe7zIxwQzha61W8+W1PvkDQRmGlJtihvD2mru9SvitViX8KGtM1HAq4QEA6BM9qoRPSUlReXm5JOk///mPTjjhBEmS1+tVfT1XzPWIPRc+0EwlPAAAQC+xXo0Se4bllre73T7TngtfVFGnYqs9ZkF6SwhfVU8IDwAABi/Wq4PI175j3q97Sdq3vde7S7aq3OsazUp4uxV9TopHLqd5ur+zSvgiqxLeXq8XWpXw26mEBwAgqnpUCX/CCSfoqquu0sEHH6yvvvpKJ598siTp888/16hRo6J5fIOH0/pR+JvkYCY8AABAr7BejZJhsyR3ilRfIZWskYbM6PJbC62Tetsr6tTYZAb4BelepXlpRw8AAMB6dRDJnyqN+rq09R3pk0elubf3andJbqsdfZO5nm6ZB+8JbZPSSfeprVYIPyqbSngAAPpSjyrhH3jgAc2ePVt79uzRs88+q+zsbEnSp59+qgsvvDCqBzhoON3mfaBJLtrRAwAA9Arr1ShxJkgjjzQfd3MufGF7lfBphPAAAAAS69VB5/DvmfefPi419a7ivHUl/PqSaknmWtuWGlYJHwwr9KptbFZZjTk/fkS2PRPeDuFbjuvVNbs15bYlWrK2uFfHCgDAYNajSviMjAzdf//9bZ6/4447en1Ag5bdjt7fJKfD/LHQjh4AAKBnWK9G0ZhjpQ2vmXPhj7yhy28bEaqErw9dZJofNhO+vsmvJn9ACc4eXRcMAADQr7FeHWQmniSlj5Aqi6Q1z0iHXNrjXdmV8LW+ZvmaA/rb+9skScdPzg9tY1fCB4LmujvJbX69zaqCz0xKUHqieT56uNWOvriqQb7mgBKchu59Y4PqfH49/PYmzZ9W0ONjBQBgMOvRGa8lS5bo3XffDX39wAMPaObMmbrooou0d+/eqB3coGK3ow+bCU8lPAAAQM+wXo0iey78tvel5sYuv80O4Xfuq9fuyrYz4SWq4QEAwODFenWQcTilr11lPv7wz1IvxpDagXpdo18vrNyp4qoG5aV6dNYhw0LbJCY4ZZ1iVk3YmruoolaSNMJqRS9JOSlueRMcCgal3ZX1WrWjMlRdv6Jon7ZX0KYeAICe6FEIf+ONN6qqqkqStGbNGv3oRz/SySefrC1btmjBggVRPcBBI6IS3lwhUQkPAADQM6xXoyhvipScKzXXSzs+7vrbUj1yuxzyB4KqbzJbZRakeeVyOkLVO+3NqAQAABgMWK8OQgdfKrkSpZI15gWuPZQcVgn/57c3S5K+ddRoeVzO0DaGYSjFaklf3dgSwrfMg0+K2Nauht9eUa+nPt4e8Xkvrd7d42MFAGAw61EIv2XLFk2ZMkWS9Oyzz+rUU0/VL3/5Sz3wwAN69dVXo3qAg4bTCuEDTXIYZgjv78UVkQAAAIMZ69UoMgxptFUN34258A6HEZovKUnpiQlKtE4Y2tXwVfVUwgMAgMGJ9eoglJQlzTjffPzBn3q+G09Lq/mNpTVK9bh00eEj2myX6jXPN4dXwm8rNyvhR4ZVwkstc+HXl1TrxZU7JUlnzBwqSfr3ql09PlYAAAazHoXwbrdbdXXmVXNvvPGGTjzxRElSVlZW6ApOdJM1B17+ptDMTD+V8AAAAD3CejXKxhxr3ncjhJdaWtJLZhW8Lc06IUglPAAAGKxYrw5Sh3/PvP/yZan0yx7tIjHBGfH1JbNHhtbX4exK+JrG8BDe/Ds3MmydLrWE8I+9u0W1Pr9GZSfpZ6dNlcth6IvdVdpYWtOjYwUAYDDrUQh/1FFHacGCBbrzzjv10Ucf6ZRTTpEkffXVVxo+fHhUD3DQcLa0o3cQwgMAAPQK69Uos+fC71whNVR2+W3hIXx+eksIH6qE7+FM+GAwqCBdowAAQD/GenWQypssTTpVUlB657c92oXTYYSCeLfLoSuPHNXudskec5v2QvhROa1DePPrnfvqJUnnHVaorGS3vj4+RxLV8AAA9ESPQvj7779fLpdLzzzzjB588EENGzZMkvTqq69q/vz5UT3AQcPR0o7eGQrhY3g8AAAA/Rjr1SjLGCFljZGCfmnL211+W2QlvCf02G6NWdWDSvhAIKjz/rxc5//5AwW4aBUAAPRTrFcHsaNvNO/XPiuVb+rRLuyA/exDhisv1dvuNimt2tE3NPm1q9IM2UdkRbajL8xsWbc7HYbOOcS8EOS0GVZL+tW7QhfBvruhTAueWqntFXU9OnYAAAYLV0/eNGLECL300kttnv/973/f6wMatMIq4Vva0ZPCAwAA9ATr1T4wfp704YPS+iXS5NO69JbhYSfzCtJb5sOnJdrt6LtfCV9e69PHW/dKkvbW+ZSd4tnPOwAAAOIP69VBbOhMacJ86asl0ju/k87s/nz4mYWZ+mRbhb53zJgOt0lt1Y6+qKJOwaDZlSonxR2xrd2OXpKOm5SnPGuU1AlT8uV2ObR5T60+31Wlt77ao9/+Z72CQWl4VpIWnDCh28cOAMBg0aMQXpL8fr8WL16sdevWSZKmTp2q008/XU6ncz/vRLvsED7QLIdhhfAU9gAAAPQY69Uom3iSGcJ/tUQK+CXH/v8cO5oJb7ej78lM+IpaX+gxITwAAOjPWK8OYkf/2FxXr/qndMyPpcxR3Xr7w5fOUn2TX8mejk/vt54Jv3lPrSRpTE6yDOv8sy08hD//0MLQ41Rvgo6bmKclnxfrir98rLKaxtBre6obunXMAAAMNj0K4Tdu3KiTTz5ZO3fu1MSJEyVJd999twoLC/Xyyy9r7NixUT3IQcERVgnvNBdBtNcEAADoGdarfWDkHMmTLtWVSTs+kUYcvt+3FGa1nMwrSG8Jy9PsdvT1PamEbznxV1Hb/RAfAAAgHrBeHeSGz5LGHidt+q/0zj3S6X/o1tsdDqPTAF6SUkIXvppr7i1lZgg/Oie5zbZZyW6dOXOoahqbdezE3IjXTp85VEs+L1ZZTaMSnIaOGJOtdzaUaU+1r81+AABAix7NhL/++us1duxYbd++XStWrNCKFStUVFSk0aNH6/rrr4/2MQ4OzpaZ8HYlfDPt6AEAAHqE9WofcCZI408wH69/pUtvSfUmKC/VDN/D50xGqxI+/DEAAEB/wnoVOuYm837lImlfUdR331IJb665t5TVSJJG56S02dYwDN17wcH6f5cfJpczMjI4blKehmcmaki6V//8zmxdcsRISZEXxwIAgLZ6VAn/1ltv6YMPPlBWVlbouezsbP3qV7/SkUceGbWDG1Qc1o/C3yxnaCZ8DI8HAACgH2O92kcmniStfUZa/6p0wh1desu958/U5rJajc9PDT2X1qoqpztat6MHAADoj1ivQiOOkEYfI215S3rjDumcR6O6e/vC15rWlfC5bSvhO+NNcOq/PzpWkuR2OfTptgpJimhNDwAA2upRJbzH41F1dXWb52tqauR2u3t9UIOSXQnvbwwL4UnhAQAAeoL1ah8ZN9e8eLRsvVS+qUtvmTMuJ1QtY0tLtNrR96ASvryGSngAAND/sV6FJOnEOyUZ5oWuRR9GddetZ8LbIfyYdtrR74/b5ZDbZUYJOSlmp6sy2tEDANCpHoXwp556qr7zne/oww8/VDAYVDAY1AcffKDvfe97Ov3006N9jIODJ828b6iU02pH72ckPAAAQI+wXu0jiRnSSKsya/2rPd5Nai8q4cOr3/cSwgMAgH6K9SokSUNmSAdfYj5e8hMpikVZ4TPhK+ubVGZdzDqqByF8ODuEr2/yq7ax++t5AAAGix6F8H/4wx80duxYzZ49W16vV16vV3PmzNG4ceN07733RvkQB4nkXPO+tixUCR8IkMIDAAD0BOvVPjTxZPO+VyG8WQnfk5nw5eEz4WlHDwAA+inWqwg5/jbJnSrtWiGtfipquw2vhN9qVcHnpXpCz/dUsselxASnJFrSAwDQmR79i5uRkaEXXnhBGzdu1Lp16yRJkydP1rhx46J6cINKco55X9cSwjfTjh4AAKBHWK/2oYnzpSU3SUXLpboKKSlr/+9pJc1rt6PvwUz4GirhAQBA/8d6FSEpedLRP5LeuF1aeoc0+TTJk9Lr3YZmwjc2t8yD72UVvC07xa0de+tVVuPTyOzo7BMAgIGmyyH8ggULOn39zTffDD2+5557en5Eg1VStnlfWx5WCR/D4wEAAOhnWK8eIJmjpLypUunn0obXpRnnd3sXLe3omxQMBmVY45i6oiKiEr77lfQAAACxwnoVHTrif6RP/yrt3Sq9e49ZHd9LKR7zwteahmZttufB50YnMM9J8VghPJXwAAB0pMsh/Geffdal7bpzAg1h2qmE9wdpRw8AANBVrFcPoIknmSH8ly/1KoRv8gfV0BRQotvZ5feGt6OnEh4AAPQnrFfRIZdHOvEX0lOXSO/dJ00+XRo6s1e7TOnDSnh7LjwhPAAAHetyCB9+JSb6QJIVwteWyWnY7egJ4QEAALqK9eoBNPk06Z3fSl+9JtXvkxIzuvX2ZLdLDkMKBM1q+K6G8IFAUHvrCOEBAED/xHoVnZp0qhm+r3tRWnyN9J1lZjjfQ/bs98bmgL4qrpYkjc7pfZt7ScpNdUuSyqpZjwMA0BFHrA8AluRc876+Qi75JZknGQEAAIC4M2SGlDtZ8jdKXyzu9tsdDiN0UrA7c+GrGprkD1sjVzc2y9fMDCcAAAAMAIYhnfp7s1ir9Atp2d292l1y2IWuG0rtEJ5KeAAADhRC+HiRlCXJrID3NFVKohIeAAAAccowpBkXmI9X/bNHu0j1mjMqqxq6PtfdbkWf4jEr6SVpXx3VNwAAABggknOk0+4zH793n7T94x7vyuV0KDHBDOIDQclhSCOykqJxlMpONivhy2sJ4QEA6AghfLxwOKXETEmSt6lCEpXwAAAAiGMHnScZDqlouVSxudtvT0s0Q/jqblTCV1ghfHaKW5lJ5om/CkJ4AAAADCSTT5UOukAKBqTF35N8tT3elT0XXpIKs5LkdkUnDshJtSrhaUcPAECHCOHjSbI5F97duFeS5A8SwgMAACBOpQ2VxhxrPl79r26/PdU6IVjdnUr4GvMkX1ayW5lW9U0Fc+EBAAAw0Jz0Kyl1qFS+Ufr3DVIPzxOnelpC+Gi1opdoRw8AQFcQwseTJDOE9/jMSng/lfAAAACIZzMuNO9XPdntE4NpVghfVd+DSvhkt7KsSvi9tV0P8QEAAIB+ITFTOudRyXBKa56WPnq4R7sJr4TvixB+zwEI4TeW1uhfn2xXkII1AEA/QwgfT5KzJUnuBkJ4AAAA9AOTTpHcKdLerdL2D7v11jSv3Y6+6yF6hTVz0qyEN99PO3oAAAAMSCPnSCf+wnz82s3StuXd3kVKWCX8mKiG8OYFsdUNzWps9kdtv+258ZlV+vEzq7Vs/Z4+/RwAAKKNED6eJOdKktxUwgMAAKA/cCdLU84wH696sltvbWlH3/VK+PJaux29R1nJdiU8ITwAAAAGqCOukaadLQWapacvl6qLu/X2lIh29ClRO6z0xAQlOA1JLSOj+kJDk19rdlRKktburOyzz+lIna9Zz3+2Q/u48BcA0AOE8PHEakefQCU8AAAA+osZF5j3a5+Xmuq7/La0RLOSvapblfAt7egzk5gJDwAAgAHOMKTT/iDlTpZqSqQnL5Qaq7v89oh29LnRq4Q3DEPZyX0/F/7zXVVqts6Rf1Va02ef05GnPt6uHz61Sg+8ufGAfzYAoP8jhI8nya1CeObcAAAAIN6NPEpKL5QaK6XPn+/y2/ZXCd/Y7G/T2rIiVAnvbqmEpyoFAAAAA5knRbrgCSkxS9q1wgzimxq69NZUqxLe43JoSJo3qoeVk2qux/syhF+5fV/o8YaSrl98EC3bK8yLjLeU1R3wzwYA9H+E8PEkyZwJ72oslyQFqIQHAABAvHM4pEO/ZT7+4E9SFy8kTe1kJnwgENSZD7yv43/3lhqaWoJ4u9VlVkpLCE8lPAAAAAa87LHSJc9I7hRp6zvSM9+S/Psf62RXwo/OSZbDYUT3kOxK+Or21+MNTX4teGqlHly2qcefsSoshN+8p1bN/kCP99UT9gW/e6q7dtEDAADhCOHjiVUJ76o3K+F9zQd2UQEAAAD0yKwrJFeiVLxG2vpul96SZoXwVfVtTx6uK67Sut1V2rG3XuuLWypeItrRE8IDAABgMBk2S7rwn5LTI61/WXrxWinQ+flje809Oid6rehtOSlWCF/bfiX8A29u1HOf7dRv/7NelfVdH0EVbtWOfaHHPn9A2yoObEW6/bvGnuq+q/YHAAxchPDxJDlXkuRqMCvh65r8CtKSHgAAAPEuKUuaeaH5+IMHu/QWux19ezPhP9hcEXr8ldV2MhgMqqIurB29NRN+LyE8AAAABovRX5fOe1wynNKqJ6UXvi8F/B1ufuqMoTptxlBdffSYqB9KqB19O5XwG0tr9NBbZgW8PxDUuxvKur3/vbU+bSs3Q/eR2UmSpA0lB3YufKgSvqaR8/QAgG4jhI8nSWYlvFFfIYcC8geCaqQaHgAAAP3B4deY9+tfkSo273fzzmbCf7C5PPR4Q6l5oq3W5w91ispO9rS0o2cmPAAAAAaTiSdJZz9iBfGLpGevkvztV5oPy0jUHy88WIeMyIz6YeTalfCtZsIHg0H9dPFaNfmDclkt8JetL+32/u0q+DG5yZplHf+Bngtvh/BN/qD21vWsmh8AMHgRwseTpCxJkqGgMmSebKzzdXwlIwAAABA3cidI406QFJQ+/PN+N09LtNrRt6qEDwSC+mhL20r4CmsefGKCU4luZ6gdfUNTQPWsmQEAADCYTDvbrIh3JEifPyf963Kp+cC2TM9OsSrhW4Xwi1fu1PLN5fImOPSLM6dJkpZ9tUeBQPcqyVda8+BnDs/Q+PxUSS0X6B4oe2tbflcpZS48AKCbCOHjiTNB8mZIkoYkWBU/jW0rgwAAAIC4dIRVDf/ZP6SGyk43tSvhaxqbI07IrSuuipgZabecLLdmTdoV8Mlup9xO89cZquEBAAAw6Ew+TbpgUcuM+H+cLdVV7P99UWLPhC+vaVmLV9Y16a6X10mSrjtuvL55yDAluZ3aU92oL3ZXdWv/q6wQfkZhhsbnpUhquUD3QGhs9qsm7Nw8c+EBAN1FCB9vks2W9EMTaiVRCQ8AAIB+ZOxxUu4kyVcjrfh7p5umec1K+GBQqvW1nNxavslsRX/wiAxJ0s599apuaFJFbcs8eEkyDEOZyeY+mAsPAACAQWnCidLF/5LcKdLWd6RHjpP2rD8gH53TTjv6Py3bqLIan8blpejqr4+Rx+XUkePM893daUkfDAa1aod5Ue+MwgxNsCrhN5fVqtl/YMa37mvVfr60ihAeANA9hPDxJjlXklTgMq/qCz8hCQAAAMQ1w5CO+B/z8ft/kHy1HW7qcTlCley7K1taO36w2azemT+1QLmp5om9DaU1Km8VwktSZpI1F54QHgAAAIPVmGOlb78uZYyQ9m6R/t9cacPrff6xdghfUedTsz+gYDCol1bvliT974kT5HaZa/1jJ5rnu99cv6fDfTU0+bVpT0ur+R1761VR65Pb6dDkIakanpkob4JDvuaAiirq+upbirC3VbetUirhAQDdRAgfb5KyJUl5DnPRwXxLAAAA9CszLpQyRko1JZ3OhjcMQ7PHmmvfR9/ZIknyB4L6aItZCX/EmGxNtGc/llSHgvbssBDeDuRbnyADAAAABpX8KdLVb0ojj5Qaq6QnzpX++wvJ33cFXlnJbhmG2dmqos6nL4urtXNfvTwuh46ZkBfa7tiJ5uPPivZqXwfr9p8uXqvjf/eW/t87myW1zIOfPDRNHpdTDoehcaGW9AdmLnzrC31pRw8A6C5C+HhjtaPPcVqV8MyEBwAAQH/ickvH3Wo+fu9eqX5vh5tef/w4SdKzK3aoqLxO63ZXqaqhWSkel6YOTdP4/JYTba3b0UtSZjKV8AAAAIAk87zypYulWVdKCkpv/5/0+GlS5c4++Tinw1CW1ZmqrNqnpetKJElHjctRotsZ2m5YRqIm5qcqEJTe3lDW7r4+LTJ/Z7jrlXVauq4kFMLPHJ4e2mZCnnmB7sbSAzMXfm9tq3b01Q0dbAkAQPviIoR/4IEHNGrUKHm9Xh1++OH66KOPOt3+6aef1qRJk+T1ejV9+nS98sorodeampp00003afr06UpOTtbQoUN12WWXadeuXX39bURHkhnCZ8tcTDATHgAAILZYq/bAtHOkvKlSQ6X07r0dbjZrZJa+Pj5HzYGgHnhzoz7YbFbBHzYqUy6nIzT78auSapXXWCF8SlglvHXSj5nwAABgMGO9ihCXWzrtXunsRyV3qlT0vvTQUdLni82S9SizW9KX1zbqjXXmzPfjJ+e32e7YSWZL+vbmwvsDQW23WswHg9L1T36m178wA/0ZhRmh7cblH+BKeKtq32GYX9OOHgDQXTEP4Z966iktWLBAP/vZz7RixQrNmDFD8+bNU2lp23+QJen999/XhRdeqG9/+9v67LPPdOaZZ+rMM8/U2rVrJUl1dXVasWKFfvrTn2rFihV67rnntH79ep1++ukH8tvqOasSPlNVkpgJDwAAEEusVXvI4ZCOv818/OFDUtXuDjf9wdzxksxq+MUrzSodu039BOtE24aSGlXUmie9sturhKcdPQAAGKRYr6Jd08+RvvuWNGSGVF8hPX259OQF0r7tUf2YnFRzPf7l7mqt2rFPknT85Lw22x1rtad/a/0eBQKRFwPs2levJn9QbqdDs8dkq9bnD819Dw/h7Ur4DaUHJoTfZ13oOyo7WRLt6AEA3RfzEP6ee+7R1VdfrSuvvFJTpkzRQw89pKSkJD322GPtbn/fffdp/vz5uvHGGzV58mTdeeedOuSQQ3T//fdLktLT0/X666/rvPPO08SJE3XEEUfo/vvv16effqqioqID+a31TLJ5VWBGsFKSVNdIJTwAAECssFbthQnzpMIjpOYG6e3fdLhZeDX82p3mhahHjDFD+HHWibbiqgZtKzdPxGUle0LvzUpKkNS2VSQAAMBgwXoVHcoeK337denoH0uOBOmrJdIDh0vL/yQFonPO2a6Ef/rT7QoGpenD0pWf5m2z3aGjMpXicam81qc1OysjXrMD98KsRD14ySEanWOG3mlel0ZbAbikUJesTXtq5A9Ev6q/NftCX/tzCeEBAN0V0xDe5/Pp008/1dy5c0PPORwOzZ07V8uXL2/3PcuXL4/YXpLmzZvX4faSVFlZKcMwlJGR0e7rjY2NqqqqirjFTJJ5wjEtsE8SlfAAAACxEi9rVSnO1qtdZRjS3J+Zjz99XNq9qsNN7Wp4SUr1uDRlSJokKT0xQQXWSbzNZbWSmAkPAABgY72K/XJ5pONukb73rjRittRUK722UHrkOGnXyl7vPtu6QNZuEd9eFbwkJTgdoW5XH22piHhta7m5zh+VnayMJLcevfxQTR6SpiuOHC2H3Qte0vDMRHkTHPI1B0LBfV+yR15NKDBD+JrGZtVxrh4A0A0xDeHLysrk9/uVnx85JyY/P1/FxcXtvqe4uLhb2zc0NOimm27ShRdeqLS0tHa3ufvuu5Wenh66FRYW9uC7iRKrHX1K8z5JzIQHAACIlXhZq0pxtl7tjpFzpMmnS0G/9PSVUmN1u5vZ1fCSdNjoLLmcLb+m2Ce9bOHt6O1Afi/t6AEAwCDEehVdljdJuuIV6bT7JG+6tHul9Mg3pNdukRp6fsGE3Y7eNredefC2qUPNvz9flUT+TmB3vBqRnSRJGpOboldv+LoWnDAhYjuHw9C4vJR299EXKurMbluFmYlKTHBKkkqrqIYHAHRdzNvR96Wmpiadd955CgaDevDBBzvcbuHChaqsrAzdtm+P7mycbkkyTz4mNlfJUICr6wAAAAaorq5VpThbr3bXafdJacOlik3Syz+Sgu23jrzj9Kk6YUq+rj1uXMTzE6wTbbaslLBK+CQq4QEAAPrKoFmvDhYOhzTrCun7H0vTzpaCAWn5/dK906T//kKqLe/2Lu129JI0JN0bCtrbM9Fq6946QN9a1lIJvz+hufAHIITfZ13om53iVl6a+X2W0pIeANANMQ3hc3Jy5HQ6VVJSEvF8SUmJCgoK2n1PQUFBl7a3F4nbtm3T66+/3umVmh6PR2lpaRG3mLHa0TvkV7pqmQkPAAAQI/GyVpXibL3aXUlZ0tn/TzKc0uqnpJWL2t1sTG6KHrnsUB0yIjPieXsGoyQlOA2lelyhr8Mr4YNWuP/ptr36YhftTwEAwMDHehU9kpovnfOYdPEzUs4EqaFSevv/zDD+1Z9Ie7d2eVe5YSH8cZPyZBhGh9vaHa6+KqlRIGymu10JP9KqhO/MuHzzAt0NpTVdPkZJenXNbn3trjf0+Ptbu/we+0LfjCR36PtkLjwAoDtiGsK73W7NmjVLS5cuDT0XCAS0dOlSzZ49u933zJ49O2J7SXr99dcjtrcXiRs2bNAbb7yh7OzsvvkG+oLLLXnSJUnZRhUz4QEAAGKEtWoUjZwtfWOh+fiV/5X2rO/yW8fnt1TCZyW7I07s2SF8kz+omsZmrdy+T+c89L4u/n8fRJzYAwAAGIhYr6JXxp8g/c+H0nl/k4bMkJrqpA8flP5wsPTUpVLRBx12sbJlh3Wp6qwVvSSNzEqS2+lQfZNfO/bWS5ICgaC2VXS/En59cdcr4Z/8qEj/s2iFSqsb9fxnO7v8PnsmfFZSeCV8Q5ffDwBAzNvRL1iwQI888ogef/xxrVu3Ttdcc41qa2t15ZVXSpIuu+wyLVy4MLT9DTfcoCVLluh3v/udvvzyS91+++365JNPdO2110oyF4nnnHOOPvnkEz3xxBPy+/0qLi5WcXGxfL5+0qbSmgufrSpmwgMAAMQQa9UoOmqBNPoY8+TeE+dIlTu69LbxYZXwWcmeiNe8CU4luc35jGU1Pt32wloFg9LeuiaV1VKlAgAABj7Wq+gVh0Oacob0nbekS56Vxh5ntqlf96L02DzpT7Ol9/4gVZe0+/bhmUlyuxxKT0zQ7LGdX6zhcjo0ttVM99LqRjU0BeR0GBqWmbjfw51itbvfWFqjxubOz5sHg0H9adlGLXxuTehagg0l1aEOWp1pbPar1jovn5nsVl6qN3S8AAB0lWv/m/St888/X3v27NFtt92m4uJizZw5U0uWLFF+vnnlXFFRkRyOlmsF5syZo0WLFunWW2/VzTffrPHjx2vx4sWaNm2aJGnnzp168cUXJUkzZ86M+Kw333xTxx577AH5vnolOUeq2KQso1qljVTCAwAAxApr1ShyOM229I/Nkyo2S4+fLl35ipTafqtUW4rHpWEZidq5r17Zye42r2cmuVXnq9eDyzZq9Y7K0PMllY2hk2UAAAADFetVRIVhSOPmmreSL6QP/iSteVras056/afSG7dLY44xXx97vJQ7UTIMZSW79eTVhyvZ45I3wbnfj5mYn6J1u6u0vqRac6fka1u5WQU/PDNRCc791wsOSfcqIylB++qa9FVxjaYPT+9w2/uWbtC9b2yQJH33mDF67N0tqvX5tXNfvYZndt76fl9dkyTJ6TCU5nUpN5V29ACA7ot5CC9J1157behqy9aWLVvW5rlzzz1X5557brvbjxo1qktXs8W1JKsS3qjSVirhAQAAYoq1ahSl5EmXvSj95WSpYpP0tzOkK14OdYLqyIT8FO3cVx9qPx8uK9mtnfvq9a9PzMp6hyEFglJxVYOmq+OTcgAAAAMF61VEVf4U6Yz7pRN/IX3+vLRykbTjI2nTf82bJKUNl8YdJ42bq1mjj5ES07q065a58GYlvD0PfkTW/ufBS5JhGJo6NE3vbSzX57sqOwzhd+6r1/3/3ShJuuXkybr66DFa9uUerS+p1oaSmv2G8PY8+MykBBmGEQrhqYQHAHRHXITwaCXZbN2TJWbCAwAAYIDJKJQuf8EM4vd8Kf3tTOnCJ83nOzBlaJreXL9HQzLaVrZnhgXzkwpSNSwjUUu/LFVxFfMaAQAAgB5LzJAOvdK8lW2UNrwmbXxD2vqeVLVDWvE382Y4pWGzpLHfkMYcKw07VHK1vXhWkibmR85031re9XnwtqlD060QvqrDbR55e7OaA0EdOS5bVx89RpI0Pj9F60uq9VVJtb4xKa/Tz9gbCuHN7yPPDuH7++8YgYDUsE+qq5DqK6S6cqmhSmqul5obpaZ6qbnBum80n29qMJ9rbpQCTVLALwX95n34Y8MhOVxmBzTDYd47XObfD2eCdXOb946wx/t73tFqm+4+73CZnR4AIAYI4eORVQmfZVSrrpFKeAAAAAwwWWOky/9tBvEla6Q/Hy2d/YjZ3rId3z5qjJI9Lp1zyPC2u0pKCD2+88xpenHlLklSSWU/P0EGAAAAxIucceZt9vclX5207X0zkN+0VCr7yqyU3/GR9NavpYQkKX+aNOQgqeAgKW+ylDlaSs7RBCuE37ynVs3+QKgSfmR21yrhJWmqNRf+i93th/BlNY168qMiSdL3jx0Xen5ifqpe0m6tt6rwO1NRZ4XwyXYIb14MHFft6P1NkWF6m8d7zfu6cut56zkNwk4XHYX+RtgFA4aj/VtHr3XlPeos/O/k52A4rOP0hB23u/PHrvZed0suj7kfl7vl3uU1H4eNKgHQNwjh41FyriSzHX0d7egBAAAwEOWMl656Q3r6cmnXZ9I/zpGOuUk65sfmSYswWclu/U/YCbRwI62qmbMPGa7DRmXpw83lkkQlPAAAANAX3EnS+LnmTZL2FUmbl1m3t6S6spZQPuJ9KRqeOVKPeJK02Z+nire2KKO4WYVGikZnzuzyx9sh/LrdVfIHgnI6IoPOv7y3RY3NAc0ozNDssdmh58dbFwBsKKnZ72fstWbCZ1oX/Nrt6CvqfGryB7o0v77HAgHzz7B6t1S127yvLg6732Xe15apx4G6J01KypISsyRvupSQaAazLq+U4G15HPG1xwyzQxXujsjHwUDHVfKBJvOiAb/Purceh54Pey3QznZder65ZZ9t/kyt7dp5aVBzuNoG9E6P9fO2HjtdLd0FHK6WW/jX7T62/q7YHQ5Cj+39ucK2c7V8Tvg+7L9XwYAUDIY97umtK/sIttwbDrOLQnsXXASDkoLt3Ada/v4HmsNu3fza/m87YjxMe8+Fvxx2LMFA2+Nq95jD36tWz3fxcfhnd/q4s+072K/hbPV3MCHsa3fbv5/2NkMOkg6+pP0/pwOMED4eWTMxs1Wl+iZ/u4sJAAAAoN/LHCl96zVpyU+kTx6T3vqVtO096cwHO21PH+6qr4/WhPxUzZ1itpTMTzOrVEoI4QEAAIC+lzFCOuQy8xYISOUbpN2rpeJVUvEaqXyTVLlD8tXIKPlcJxgyU4m3X9ZdkuSRgs+5pDeGSSn5UkqeeUvOk1Jyrfv80OPROSnyJjhU5/Nra3mtxuamhA6lqqFJf3t/myTp+8eOlRHWhnxCvrndhtJqBQJBOTo53263o8+yKuGzk91yOgz5A0GV1/hUkN52TNZ+BYNmK3g7UG83YN8t1ZRYIVxXGFJippSU3RKqJ2W1epzd6nGmGVQNVMGg+efn90WG835fq+ebwi4csANY+3Gw89cing9/LWD+NxD+Wk9a4Qf8YRcc+Fo9bu+59h43Ss2+Vvetfke2A9+m2uj82QPxYsqZhPDoRJI1E94wW+rUN/mV4uFHBQAAgAHI5ZFO/b1UeLj00gJp6zvSg0dKp/xWmn7ufk9apHoTdMpBQ0Jf2yfECOEBAACAA8zhkHInmreDzm15vrnRrJiv2KLFb76riu3rNSerSs592zTCKJUn0CTt22be9sOZkKRlCWnaaaQq6bkR0tARoZD+/a0BzWiqUE5WuuamD5X2VFrV3IkameJRiqtZ9U2GtlfUamROSoefUdFqJrxDQQ1LDqqqulp7d29WQZM7bF56vTlDvaleaqwyK9Trys1b6HGZVFPaNgTtkGFeiJBaIKUOte6HmPdp1tcpBWaOQEvxSIbR0nZeybE+mvgSDLYT0DeawX2z/bjVc4Fmq+NAs9V1oDnscVNkp4PwSu7wr+2OBQF/O8+3t1/rcdDfMjLAcJh/1zsaAWAYnby2v22cbV8z/8DaXnBhf21vL8M6Z2G0PGd3iAjd2vna6GwbZ9gxhAmdGzFafd3quTbH5Yg8xtB9q3325nFoX+097so27e1XYX+/miP/noU6YYT9/Qr/Om9y2z+/GCHZjUdWO/rxxk79NuEh+bZlSeOPkEq/kNa9JG34j/mXKW2Y+Y9u2tDIx5mj2rTwBAAAAOLajAuk4YdJz39X2vGx9NzV0pcvSSfe1eWqeEkqsCrhi9uZCf/35VuVm+rR/GlD2rwGAAAAoI+4POY4qpzxKisZp19sWaeCBq+KfQ0alubWe9+fIlVuN4Pq2lLzvqZUqt1jPS4xHzfVSU11KlCdChzF0u4N0u6Wj5kvab5bUp2k/xd5CE5Ja10yE5H7FdkK2z6XbrVI/klTk270BOT5yJA+Dkh+n96WJK+kf/byzyIxsyVQDwXsVsieNsS8T84z2ywD0WQY1kx4t+SJ9cEAgwP/J49HuZOkEbPlKlquc5xvS4veNq9qqyuP3G73yvbfnzZcOvRK6ZDLzTY9AACgxd6t5i/ZacN61hYMQN/JHitduUR69x5p2a+kL16QvnpNmnOddOQPJE/H1Sq2fKsSvqqhWfU+vxLd5gm1zXtq9NMXPpfLYejtH2doaEZiX34nAAAAANoxscCczV5sda4akZMqpQ8zb/vTWCPVluo/H63Vs29/qtn5fl1xULJUW6rt27eqZPcOZTh9GpvplNFUH1mt3lpo9nJbXsks0Ay0fc1vuOR0J7XMUU9ItB4nSp5Uc9RsUpaUlGOe00+273PNgD2hB63sAQD9EiF8PHK5pStf1bfv+pNOaXxFZyZ8JEddueT0SGOPkyafav4jXrVTqtpl3VuPK3dIVTuk/94pvfVraeo3paN+GFftFwAAiIm6CmnJQmm1ddl6YpZUMF0ac4w05/qBPRMN6E+cLumYH0sT5pn/zW57T3r7/6QVfzfXtYdcKrk7biuY6nEpye1Unc+v4qoGjc4xt91QWiNJag4E9Zf3tuiWU6Z0+ZCa/QG5nLR5BAAAAHprYn5qxNejcpK6/mZPiuRJUd7ULL22zKlPqty6/Ni5kqRv/f5tbfDV6KenTtG4o0ZHvi8YlJob9PCy9Xpg6XqdNi1HvzhtUmT77LB20t/5+6daV1KjX589Q3PG5UquRN32yiY9saJU18+drBvmju/lnwIAYDAghI9XhqEt3qlaUDNKoy78vQ5JLJGGzjSvputMU4P0+fPSx49IOz+VVj8lrf6XNPVM6ZibCOMBIBYCfjMArisz59LkT2VsyIH25cvSSz80W9jZ85DqK6Qtb5m3yh3mTGoA8WPIDOmKl6V1/5Ze/6nZxWLJTdJbv5IOu0r62nfMOYmtGIahgjSvNpfVqriyJYTfvKc2tM2TH23XdcePV5p3/xffbK+o0zf/9J6OnpCre86bGa3vDgAAABiUclM9Sk9MUGV9kyRpZHb353ZPKkiV02GovNankqpGbSyt0YbSGiW7nTr30OFt32AYUkKixgwbokrt1Kfl7k4r7z9v2KadwWQl5o2RMjIlSRkZFfKrXKXVXZ3rDgAY7Ajh41iSxwxoKp0Z0ugJXXtTgleaeaF52/mp9O690roXzWD+88XSlDPMMD6/65U/AIAeKt8kPfttaddKScGW51OHStPPlqafZ1Zi91VL9GDQDJ2rdpm32lKzBVrWGClzdJfaOvd7e9ZLS39uzpWWpJwJ0hl/Mv/c96yTtrwjvX6b9MljUt4U6WtXx/Z4AUQyDGnK6WZV/Gd/l96/X9q7xayMf+d30og50uTTzE5R6S0n2/KtEL6kquUE2ZaymtDjmsZm/fOjIn3n6LH7PYRH392ishqf3vyyNLrfGwAAADAIGYahifmp+mhrhSRpVHY3KuEt3gSnxuYm66uSGn2xu1KLPiySJJ0za3inF9pOsKrwN+2pkT8QlNPR/vmYvXU+SVJWsjv0XG6qOUR7T3Vjt48XADA4EcLHsaQE88dT7/P3bAfDZknn/10qXmu2pl/3ovTFYvM25Qzp6BvNEAIAEH07P5WeOM+sfrclZkr+Zql6l/T+H81b4RFmBXY0L44KBqX1r0r//YVU+nnH2+VPl8573JzBPNDs227Ok161SAoGzMr3I2+QjvlJy/y1oQebt2BAeuNn0qs3STnjpTHHdr7vZp/04YPS1nel5gbz66DffN+sKyKCQABR4vKY1e+zrjQvqnn/j9KOj6Vt75q3JTdJQw8xw/jJp6vAmgtfHBHCm5XwXx+fo3c2lOmxd7fqijmj5XZ13Ga+uqFJz3y6Q5K0t65JDU1+eRPoZAIAAAD0xoSClFAI35NKeEmaOjRdX5XU6NU1xVpqXTB7+ZxRnb5neGaiEhOcqm/ya1t5rcbkti1OaGjyq846H5+RFB7Cm79jlBLCAwC6iBA+jtmV8LWNzb3bUcE0M4wv+Vx66zdWEP+CecufLk37pjT1LClr9H53BQB9Ihjsu2rwWNjwuvSvy6SmOqngIOncv0oZI805x82N5utr/iWtXyJt/0D689fNmeTH/FhKSOzdZ295R1p6hxlOSWb4nJIvpQ2VkvOk2j1mFWlduVSyRvrrKdLlL0k543r9bcdcQ6XZdn7ts9KmN81gXJImnSodd2vHI1mOvEEqXWfOiv/X5dIVL3V8kdrOFdIL17Z/ccOOj83K3AnzpSOukUYfHZ3vC0ALh9O8mHTKGdLebeZ/8+v+LRUtl3atMG9Lf65bvKM0xjVTxu4zpOAYc9STFcL/YO4EfVlcreKqBr20epfOOqTjC2ee+XSHasLW4rvD2tsDAAAA6JnwufAjsrpfCS9JU4ak6fnPdupp66LZYyfmthuqh3M4DI3LS9GanZX6qqS63e331Zlt8p0OQ2nelvgkL41KeABA9xDCx7Fkt/njqetpJXxr+VPNiseSL6S3f2OesCxZY96W/lzKHieNmC2NnCONPFLKHBmdzwWA9jQ1mBcFffKYtOMTM3x2J0vuFGnscWa3jtT8WB9l963+l/T898wAeOxx0nl/kzwtv1zK5bEqNU+VKndKr/7YrOp89x7p8+ekeb+UJp7c/YsSakqlJT8xA2hJciVKR3zPDJgTM9tuX7lT+sfZZkv2v54iXf5vKbeLo0/a0+wzj7/0C/Oxv1GSIY0/QRp3gnkBQl9653fSsl9bn2sZ9XXp+J9JhYd1/l7DkE67T6rYZAbpDx1ltrg++GJp9DHmhQvVu6Wt75kV8MGA2db/6z8yL3BwuiVfjbRykbT1HWn9K+Zt2tnS/F+1O7MaQBRkjpRm/495qyk1/7tb929p81vKadiq61xbpS8XS/feJt+oY3VEXYbe11RNLEjVFXNG6f9eW6+H396sbx48TEY7/88NBIJ6/P2tEc/trqwnhAcAAAB6adKQNElSfppHyZ6enS+YOjQt4usr9lMFb5uQn2qF8DWaP63t6xW1Ziv6zCR3xO8JuSktIXwwGGz3dwgAAMIRwsexJLdVCe/rZSV8a/lTzKrMugrzROXnz0lb3pbKN5q3z/5ubpc9zgxOxs2VRh3V0r4XAHqjulha/oD5/5r6vS3P+2rMm0rMMHTlE9IR/yMdeb3kTY/Z4XbLqqek578rKSgddIF0+h8ll7vj7dOHSRc8YVZyvnKjtHer9M+LzArqeb/s2siQYFD67B/Sf26VGvaZle+Hfsu6iKGg88++/N/S384wq7r/eop0ybPSkIO69z37aqVPHzdbQ1fvavv6J4+aQfWMC81W7X3RdeWDh8yLySRz5vu0c8wAvDvV/Qle6YJF0ovXSRv+IxW9b97aM+1s6aTfSMk5kc/PvMicQf/hn6VP/2JeELFxqXTindLMi80KXgB9IyXP/H/MrCukhkqt+u9T2rn8aR3nXCVv5Xa5V/1d99v/O37sAX278CitdqfrneIJemNdqU6Y0vairzfXl2preZ3SvC6Ny0vRiqJ9Kq5saLMdAAAAgO6ZNSJT1x8/XtOH9fx8z5SwEH5MTrKOHp/bpfdNyDer378qqW73dXsefGZS5Gz53FSPDEPy+QMqrmrQkPRedjIEAAx4hPBxzL4KsK4xSpXwrSVlSbMuN2/1e6WiD83AYdtyc5axHcp/+KDkTpUmzpcmn26G8u6etQkCEIfKN0mrnzIrfb3pkiddSsqUhs0yR1ZEq4K5cqf03r1mYGtXK6cXmv8PmnqWWY3sq5Uqd0hv/1ba+Yn0zm/NMPOsh83/98Sz8AB+1pXSKfdIjo7nDEeYdIoZvL/7e+n9+80Lox76ujT661L+NLONes5EM/RNyja7Bez4uKXiunyjuZ+Cg6TT/2DOOe+KlNyWIL5kjfTIN6Q510lH/7jz/88Hg9LuVebfm1X/lOrNOW5KHWL+O+FOkpwe89+Wtc9INSXmz/6DB6UT7pC+9t2u/9nsz5pnzFnQkvSNW6Wj/7fnow1S8qSLnpKqdkmrnjQr2ys2m23804ZIacOkgy+RJp7U8T5yJ0qn3iMdcqn04vVS8Woz2H/tVmnUkWZl/eijzZ9pe8fpb+77rgHAQOdNV2Daufqft4dpdKKhN89xauOHL6lpwzJNdhRJJWvkLVmjPzskv8fQrn/lq3H0NHkKJpkXoeZMkHLG6y/vbpEkXfC1Eaqo9WlF0T7tJoQHAAAAes3hMLTghF5045M5r314ZqJ27K3X5XNGyeHo2rmACVYr/P2G8MmRRRXeBKemD0vX6h2VeuerMp13WGEvjh4AMBhwljeO9VklfHsSM82QfeJ88+uGSmnzW9LG183ZxdW7pTVPmzdXohkMjTtBGj9XyhrT98cHILqaG6W1z5nV6Nve63g7d4pUeLgZgE8/1wxtu6O6xKwq/mqJee83f5FR4eHSkT+QJsxrWx1cMN2cqf3lS2Z1c9lX0j/OkY6/TTrqh9GfHd/b0DMYNMPaF6+VGcBf0b0A3uZJNb/HQy6X3viZ9PnzZhi/5e12NjbMz7IlJEnHLjQ7B3T3e0nOli5/0QyKv3zJvBBg7XPScT81x5hkjDDHBFTvlnZ9Zl6kte4lqWx9yz4yR0tH/cCsdnd5Ivd/4i/Mn/+Hf5a2vWu2zP9qiXTGn8xq/N7YuNRs/S9JX/tO7wL4cGlDzVbzX/+RFAj07IKBoQdLV78pffAns1V+w76WiyYkKTnXDOOHH2Z2hyj7Strzpfnv742bov/3HBhkCtLNDk7ba6TAuBP1wtZR+uPn83XVIam6dXKptHmZgpuXyVm5XYUqlrYUS1veiNjHA8EkbXEP0fiqg7WiLlc1Do/8xc1S03A6RAEAAABx4OdnTNUHmyt0fjcC8QkFZgi/paxWTf6AEpyRv/PvtdrRZyW17Wz4jYl5Wr2jUv/9srTdEN4fCGpfnU/ltT75A0FNzE/t8sUBAICBhxA+jvV5JXxnvOnSlNPNWyBgVqR+8YL0xYtSZZEZpm34j/SqWtrWj58rjYxh2/pg0Ky6rNppVjE21bW85nCZFZppw8xKR1oC40Bp9pkzt8s3mS3W9xVJacOlkbOlYYce+K4STQ3Sir+ZQavdOtxwSGOPN8PAxirzVrVL2v6x1FgpbVpq3l7/qTT+RDOMz58qpQ83w9mmBqnkc2n3Z2Yr7ppSqa7crH4u+yry80d93WyTPvrozkNGw5Amn2Z+3iv/ax7z0juk3SulMx6InLHeVcGgGST/f/buOr6u+nzg+Odcjbtb00ibauouFHfKcHfGgA3Zb8KECUzYgA0Ggw0GG1LctaUtpe7eNG0aadxdrp/fH+fem9xGmrZpm6bP+/W6r+Te4zltcs55vs/zVOyAip1ahnLlLmg8COGpkDITUmZA/AStz3BPfdQPXd++r7QAa9lm7bPJt8JFfzu2LO/wYVrLkPk/g9LNUL1XKxdfX6C1EbG1Aqr2ezrzPC0rO+Ns8As53Jp7FxChlcXf+7nWo77xIHx4Z+d0YyDY23yX0Zsh60Kt7H7G2b0H/w0m7W/JqEtg08uw5NdQsAJemAlXvgoZZx3dPu/7Gt6/HVx2rZLC+U8cn8D1sZxLvUFrpzDzPu3fXeFKKPxOqzjTVqOVq9/9QfflWqshuHtpbCFE/0UHmdEp4HCp1LZZKajVfofFxiXBuHkw7koUVaWwKJ/fvPIJya5Srkq1MMG/BktlLqbWUkKVdiYo+ZCbz1xgrgnYB/xB0QYoRWVCZKbW+iIyU3sfHC+DaIQQQgghhDhBzsyK5cysI7t/Tgj1I8hsoNXqIL+mlaw43+cp9W12oHsmvLa9GJ5ZlsfqA7XYHC5MBu2ZgcPp4pZXN7Iuvw5Xl5yJP1w+lhumDzvCoxJCCDFUSBB+EPM3nsBM+L7odJA8TXud+zhU52jZ8QeWQvE637L1fqEw8SaYdpcW1DqebO1QuhGK1miZvOXbuweJejweA4QN00oGR2VCzBgtsz8k4fjurxhcOhq1f7e1+6GtViuDbmvVpiVN1YLEARFHt+7mcti/WPs/UrCic72H0hm1ktSBUVrA1z9cGygSMVz7/xM+HPzDjm4fPFRVC/xX7db+j2x9DVortWnBCTD1dsi+vueMZJdTC64XrdZKipdt8c3kBW2frS3g6uP3VMIkLeN9xPmQMOHI9t9g1vqqJ0zSeqbnfAJl2+DCv/RdElxVoaFQC7ZX7Oh8tdf2PH9Dkfba8VbnZ+ZQLcgSlqIFxsNStN8frVVa5nLZFu33IYDBTwu0LvjVwJVZjxmlvQ5lt2gDjgKjQG/sPv1YjLoY0uZr7QDyl2v/diyN2u9WRa/tT8IEbcDCqEu03/n9pSja34a0M+DDu6F8Kyy6Rms1MPZ7/V+PqsK657RgPqo2gOTyFwfu53486PSQOEl7zXlQq0RRulkLyFfu0v7+RI2E6BEQnaUNFhNCHBODXkdUkJnqFitVTVYKa7RrxLTowM6ZFIXhwzO4+NKr+ekHO3m7UGFySjgba+sxY2OksYbnzg0iRS2jsmA3lQW7yNBXEqS2aYOVGg9qf+u7MgVpf8M9f9f9wyEoFoLjtP/rwfHa14Cowf17SwghhBBCiCFKURTGJ4WyNr+OLQcbugXhe+sJDzAuMZSoIDO1rVY2FdUzOyMKgOW51aw5UOedz8+ow2J3sXhPlQThhRDiNCZB+EEs0KwF4TtsJyETvjeKomXAxo7RAgmWZi3I2LVs/brntPK7Iy7QgjSps7Xg1UBwOaFoFWx/C/Z+6pvt7hEQpQUUTV0yZR0Wbd9aKrRgYb07K7lLNWWiRmrBoWEztTLCYcMkk2kocNi03tmVO7WAe22e9rW1qu/lFJ2WET3qYph4c//KsFfs1DLMcz4G1dX5uX+41l82Ik37v1CXDwfXapnolTv7XqdfWJegfKoWmA9P1QYI2C3g6NAGELTVasfUVqNl0bbVdAaLrc2+6wxJgrkPaQNmDi0d3pVOD/HjtdfMe7Us9+2LtIBDY7G23o4Gbd6AKC04GztGCzAERmu9y2NGD0xG75TbtHW/f7tWjeOta2HkRXDe4xCWqgUyVFX7ee56Xyvl3lTSfT2KXhuAE+c+rrjx2nmp2QvF67VXTa7287M2aX3Sq3b1vl+mIJh6pxaAP1GBU6MfGOOP3/rNwVrf9nN+p73vaNT+LYUmD0zlhqhMuH0xfPR92POhdk476rWf4+E4bPDFw1obBdBK91/01MAPRjjeDGbtb2Pq7JO9J0IMaXGhflS3WKlo6qDQnQk/PCqw23xXTUliTX4tn2wvZ2NRPUa9wlVTM/jhmRcQG6JVeGoc0czCv68iIsDI1h9P0K4n6vLcXw9oXxuKtIF3VbsPv3M6oxaYD47rDMx3/Rocr10/mIO1iiJCCCGEEEKIATNlWLgWhC9q6BYk9wThI3rIhNfpFM4YGc37W0pZnlvtDcK/vv4gAHfOGc7PLsgiv6aV8/++is1F9T4Z8wAul0p1i9XbQutEK6lvJy7Ur1sZfiGEEANPgvCDWIBJOz0nPRO+L34hvmXrD3wDG17UMij3faG9AEJTtDLPiZO1TMC4cWD07/92avZrGao739HKzXsEJ0DqHBg2S8vMDB/W93qdDi0LuO6Ats7afVC2VStxXbtPe238lzZvQKS2vykztfUnTOw7YCkGj9ZqLQibvxwKV/VeISE4vrN0rClICzDaLVrJ6Np9WqZu+Vb49k8wZiFMvg2Spvj+O+ho0Obf+rr2798jaZpWSj3zbIjL7p7tpqpaBl11rraOjgathHtTifYQv74Q2qq1LOTybdrraOmMWnZt3Fjt/8u4q47u33L0SN/grKUJmkq1bOiQxOM/aCV5Gty3Ab57AtY93/k7RtFpgxUMZm2gjYfepAXu48ZDfLY2qCJ2dM+/I0ITtZLqHrZ297lwZzo2FmtfXU4tYBIUqwVKsi46fNn6U51/2LFXZDiUwQRXvKwNJtn0MnzxY6jcDaMv0/5WHHqObO2w/U1Y+w/tPCg6OPcPMOMHMlhKCNErLYDexM7SJjrsTvQ6heSI7oOJFEXh8YVjcbhUQvwM3HtGRrf54kO030v17XYs5kj8UmO6D6Rx2LS/4Z4qIp6/7y2V2t+n5nLta2u11kqjqaTnAWOHMvhpwXhziPbVL8T9fYj2fX//pqvq4efx0BnAGKAN/DL4ab+Xjf5g8HcPBgtwfx6gXT+ZArVrqVNtUJQQQgghhDgtTU7Vql9uPtjQbVp9mycTvufBsGdmxfD+llK+za3m1xePpqCmlVV5tSgK3DIrFaNex4iYYCICTdS32dhZ2siU1M5qm88uz+PvS/P4102TOW9M3HE4ut5tOdjAFS+s5XuTEnn66gkndNtCCHE6kiD8IObJhG8fTJnwfdHp3CWnz+vMmC1arQUPm4phVzHselebV9FBkLssZ4i7V3tIghZUD4zUylu312vZqPu/1so+e/iFwtgrtBLaSVOOLACjN2h9rEOTtKx3j44GLVhb+J1WIrhqjxYQzVuivUB70Jg0VQvID5ulfW/qnk0lBoDToQXQd7ylfQ2K7azAEJ+tDY44tFS8qkLJBi2gt+dj7eG2R2A0JE93tyAY0dnDta8e2s3lWnWHra9p/b53vae9dAatakLsaO1Be9mWzqx3RQdjLoc5D2kDTfqiKJ3Z7b2xtWlB4IbCznLp9YXae0tz50Nwo7+WiR4Uox1rUGzn98FxWvb88cii8ws9snLkA8EUCOf8XutD/tVPtcoYqkvLpAatT/mI82DcldogiCMZ7OOznQDt30v0yIHbd+FLp4cLn9QGPH33BGx5VXsZ/Nz/xyPdAR0D5H6h/U4G7fOFL8KIc0/u/gshBr04dxb72nytFUlKRECv2R7Bfkaev35Sr+sK8Tfgb9TTYXdS2WQhtYeMegwmd1uJEX3vmNOuVRhprtCq4rRUdgboPV9bKjvb2Tgs2qut5vAHfbLpjJ0B+a7BeU+w3hio/W02BbivYdzXMSb358Yun5vc04xdpkkJfyGEEEIIMQAmpoShKFBc3051s4WYkM6s9L4y4QHmZEZh0CkU1LZRVNvGG+uLAThzZIx3MK9OpzAzLZIvdlWwLr/OG4R3uVQWbdDm/za3+oQH4VflafcUuRUtJ3S7QghxupIg/CDmzYS3DuJM+N54MmYBrK1acLR0s5ZVXLZVy/BtKddeZX2vCtBKSGecDROu08rcGwe4XI9/eGdGP2jZ0FV7tP0uXquVDm+v0wJ+Rau0eQx+WhZs9vVaQF9/iv13crm0QPBgySJVVa038o63tWB3W3XnNEujlpm+58POz6JGaJnNtjb3Q+sy3xLziZNh1KWQfibEjj3yh7YhCTD5Fu1Vvg02vgy5n2v7Ur1He3n3ZaT273PqHRCZfhQH3wtToBbsjx09cOscKmJHw62fa721Oxq0QTvWFojJOvEDA8TRUxRY8AtImKS1cShYof1/Prim+7xhw2DWD2HCDQNTFl8IMeTFhmgZ4jtLmwBI6ylw3k+KohAf5kdBTRsVvQXh+0tv7BwU2henA2wt2sA7a4vWBsbqed/c+d5hPZID6d98TofW9slhAXuH9vL5vkO7Xra3adVKPIMfXXbtWsnS2P99OhKmIAiM0gYaHvoK6vo+Rru+l6C9EEIIIYToQYifkZGxweRWtrD5YAMXjuts+9fQpl3bhvXQE96z7NTUCNYV1PHFrgre26JVt7pxpm9Z+5npWhB+bX4dPzwrE4AtxQ1Ut2jX7zkVh7SPPAF2l2n3Rp6BBkIIIY6vUyxqeHoJdAfhT5lM+N6YgyDjLO0FWrC1tRqaS7Vsn2Z3ANWT/dNWq2UoB0Rq2c4xY7Ss1hPVbxm0IH/SZO01815tn2vztMDQwbXa1+Yy2P2B9gqK1Up8Z1+nlfwejFxObSBE0Spt/4s3aA9XTUHuEqdBXb4P9v3cU5o/YWL/M4sbDkL1XnegX6e9woZp/c11WpUHHDYt8F60Ena+5xvYDojUfqZjLtcGclTt1l5lW6E+393ffb/vNg3+2r+VqXdo+zpQEibCwudBfU4775W7tEEaQTGQtgDCkgduW+LIGMydPXXFqWvk+dpLVbX/1+XbtMCSrU17xY6BrItPvcFOQoiTytPP3eHSyrD31A/+SMSHeoLwHce8b/2iN2iB5FOh7YnD1hmQt7VpWfz29s7f47Y27b29XZvH8729wz2t45DpHdr6PJ972Fq1V0PR4fdJ0WvXk0ExWuA+IModwPd8H+3+PlJra+MXenwqBwkhhBBCiEFpSmq4FoQv6gzCt9sc1LRqQfLIwN7bPp2ZFcO6gjr+sTwPi91FSkQA8zOjfeaZmR4JaIF3i92Jn1HPl7s62yjmVrbgcLownMDe7LskCC+EECeUPM0exALc5ehPyUz4vigKBMdqr8TJJ3tv+kdROsuLTrlNCxSVb+vM2m6tgnXPaa/YcTDqEghLcZfYj9cC0C67Vn7U2qzN31Kl9afv+tXeBriD1noTxI93l7+frWV+H03WelsdbP0fbH5VawtwKFuL9upPFSKdUdun4fNhxPlaOwBPQF1VtQD13s+0gQmlm3peh8FPOxaDGSp2grNL9pbeBCMvhOxrtczyrn1FM7v0626r09ZftVvrVR2coAVhIzP6LjF/rBSlM3Nt5AXHbztCnK4URdoACCEGTFyob+Wk4dHHFoSPc/eFr2iyHNN6hiSDSXsdjwEDLldnFr6lURuw21atledvq9UG97bV+L46GkB1uuerPuwmvIwBWkDeP6wzMO8ZoOoX4v4+xP0K9p3mmd9zbSyEEEIIIQa1KcMieGN9MVsO1ns/+3JXJTaHFlRPCu89EWlBVgx/+HIvFrvWovLGGSnodL7PbdOiAokNMVPVbGVrcQMzhkfy1a5K73Sbw0VBbRsjYoMH+Mh6Vt1ioapZew5rsbvosDnxN8m1qxBCHE8ShB/EumbCq6qKMljKhgstUJQ4SXud+zgcWAo7FsG+r6Fql/YaCLX7tCA/aBk7w2bCsDmQMkPrJe4X2j0w73JBTS4Ur9Oy3nO/7Ax0+4VqAfTUOVpgPzBayyaytrizTlu1rHOb+73VnW3UVAIlG7XBA2VbtNfqp7XMofhsrZpBY7F7EIHnZ6TTsld1Bq1nt8OmZS05OqByZ+d8AZGQOEULao9Z2L+Ht4GRnZmzQgghhBA9iAs5JAh/jJnwCWHa+k5YJrzQ6HTu/vIB2jVgf1r/OGxaK6m2Gncgvtb9qoH2Wm1Apzdg3whWLSPIm43fUn6UO6t0BuS9gfwQbaCpzqANaNXpte/1RvdnevfnBu36Gbpc3ys+X7p808M8A/weVRtke7ivqsv3e+/rkPeonetXlEO221OLrB7ufQ83j97ofpl8X4au742gN3d+b+jy/aHL6Y2Dp3WXEEIIIQbclFTtGeSe8mZvQPrdzVpp+aunJHULqneVHh1ISkQAxfXtmAw6rprcvUqmoijMSo/io21lrMuvw2zQU9lsIchsID06kB2lTewpbzphQXhPKXqP+nYbiaZ+VjwVQghxVCQIP4h5RqI5XCo2pwuzQUamDUoGE2RdqL3a67W+5aVbtId3zeVahjtoJUV1Rq3Pd3CcVhozKE6rCOD5ag7pfGBla4GSTVrp+NJN2gPDvZ9pL++2/bV1GQPAadOC7R2NWrZ9V/ETYNrdMPZ7PZSTj+3fcaqqFmgvXgd5SyBvqfZwM395l5kULTt+7JVaGfngQ9btcmqB+Oq9WkZTwkSISJOHW0IIIYQYcLGHZMKnRwcd0/o8mfWVkgk/+BlMEBKvvfrD5QRLk7uffZN2PW1pBEuze2DqIV+9n7s/szS7B6Oq7vU0QePB43d84sTRm7SgvaHrV/f3Ol1n260eX562XPrOwReKrsvgC/f9YdfBAAbzIds59DNz5/w6o3aPqTd1rsczmODQaTq93HMJIYQQh0gM8ycuxI/KZgvbSxqJC/VjY2E9OgWumJzU57KKonDO6Fj+s7qQS7MTCA/sua3RzLRIPtpWxtr8Om/L2bNGxRAeYGJHaRM55c1cPoAdNfuyq9T3eXFDm43EMAnCCyHE8SRB+EEsoEs5mA6bU4Lwp4KACJh6p/YaCBnuEuwOK5Rv7+xJX7YFOuq1rPKGwu7LGQMgaSqkzITMc7WM/WN96KIoED5Me2Vfq5XWL16vbT8kUcvMD03SHgj1RqfXspf6k8EkhBBCCHEMgs0GAkx62m1OAkx6YoL7uEbph/hQTya8BOGHHJ1eu44PiDj6dThs7gB+gxbA72jUvrc2g8vR+XJ2+d5l1wYAuBzatbU3yxy8meOHvu/pM++kXpY5mvc+GeqH+dpr8LnLe5RDjs+z3UM+63qcPvvWj2kuh3YenJ6Xvcv3XT5zWHue7rB234Zn2infNlXpEqA3HPK9qTOA3zWYr/NUB/BUaejnv4ceKye4+QxG0HcOUPB+PeRznaFzH30GKnQZnNDrIIau08zacQghhBBdKIrC5NRwvthZwZaD9d4g+bwR0cSHHj44/eDZmQyLDODyiYm9zuPpC7+jpJHShnYALhwXT1O7HYCciuZelx1ouw7JhJe+8EIIcfzJXcggZtTrMBl02Bwu2mxOwgJO9h6Jk8ZghpTp2mvuw9pn9g5oqdBKwTttnZkSpgCt53rXfurHg94Iw+dqLyGEEEKIQUZRFOJC/CiobWN4VOAxt3byPIiTILzokcEEQdHaS5y6XM4uQfouwfmevvqU3+/ppWrrU52+X73fO3wHAvS2nR4/cy/ncnR5b9cGdnj2zYfaua7TlaI7JEBvOqTCgdkdsDf2UP2gt2ldgv+KvssAFKXLwIXeBqgoh5nedflDvx463TOtr+k9rOfQ6Xp31QQhhDiNTBmmBeE3FNazr7IFgGumdC8t35NgPyM3z0ztc55kd2/50oYOqpqtBJr0zB8RzYHqVkArhd+1Da3F7mRvRTMTksMGvDWtpxy9v1FPh91JfdtpfF0ghBAniAThB7lAkx6bw0W71XGyd0UMNkZ/rZR7RNrJ3hMhhBBCiEEptksQ/lh5MuHr22xY7E78jBKoEGLI0em1Qc2c4iPgXc4uQflDAvROd+C+67RDA/o+wX1bL9ntvXztLUseugxEcGgDBXoapODzubt6hNMzCMHdgs37tetAhR6m+VSQcGmV5BwdJ/RUnHqUzmoJnrYGngoJns/Dh8MN757sHRVCiAExZZhWCWlVXi0AEYEmzhrVz9ad/TQrPZJ3N5cCcOaoWPyMejJjgzDoFBrb7VQ0WUhwl4X/9ce7eW9LKf+4biKXZCcM2D7UtFipbLagKDA9LYIV+2pokCC8EEIcdxKEH+QCTAYa2u20ucvhCCGEEEIIIfrH8zDrWPvBA4T6G/Ez6rDYXVQ1WxgWeeyBfSGEOC507nLu+J3sPTl5VLVzMEG/qwxYfVsa+HzWddqhn1m7V0FQ1c73qD1M7/LVZ/oh83LIunqc3sM6e9p2/35w7lYZ9uN1ZoQQYlAZFR/sbWEFcPnEREwG3YBuY1Z6lDcIf9G4OADMBj0ZMUHkVraQU95MQpg/TR12PtlRDsA3OVUDGoT3ZMGnRQV6+8A3tMvveiGEON4kCD/IBZq1DBvJhBdCCCGEEOLI3DVvOCaDjuumpRzzuhRFISHUn4LaNsobjzwI37XMpBBCiONMUTr725tk0BTQfXBA1yC9q0uLBE+VBJ/3js7PDeaTfSRCCDFgDHodE5LDWJtfB8DV/SxFfyRmZURiNujwN+mZPyLG+/nohBByK1vYU97M2aNj+WpXBTaHNmhqbX7dgN4/ePrBj0sMJSLQBEhPeCGEOBEkCD/IBZi0UySZ8EIIIYQQQhyZrLgQ/vS9cQO2vrhQrbx9ZfORlzP+v/d2sjKvhi9/NJfoYAlgCCGEOME8feMZ2AxPIYQ41U1JjWBtfh3ZyWGMjAse8PXHBPvxwQ9m4WfUAvEeo+ND+JAyciq0APmH28q802pbreRVtzIidmD2Z2epto2xiaHo3IF96QkvhBDHn1x5D3IB7j/M7TbJhBdCCCGEEOJkig/VSjeWN1qOaLmDdW18sLWUmhYraw7UHo9dE0IIIYQQQhyF22alcu3UZP6wcOxx28bYxFAyYnwD6mMSQgHIqWimpL6djYX1KAqMdAfe1x7lfYPD6eKjbaUcqG71fuYpRz8+KYzwQCMgmfBCCHEiSBB+kPNkwrdLJrwQQgghhBAnVXyo1l+5sunIgvBvbyrxfp9T0Tyg+ySEEEIIIYQ4euGBJv58xXjGJoae0O2Ojg8BoKS+g9fWFQEwKz2SyyZqveA9JfKPhNOl8uP3dvDQOztY+PwadpY2UtNipbLZgqLAmIQQwgPc5ejbpCe8EEIcbxKEH+Q8PeHbpCe8EEIIIYQQJ1WcOwhfcQRBeLvTxXubS73vc8olCC+EEEIIIcTpLjTASGKYVmnrf2sPAnD5xCRmpUcBsL6gDqdL7ff6nC6Vn7y3g0+2lwPQanVwyysb+Wibdi+SFhVIoNkgPeGFEOIEkiD8ICeZ8EIIIYQQQgwOCWGeIHz/e8Iv21tNbasVg07rvbinvAlV7f/DNCGEEEIIIcTQNDpBy4a3OV34GXWcPzaOsQkhBJsNNFsc/R7A63Kp/PyDnXy4rQy9TuGpq7LJTg6jod3OH7/MBWCcO9PfkwkvPeGFEOL4kyD8IBfo7gnfJj3hhRBCCCGEOKniQrRMlSMpR//2pmIAbpo5DL1OoaHdTmXzkZWzF0IIIYQQQgw9Y9xBeIDzx8QRZDZg0OuYnhYBwNr8/vWFf/qb/by3pRS9TuHZaydyxeQk/nfbVG9/ecBbbj/cnQlvdbjokMQ/IYQ4riQIP8gFmN2Z8Fb5gyiEEEIIIcTJ5OkJX9dmw2I//PV5WWMH3+2vAeCWmamkRwcC3UvSP/55Dle9uFZaUAkhhBBCCHEa8fSFB7h8UpL3+5nukvRd+8JvKqrnsc9zut0zuFwqb23UBv7+6fJxXDQ+HoCwABOv3zGN1MgAFAVvmftAkx6TXgsL1UtJeiGEOK4kCD/ISSa8EEIIIYQQg0NYgBE/o3YLVdWPbPZ3N5WgqjAzLZLUqEDGJGjZJ12D8E3tdl5ZU8imogZW5dUcnx0XQgghhBBCDDoTU8IJNOkZHhXI7PRI7+ez3N9vKqrH5nCxuaiem/6zgf+sLmTRhmKfdeRUNFPXZiPQpGfhxESfaTEhfnz5wFy+eWi+t/S9oiiEBxoBaOijJL3N4aKpwz4gxymEEKcrCcIPcpIJL4QQQgghxOCgKArxoVpJ+n+tLGBpThXVLT0H450ulfc2lwBw7bRkoDPTJaeiMwi/+kAtLneL+E1FDcdr14UQQgghhBCDTHSwmSUPz+f9e2Zi0HeGakbGBhMRaKLd5uTdzSXc/t9NWOwuAL7JqfJZh6fy1sz0KEyG7uGeAJOBjJggn88O1xd+aU4Vc/+ynFl/WkZdq/XoD1AIIU5zEoQf5AKMkgkvhBBCCCHEYJHpfoC1aEMxd762mWl/WMZ9b27tVp7+xe/yKW+yEBZg5LwxcQDe7JOuQfjv9ld7v99UVH+8d18IIYQQQggxiCSG+RMZZPb5TKdTmJmmZcP/6uPdNFsc3gG9mw/W+wTGV7qD8PNHRPV7m54gfMMh5ejrWq388K1t3PnaZqqarbTZnOwobTziYxJCCKGRIPwgF2jWgvAdNsmEF0IIIYQQ4mR74orx/P6yMVwxKYkRsUEoCnyxq4LbXt1Eq7s/479X5vPXxfsA+NGZmfi5B9Z6HpwdrGunxWJHVVVv5grAnvJm6QsvhBBCCCGEYGaX8vQjY4N5664ZjEkIwaXCslxtIG+r1cGWg1o1rXkjovu97ohAdxC+SyZ8eWMH5/xtJZ/tKEenQEywNjAgv7rtmI9FCCFOVxKEH+QCTFo5+jYJwgshhBBCCHHShQeauHlmKk9dnc2Sh+bz1l0zCDIbWFdQx40vb+DZZXn88ctcAB46ewS3zxnus2xCqB8Aeyta2FfVQlWzFT+jjrgQP5wulW3FjSfjsIQQQgghhBCDyIKsGMwGHckR/rx2xzRCA4ycMzoW6CxJvy6/DodLZVhkAMMiA/u9bk9P+Pr2zp7vX+ysoL7NxrDIAD6+bzbXTUsB4EB160AdkhBCnHYkCD/IeTLh26UcvRBCCCGEEIPOjLRI3rxzOmEBRraXNPL0N/sB+NFZmTxwdma3+b0l6cub+G6fu39jWqQ302WjlKQXQgghhBDitJcY5s/Kny5g8YPziA3RBvJ6gvCr8mrosDm9pejnZfY/Cx46y9E3dilHX1CrBdsvzU5gfFIY6e42XAdqJAgvhBBHS4Lwg5w3E94qmfBCCCGEEEIMRtnJYbxz90xvycb7F2TwUA8BeOgsSZ9T0ewtRT9/RDRTUyMA2FQoQXghhBBCCCEExIb4eeMDoN1LJIb5Y7G7WJVXw8o8dxD+CErRQ2cQvr5LOfr8Gq3sfFq0llGfEe0Owle3oqrq0R+EEEKcxgyHn0WcTIHuP7KSCS+EEEIIIcTgNTIumMUPzqOwro2JyWEoitLjfJ5M+M0HGyipbwdg/sgYHE4XANtKGrA5XJgMMl5aCCGEEEII0UlRFM4ZHct/1xbxn9WFHKxrx6BTfPrH94e3J3zXTHh3xntalBZ8T4sORFGgqcNOXZuNqCDzAB2FEEKcPuTJziAX4C1H78TlkhFnQgghhBBCDFbhgSYmpYT3GoAHGJMQCkBBTRt2p0pKRACpkQFkxAQRHmDEYnexp7zpRO2yEEIIIYQQ4hRyrrsk/QZ3Ba1Jw8IJMh9ZrmVYgLsnfJvWE76pw05tqxaQ92TC+xn1JIX7A9IXXgghjpYE4Qe5wC7lZjrsUpJeCCGEEEKIU1lSuD/BXR6SzR8RjaIoKIrCFE9JeukLL4QQQgghhOjB1OERhPj53k8cKU8mvKcnvCcLPjrYTLCf0TufpyR9/gnuC7+1uIE7/ruJg3VtJ3S7Qggx0CQIP8j5GXV4EmnapCS9EEIIIYQQpzRFURjlLkkPvg/NpqaGA7CxsOGE75cQQgghhBBi8DPqdZw1Ktb7fl7mkQfhu/aEV1WVAk8/+KhAn/nSu/SFP5FeWJHPstxqnlt+4IRuVwghBpoE4Qc5RVEIMGol6TtskgkvhBBCCCHEqW50vBaEN+p9+zdOdWfCbzlYL62ohBBCCCGEED06x12SPjLQxJguA3z7y5MJb3W46LA7Kah194N3B909MmJ6DsI3ddipbrYc8Xb7Q1VVtpc0ArB4TyU2h+u4bEcIIU4ECcKfAgLc5SrbrBKEF0IIIYQQ4lQ3eZiW8T4zPYrALqXpxySE4mfU0dBuJ7+mlfyaVv745V7+8EUOdqc8fBJCCCGEEELAeWPiePDsTJ6+ZgI6nXLEyweY9Jj0Wmiood3uzYRPj/bNhPcE4T3TAVwule/9cw3z/7qCPeVNR7TdJXsq+e+aQqpbeg/gVzZbqGmxAtBscbDmQG2v87ZaHVz07CoefHsbqiqDmIUQg4/h8LOIky3QpKcGaJdy9EIIIYQQQpzyLhoXj8PlYmZalM/nJoOOicnhrCuo47b/bqK0ocNn2k/OyzrRuyqEEEIIIYQYZPQ6hQfPHnHUyyuKQnigkapmKw1tti5BeN9MeM/7ssYO2qwOAs0GtpU0ku+e/0dvbePzH87F36RV8rU6nPzusxzsDhdPXDHeZ4BAdYuFe97YgkuFx77Yy4KRMVw7NZmzRsWgKJ3z7XBnwXt8vrOCBVkxPR7Hyv017ClvZk95M3Mzo7lictJR/0yEEOJ4kEz4U0CAyZ0JL+XohRBCCCGEOOXpdAqXT0wiLtSv27Spw7WS9KUNHegUmOZ+/88V+aztIwtECCGEEEIIIfrL0xe+ptVKYZ27J/whmfDhgSYi3aXrPYH6JXsqvdPza9p47IscACx2Jz94YyuLNhTz3pZSdpX5Zsmvy6/DpYJJr8PpUlm6t4o7X9vMWxtLfObbXqItNzI2WNteTiVWR89xkbX5nfdHj3+RQ32b7Qh+AkIIcfxJEP4UEGjWRpK1WyUTXgghhBBCiKHsphnDuGBsHD88M4NVPzuTd78/k+umJaOq8OA726lrtZ7sXRRCCCGEEEKc4jx94XPKm7E5XJj0OpLCA7rNl+4uSZ9f04qqqix2B+FvmJ6CosCiDcV8uqOce97YwvLcau9yK/fX+Kxn7YE6AG6ZNYylD8/jsgkJAHywtdRnPk8m/K2zU4kNMdNicbA6r+fByOvytXUGmPQ0tNv545d7j+hnIIQQx5sE4U8BkgkvhBBCCCHE6SE62MwLN07mx+eOJDHMH4BHLx5DRkwQ1S1WfvL+Tul3KIQQQgghhDgmnkz4zUX1AAyLDEDfQ395T0n6A9Wt7K9qpaiuHZNBxyMXjuLuuWmAVpZ+xb4a/Iw6vjcxEYCVeb5B+DXurPVZGVFkxATz0/O1VlvbihtocGewO12qN4N+YkoYF46LB+CLnRXd9qu62UJ+TRuKAs9fPwlFgfe3lPpkx/elpL5d2v8KIY47CcKfAkL9jQDUt0nWixBCCCGEEKcbf5OeZ6+diMmgY3luNW9vKjn8QkIIIYQQQgjRi/BALeawtbgR6F6K3iMjpjMI7ylFPycjiiCzgR+fO5KxiSEA+Bv1vHrrNB46Z4R3vc0WOwDFde2UNnRg0ClMS9XabSWG+ZMVF4xL7QzYF9S00mp1EGDSkxkTzMXjtSD8kpwqLHbfBMV1BVoW/Ki4EBZkxXDD9BQAfvnRbpo67H0ee25lM2c8uYLbXt0kA5yFEMeVBOFPAYnhWgZMWUPHSd4TIYQQQgghxMkwOiGEB87KBODzneUneW+EEEIIIYQQp7IIdya8J2Cd5s54P1S6OzifX9PK4hwtCH/emFgATAYd/7ppCrfMHMaiu6YzMz2S5IgA0qICcbpUb7l4Txb8xJQwAs0G77rPGBkDwLfuMvbb3aXoxyaGotcpTEwOJz7Uj1aro1t5+/XuIPzM9EgAfnp+FtHBZgpr25jz5+X8dXFur628Vu2vxelS2VBY791HIYQ4HiQIfwpIcgfhSyUIL4QQQgghxGlrgfsh1Y6SJpwuydgQQgghhBBCHJ0wdxDeIy2q70z4/JpWdpc1o1Pg7FGx3umJYf787rKxTEwJ9342NzMK6OwLvzbfEzCP8ln3mVna/c13+2twulR2lDYCMCE5DACdTuksSb/LtyS9J3g+M00Lwof4GXnxxklkxgTRYnXw/Lf5zH5iOe/2UEXME+wHeH7FgR6PWwghBoIE4U8Bnl6QZY0ShBdCCCGEEOJ0NTIumACTnlargwPVrSd7d4QQQgghhBCnqIjAQ4LwvWTCJ4T642/U4xkDPDU1gsggc5/rnjciGtDKzKuqyjp3Jvxsd9a6x6SUMEL8DDS029le0siOEq0f/PikUO88F7lL0i/eU0llkwWAiqYOiura0SkwLS3CO+/kYREsfnAe/7ppMtlJoVjsLh77PKfbAOauQfg1B+rY0eV9Xyx2J88tzyO3srlf83uUNXbwi492kVN+ZMsJIU59EoQ/BSSFBwBaJrz0KBFCCCGEEOL0pNcpZCeFAbC1uKHbdJdkxwshhBBCCCH6IfyQIHx6Lz3hdTrFp1/8eWPiDrvuGWmRGPUKJfUdLN5TRW2rDX+j3idbHsCg13kD9ov3VLK3QgtSe+55ACYmhzE1NRyL3cVfF+8DOrPgxyWGEuJn7La/542J48N7ZxNsNtBidfgEv2tarJQ1dqAonWX1/9nPbPjPd1bw5JL9/OGLvf2aH8DhdHHvm1tZtKGY578duKz71Xm1XPb8GnaXNQ3YOoUQA0+C8KcATzn6VqvD26NFCCGEEEIIcfqZmBIGwLZDgvDf5FSR9ejXvLSyoM/lHU4X9y3aygNvb6PD5jxeuymEEEIIIYQYxCK6lKOPCDR1K0/flackPcC5Y2J7nc8j0Gxg8jAt4P6XxbkATB0egcnQPRzlabn15vqDOFwqkYEmbzwEQFEUfnXRaAA+2FrKrtImbxB+xiGZ9V3pdQrThmtZ8p7+8YA36z0jOoj/O3ckAIv3VHGguuWwx5XrHiSwp7y538mS/1yR793m3iPMoO/LG+sPsqOkkU+2lw3YOoUQA0+C8KcAP6OeqCDtj6D0hRdCCCGEEOL0NcmdPbKtuNHn89fWFWFzuPjjV3u9vRd78vnOCr7YWcEn28u5/b+baLc5jufuCiGEEEIIIQahsIDODPLe+sF7pLtL1Y9NDPFW7T0cT4Z7QU0b0L0Uvcf8kdEoCrS5BwhnJ4ehKIrPPNnJYVw+MRGAxz7PYV2Bbz/43sxwT/cJwrv7zmcnh5EZG8y5o7VBBS+s6HswM0CeuyVYfZuNmlbrYeffVdrEs8vyvO+Latuw2AdmILSnJP7BuvYBWZ8Q4viQIPwpIrFLSXohhBBCCCHE6WmCOxM+r7rVWyWrqd3uzQZRVXjg7W2UNnR/GONyqT4lENcV1EkgXgghhBBCiNNQ157wab2Uove4akoSczOj+Nn5Wf1e/7zMaJ/3szOiepwvKsjM+C7l57uWou/qJ+eNxM+oY2NRPaUNHRh0ClNTI3qc18MThN9YWO/tC+/pBz8hWdvOvQsyAPhkexkl9X0HtA+4g/AAuRV9Z85b7E4efGcbDpfKhePiCA8w4lJ913G02qwODrr3VYLwQgxuEoQ/RXhKsJQ1ShBeCCGEEEKI01VUkJlhkdoAXU9Zw2W5VThcKunRgYxLDKWh3c69b27tlmWxJKeKvOpWgs0G/nvbVILMBtYX1HPrq4cPxNudLh58e1u/+yUKIYQQQgghBq8Ak95bHj4tOqjPeeND/Xn9junMPSSw3pfR8SFEugP9of5GRsWH9Drvme6S9ADZyaE9zpMQ5s/dc9O878cnhRJoNvS9DwkhPn3hXS7Vew/lCcJPSA5jbmYUDpfKbz7d02uZ+Tarwyc2s6+y7yD8XxfvI7+mjehgM39YOI4RscH9Wq4/9le14NnNg/VtuFz9K41/KKdL5a+Lc/l6d+Ux75MQomcShD9FJIVpQfieMlqEEEIIIYQQp4+J7gdGnpL0i/doD00uGhfPCzdOIizAyM7SJn7zSedDJFXtzIK/edYwzhgZw2t3TCPYbGBjYT3/W3uwz21uLmrg4+3lPL1kP21WyZwXQgghhBDiVKYoCuHukvSHK0d/NHQ6hbmZWvb7zLRI9Dql13kXZHUG93vLhAf4/vx0YoLN2jr76AfvcWhf+KK6NpotDswGHSPjgr3z/eaS0Rj1Cstzq3sNSOfX+Gaw5/YRTG+22HltXREAf7liPOGBJrLc29tfdexB+K7btthdVLccvjR+T5bnVvP8t/k88uHOfve4F0IcGQnCnyI8mfBSjl4IIYQQQojT20R3X/itxQ102Jx85+4Bf+6YOJLCA3jm2okoCryzuYQfvrUNi12bZ1dZE/5GPbfPHg5o/eX/77yRAKzK672PPEBOhdZz0OFS2VRUf7wOTQghhBBCCHGCXD4xiZGxwUw/TG/1o3XvggzmZkZxn7vke2/GJYZyz/x0fnZ+FuFdyuQfKtBs4JlrJ3LemFhunpnar33wlKRfV1Dn7Qc/NjEUo74zNJYRE8w989MB+O1ne2ix2Lutx1NG3jOYYF9Vc6/bXLa3CrtTJTMmiAVZWpb/CHcQvq/gfX/lVvhuu6iu7ajWs2JfNQAN7XaJOwlxnJz0IPzzzz9Pamoqfn5+TJ8+nY0bN/Y5/3vvvUdWVhZ+fn6MGzeOL7/80mf6hx9+yLnnnktkZCSKorB9+/bjuPcnTpK7J3yZ/DIUQgghhDih5HpVDDaT3EH47SWNrNhXjcXuIincnzEJWonH+SOi+csV4zHoFD7fWcF1L63nb0vzALh+egqRQWbvumZnaA+lthxswOpw0puc8s4HPesK6gb8mIQQQghx9OR6VQhxNH5+QRaLH5pHqL/xuKx/RGwwr98xnXFJPZeY91AUhZ9fkMUPzkg/7Dpnpkfyr5umEBvi16998AThNxXWs+VgA9Bztv19CzIYFhlAVbOVp5bs7zY9zx2En+XOwM+ravX2mT/Ul7u0bPoLxsZ5P/Nkwh9ajr68sYNff7ybPeVN/ToegL3ufvSKu7jAwaMIwquqyop9nQOxd5f1f/tCiP47qUH4d955h4cffpjf/OY3bN26lezsbM477zyqq6t7nH/t2rVcd9113HHHHWzbto2FCxeycOFCdu/e7Z2nra2NOXPm8MQTT5yowzghEsOlHL0QQgghxIkm16tiMMqKD8bPqKOpw86LKwsAOG9MHIrSWeLxqinJvH7HdEL9jWwrbmRHSSMmvY6756X5rCs9OoioIBNWh4sdJb0/eMnpkm2xPl+C8EIIIcRgIderQgjRu9EJIQT7aX3hP9leDsCElLBu8/kZ9Ty+cCwAr60rYqc7a94jr0oLwp+ZFYO/UY/V4eoxA73V6vBWKrtgXLz3c09P+MpmC03tnZn2/1xxgNfXH+Taf61ny8HDVxxTVZW9ldq92dRhWqn9orojjxkdqG716XG/8wQE4VVV5dt91TS02Y77toQYLE5qEP7pp5/mrrvu4rbbbmP06NG8+OKLBAQE8Morr/Q4/zPPPMP555/PT37yE0aNGsVjjz3GpEmTeO6557zz3HTTTTz66KOcffbZJ+owTohEd0/4ZouD5h7KoQghhBBCiIEn16tiMDLqdYxPDANgR0kjAOd3ybLwmJkeyUf3zmK4u8fj1VOTumWMKIriLT+5vpcMd5vDxYHqzoyNXWVNck8ihBBCDBJyvSqEEL3T6xSmu/vCt1gcAEzope/83MxoLs1OwKXCXxfv85nmuR8aGRvMiNggAHIrupeW/za3GpvDRWpkgDf7HSDYz+iN8exz94VXVZVvc7WAfYvVwU3/2ci6wwx4Lm+y0GJxYNApnDlKK3V/NJnwnix4d3X9E5IJ/+qaIm57dROPfZ5z3LclxGBx0oLwNpuNLVu2+FzM6XQ6zj77bNatW9fjMuvWret28Xfeeef1On9/Wa1WmpubfV6DTaDZQIS7H4qUpBdCCCGEOP7kelUMZhO7ZG9EBZm8JeoPlRYdxMf3zeZfN03m0YvH9DjPTE+fxF4e+ORVt2B3qgT7GUiNDMClauUchRBCCHFyyfWqEEIc3owuPe8jAk0kR/j3Ou9D54wAtHsjT294i91Jcb2WbZ4RE8RIb2n57r/nvt7tLkU/Lt6nUhnQbbn9VVo2utmgY05GFO02J7e+upGV+2vojacffEZMEJkx2mCAotojz4RfsV+rlnLZhERAG2itqj2X1x8IFruTf67IB6S9mTi9nLQgfG1tLU6nk9jYWJ/PY2Njqays7HGZysrKI5q/v/70pz8RGhrqfSUnJx/T+o4Xz0ipUgnCCyGEEEIcd3K9KgazrkH4c0bHodcpvc4b6m/kvDFxmAw93/55HkptLW7AYu/eF97TD350fAgz0/sO2AshhBDixJHrVSGEOLyuQfjspNBuwfGuhkcFMjwqEIdLZc0B7Z6nsLYNlwohfgaig81kxYUAkHtIf/cOm5PluVpw+4IeKpV5g/DuTHjPvDPTI3n5limcmRWD1eHivje30mHrfl/WdZtZccEMi9Qqnh2sazuiAHqb1cGmwgYAvj8/DaNeobHdflzjTm9vLKa21QpARZOF6hbLcduWEIPJSS1HP1g88sgjNDU1eV8lJSUne5d6lCR94YUQQgghTkunyvWqOHEmdsl8P29MbB9zHl56dCBRQWZ3X/jGbtM9/eBHJ4R4H2B1zV5wuVQ+3FrKrtLjX8JQCCGEEIOTXK8KIQarUfFaX3iA7OSww84/f0Q0ACv2aUHyvGqtH3xmbDCKonjLzHuC6R7f7a+hw+4kMcyfcYmh3dY7MtaTCa8t9607CH9mVgx+Rj0v3jiZyEATLVZHt3V77HXfm2XFh5Ac4Y+iQJvNSW1r//usr82vw+Z0kRIRwMjYYO/ggL5K0jd12L37faSsDicvflcAgGf8w84SuXcUp4eTFoSPiopCr9dTVVXl83lVVRVxcd1HCQHExcUd0fz9ZTabCQkJ8XkNRp4gvJSjF0IIIYQ4/uR6VQxmsSF+XD0liTOzYpiVHnVM61IUhRlpWp/E9QXdy8x7MuHHJIR6S9fnVDTT2K496Fm0sZiH393BfYu2HnZbzZajf3gjhBBCCF9yvSqEEIen1ylckp2AQadw9qjDD2BekKX1Wl+xrwZVVTngDsJnRGvl3z1B6+L6dtqsDu9yX+2uALQs+J6y7T3L5Va20NhuY0uxlo2+YKS2PZNBx+gEd5Z9Rc8tPbxB+LhgzAY9CaFazOhI+sJ/6x5ccMbIaBRF8Q4Y2NlHEP7H7+7gvL+vZMmeI6+a8t7mUiqbLcSH+nFpdoK2rdLGI16PEKeikxaEN5lMTJ48mWXLlnk/c7lcLFu2jJkzZ/a4zMyZM33mB/jmm296nX+okXL0QgghhBAnjlyvisHuL1dm88qtU3stM38kOjPca30+V1W1MxM+PoSYED/SowNRVdhQWE95Ywd//ioX0B5CeUoM9kRVVe7832bO+/tK3lh/8Jj3WQghhDjdyfWqEEL0z+8uHcOWX53D2B4y1A81fXgEfkYdlc0WcitbOFCtDSLOjNWC8JFBZqKCzKgq7HdnrFsdTpbtdZeiHxff43rTo4Mw6BRaLA7e3VyC06WSGRNEckSAd55R8VoQfm8PQXiL3UlhbZvPfKlR2rJFdf2rnqyqKt/t03rOnzFSy/j3/Ex6y4R3OF2sOaDdJ/7hy73YHK5+bQvA5nDxgrsX/D3z05kyTKvotl2qqInTxEktR//www/z0ksv8b///Y+9e/fygx/8gLa2Nm677TYAbr75Zh555BHv/A888ABff/01Tz31FLm5ufz2t79l8+bN3H///d556uvr2b59Ozk5OQDs27eP7du3H3Nfo8EgKVz7hVraKOXohRBCCCFOBLleFacLT6/3rcWNPn3hSxs6aLE4MOoVMmKCfOZdl1/Hrz7eTWuX7I++ShhuKKxnY6GWaf+bT/ewcn/NgB+HEEIIcbqR61UhhDg8o15HaICxX/P6GfXeamPf7qsmr0rLhE933w8BnSXp3VW+vtxVQavVQWyImYm9lLw3GXQMj9L6uP9ndSGglaLvyrPevT1UD8urasWlQniAkZhgM4BPX/j+OFDdSlljByaDjplp2jF6MuF3lTX12Fv+QE0rHe57xIN17by2rqhf2wL4aFspZY0dRAebuWZqMuOTwgAtE/5I+tgLcao6qUH4a665hieffJJHH32UCRMmsH37dr7++mtiY7WSIMXFxVRUVHjnnzVrFosWLeLf//432dnZvP/++3z88ceMHTvWO8+nn37KxIkTueiiiwC49tprmThxIi+++OKJPbjjIClCytELIYQQQpxIcr0qThdpUYFEB5uxOVxs79IX3pMFnxkT7M249zyseWdTCctzqzHpdUxwP2jqKwj/4ndaBkSovxGnS+W+N7eS10uvQyGEEEL0j1yvCiHEwFvgzhJfmlNFkTvAndlDED63soWc8mZ++dFuAK6ekoxO170UvYenJH1Vs1ZBbEG3IHxnOfpDg9R7K5u983jK3adGds+EX7m/huv+vZ7iHrLjV7iz4KcPj8DfpPfuk1Gv0Nhu77EK8w73/aGfUbsf/MfyA97WZH1RVdXbC/7789LwM+rJiu/cVkm9xLnE0Gc42Ttw//33+4y07GrFihXdPrvqqqu46qqrel3frbfeyq233jpAeze4eMrRN7TbabU6CDKf9NMnhBBCCDHkyfWqOB1ofeEj+WxHOesL6rzl6T394D29CQFv/3hPNsSPzsrAbNCzvaSRXb0E4XPKm1mxrwadAh/8YCa/+HA3G4vque2/m/j4vtlEBZmP5+EJIYQQQ5pcrwohxMA6Y2QMsIetxY0ABJg6+69DZzB9Q2E9S/ZU0m5zMjsjkh+dldnnerPigvl8pzYwKtjPwGR3eXaPjBitZH2zxUF5k8UbEwLIrdAGMHtK0UP3THhVVfntZ3soqGnjtXVF/Ori0T7rX5nnKUXfGfw3G/SMjAtmd1kzu8uafMrjA+xwl46/acYwVuXVklvZwrPLDvDoJb7rPtT6gnoKa9sIMhu4blqKd1uj4kPYWdrEjtJGUiID+lyHEKe6k5oJL45MsJ+RUH+tZIpkwwshhBBCCCEGkie4vi6/zvtZ137wHpFBZkbGag+dsuKC+f789C59BLv3LoTOLPgLx8WTERPMv26aTGpkAKUNHTzy4a6BPxghhBBCCCGEOErJEQGkRwd636dHB/lkuHsy1vdWNFPeZCEtKpB/Xj8Zo77vkNsI930UwLzM6G7zmww6bxuw3EP6wud6MuHjO9eR6g7CF9a2oaoqGwvrKajRAvLrC+t8lrc6nGwq0tqDzc2M8pnmKUm/s4dB1Z5M+Ikp4fzyolEAvLauyNufvjfvbi4B4JLseAK7JJRmdylJf6gWi51XVhdy5lMrWPj8Gp9WaUKciiQIf4pJCneXpJe+8EIIIYQQQogB5Ol7uLGonmV7q4CeM+EB7p6Xxuj4EP52zQSMeh1jErXpZY0d1Lf5liYsrmvn853lANwzPx2A8EAT/7ppCgBL91ZR3iiDjIUQQgghhBCDx4Iu2eJdS9EDZMYG4YnJh/ob+c+tU/vVc94TvIfupeg9PJnue7sE4VVV9b4f1WUdKe6s9RaLg8Z2O29tLPZO21PeTFO73ft+e3EjFruLqCBTt+PpHFTtG4S32J3kuvvTZyeHMTczmjNGRuNwqTy5ZF+vx9nUYefLXVrG/zVTU3ymjU/StrWjpHNbHTYnj32ew8w/Lef3n+dQUNPWZ6U1IU4VEoQ/xXjKj/TUm0MIIYQQQgghjtbwqEBumJ6CqsIDb29nc1E9Ze7geNeShwBXTE7iywfmej8P8TMyPErLwjj0QclLqwpwqVq2hefhDmglHKcPj0BV4YMtpQN+PKqq8szSPH776R6cLvXwCwghhBBCCCGEW9cgeUasb9Daz6hnamoEZoOOF26c5L0XOpykcH+SI/wJ9jN4+84fytNvfq87+A1apntDux2DTiGzy774m/TEhfgBsL2kkS93VwIQbDagqtoAa4+17opnM9OjvD3lPTyZ8LvKmnx60e8pb8bpUokKMpMQqm3nJ+eNBGDx7krqWq09HsOn28uwOlyMjA0mOynUZ1p2chgAu8ubvPdpj32Rw39WF9JqdZARE+StQrCzVILw4tQmQfhTTFK4NrJJytELIYQQQgghBtpvLhnDtOERtFod3PLKRkB7UORpi9WXnrInalut3jKEPzgjvdsyV09JBuC9LaW4BjhQ/tbGEv62dD//XVvEV7srBnTdQgghhBBCiKFtSmo4ASY9ABnRQd2m/+/2aaz9+ZneimL9odMpfHDPLL56YC6RQeYe58lyD3TuWo7ek1U+KyMKP6PeZ/5h7r7qf1u6H5vDxZiEEC6ZkAD4thrzfD8rPbLbNkfGBWPUKzS2230SQD2l6LOTQr2B+zEJoYxLDMXhUvlke3mPx/CO+x7wmqnJ3QL+6dFBBJj0tNucHKhuZVdpkzeD/x/XTeSbh+Zx2YREAHb1ULJeiFOJBOFPMZ5y9JIJL4QQQgghhBhoJoOOF26YRGKYP202rf/e6EOy4Hszzl2SfleXbIX3NpdidbgYnxTKzLTuD3suGBdHkNlAcX07Gwrru03vTdfsjJ7klDfz28/2eN8/t/zAgAf5hRBCCCGEEEOX2aDn5xdkccHYOOaN6J617mfU9xpI70tMiJ832bIno9w93wtr27w90b/YpWW4XzQurtv8nr7wnqzx66eneO+91hVogfd2m4NtJQ1Az0F4s0HPSHcG/vqCzsD9DncQ3JO97nHVlCRAG0x9qN1lTewua8ak13H5xMRu0/U6xTuAe0dJI49+uhtVhYUTErgkOwFFUXwy8wdKSX071S2WAVufEP0hQfhTTKI3CC894YUQQgghhBADLzLIzMu3TPFmfRzaD743Yw95UKKqKu9s0jIabpie0i0DAiDAZOCSbC1Lw5MxfzhrDtSS/bslvLyqoMfprVYH9y/ais3hYk5GFIEmPbmVLSzLre7X+oUQQgghhBAC4OaZqbxw4+Ru2efHU3SQmchAEy4V9le1UFjbxt6KZvQ6hXNHdw/CD4vqDOgHmPRcmp3ADHcQPreymcZ2G5uLGrA7VRLD/L195A91/hht3a+sKfIOevYE9g8Nwl+anYBJr2NvRXO3PvKe+7pzx8QSHmjqcVueEvV/X7qfbcWNBJr0PHLhKO90z71lQW0bLRZ7j+s4ElXNFi54ZhVznviWN9YfPOygbiEGigThTzFp7t4i+6pa6HBnpgghhBBCCCHEQBoVH8LLN0/h4vHxXDs1pV/LeB6UlDV20NBmY11BHUV17QSa9Fw8PqHX5a52Z1F8uauC5sM8YGm1OvjJeztotjh4Z1P3oL2qqvziw10U1LYRH+rHP66byE0zUwF47tsD8rBFCCGEEEIIMagpisIodzWyvRXNnaXo0yN7DGp7MuFBC44H+xmJDjaTEROEqsL6gvou/eAjexwcDXDD9GH4G/XsrWhm9YFaGtttFNa2ATA+0beve1iAiXNGxwLwfpdseIvdycfbygCtFH1vPEH98iYtM/2BszOJdfe2B4gO1nrQq6rWl76rT3eUewd799fH28potTqwOVz86uPd3P/WtgEJ7gtxOBKEP8VkxASRGOaPxe7iu/01J3t3hBBCCCGEEEPUrIwonrt+EnGhfoefGQjxM5Lq7ke4q6yJtzdqQfLLJiYSaDb0utyE5DAyY4KwOlx8tqPnnoIef/061/ugJq+6lYY2m8/0xXuq+HRHOXqdwnPXTyQ80MSdc4fjZ9Sxo6SR1Qdq+3UsQgghhBBCCHGyZLlLw++taOGLnVoQ/qJx8T3O6+kJD1opeg9PSfr1BXWsy9fug3oqRe8RHmjyBs7/vbLAmwU/LDKgx+D/le7B1J9sL8PmcOFyqTz2eQ7NFgeJYf7MTo/qdVvZSWHe7zNigrht9vBu84xzZ8t3zbSvbrbwwNvb+NkHu3zK5h/OR+6BAfNGRGPQKXyxs4KL/7Gag3Vt/V6HEEdDgvCnGEVROH+sVhZkyZ7Kk7w3QgghhBBCCNFpjDtDYvWBWr7erd2vXHeYTHpFUbwPe97ZVILD6epxvs1F9by2/iAAwX5aUH/zwQafeb7arT2gunVWKpOHRQAQFWT2ZvP/Y/mBIz4mIYQQQgghhDiRPJnwS/dWkeMpRT+meyl6gJGxwZyZFcPVU5K8vdQBb0n6ZblV3pZhM/sIwgPcMWc4OgVW5dXytjvbvGvAvKt5mdHEhphpaLezdG8Vv/5kN29uKEZR4JELs9Dpes64B0gK9ycxTGu9/NtLxmDUdw9Veo7FMxgAYPGeSjzFzf7ydW6/Kp3llDeTW9mCSa/jH9dO5N17ZpIY5s/Bunb+770duFxSLU0cPxKEPwWd5/5lu3RvFfZeHlAJIYQQQgghxInmeVDy3zVF2JwuxiSEeDMY+rJwYiIGncLO0iZG/OorZvxxGZf/cw1/+CKHjYX1dNic/OyDnagqXDU5iYvHa1kgm4vqvetwuVRW52kZHue6SyN6fH9+Gka9wsbCejYW1iOEEEIIIYQQg1VWvJYJX9rQAWgZ7BG99Fc36HW8cutU/nJltk+p+Rlp2qDkkvoOXKrW6jg+1L/P7SZHBHChO+P+y13aoOrxvdzP6XUKl0/UsuF/+v5ObwD+ySuz+2xHBtpA7P/dPo137p7BnMyeM+bHuYP/u7pkwn+1uzMxdWtxI0v3Vvss893+Gtbl+2bIf7RNK5d/1qgYQgOMTEoJ5917ZhJo0rOpqIE3Nhz0mb+u1crXuytwHofgvNOlsmRPJQ+/u51VeVLp+nQgQfhT0ORh4UQFmWi2OI6o5IYQQgghhBBCHE+eILzNPVj42mn96ycfFWTmzrlpGHQKLhUqmy1sK27kpVWFXP2vdUx8bAn5NW1EB5v51UWjmZqqPVDa2CUIn1PRTF2bjUCTnokp4T7rjw/158rJWrb9Xxf3L2NCCCGEEEIIIU6GjJggDF0yyS/spRR9XyKDzIyMDfa+P1wWvMf356X7vJ/g7t/ek6vcJelbrQ4UBZ66KpsrJif1azsZMUFMT+t9nzz3loW1bTRb7NS32djgHlDtGZT95OJ93mD5i9/lc8srG7n+5fWsdZffd7pUPtmutTy7fGKid92JYf787IIsAJ74KpfShnYA9lY0c9Gzq7nnja28s6mkX8fRH00ddl5Ykc+8v3zL3a9v4cOtZTzy4S7Jwj8NSBD+FKTXKZzjzuz4ereUpBdCCCGEEEIMDmMTOrMk/I16LpvQdwZEVz+/IIv9j1/Axl+cxSf3zeaZayfwvYmJhPobsdi1oP7vLx1DaIDRG4TfXdZEh80J4O33PiMtEpOh+63uj87KwM+oY1NRgzerQwghhBBCCCEGG7NBT3p0EKDFg87rpRT94Xiy4QFm9dGjvatxSaHefvJ6ncKYhN4rm6VHBzE3Mwq9TuHpq7P53qT+BeD7IyLQRFK4lrm/u6yJpTlVOF0qo+ND+MPCcYT4GdhX1cIn28t4YUU+f/4qFwBVhQff3k5dq5U1B2qpbrESHmDkjJExPuu/cfowpgwLp83m5Jcf7WZ1Xi1Xv7iOymYLAJ/tKB+Q42i1OrjqxbU88XUuZY0dhAcY8TPqKG3oYEtxw+FXIE5pEoQ/RXl+6S7JqZLRMkIIIYQQQohBITTASEpEAAAXjY8nxM94RMvrdAoxIX5kJ4dx2YREnr5mApt/dTaL7prO63dM4wJ3BkhSuD9xIX7YnSrbSxoBvOX85vZSzjA+1N+b1fGnr/ZisTuP5hCFEEIIIYQQ4rjzlKSfmdZ7KfrD6Zr93jUgfzj3LtDumyanhONv0vc570s3T2HdI2d6S9MPJE8p/F2lTXy9RxtIff7YOEIDjNxzhraPj36yhye+1gLw9y/IICMmiOoWKz9+bwcfbNVK0V+SndBtoLZOp/DEleMxGXR8t7+Gm17ZQIvVQbZ7mxsK66httfZ7X5ftreLhd7dTWNvm/czlUnnone3sr2olOtjMX68cz7pHzuISd7n+j7aVHc2P5YjYHC6W7a2S+9+TRILwp6hZ6VEEmw3UtFjZViKjZYQQQgghhBCDw9VTkogKMnPX3LQBWZ9Rr2NWehRzM6O9nymKwpRUreT8piKtZ/ymQu2+aO6I6B7XA1pv+LgQP0obOnhlTaH38+W5VXz/9c088uFO/rO6kO/219DUbh+Q/T9eVFXlq10VVDR1nOxdEUIIIYQQQgywa6YkkxoZ4A2IH405mdGMSQjhe5MSiQwy93u5uZnRfHLfbJ6/YdJh5/Uz6okJ9jvqfezLWHdJ+nUFdazO0yqfXTBWS1C9bdZwYoLNtFodADx8zgj+77yRPHf9REwGHSv21fRYir6r9OggHjgrE9Ay6C/JTuDde2YyPikUlwqL9/SvgprV4eQn7+/kw61lXPbcar7brw0Qf3Z5Ht/kVGHS63jp5ilcNSUZP6Oehe79+WJnBVbHsQfHVVWlqLatx7ZrP/9wJ3f8bzOPfZ5zzNsRR06C8Kcok0HHmaO08hlSkl4IIYQQQggxWNx/Ziabf3U2I+OCDz/zMZg2XMvk2FRUz4bCOmxOFwmhfqRFBfa6TIDJwM8uGAnA88sPsL+qhYfe2c7t/93M4j1VvLWxhMc+z+GWVzYy54nlvLOpeND2j/9iVwU/eHMrP31/58neFSGEEEIIIcQAm5URxYqfLOh3GfmeBJkNfPGjuTx99YQjXjY7OYzo4P4H7o+H8YlhAKzYV4PN6SItOpCMGK1Mv79Jz+8uHUNkoImfX5DFj9zB9Ky4EB69eLR3HcOjAvvsa3/3vDTumZ/Ory8ezTPXTMBs0HPBWK0C21f9bGP29e5K6ttsADRbHNz26kb+770d/H1pHgB/uHyszz7MSIskNsRMU4edFftqelxnQU0rt726kSteWNvnAHGH08X/vbeTM55cwQ/e2IqzS+Xsr3dX8uFWLdv+3c0llDX6DuDeWdrI91/fzIHq1n4dpzhyEoQ/hXlK0i/eUzVoHwwJIYQQQgghxPHg6Qu/9WCD98HF3MxoFEXpc7nLshPJTg6jzebkvL+v5KNtZegUuHVWKj88M4MLxsaRHOFPi9XBzz7YxU3/2UhJffsx7WtDm40bX97AU0v2HdN6ulqypwqA9QV1dNiktKAQQgghhBBiaBmX6NuP/oKxcT73exeMi2fzr87mnvm+1QJumJ7CRe5WZtdOTe7zHtGo1/HzC7K4Y85wdDptvgvHabG3dQV13uC6R0+xuDc3FANw7xnpXDMlGZcK72/RSuHfOiuVq6Yk+8yv1ylcNkHLhv/4kJL0NoeL55bncf4zq/h2Xw1bDjbw71X5Pe673enigXe2e8vuf72nkse/0DLea1ut/PKjXQD4G/XYnSovruhcT7vNwX2LtrJ4TxV/+nJvt3Vb7E5W5dVIO+xjZDjZOyCO3vwR0ZgNOorr28mpaGZMQujhFxJCCCGEEEKIIWBEbDDBfgZaLA7e21wCwNwRh88S0ekUHr14FFe8sA5VhcyYIP5y5XgmpoR753G6VF5ZXciTS/ax+kAtZz39HdFBZkwGHUa9QmyIH9lJYYxLCmViSthhyy8++ukeVh+oZU1+LVdNTiYlMuCYjt3pUlmZpw08sDtVNh+s9ynXL4QQQgghhBCnutAAI8MiAzhYpw2KPn9MfLd5egqwK4rCM9dO4JZZqUweFt5t+uEMiwxkTEIIe8qb+SankmumpqCqKn/6KpfPdpTz7HUTvYPCD1S3sLGwHr1O4eaZqcSGmBmdEMIfvtjLrIxIfnnRqB63sXBCIv9eWcCyvdU0ddgJ9TeSW9nMA29tZ19VCwCj4kPYW9HMq2uKuG32cKK6tBSw2J3cv2grS/dWY9Qr3DhjGK+uKeLVNUUkhvmzqaieujYbWXHB/OLCUdz8ykbe2VTCfQsyiAv142/f7KekXsuMX76vmqLaNlK7VJX7+Qc7+Xh7OQ+fM8JbZUAcOcmEP4UFmg2cmaWVpH9pZcFJ3hshhBBCCCGEOHH0OoUp7gcqbTYnigKz+1mqcfKwCP52TTaPXjyaz380xycA71n3XfPS+PrBeUxLjcDmcFHW2EFhbRv7q1pZlVfLc98e4Puvb2HWn5bz2Y7yXrf1+c5y73RVhdfWFR3dAXexvaSRxi4lCdfm1x3zOoUQQgghhBBisPH0hU8M82dsYki/lzPodUwbHoFe13eltN5c6M6k/9Jdkv7VNUX8e2UBFU0WfvTWNm+J+EUbtAHhZ2bFEBfqh6Io3DIrle2/OYdXb52KUd9zGHZUfDAjY4OxOV18tauCj7eVcfnza9lX1UJEoIm/XzOBL380h/FJobTbnD5Z7FaHk7tf38LSvdWYDTr+ffMUfnPJGH5xYRYAj3+xl8V7qjDoFJ66Opt5I6KZNjwCm9PFi9/ls7O0kf+sLgQgKdzffZ960Lv+nPJmPt6u3cO+tLKgz3L4om8ShD/F3bcgA4BPdpSz3z06RgghhBBCCCFOB1Pc2QeglSoMDzT1e9nLJyZx+5zhmA36XucZHhXI23fP4JuH5vHxfbN5756ZvHnndB5fOJZrpiSTEROEw6Xyi492Udlk6bZ8dYuFX3+8G4DZGZEAvLO5hDaro9/72ZMV+6oBrccjSBBeCCGEEEIIMTQtGKklol49pe+y8gPtgrFaSfo1B2r5dEe5t8x7sNlARZOFX3y0C4vdyftbtCD8DdNTfJYPMBn63F9FUbhsYgIAf/xyLw++s50Ou5O5mVF889A8Fk5MRFEUHj5nBACvrz9IVbMFh9PFA29tZ+X+GgJMev572zTvz+iuuWncPHOYdxsPnJXpraD9oDubfdHGYn787g5cKlySncDjC8cC8N7mElrd96lPf9PZRq3F6uA/q32TgCubLLy7uQSLvXtbtHabg42F9didrt5/uKcRCcKf4sYmhnLB2DhUFZ5esv9k744QQgghhBBCnDDThncG4edm9i8L/kjpdAqZscFMSA5jamoEszOiuHHGMJ64cjxfPzCX7KRQWiwOHvlwp09/QFVV+cWHu2lotzMmIYRXbp1KWlQgLRYHH7p79h2tb91B+HvmpwGwq7SRZotkJwghhBBCCCGGlismJbL04Xn88MyME7rdtOggsuKCcbhUfvTWNlwqXDU5iTfunI5Bp/DFrgp+8MYWmi0OksL9mXcU7cE8feGbLVrw+4dnZvDf26YR2aXs/PwR0UwZFo7V4eIfy/P4+Ye7+HpPJSaDjpdvnsLM9EjvvIqi8JtLxnDP/HRumTmMH5yR7p02Mz2SKcPCsTlc5FW3EhZg5DeXjGZeZrR2n2rV7lO3FjewdG81OgV+ev5IAF5ZU0Rjuw3QBppf8cJafvr+Tn750W6f47E7Xdz48gau/tc6zvjrCl5aWXDa36dKEH4IeOicESgKfL2nkl2lTSd7d4QQQgghhBDihBifFIrJoN3Wzsk48T3RDXodT16Vjcmg49t9Nby3RQuuW+xO/vbNfpburcKk1/HU1dmYDXpumZUKwH/XFuFyqX2sWVPdbOHhd7fzxc6Kzs9aLOwuawbgmqkppEUF4lJhY0H9wB+gEEIIIYQQQpxEiqKQEROM7ijLyh8LT0l6gCnDwnn88rFkJ4fxkDs7/dt9NQBcNy3lqPYvMcyfyycmEhVk4j+3TOHH547sVj5fURR+fK4WDH9jfTHvbylFr1N47rqJzMroPhBdr1P4+QVZ/O6ysRi6lMJXFMWnt/uvLhpNVJAZnU7xuU99aomWBX/FpCTumZfOqPgQWq0OXlpVQIfNyZ3/20xZo9ZL/oOtpT73qk9/s5+txY0AlDV28Icv9zLrT8v5x7I8nP24//UorG3jkQ938m1udb+XGawkCD8EjIgNZqF7xMxTXcpECCGEEEIIIcRQZjbo+dPl4/jhmRlM75IVfyJlxgbzY/dDmMc+y+E/qwtZ8OQKnl1+ANAGTWfFab0Lr5icRJDZQH5NG6sO1Pa53qYOOze/spEPt5bx4DvbyHO3H/vO/aBnXGIo0cFmb+aDlKQXQgghhBBCiIFzaXYCJr2OpHB/XrxpsreV2T3z05mRpt1/GnQKV01JOupt/O2aCWz8xdmcNSq213lmpkcyq0vG+1+vHM+5Y+KOeFtzM6O4f0EG9y1I54pJid7PPfepBTVtrDlQh1GvBex1OoUHz9YC96+uKeLeN7ews7SJ8AAjV7uP+Rcf7aKiqYPVebW8+J3Wt/7v10zgiSvGkRkTRKvVwVPf7Oe2/26ioc3W5/65XCqvrinkgmdW8tbGEr7/xhZ2ljb6zLPmQC2z/7yckb/6inG/XcyUx79h4fNrWHuY++uTRYLwQ8QDZ2Wi1yms2FfD5iLJgBBCCCGEEEKcHq6YnMSPzx15UjIjPO6cm8bElDBarA4e+zyHiiYLCaF+/PXK8d6S8aD1cPc8oPnvmsJe12exO7nzf5vIrdQC73anys8+2InTpbJivxaEXzBSy/yfla5lP6zNH5wPHYQQQgghhBDiVJQaFciyH8/nywfmEtWlRLxep/C3ayYwKSWM+xZkEBPsd0zb6c+97KOXjGZMQghPXDGO7006uqC/oij833kj+cl5WT796rvepwJcOzWF5IgAAM4dHcuYhBDabU6+3VeDyaDjpZun8IfLxzE+KZSmDjsPvLWdh97djqrC9dNTWDgxkWumprDkoXk8eVU2fkYdK/fXcPE/VrO9pNEnK95id1JQ08p3+2u4/uX1/O6zHCx2F2EBRmwOFz94Yyv17uD9loMN3PWalolvdbhosTiobbWxvaSR61/ewA/f2kZVs+WofjbHi6J2bVonAGhubiY0NJSmpiZCQkJO9u702yMf7uStjSUYdAoZMUGMTQxlTkYUl01I8PkPJYQQQojT16l6nSN8yXkUYvDJr2nl8ufXoNcp3LcggxtnDMPPqO82X1FtGwueWoGqwut3TGPuIb0DHU4X97yxhaV7qwn2M/DstRP54VvbaLU6+NVFo3hmWZ7WV/7eWUxKCaeu1crkx5cCsOVXZ/v0DwStN/1zyw9QVNfOH7831pu9cbJ4HkHIPaoQojdynTM0yHkUQgghTh1FtW2c/fR3GPU6VvzkDGJDOgcWfJNTxV2vbQbg2esmcml2AgAFNa1c9OxqOuxOAEbEBvHp/XO63QfvrWjmnje2cLCu3fuZSa/DbNDRYnX4zOtv1PPIhVlcNiGRhc+vobC2jTkZUfz8giyuf2k9zRYHczOj+MPCcThcLix2F29vKuaN9QdxqRBo0vPQOSO4Y87w43rP2d/rHAnC9+BUvUisbLJw8ysb2F/V6vP5by8Zza2zh5+kvRJCCCHEYHKqXucIX3IehRicWix2TAbdYQPdP3hjC1/trgTghukp/PyCLPyMepbsqeKVNYVsOdiA2aDj9TumM214BK+vK+LXn+xBp4BLhfAAI5t/dY63X+D5f19JbmULz18/iYvGx/ts61/f5fOnr3IBeOKKcVwzNeU4HHn/1LZauey5NSSG+7Pozuk+PQqFEMJDrnOGBjmPQgghxKllW3EDfkY9o+J9/26rqsr/1hYRGWTmEncA3uON9Qf51ce7MRt0fPbDOYyIDe5x3U0ddn7+wU7vfXBXASY9SeH+jIwL4cfnjCA1KhCAfZUtXP7PNbTbnBh0Cg6XypRh4bx2xzQCTAafdewua+LXn+xmW3Ej54yO5aWbpxzLj+Kw+nudY+h1ijjlxIX6sfjBeZQ3WdhT1sTy3Gre3lTCU9/s5+LsBJ9yGUIIIYQQQgghBlawn7Ff8/31qmwig0y8sb6YNzcUszy3GqdLpbrFCmhZAc9dP4lp7j73N0wfxifby9l8sAGAeSOivQF40HoE5la2sDa/1icI//XuCv78da73/curCrl6SvJJy0L/2zf7KWvsoKyxg7c2FnPTzNSTsh9CCCGEEEIIIXxNTAnv8XNFUXpN9L1hegoBJj3JEQG9BuABQv2NvHDjZCx2J+02Jxa79goPMBEWYOzxHnVkXDB/uXI89y/ahsOlMjo+hP/cOrVbAB5gbGIoH9wzi/e2lHhbtg0GMux8iFEUhcQwf84dE8cfLh/H2MQQWiwO/tLlwYsQQgghhBBCiJMnyGzg8YXjWHTXdFIiAqhoslDdYiUqyMyPzsxgxU/O4JzRsd75dTqFP18xHpM7c/yMkb4l7D0PGdbl13k/21HSyIPvaH35rp6SRJDZQF51q7enfE+K69q5b9FW3lh/ELvT1W26xV1m8Gjsr2rhrY3F3vdPLtlPg7u3nxBCCCGEEEKIU4+iKHxvUhJTUyP6Nb+fUU9EoImEMH/SooMIDzT1OUj84vEJPHbZGC6bkMBrd0wj1L/3ge86ncI1XfrZDwZSjr4HQ6lc0paDDVzxwloAPr5vNhOSw07uDgkhhBDipBpK1zmnMzmPQgwd7TYHizYUExfqx7mj4zAZeh8r/9WuCtYX1PGLi0b5lLxv6rAz8fdLcKkQH+pHqL+RiiYLTR12zhgZzcs3T+HPX+Xy8upCZqVHsuiuGT2u/67XNvNNThUAKREBPHh2JuOTQvlqVyVf7q5kb0UzD56dyYNnj/BZbmtxA+9sLOGeM9IZ7i4deKhbXtnId/trOGd0LCX17eRWtnDjjBQeXzjuSH9kQoghTq5zhgY5j0IIIYQYqvp7nSOZ8EPc5GHhXDEpCYBHP9mNyyVjLoQQQgghhBBisAgwGbhzbhoXj0/oMwAPcMG4eH532dhuPedD/Y2cPUrLnK9ospBb2UJTh52suGCeu34SBr2O2+YMR69TWJtfx57ypm7rPlDdyjc5VSgKRAWZKK5v5+F3d3D20yt56pv97K1oBuDvS/N4dU2hd7l1+XXc8NIG3tlcwv2LtuLoIYN+xb5qvttfg1Gv8MsLR/GbS8YAsGhDcY/7IoQQQgghhBBCnOokCH8a+NkFIwk2G9hZ2sRbm4oPv4AQQgghhBBCiFPKizdOZtVPF/DZ/XN47fZp/POGSbx99wyCzFq/vMQwfy4ap/WLf3lVYbflX1pZAMA5o2JZ+dMF/PT8kYT6GzHqFc4YGc0TV4zjh2dmAPC7z3L4eFsZaw7Uctt/N9LhLlO/p7yZV9b4rtvhdPHHL/cCcMvMVFKjApmZHslF4+NxqfC7T3OQAn1CCCGEEEIIIYaa7t3rxZATE+zHg+eM4LHPc/jtp3uIDjJz7pi4k71bQgghhBBCCCEGiE6nkBwRQHIfrfjumpvGpzvK+WxHOT89fyTxof4AVDVb+GhbGQDfn59OgMnAvWdkcNfcNBxOFX+TlnmvqiotFgf/XVvE/723A71OwepwsWBkNGeOiuXXH+/m6W/2c8HYeJIjAlBVlWeX5bG/qpWwACM/PDPTuy+/vHAUy/ZWsbGong+3lnHF5KR+H6uqqnTYnQSYTp1HGkW1bfxndSG3zxnea8l+IYQQQgghhBBDh2TCnyZunZXKJdkJ2J0q9765la93V5zsXRJCCCGEEEIIcQKNSwplRloEDpfKo5/sweLOYH91TRE2p4upqeFMHhbund+o13kD8ACKovDoxaNZOCEBh0vF6nBx9qgYXrxpMjdOT2FGWgQWu4tffrybpnY7d7++hWeXHwDgx+eMIDTA6F1XQpi/Nyj/+89zqG629OsYvttfw7l/W8mkx75hQ0HdER3/y6sKuOk/G3hnUzEdNucRLXssVFXlZx/s5PX1B7nhpfVUNvXvWAebxXsq+ceyPGlzJ4QQQgghhBD9IEH404Rep/C3q7O5zP2w5L5F2/h0R7mU/RNCCCGEEEKI08iDZ4/AoFP4JqeKq/+1jgPVLby5/iAA35+XftjldTqFv16Vze2zh3PnnOH884bJmA16FEXhj5ePw2TQsXJ/DWc8+S3f5FRh0ut4bOFYbpwxrNu67p6XxtjEEJo67Pzio9193p/mVbVw26sbueWVjeRVt3qD/fYeetD3JL+mlT9+uZdVebX87INdTPvjUn776R7W5tfSZnX0ax1Ha21+HRsK6wEob7Jw66sbaeqwH9dtDrTqFgs/emsbT32zn2W51Sd7d4QQQgghhBBi0FNUicJ209zcTGhoKE1NTYSEhJzs3RlQTpfKT97bwYfuUoORgSYmpoQxMSWca6cmExlkPsl7KIQQQojjaShf55xO5DwKIY7Fuvw67n1zCw3tdgw6BYdLJSMmiCUPzkOnU45p3c8tz+PJJfsBSI7w55/XT2ZcUmiv8++taObS51Zjd6o8c+0ELpuQCEC7zcGqvFrWHKhl9YFaCmraADDoFG6cMYzPdpRT12bjFxdmcXc/Bg/cv2grn++sICsumHabk+L6du80nQJZcSHMzojk7nnpRAf73hdb7E62lzSyvaSRbcUNFNS0MXlYOFdNSWZSShiK0vvPTFVVrnxxHVsONnDRuHg2FtVT02JlRloE/7t9GmaDvtdlB5M/frmXf68sAOCi8fE8f/2kk7xHYiiT65yhQc6jEEIIIYaq/l7nnDoN1MSA0LuzFkL8jSzaUExdm42le6tZureaD7eW8sWP5uJnPDUeAgghhBBCCCGEOHIz0yP55L453PXaZvZVtQBaVvqxBuC19aRTVNeOUa/w8wtGEepv7HP+UfEh/PDMTJ7+Zj+/+XQPIX5GFu+p5POdFbR2yVDXKXDWqFgeuSCLtOggRieE8NP3d/LM0jwuzU4kLtSv123klDfz+U6tJdvTV08gKy6YVQdq+WBLKVsONlDW2EFORTM5Fc0s2lDMvQsyuGPOcMobO3hjfTHvbSmhxeKbLZ9X3crbm0pIjw7kvDFxpEYGkhwRQGpUAPGh/t75vttfw5aDDZgNOn5zyWhqWq1c86/1rC+o5yfv7eSZayf0GcQ/Fi6XOiDntL7NxhvuagkAS3OqaLU6CDLLIyUhhBBCCCGE6I1kwvfgdBmpaXU42VPezLbiRl78Lp+aFiu3zkrlt5eOOdm7JoQQQojj5HS5zhnq5DwKIQZCq9XBH77YS4fNwRNXjj9pWdl2p4vLnltDTkWzz+fJEf4sGBnD7IwoZqRF+gT0XS6VK15cy7biRi7JTuAf100E8Ja07xrYvvN/m1m6t6rXDO7KJgubD9bz75UF7CxtAiAswEhje2fJ+JhgM5OHhTMhOYxhkQF8k1PNl7sq6LB37y1/3phYHrtsLNHBZi57fg07S5u4a+5wfnnRaADWHKjlllc24nCpvHzzFM4eHdvjz8XlUlm0sZg1B2r59cWjSQjz73G+nvz+sxze3lTMG3dOZ1JKeL+X68mTi/fx3LcHGJsYQrvNSUFNG09dlc0Vk5OOab1C9Eauc4YGOY9CCCGEGKr6e50jQfgenI4Xid/tr+GWVzYC8Pod05ibGX2S90gIIYQQx8PpeJ0zFMl5FEIMNTnlzVz54lpUFS4cF8/VU5KYNjyizyzx3WVNXPrcalwq3DgjhZL6DnaVNWF3urhjznDumpvG/qoWLv/nWnQKLHloPhkxQb2uz+VS+WRHGX/5eh8VTRYUBc4cGcONM4cxPzO6W1Z5q9XBlzsr2FHaSHF9O6UNHRysa8OlQoifgUsnJPDG+mICTHpW/nQBUV3av/35q1xe/C6flIgAljw0r1tFugPVLfz8g11sPtgAwBWTknjq6ux+/Szza1o55+nvcKlapYHP7p+NQa/r17KHauqwM+fPy2mxOnjxxsnsq2zhb0v3M29ENK/dPu2o1inE4ch1ztAg51EIIYQQQ5UE4Y/B6XqR+Ognu3lt3UFiQ8wsfnAeYQGmk71LQgghhBhgp+t1zlAj51EIMRQ1ttswGXQEmPpf5txzH9uT6GAzEQEm9lW1HFEQu8PmZH1hHRnRQSRHBPR7X0Drcf+zD3Z6M+oBfnBGOj87P8tnvlargzOfXEF1i5WfnDeS+xZkAOB0qfzz2wP8Y/kBbE4XfkYdFrsLk0HH+kfOIiLQ9z7d6nB2q2Dw4Nvb+Hh7uff97y4dwy2zUo/oODyeXZbH09/sZ2RsMF89MJfi+nbOeHIFOgU2/OJsooPNh1+JEEdIrnOGBjmPQgghhBiq+nudc3RDocWQ9MgFo0iLCqSq2covP96NjM8QQgghhBBCCHGihAWYjigAD/B/543ke5MSuXpKEo8tHMsn983m+esnkRIRQE2LlX1VLRj1Cg+endnvdfqb9CwYGXPEAXjQMs8//MEsfnFhFmaDjuhgM3fPTes2X5DZwCMXaoH555YfoKKpg/o2G7e+upGnvtmPzeliwcholv34DMYlhmJzuHhnU4nPOv7wRQ4Tf/8Nn2wv8352oLqVT3doAfjrpqUA8NSSfdS2WnvcX1VV2V3WRLvN0W1aq9XBK2sKAbjvzAx0OoXUqECyk8NwqfD5zvJuyxzOmgO1PPD2NnaUNPY5n6qqvLupxHssA0VVVXnWIYQQQgghhDghjuzuVgxp/iY9f7tmAt97YS1f7KzAbNDxx8vHdSuLJ4QQQgghhBBCDAYhfkaevnqCz2fZyWGcMzqWN9Yf5PX1B7lqStJRBdSPlkGv4+556VwzNQWXSyU8sOcqcwsnJPL6uoNsLW7kJ+/tpLC2jbLGDvyNeh5fOJbvTUpEURRunjmMn7y/kzfWH+TueWnodQrrC+p4aZUWIP+/93YQHWRmVkYU/1ieh0uFc0bH8vjCsewsbWRPeTN/+TqXv1zpWwmgpL6dX368m5X7axgVH8JH987yuf//y9e5NLbbGR4VyEXj4rvsdwI7Shr5ZHs5t80e3q+fSVO7nce/yOG9LaUArMqr5ZP7Zvd6Xp7/9gBPLtkPgEmvcP7Y+B7nOxKf7Sjn95/nMG14BM9dN7HPVgdCCCGEEEIIcaykHH0PTvdySW9vLOaXH+/G6VKZmBLGv26cTEyIn3d6s8XOsr1VfLWrko1F9TxwVma/b7yFEEIIcXKd7tc5Q4WcRyGEGBp2lTZx6fOr8TyZSY0M4MWbJpMV1/m73WJ3MuNPy2hst/PvmyYzf2Q0Fz6zivyaNsIDjDS02wk2G3jiyvHct2grqgqf/3AOYxND2XKwniteWAfA89dPIj0mED+Dnq/3VPL3pfux2F3e7VwzJZknrhwPwJI9ldz9+hYA/nf7NOaPiPbOV91iYcYfl+FS4bXbp7GvsoVluVWUN1oIMhsI8jMQ4mcgyGwg2M+Iv0nPh1vLqG21oigQHWSmusVKVlwwH947q1v1gw+3lvLwuzu870P8DHz5wFySwo9uIEWb1cFvPt3D++4BAACL7prOrPSoo1rfkdhX2UJSuD+B5v7nwOwoaeRnH+zkx+eO5JzRscdx7wYvuc4ZGuQ8CiGEEGKo6u91jmTCi26unZZCckQA9765lW3FjVz63BpmpUdS22ajtsVKXnULdmfn2I0/fLGXqakRjE0M7XF9qqryt6V5NHfYefjcEYT4GU/UoQghhBBCCCGEEIPWuKRQbp4xjP+tO8jZo2J56upsQv1975n9jHqumZrMv74r4LV1B8mtbCG/po2oIDNfPjCH+9/cxsaieu59cysA546O9d6fTx4WwRWTkvhgayn3Ldrabfsz0yJZODGBn3+4i3c2lzB1eARzMqL46Qc7Abh7XppPAB4gJtiP2RlRrMqr5eZXNvb7WNOjA3niivEkhPlz6XOrya1s4f/e28Hz10/yZqWvOVDLT9/Xtn3nnOFsKW5gW3EjP3prG+98fyZGfWdXRVVVya9pY9neKnIrW8iICWJCchjjk0JxuSC3spl9VS28uqaIwto2dAqMiA0mt7KFZ5bmdQvClza0E+JvHLBnFi+vKuDxL/YSFmDkzjnDuWVWKsH9WPczy/LIrWzh5x/sZNrwM7r9exBCCCGEEEKcGiQTvgcyUlNTVNvGna9t5kB1a7dpmTFBXDA2jj3lzSzLrSYzJojPfjinx9L1nhtPgOFRgbxw4ySfUf1CCCGEOHHkOmdokPMohBBDh6qqHKxrZ1hkQK8l0kvq25n3129RVTDpddicLp69biKXZifQ2G7jihfWkl/TBsCXP5rL6ITOvw21rVbue3MrpQ0dWB1OLHYXIX4GHjpnBFdOTkJRFJ5dlsfT3+zHz6hjRGwwO0ubGJcYygc/mIXJoOu2P1/vruSeN7Zg1CtMHx7JWaNiGJsYSpvVQavVQavFQYvFQYv7+6Rwf26YkYLZoD0z2FxUz3UvrcfuVLk0O4GYYDOtVgdf7KygxergkuwEnrlmAmWNHVz47CpaLA7uPSOda6Yms72kkW3FjXy3v4bC2rZ+/YzjQ/34+zUTSIkMYP5fVmBzunj77hnMSIt0H08F97651Tvg4fbZw0mOCKC21cry3GpW59XSbnOgKAo6BeJD/fn5BVm9tu/bcrCeq/+1Hqer85FbqL+Ru+elccec4b0uV9lkYdaftSoDAHfMGc6vLx7dr2McSuQ6Z2iQ8yiEEEKIoaq/1zkShO+BXCR2arbYeW9zKXani6ggM5FBJlIjAxkeFQhAfZuNc/+2ktpWK3fPS+MXF47yWX7LwXqu+dd6HC6VYD8DLRYHfkYdv790LEkR/hyobuVAdStJ4f7cPDNV+s8LIYQQx5lc5wwNch6FEOL0c+f/NrN0bxUAczOjeO32ad6gfUl9O/cv2sr0tMhu9+X94XKp3PLqRlbl1QIQaNLz+Y/meu/9e1JQ00p0sLlf2d09eXtjMT//cFe3z6cPj+C1O6Z5A/Zf7KzoMYsfwKhXmJkexaSUMA5Ut7K9pJHShg4AEsP8GRkXzLjEUG6bnUpYgAmAX328izfWFzMrPZJFd81gd1kTV724jg6707tevU4hMyaIfVUt9PbU7MfnjOCHZ2V2+7yhzcaFz66iosnCJdkJnD0qhmeW5VHgHiSRFh3IHy8f5x0A0NXz3x7gr4v3EROslew36BS+fnAuGTHBffwkj4yqquwqayIyyEximP+ArXcgyXXO0CDnUQghhBBDlQThj4FcJB6ZpTlV3PnaZhQF3rl7JtOGRwBQ12rlomdXU9ms3Xj+7tIxPPD2Nu9N/aGGR2k3ojPTu9+ICiGEEGJgyHXO0CDnUQghTj+r8mq46T8bMRt0LHloHsMiew+QH42u9/BPXZXNFZOTBnT9PVm0oZjd5U0E+xkINhuICfbj4uz4bn3iH/1kN6+tO4hJr2N0QggTksOYPjyCuSOiCTqk33p9mw2DXum1rHxZYwdn/PVb7E6Vf94wicc+z6GiycLczCjumDOcl1cVsvpA53OLMQkhnJUVQ0KYPy4Viura+PfKAgJMelb85Axigv2887pcKnf8bxPf7qshLSqQT384hyCzAadL5dMdZfzxy1xqWqwAXDMlmV9cNMpbbt7lUlnw1AoO1rXz1yvHs3hPJUv3VncbcNFfpQ3t1LRYiQoyExVkps3m4MOtpby9qYSCmjb8jDoevXgM101LPuJ1H29ynTM0yHkUQgghxFAlQfhjIBeJR+6n7+/g3c2lhAcYmTcimnGJoXy7r5o1B+pIiw7k0/s7bzyfXZbHq2sKCQswkRkTRGpUIJ/tKKfafSN69ZQk7pmfTlp00IDvZ02LlUUbipmQEtatr50QQghxOpDrnKFBzqMQQpx+VFXlg61lJIb5H7fB6w1tNkoa2hmfFHZc1n+0VFWlsLaNxHB/b4b8sfjFR7tYtKHY+z4tOpCP7p3tDYjnlDeTV93CtOERxIf6ZourqsrCf65lR0kj101L5k/fG++d9tzyPJ5csh+zQcfH981mVLzv3+imDjtPfJ3r3fa01AjevGs6Rr2O9QV1XPvv9QSZDWz85VlUN1s5928rsTldPHlVNoEmPRuL6tlf1UJKRABjE0MZlxhKVlxIt5YBW4sbuO7f67E6XD0ev16neEvlnzcmlj9/bzxhAUYa2u1UNllIjvA/6goHA0Guc4YGOY9CCCGEGKokCH8M5CLxyLVY7Fz2/BpveTUPP6OOT+6bw8i4vkunNVvs/OXrXN5Y33kTPCo+hIvHx5OdFIZOB3pFIdBsYFR8CHrdkY3SbrU6eHlVAS+tLKDN5kSnwBNXjOeqKclHtB4hhBDiVCfXOUODnEchhBDi6JU2tLPgyRXYnSqh/kY+vm92n6X3D7W5qJ4rX1yHToGvHpjHiNgg/rH8AE9/sx+AP39vHNdOS+l1+Y2F9dzx3020WB3evu8Pv7OdD7eV+QT2n/g6lxdW5Pe5L8kR/rx08xSy4rTrgbLGDi57bg21rVZC/AxYHC5s7mB8dnIY105N5qLx8byzsYS/LM7F7lS9SROekvyh/kZ+edEorpqcdFKy5OU6Z2iQ8yiEEEKIoUqC8MdALhKPTofNycaienaVNrKztInC2jYePmcEF4yL7/c6NhfV89y3B1idV4vD1fM/zZhgM5dNSOCyCYlEB5vZX9XC/qpWmjvsLJyY6HPjbHe6eHtjMc8sy6O21QZAXIgflc0WAB5fOJYbZww7hqMWQgghTi1ynTM0yHkUQgghjs1fF2uJAP+8YRKzM6KOePkfvLGFr3ZXMjczivToIP67tgiAB87K5MGzMw8bvP56dyX3vLEFgD9ePo7ff74Hi93FR/fOYmJKOABtVgcXPruKg3XtZMUFMzU1gjEJIRysb2d3WRM7ShpptjgIMht47vqJTEmN4MoX1pJb2UJWXDAf/GAWASY9rVYHFruL6GCzzz7sLmviR29v80moCDTpabNpwfiZaZH8/IIsalqs7CxtZEdpE5FBJp6+esIR/7yOhFznDA1yHoUQQggxVEkQ/hjIReLJ19BmY0lOJV/uqqSyyYJTVXG5VGparbRYHL0up1Ng4YRE7jszg70VzTy5eB9Fde0ApEYG8JPzsrhgbBy//zzHe4P8q4tGcefctD73p7bVype7KpiVHkVGzMCXyRdCCCFOFLnOGRrkPAohhBDHTlXVo870PljXxtlPf4fd2flY7beXjObW2cP7vY5DM91HxAax+MF5PvtksTuxOV099rhvarfz/Tc2s76gHp0CI+NC2FvRTFSQmU/un01imH+3ZQ5lsTvZW9FMeICJuFA/9DqFV1YX8rel+7HYu5ezjwoysemXZx/XDHm5zhka5DwKIYQQYqiSIPwxkIvEwcvmcLFiXzUfby9j6d5qHE4XqZGBZMYG0WF3sXJ/TbdlooJMPHBWJtdOS8Go1/qkqarKXxbv897sXpqdwG8vHUNEoMln2bLGDl5aWcDbm4qx2F1EBZn58kdziAnxO/4HK4QQQhwHcp0zNMh5FEIIIU6+xz7P4T+rCzHoFJ68KpuFExOPaHmH08Utr25kzYE6oH9JAoeyOVz84qNdvL+lFACTQcc7d8/wZtMfrZL6dn79yW5W59UyPCqQ8UlhTEgOZXxSGOOTQiUILw5LzqMQQgghhioJwh8DuUg8NVjcvcr8jHrvZztLG3l2WR5L91YTYNJz97w07pqbRqDZ0G15VVX554p8nlqyD5eqBet/f9lYhkcFsuZALWvz61i5v8ZbFt9s0GF1uJg2PIJFd07H4A7oCyGEEKcSuc4ZGuQ8CiGEECdfu83BSysLmZkeybThEUe1jrpWKwv/uYZWi4OlD88nMsh8+IUOoaoq/1pZwKINxfziwizOH9v/toCH43Kp6HQnti+8XOcMDXIehRBCCDFUSRD+GMhF4qmvsLaNMH8j4YdktvdkR0kjP3l/B/urWnucPjsjknvPyCA+1I9Ln1tDq9XB9+el8ciFowCtVP0XOysorG2jrLGDsoYOAKakhjN9eCTT0yKIOoqb6K62HKzH6eKob+qFEEIID7nOGRrkPAohhBBDR7vNgd2pEurfveT86Uiuc4YGOY9CCCGEGKr6e53TPT1YiCFgeFRgv+fNTg7jsx/O4bnlB3hhRT5GvY5pwyOYnRHJvBHRZMV1/gf6y5XjuffNrfxrZQFRQWZyKpr5YmcFNmf3Pmk5Fc28tu4gAOEBRhLD/UkKp95X3wAAKd5JREFUCyAjJoi5mVFMGhbuLY/fl/c2l/DTD3aiqnDdtBQevXg0/ib9YZcTQgghhBBCCCHE4BdgksdzQgghhBBCDDWSCd8DGal5+rLYnegUBZOh9+D445/n8PLqQp/PspPDmJkWSWKYH4nh/ljsLjYW1rO+oI7cypYe1xNkNjArPZJJw8IZkxDCmITQbj3puwbgPTJignj22omMThi4f5uqquJwqf0aFCCEEOLUJtc5Q4OcRyGEEEIMVXKdMzTIeRRCCCHEUCWZ8EIcha795Xvzswuy2FfVwobCei4Zn8DNM4eRnRzWbb4Lx2k92FqtDkob2imt76C0oZ3tJY2szKulvs3GkpwqluRUeZdJjvDnjBExnDEymqpmK7/8eBeqCjfNGMZ5Y+J4+N3tHKhu5bLnV5MWFURsqB9xIWbGJYWxcEICwX79L12nqiq7ypr4anclX++upKyxg6evzubi8Qn9Xkd/WexOPtxaxtTUcDJjgwd8/UIIIYQQQgghhBBCCCGEEEIMFpIJ3wMZqSkOx+VScapHnznucqnsLm9i9YFa9pQ1k1PRTGFtW4/z3jRjGL+/bAyKolDfZuOn7+9g6d7qbvMFmvRcPimRG2cM8ymh35MNBXU88tEuCmp8t2nQKbx08xQWZMUc1XH15mfv7+SdzSX4G/X8/doJnDcmbkDXL4QQov/kOmdokPMohBBCiKFKrnOGBjmPQgghhBiq+nudI0H4HshFojgZWix2NhTUs2J/Nd/m1lDW2MGts1L5zSWjURTFO5+qqhTUtlHa0EFVs4Wyhg6+2FXBgepW7zypkQHMGxHN/BHRTEmNINRfy5C32J38dfE+XllTiKqCv1HPmVkxnD82jm9yqvh0Rzlmg47Xbp/G9LTIPvdXVVX+uSKftfm13DM/nbmZ0T3O98n2Mh54e7v3vaLAz8/P4u55aT7HJYQQ4sSQ65yhQc6jEEIIIYYquc4ZGuQ8CiGEEGKokiD8MZCLRHGyqapKU4edsADT4Wd2z7++oJ7X1xexZE8VDpfvf+uYYDOZsUFUNFoocGfcXzMlmV9ePIoQdwl7u9PFPa9vYVluNUFmA7+5ZDSxIX4E+xmIDfEjIczfuz6708XPPtjJh1vLvJ+dMzqWX180mpTIAO9nRbVtXPTsKtpsTn5wRjqtFgevrz8IwPcmJfLQ2SNIjuic/2i1WOw8/O4O6lqtXJqdwCXZCUQGmXuc1+VSKW3oIDnCXwYBCCFOS3KdMzTIeRRCCCHEUCXXOUODnEchhBBCDFUShD8GcpEoTmUtFjvr8uv4bn8Nq/JqKa5v95keE2zmz1eM48ys2G7LWuxObn11I+sL6rtNmzY8ghtnDGNeZhQ/ens7K/fXoNcpnDcmlsV7qnC6VEx6HRePj2f+yGhmpkVy+/82sbusmWmpESy6azp6ncJ/1xbx2Oc5uFQtK37+iGium5bC8KhA77YiAk1E9RJEP1Szxc7N/9nI9pJG72cGncIZI2O4fU4qM9MivcH2A9Ut/N97O9le0siZWTH8+YpxxAT79Ws7QpzOnC4VvU4GrQwVcp0zNMh5FEIIIcRQJdc5Q4OcRyGEEEIMVRKEPwZykSiGkmaLnfzqVvKqW2m3Olg4MbHPDPtWq4M/f7WX/ZWtNFvstFgcVDR14Emu1+sUnC4Vf6Oef94wiQVZMeRVtfC7z3JYfaC22/rCA4x8+cBc4kM7M+nX5tfyz2/ze5wftOD81GERXDQ+ngvGxRHmb8LmdGG1O/E36QkwGQBoardz8ysb2FHaRKi/kbvmDmdJThU7S5u865qWGsGPzspkV1kTf1u6H5vD5Z0WEWjij5eP4/yx3XvU2xwuFu+pRAXmZkQRHtjzz6ypw863udXUtdn43sTEbvOpqkq7zUmASS+Z9+KU9OWuCh56ZztnjIzm95eNJTZEBq6c6uQ6Z2iQ8yiEEEKIoUquc4YGOY9CCCGEGKokCH8M5CJRCF8VTR28tbGEtzcWU91iJTLQxCu3TiU7Ocw7j6qqbCpqYNneKr7bX0NuZQs6BV66eQpnjeqedQ9aufq3Nhbzxa4KOmxObT1AfZutz/0ZFhlAVlwwB+vaya1sITzAyBt3TmdMQigAeVUtvLbuIO9sKsHmdPkse8bIaO6YM5w/fpnL3opmAM4dHcvVU5KZNyIao17h692VPPF1LkV1WhUBnQLZyWHMSIsk0KRHp1NQVdhQWM+6/FrsTu3XaGSgiUcvGc2l2QmoKizJqeKZZXnsrWjGbNARHWwmOtjMqPgQpg+PYEZapAQ0xaBW3WzhnL+tpKnDDkCwn4FfXDiKa6cmy6CSU5hc5wwNch6FEEIIMVTJdc7QIOdRCCGEEEOVBOGPgVwkCtEzu9PFhoJ6RsQGEXOY4HFFUwcWu8unzHx/lTd28OWuCj7bWcGOLmXmexIZaOLNu6aTFdf9/2pFUwf/+q6ARRuL8TPoePSSMVwxKRFFUbA6nPx9aR4vfpeP57dgWICRhFB/ctzB+aggrSx+bmVLn/uQGROEChyobgVg3ohoalus3vX0JSrIhKIoqKqKqmrZ+Ynh/iSG+ZMeHcQZI6NJiw7qdXlVVWm1Oiip76C4vo2Dde3UtdlotznosLlwqSpnjIzmgrHxmAy6w+5PT9qsDlyqSrCfsdvnaw7UEhlkYlJK+EkNyq7YV81r6w4yf0Q0N80Yhk5Kp/eo2WJnV2kTO0ob2eWuIPGT80YS2UP7B1VV+f7rW1iSU0VWXDBmo977/3HysHBunz2cc0bH9vvfledyQ4L3J59c5wwNch6FEEIIMVTJdc7QIOdRCCGEEEOVBOGPgVwkCjF4NFvsqCqYDTpMeh0N7Tb2Vbawt7KFsoYOrp+eQkZM70Fq0MrW63R0CyID7K1o5v0tpXy6o5yaFisAfkYdd89N4+756QSZDVQ0dfDdvhp2lTXhdKm4VBWnC9JjAjlvTBzp0UHYHC5e/C6f55Yf8GbfB5kN3DY7lZtmDMPqcFHdYqWyycLW4gY2FNaRU97sLfPfl+FRgcwfEY2qqpQ1Wihv7KCuzUqb1UmbzUF/fotHB5u5cfowJqSEkVfVwv6qFopq27G7XKiqVoEgJSKAKycnMScjCr1OoaKpgxdX5PPWphIcThfjksKYnR7J8KhAludWszy3Gqu7vP/YxBDumpvGeWPiyKloZuX+Gtbl16ECSeH+JIX5kxoVyJyMqG4DOKqbLewqa6KssYOyhg7KGjuobbVS32ajvs2O2aDjhhkp3DhjGCGHnMMD1S08/sVeVuyr8X42LTWCv1w5ntSjGAByNFRVpaS+A5NBR1xo57F12Jy8s6mYtzaWEOJv4IdnZjI3M+qYgtCqqrJ4TyUvrMinqcOO2aDHbNQREWhiXmY054yOJTkioMdlP9xayiMf7vKeM4/UyAD+d/s0hkX6/rw+21HOD9/ahlGv8On9cxgRG8yrawp5asl+Ouxa5YqoIDPXTE3ittnDieohkA9gsTtZtKGYl1YV0NBuIy0qiPSYIEbGBnH26FifATSqqrK1uJH8mlbOyorpcXDAQFueW8Wu0mZunZVKaED33xGN7TY2FzWwqaienIpmRsQGc+G4OCYmh5+ygz3kOmdokPMohBBCiKFKrnOGBjmPQgghhBiqJAh/DOQiUYjTj9Olsi6/jvyaVs4bE+cTTD0SB6pb+PvSPFIjA7ljzvBee8mDNsCgpL4dnaKgKKCqUNtq9Qait5c0sr6gzlvuvi/hAUZSIgMZFhFAbIgZf5MBf6OeVqud9zaXUu0eYNAfCaF+TBoWzpI9Vd3K+R8qOcKf6marN7Cr1yk4DzOyYFxiKGeMjKah3eb+mbf1a7+C/QzcNGMYUUFmDta1UVDbxtr8OpwuFaNe4aJx8XyTU0WbzYmfUcf104bhUlUa2m00d9gJCzARF+pHQqgfwyIDyU4OI9RfC7o2W+x8sq2M97aU0mJxMDEljKmpEYxLDKWiycL+qhb2VbZgdTiJDDITFWjCZNCxo7SJrQcbqHO3UEiNDGBmeiRRQWYWbSj2fu4xfXgEt80eTmlDO5uLGthW0oDTpRIRaCIy0ExsiJmxiaFMSA5jbGIofka9d9mdpY08/vleNhbV9/lzGhkbzDVTk7lhRgpmg7b8q2sK+d1nOQAkhvkzITmM0QkhLNpQTFljB1FBWouJ8UlhANS1Wjnnbyupb7Px4NmZPHj2CO/6K5ssLNpwkLc3lXj/XQWZDdy7IJ3bZw/37nNlk4XPd5bzr5UF3gEuPcmKC+bSCQm0WR18uqOckvoOAAJMem6dlcrd89IICzBR3tjBpqJ69le1YHO4sDtVnC6V6WkRXDQu/ogHNzicLp74OpeXVhUCWlWKX1+stZNwqfBNThWvrCnk/9u796io68T/46/hNqAICCoXFcHUvF9RIvyuP39S7a7VurardSjZ2r6eNvvmLdNs7ea2aP3cWq3V6re/3M5WlrvZlm1tqGmroSJoecUbC2oCCoIIyG3evz+osXFGGRMZYp6PczjB5/Oe8f15DUOvc97z+Xy257nOOzLEqp8MjNaPB0ZpZFy4fJtYkK9rsCnvdKUOFFYoOjRQI+PCncaUV9WpoLRKg7qFXtGxXCl6TtvA6wgAANoqek7bwOsIAADaKhbhrwIlEUBrca6mXpsPndLWo6VqF+CrmLDGS9V37mBVsNVP7a1+Crb6KSjA95LPUVtv08d7TurNbQU6fa5G10d2UJ/IDrquS7AC/XxksVhkM0ZfHD6tNTtP6Oz5evtjR8WHa8a43orv3F5bDpdoy+HTOnq6Ukk9I3Tr4GgNiAnRmao6vbk1X3/JzNfpczUKCfTT6N6dNLpXZ7W3+ur4Nx8q2HuiXF8eL3ean8XSuHAcG97Ofin+zh2simhvVXj7AB0oPKvlG4/o0DeX+7/YTf0jNf+n/RTfqb2OlVZp7t+/0hdHStzKt1eXYMVFtNPmw6d1vu7yHzi4nABfH9XbbE5XNujWMUj//V89day0Sm9szVdtvfv/hq+PRR0C/ew/l1U13pc90N9H//1fPfWjPp1VW29TTX2Djp6q1Lr9Rcr6zxn7hyC6hwfpkZuv19FTlfrj+kOSpPuS4/Xb8f3sZ3AXnz2vX72epX0nz6pdgK8S4sJVU9egr8urday0Wn2jOuiDh0a7vOR8XYNN6/YVafmmI/rqm9e1a1iQEnuGa8d/zqigtMo+tmtYkKaN7aXEnuHKO1Wpw6fOKTv/jDblnnL6oEe7AF9FhwbaP5wRbPVTaJC/TpRVXzKrG3qG63cTBqpXlw4qOVejd3Yc0we7vlZ7q59GxYcrMT5cQ7qFKSTIX74+FhVXnNdDb+20L7BHhwbqZPl5SY0flDhZft5h/j07t9eouHANiAlRTkGZ1u0rUkXNhfdJp+AA3TwgSkO7hSm+c3vFRbRXTX2DsvMbz6DfWVCmQ0XnHI51wtAYPXX7AIW1C1CDzWhVVoGWfHpQgX4+Wj/7f132PX216DltA68jAABoq+g5bQOvIwAAaKtYhL8KlEQA3up8XYP+tbdQXx0vV0q/SCVdF+H2Y2vqG3T8TLV6hLeTn6/r+4SfqqjRxtxifXGkRKFB/kq6LkI3xEe4vAz4d9lsRhn7i/Ru1jEF+PmoR0R7xUW008CuoRrY1fGsYWOM3ss5oZyCMwpr56+O7QLUIdBPZ6rqdLKsWl9/c2Z7fkmVw+P6RAbrzpGxiu/cXjn5Z7Q9r1S5RRWKCQ3S9VGNH1wItvqqpLJWJedqVVlTr77RHTSiR0cN7BqqmnqbsvJKlXmkRAWlVfrJoCjdNjjGnsXJ8motXX9YWw6fVp/IYI3oEa6EuI4Ktvqp5FytSiprdKy0Sl8eL9euY2Uuzx6fOKyrHrnlesWEBbnMqbyqTh989bWWrT/kdPWD2Tf10UP/u5fTGeMV5+v0m7/maPPh0w7b/X0teu83yU2elW2zGf3jyxN67pNc+0K2JPlYpAExoUpNjNXE4d1cLuSXV9Xp4z0n9fGeQgX5++rWIdEa1zdSgf4+ythXpD9kHNSBwgqH5xvcLVTBVj/5+VpUWdOgVVkFOl9nk7+vRcm9OumLwyWXvYJDkL+vbMaopt6mYKufnv/FYI3rF6lXNh3Rss8O2z8oEdbOX6mJjbdBiA51zLumvkFbDp/WP3cXKmNfkcqr6y6b0bfaB/iqV5dg7T5RLpuRunSwatrYXnon65j2nTwrSerdJViv3DNCPTtf/jYbV4Oe0zbwOgIAgLaKntM28DoCAIC26ge1CP/yyy/r+eefV2FhoYYMGaJly5Zp1KhRlxy/evVqLViwQP/5z3/Uu3dvLV68WD/96U/t+40xevLJJ/Xaa6+prKxMycnJWr58uXr37u3WfCiJAND2nT5Xo53f3H98ZFy4hseGXdX92puTMUbFFTWq+M5VCUIC/dQlxL3bJFTV1uv/bc7Tik1Hda6mXk/fPkBpN8ZdcnxtvU0bDhTpXE3jpfytfr6K79Revbq4vxBcXdugt7cXqLSyVglxHTWiR0d1CLz8hyuaYrMZZR4tkc0YDYtt/MDCxY6VVumpD/Zq/YFi+7Yh3UKVmthDFou0La9U2/NKHc5slxoXu5ffPcLhGPNOV+r//vuo+seEaOKwbm6djV7XYFPmkRJtOFCsI6fOKe90pU6UVcvXYtGAmBAlxIVrRI+OGtQ1VF3DguTjY9HOgjOavfpLHf3OrRhCAv0086Y+uvuGHvK/xIdYmgs958q1tq4q8ToCAIC2i55z5eirAAAALecHswj/zjvvaMqUKVqxYoUSExP14osvavXq1crNzVWXLl2cxn/xxRf60Y9+pPT0dN1666166623tHjxYuXk5GjgwIGSpMWLFys9PV1/+ctfFB8frwULFmj37t3at2+fAgObXsCgJAIA2oLy6jqVV9UpNqKdp6dyTRljtG5/sbYdLdFtQ2I0pHuY05jzdQ06V1Ovypp61dTb1LNT+0teseFqna9rkCQF+l96Ef98XYP+z79y9U7WMd06JEaP3NxHEcHWazKfi9Fzrkxr7KoSryMAAGi76DlXhr4KAADQsn4wi/CJiYkaOXKkXnrpJUmSzWZT9+7d9T//8z+aN2+e0/jJkyersrJSa9eutW+74YYbNHToUK1YsULGGMXExGj27Nl65JFHJEnl5eWKjIzUypUrdeeddzY5J0oiAABoCcaYFr8CAz3nyrTGrirxOgIAgLaLnnNl6KsAAAAty92e43xd1xZUW1ur7OxsPfbYY/ZtPj4+SklJUWZmpsvHZGZmatasWQ7bbrnlFr3//vuSpLy8PBUWFiolJcW+PzQ0VImJicrMzHRZFGtqalRTc+HeueXl5ZIaQwQAAGhLvu03reCORK1ea+mqEn0VAAB4D/qq++irAAAALc/dvurRRfjTp0+roaFBkZGRDtsjIyN14MABl48pLCx0Ob6wsNC+/9ttlxpzsfT0dD399NNO27t37+7egQAAAPzAVFRUKDQ01NPTaNVaS1eV6KsAAMD70FebRl8FAADwnKb6qkcX4VuLxx57zOEToDabTaWlpYqIiLiml4g9e/asunfvrmPHjnFZpm+QiWvk4hq5OCMT18jFGZm45g25GGNUUVGhmJgYT08FV4C+2nqQiWvk4oxMXCMXZ2TiGrm45g250Fd/mOirrQeZuEYuzsjENXJxRiaukYszb8nE3b7q0UX4Tp06ydfXV0VFRQ7bi4qKFBUV5fIxUVFRlx3/7X+LiooUHR3tMGbo0KEun9NqtcpqtTpsCwsLu5JDuSohISFt+pfx+yAT18jFNXJxRiaukYszMnGtrefCGUXuaS1dVaKvtkZk4hq5OCMT18jFGZm4Ri6utfVc6Kvuoa9e0NbfE98HmbhGLs7IxDVycUYmrpGLM2/IxJ2+6tMC87ikgIAAjRgxQuvXr7dvs9lsWr9+vZKSklw+JikpyWG8JGVkZNjHx8fHKyoqymHM2bNntW3btks+JwAAAHAxuioAAABaM/oqAABA6+Xxy9HPmjVLaWlpSkhI0KhRo/Tiiy+qsrJS9957ryRpypQp6tq1q9LT0yVJ06dP15gxY7RkyRKNHz9eq1at0o4dO/Tqq69KkiwWi2bMmKHf/e536t27t+Lj47VgwQLFxMRowoQJnjpMAAAA/ADRVQEAANCa0VcBAABaJ48vwk+ePFmnTp3SE088ocLCQg0dOlSffPKJIiMjJUkFBQXy8blwwv6NN96ot956S7/97W81f/589e7dW++//74GDhxoH/Poo4+qsrJSU6dOVVlZmUaPHq1PPvlEgYGBLX58l2O1WvXkk086XarJm5GJa+TiGrk4IxPXyMUZmbhGLriYN3dVifeEK2TiGrk4IxPXyMUZmbhGLq6RCy5GX+U9cTEycY1cnJGJa+TijExcIxdnZOLIYowxnp4EAAAAAAAAAAAAAABtgUfvCQ8AAAAAAAAAAAAAQFvCIjwAAAAAAAAAAAAAAM2ERXgAAAAAAAAAAAAAAJoJi/AAAAAAAAAAAAAAADQTFuE95OWXX1ZcXJwCAwOVmJio7du3e3pKLSo9PV0jR45Uhw4d1KVLF02YMEG5ubkOY86fP69p06YpIiJCwcHBuuOOO1RUVOShGbe8RYsWyWKxaMaMGfZt3prJiRMndPfddysiIkJBQUEaNGiQduzYYd9vjNETTzyh6OhoBQUFKSUlRYcOHfLgjK+thoYGLViwQPHx8QoKCtJ1112nhQsXyhhjH+MNmXz++ee67bbbFBMTI4vFovfff99hvzsZlJaWKjU1VSEhIQoLC9Ovf/1rnTt3rgWPovldLpe6ujrNnTtXgwYNUvv27RUTE6MpU6bo66+/dniOtpZLU78r3/XAAw/IYrHoxRdfdNje1jIB3EFfpa82hb56AX3VEX21EX3VGV3VNfoq8P14c1+lq7qHvtqIruqMvtqIvuqMvuoaffX7YRHeA9555x3NmjVLTz75pHJycjRkyBDdcsstKi4u9vTUWsymTZs0bdo0bd26VRkZGaqrq9PNN9+syspK+5iZM2fqww8/1OrVq7Vp0yZ9/fXXmjhxogdn3XKysrL0yiuvaPDgwQ7bvTGTM2fOKDk5Wf7+/vr444+1b98+LVmyRB07drSPee6557R06VKtWLFC27ZtU/v27XXLLbfo/PnzHpz5tbN48WItX75cL730kvbv36/Fixfrueee07Jly+xjvCGTyspKDRkyRC+//LLL/e5kkJqaqr179yojI0Nr167V559/rqlTp7bUIVwTl8ulqqpKOTk5WrBggXJycvTee+8pNzdXt99+u8O4tpZLU78r31qzZo22bt2qmJgYp31tLROgKfRV+mpT6KsX0Fed0Vcb0Ved0VVdo68CV87b+ypdtWn01UZ0Vdfoq43oq87oq67RV78ngxY3atQoM23aNPvPDQ0NJiYmxqSnp3twVp5VXFxsJJlNmzYZY4wpKysz/v7+ZvXq1fYx+/fvN5JMZmamp6bZIioqKkzv3r1NRkaGGTNmjJk+fboxxnszmTt3rhk9evQl99tsNhMVFWWef/55+7aysjJjtVrN22+/3RJTbHHjx4839913n8O2iRMnmtTUVGOMd2YiyaxZs8b+szsZ7Nu3z0gyWVlZ9jEff/yxsVgs5sSJEy0292vp4lxc2b59u5Fk8vPzjTFtP5dLZXL8+HHTtWtXs2fPHtOjRw/zwgsv2Pe19UwAV+irzuirF9BXHdFXndFXndFXndFVXaOvAu6hrzqiqzqir15AV3WNvuqMvuqMvuoafdV9nAnfwmpra5Wdna2UlBT7Nh8fH6WkpCgzM9ODM/Os8vJySVJ4eLgkKTs7W3V1dQ459e3bV7GxsW0+p2nTpmn8+PEOxy55byYffPCBEhIS9Mtf/lJdunTRsGHD9Nprr9n35+XlqbCw0CGX0NBQJSYmttlcbrzxRq1fv14HDx6UJH355ZfavHmzfvKTn0jyzkwu5k4GmZmZCgsLU0JCgn1MSkqKfHx8tG3bthafs6eUl5fLYrEoLCxMknfmYrPZdM8992jOnDkaMGCA035vzATejb7qGn31AvqqI/qqM/pq0+ir7qGrNqKvAo7oq87oqo7oqxfQVV2jrzaNvuoe+moj+qprfp6egLc5ffq0GhoaFBkZ6bA9MjJSBw4c8NCsPMtms2nGjBlKTk7WwIEDJUmFhYUKCAiw/+H6VmRkpAoLCz0wy5axatUq5eTkKCsry2mft2Zy9OhRLV++XLNmzdL8+fOVlZWlhx9+WAEBAUpLS7Mfu6v3VFvNZd68eTp79qz69u0rX19fNTQ06Nlnn1VqaqokeWUmF3Mng8LCQnXp0sVhv5+fn8LDw70mp/Pnz2vu3Lm66667FBISIsk7c1m8eLH8/Pz08MMPu9zvjZnAu9FXndFXL6CvOqOvOqOvNo2+2jS66gX0VcARfdURXdURfdURXdU1+mrT6KtNo69eQF91jUV4eNy0adO0Z88ebd682dNT8ahjx45p+vTpysjIUGBgoKen02rYbDYlJCTo97//vSRp2LBh2rNnj1asWKG0tDQPz84z3n33Xb355pt66623NGDAAO3atUszZsxQTEyM12aCK1dXV6dJkybJGKPly5d7ejoek52drT/+8Y/KycmRxWLx9HQAtFL01Ub0Vdfoq87oq7hadNUL6KsAmkJXvYC+6oyu6hp9FVeLvnoBffXSuBx9C+vUqZN8fX1VVFTksL2oqEhRUVEempXnPPTQQ1q7dq0+++wzdevWzb49KipKtbW1KisrcxjflnPKzs5WcXGxhg8fLj8/P/n5+WnTpk1aunSp/Pz8FBkZ6XWZSFJ0dLT69+/vsK1fv34qKCiQJPuxe9N7as6cOZo3b57uvPNODRo0SPfcc49mzpyp9PR0Sd6ZycXcySAqKkrFxcUO++vr61VaWtrmc/q2JObn5ysjI8P+SU3J+3L597//reLiYsXGxtr/9ubn52v27NmKi4uT5H2ZAPRVR/TVC+irrtFXndFXm0ZfvTS6qiP6KuCMvnoBXdURfdUZXdU1+mrT6KuXRl91RF+9NBbhW1hAQIBGjBih9evX27fZbDatX79eSUlJHpxZyzLG6KGHHtKaNWu0YcMGxcfHO+wfMWKE/P39HXLKzc1VQUFBm81p3Lhx2r17t3bt2mX/SkhIUGpqqv17b8tEkpKTk5Wbm+uw7eDBg+rRo4ckKT4+XlFRUQ65nD17Vtu2bWuzuVRVVcnHx/HPt6+vr2w2myTvzORi7mSQlJSksrIyZWdn28ds2LBBNptNiYmJLT7nlvJtSTx06JDWrVuniIgIh/3elss999yjr776yuFvb0xMjObMmaN//etfkrwvE4C+2oi+6oy+6hp91Rl9tWn0Vdfoqs7oq4Az+ipd9VLoq87oqq7RV5tGX3WNvuqMvnoZBi1u1apVxmq1mpUrV5p9+/aZqVOnmrCwMFNYWOjpqbWY3/zmNyY0NNRs3LjRnDx50v5VVVVlH/PAAw+Y2NhYs2HDBrNjxw6TlJRkkpKSPDjrljdmzBgzffp0+8/emMn27duNn5+fefbZZ82hQ4fMm2++adq1a2f++te/2scsWrTIhIWFmX/84x/mq6++Mj/72c9MfHy8qa6u9uDMr520tDTTtWtXs3btWpOXl2fee+8906lTJ/Poo4/ax3hDJhUVFWbnzp1m586dRpL5wx/+YHbu3Gny8/ONMe5l8OMf/9gMGzbMbNu2zWzevNn07t3b3HXXXZ46pGZxuVxqa2vN7bffbrp162Z27drl8Pe3pqbG/hxtLZemflcu1qNHD/PCCy84bGtrmQBNoa/SV91FX6WvukJfbURfdUZXdY2+Clw5b++rdFX3eXtfpau6Rl9tRF91Rl91jb76/bAI7yHLli0zsbGxJiAgwIwaNcps3brV01NqUZJcfr3++uv2MdXV1ebBBx80HTt2NO3atTM///nPzcmTJz03aQ+4uCR6ayYffvihGThwoLFaraZv377m1Vdfddhvs9nMggULTGRkpLFarWbcuHEmNzfXQ7O99s6ePWumT59uYmNjTWBgoOnZs6d5/PHHHf5H7w2ZfPbZZy7/jqSlpRlj3MugpKTE3HXXXSY4ONiEhISYe++911RUVHjgaJrP5XLJy8u75N/fzz77zP4cbS2Xpn5XLuaqJLa1TAB30Ffpq+6grzairzqirzairzqjq7pGXwW+H2/uq3RV99FX6aqu0Fcb0Ved0Vddo69+PxZjjHH3rHkAAAAAAAAAAAAAAHBp3BMeAAAAAAAAAAAAAIBmwiI8AAAAAAAAAAAAAADNhEV4AAAAAAAAAAAAAACaCYvwAAAAAAAAAAAAAAA0ExbhAQAAAAAAAAAAAABoJizCAwAAAAAAAAAAAADQTFiEBwAAAAAAAAAAAACgmbAIDwAAAAAAAAAAAABAM2ERHgB+IDZu3CiLxaKysjJPTwUAAABwQl8FAABAa0ZfBdCSWIQHAAAAAAAAAAAAAKCZsAgPAAAAAAAAAAAAAEAzYREeANxks9mUnp6u+Ph4BQUFaciQIfrb3/4m6cKljD766CMNHjxYgYGBuuGGG7Rnzx6H5/j73/+uAQMGyGq1Ki4uTkuWLHHYX1NTo7lz56p79+6yWq3q1auX/vznPzuMyc7OVkJCgtq1a6cbb7xRubm59n1ffvmlxo4dqw4dOigkJEQjRozQjh07rlEiAAAAaE3oqwAAAGjN6KsAvAmL8ADgpvT0dL3xxhtasWKF9u7dq5kzZ+ruu+/Wpk2b7GPmzJmjJUuWKCsrS507d9Ztt92muro6SY3lbtKkSbrzzju1e/duPfXUU1qwYIFWrlxpf/yUKVP09ttva+nSpdq/f79eeeUVBQcHO8zj8ccf15IlS7Rjxw75+fnpvvvus+9LTU1Vt27dlJWVpezsbM2bN0/+/v7XNhgAAAC0CvRVAAAAtGb0VQDexGKMMZ6eBAC0djU1NQoPD9e6deuUlJRk337//ferqqpKU6dO1dixY7Vq1SpNnjxZklRaWqpu3bpp5cqVmjRpklJTU3Xq1Cl9+umn9sc/+uij+uijj7R3714dPHhQ119/vTIyMpSSkuI0h40bN2rs2LFat26dxo0bJ0n65z//qfHjx6u6ulqBgYEKCQnRsmXLlJaWdo0TAQAAQGtCXwUAAEBrRl8F4G04Ex4A3HD48GFVVVXppptuUnBwsP3rjTfe0JEjR+zjvlsgw8PDdf3112v//v2SpP379ys5OdnheZOTk3Xo0CE1NDRo165d8vX11ZgxYy47l8GDB9u/j46OliQVFxdLkmbNmqX7779fKSkpWrRokcPcAAAA0HbRVwEAANCa0VcBeBsW4QHADefOnZMkffTRR9q1a5f9a9++ffb7Fl2toKAgt8Z99/JHFotFUuP9lCTpqaee0t69ezV+/Hht2LBB/fv315o1a5plfgAAAGi96KsAAABozeirALwNi/AA4Ib+/fvLarWqoKBAvXr1cvjq3r27fdzWrVvt3585c0YHDx5Uv379JEn9+vXTli1bHJ53y5Yt6tOnj3x9fTVo0CDZbDaHeyB9H3369NHMmTP16aefauLEiXr99dev6vkAAADQ+tFXAQAA0JrRVwF4Gz9PTwAAfgg6dOigRx55RDNnzpTNZtPo0aNVXl6uLVu2KCQkRD169JAkPfPMM4qIiFBkZKQef/xxderUSRMmTJAkzZ49WyNHjtTChQs1efJkZWZm6qWXXtKf/vQnSVJcXJzS0tJ03333aenSpRoyZIjy8/NVXFysSZMmNTnH6upqzZkzR7/4xS8UHx+v48ePKysrS3fcccc1ywUAAACtA30VAAAArRl9FYC3YREeANy0cOFCde7cWenp6Tp69KjCwsI0fPhwzZ8/3365okWLFmn69Ok6dOiQhg4dqg8//FABAQGSpOHDh+vdd9/VE088oYULFyo6OlrPPPOMfvWrX9n/jeXLl2v+/Pl68MEHVVJSotjYWM2fP9+t+fn6+qqkpERTpkxRUVGROnXqpIkTJ+rpp59u9iwAAADQ+tBXAQAA0JrRVwF4E4sxxnh6EgDwQ7dx40aNHTtWZ86cUVhYmKenAwAAADigrwIAAKA1o68CaGu4JzwAAAAAAAAAAAAAAM2ERXgAAAAAAAAAAAAAAJoJl6MHAAAAAAAAAAAAAKCZcCY8AAAAAAAAAAAAAADNhEV4AAAAAAAAAAAAAACaCYvwAAAAAAAAAAAAAAA0ExbhAQAAAAAAAAAAAABoJizCAwAAAAAAAAAAAADQTFiEBwAAAAAAAAAAAACgmbAIDwAAAAAAAAAAAABAM2ERHgAAAAAAAAAAAACAZvL/AetKzgbbM+lUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = list()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "\n",
    "def plot_graphs(metric, val, ax, upper):\n",
    "    ax.plot(val['history'].history[metric])\n",
    "    ax.plot(val['history'].history[f'val_{metric}'])\n",
    "    ax.set_title(key)\n",
    "    ax.legend([metric, f\"val_{metric}\"])\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim([0, upper])\n",
    "    \n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    \n",
    "    plot_graphs('loss', val, ax, 0.05)\n",
    "print(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MAE Curves\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs('mae', val, ax, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Test Results\n",
    "It's surprising to see how well a CNN did. LSTM would be expected to perform well because of its ability to learn and remember longer trends in the data.\n",
    "\n",
    "Putting the models' performance in perspective however the results show how with a limited lookback window, and simple features a lstm, and a cnn stacked with an lstm are a good starting choice for architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0064 - mae: 0.0973\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0831\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.097275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.083133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM-CNN</th>\n",
       "      <td>0.057417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae\n",
       "CNN       0.097275\n",
       "LSTM      0.083133\n",
       "LSTM-CNN  0.057417"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list()\n",
    "performance = list()\n",
    "\n",
    "for key, value in model_configs.items():\n",
    "    names.append(key)\n",
    "    mae = value['model'].evaluate(value['test_ds'])\n",
    "    performance.append(mae[1])\n",
    "    \n",
    "performance_df = pd.DataFrame(performance, index=names, columns=['mae'])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions\n",
    "\n",
    "Plot the actual and predicted 24 hour intervals. Below is the first 14 days of predictions. Interesting to note how the LSTM appears to oscilate over a longer frequency compared with the other models. The CNN also seems to capture the intra day oscillations (within the 24 hour period). Looking at the CNN stacked LSTM we can see how these two characteristics of the model's learning combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(18, 10))\n",
    "days = 5\n",
    "\n",
    "vline = np.linspace(0, days*24, days+1)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "\n",
    "    test = val['test_ds']\n",
    "    preds = val['model'].predict(test)\n",
    "\n",
    "    xbatch, ybatch = iter(test).get_next()\n",
    "\n",
    "    ax.plot(ybatch.numpy()[:days].reshape(-1))\n",
    "    ax.plot(preds[:days].reshape(-1))\n",
    "    ax.set_title(key)\n",
    "    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "    ax.legend([\"Actual RV\", \"Predicted RV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
