{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:38:25.324127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from handler import build_dataset\n",
    "from models import cnn_model, lstm_model, lstm_cnn_model, run_model\n",
    "from tuning import create_study, get_optimized_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = build_dataset(path='./src/rv_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:295: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2023-12-04 18:42:40,236] A new study created in RDB with name: no-name-09d75dc2-5941-48b0-a3f0-654f098b84fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0439 - mae: 0.2295 - val_loss: 0.5052 - val_mae: 0.8823\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5836 - mae: 0.9529 - val_loss: 0.3337 - val_mae: 0.7179\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2958 - mae: 0.6610 - val_loss: 0.0294 - val_mae: 0.1454\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0146 - mae: 0.1367 - val_loss: 0.0223 - val_mae: 0.1140\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0199 - val_mae: 0.0867\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - mae: 0.0728 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0715 - val_loss: 0.0203 - val_mae: 0.0886\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0818 - val_loss: 0.0193 - val_mae: 0.0863\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0196 - val_mae: 0.1374\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0879 - val_loss: 0.0184 - val_mae: 0.0843\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0828\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0656 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0166 - val_mae: 0.0900\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0688 - val_loss: 0.0170 - val_mae: 0.0926\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0722 - val_loss: 0.0174 - val_mae: 0.0950\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0720 - val_loss: 0.0177 - val_mae: 0.0960\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0044 - mae: 0.0704 - val_loss: 0.0177 - val_mae: 0.0952\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0690 - val_loss: 0.0175 - val_mae: 0.0937\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0730 - val_loss: 0.0171 - val_mae: 0.0917\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0687 - val_loss: 0.0168 - val_mae: 0.0902\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0677 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - mae: 0.0680 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0166 - val_mae: 0.0868\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0663 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0660 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0823\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0167 - val_mae: 0.0824\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0823\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0165 - val_mae: 0.0865\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0851\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0855\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0857\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0165 - val_mae: 0.0839\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0875\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0166 - val_mae: 0.0878\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0873\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0873\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0865\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0638 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0850\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0165 - val_mae: 0.0856\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0163 - val_mae: 0.0857\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0164 - val_mae: 0.0881\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - mae: 0.0656 - val_loss: 0.0165 - val_mae: 0.0876\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0176 - val_mae: 0.0855\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0177 - val_mae: 0.0854\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0866\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0867\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0636 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0640 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0849\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:42:51,500] Trial 0 finished with value: 0.08503767848014832 and parameters: {'learning_rate': 0.017352599516071498, 'weight_decay': 8.69895482936706e-05}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0500 - mae: 0.2528 - val_loss: 0.0320 - val_mae: 0.1594\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0456 - mae: 0.2365 - val_loss: 0.0318 - val_mae: 0.1587\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0551 - mae: 0.2597 - val_loss: 0.0316 - val_mae: 0.1579\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0574 - mae: 0.2696 - val_loss: 0.0314 - val_mae: 0.1571\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0629 - mae: 0.2795 - val_loss: 0.0312 - val_mae: 0.1563\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0567 - mae: 0.2698 - val_loss: 0.0310 - val_mae: 0.1554\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0458 - mae: 0.2476 - val_loss: 0.0308 - val_mae: 0.1546\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0475 - mae: 0.2466 - val_loss: 0.0306 - val_mae: 0.1537\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0396 - mae: 0.2244 - val_loss: 0.0304 - val_mae: 0.1528\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0783 - mae: 0.3004 - val_loss: 0.0302 - val_mae: 0.1520\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0477 - mae: 0.2459 - val_loss: 0.0300 - val_mae: 0.1511\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0521 - mae: 0.2527 - val_loss: 0.0298 - val_mae: 0.1502\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0568 - mae: 0.2631 - val_loss: 0.0296 - val_mae: 0.1492\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0482 - mae: 0.2419 - val_loss: 0.0294 - val_mae: 0.1483\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0487 - mae: 0.2483 - val_loss: 0.0292 - val_mae: 0.1474\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0399 - mae: 0.2157 - val_loss: 0.0290 - val_mae: 0.1465\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0515 - mae: 0.2530 - val_loss: 0.0288 - val_mae: 0.1457\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0466 - mae: 0.2405 - val_loss: 0.0286 - val_mae: 0.1448\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0412 - mae: 0.2217 - val_loss: 0.0284 - val_mae: 0.1440\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0422 - mae: 0.2373 - val_loss: 0.0283 - val_mae: 0.1432\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0445 - mae: 0.2321 - val_loss: 0.0281 - val_mae: 0.1424\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0575 - mae: 0.2607 - val_loss: 0.0279 - val_mae: 0.1416\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0475 - mae: 0.2457 - val_loss: 0.0278 - val_mae: 0.1408\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0458 - mae: 0.2338 - val_loss: 0.0276 - val_mae: 0.1401\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0485 - mae: 0.2468 - val_loss: 0.0275 - val_mae: 0.1393\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0398 - mae: 0.2265 - val_loss: 0.0273 - val_mae: 0.1386\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0439 - mae: 0.2342 - val_loss: 0.0272 - val_mae: 0.1378\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0414 - mae: 0.2194 - val_loss: 0.0270 - val_mae: 0.1371\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0482 - mae: 0.2475 - val_loss: 0.0269 - val_mae: 0.1364\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0448 - mae: 0.2375 - val_loss: 0.0267 - val_mae: 0.1357\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0442 - mae: 0.2408 - val_loss: 0.0266 - val_mae: 0.1350\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0559 - mae: 0.2627 - val_loss: 0.0265 - val_mae: 0.1343\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0471 - mae: 0.2332 - val_loss: 0.0263 - val_mae: 0.1335\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0459 - mae: 0.2424 - val_loss: 0.0262 - val_mae: 0.1328\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0420 - mae: 0.2321 - val_loss: 0.0261 - val_mae: 0.1321\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0418 - mae: 0.2277 - val_loss: 0.0260 - val_mae: 0.1314\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0419 - mae: 0.2306 - val_loss: 0.0258 - val_mae: 0.1308\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0512 - mae: 0.2459 - val_loss: 0.0257 - val_mae: 0.1301\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0421 - mae: 0.2305 - val_loss: 0.0256 - val_mae: 0.1294\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0519 - mae: 0.2504 - val_loss: 0.0255 - val_mae: 0.1288\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0488 - mae: 0.2464 - val_loss: 0.0253 - val_mae: 0.1281\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0483 - mae: 0.2397 - val_loss: 0.0252 - val_mae: 0.1274\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0333 - mae: 0.2044 - val_loss: 0.0251 - val_mae: 0.1267\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - mae: 0.2227 - val_loss: 0.0250 - val_mae: 0.1260\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2211 - val_loss: 0.0249 - val_mae: 0.1254\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0399 - mae: 0.2192 - val_loss: 0.0247 - val_mae: 0.1248\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0464 - mae: 0.2320 - val_loss: 0.0246 - val_mae: 0.1242\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0432 - mae: 0.2339 - val_loss: 0.0245 - val_mae: 0.1235\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0394 - mae: 0.2199 - val_loss: 0.0244 - val_mae: 0.1229\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - mae: 0.2225 - val_loss: 0.0243 - val_mae: 0.1223\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0434 - mae: 0.2301 - val_loss: 0.0242 - val_mae: 0.1218\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0413 - mae: 0.2266 - val_loss: 0.0241 - val_mae: 0.1212\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0366 - mae: 0.2125 - val_loss: 0.0240 - val_mae: 0.1206\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0379 - mae: 0.2221 - val_loss: 0.0239 - val_mae: 0.1201\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0349 - mae: 0.2057 - val_loss: 0.0238 - val_mae: 0.1195\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0375 - mae: 0.2153 - val_loss: 0.0237 - val_mae: 0.1190\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0416 - mae: 0.2200 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0404 - mae: 0.2277 - val_loss: 0.0235 - val_mae: 0.1180\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0345 - mae: 0.2036 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0333 - mae: 0.2061 - val_loss: 0.0234 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0370 - mae: 0.2147 - val_loss: 0.0233 - val_mae: 0.1164\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0372 - mae: 0.2132 - val_loss: 0.0232 - val_mae: 0.1159\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0360 - mae: 0.2117 - val_loss: 0.0231 - val_mae: 0.1153\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0383 - mae: 0.2157 - val_loss: 0.0230 - val_mae: 0.1148\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0323 - mae: 0.1961 - val_loss: 0.0229 - val_mae: 0.1143\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0348 - mae: 0.2074 - val_loss: 0.0228 - val_mae: 0.1138\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0386 - mae: 0.2204 - val_loss: 0.0227 - val_mae: 0.1133\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0344 - mae: 0.2043 - val_loss: 0.0226 - val_mae: 0.1128\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0329 - mae: 0.2006 - val_loss: 0.0225 - val_mae: 0.1123\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0405 - mae: 0.2233 - val_loss: 0.0225 - val_mae: 0.1118\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0416 - mae: 0.2273 - val_loss: 0.0224 - val_mae: 0.1113\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0432 - mae: 0.2361 - val_loss: 0.0223 - val_mae: 0.1108\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0359 - mae: 0.2100 - val_loss: 0.0222 - val_mae: 0.1103\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0387 - mae: 0.2213 - val_loss: 0.0221 - val_mae: 0.1099\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0372 - mae: 0.2104 - val_loss: 0.0221 - val_mae: 0.1094\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0415 - mae: 0.2248 - val_loss: 0.0220 - val_mae: 0.1090\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0307 - mae: 0.1979 - val_loss: 0.0219 - val_mae: 0.1086\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0352 - mae: 0.2057 - val_loss: 0.0218 - val_mae: 0.1082\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2245 - val_loss: 0.0218 - val_mae: 0.1079\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0315 - mae: 0.1888 - val_loss: 0.0217 - val_mae: 0.1076\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0451 - mae: 0.2299 - val_loss: 0.0217 - val_mae: 0.1073\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0327 - mae: 0.2021 - val_loss: 0.0216 - val_mae: 0.1070\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0325 - mae: 0.1936 - val_loss: 0.0215 - val_mae: 0.1067\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0290 - mae: 0.1876 - val_loss: 0.0215 - val_mae: 0.1064\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0312 - mae: 0.1913 - val_loss: 0.0214 - val_mae: 0.1062\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0317 - mae: 0.1986 - val_loss: 0.0214 - val_mae: 0.1059\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0306 - mae: 0.1928 - val_loss: 0.0213 - val_mae: 0.1056\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0342 - mae: 0.2079 - val_loss: 0.0213 - val_mae: 0.1053\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0306 - mae: 0.1971 - val_loss: 0.0212 - val_mae: 0.1051\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0337 - mae: 0.2083 - val_loss: 0.0211 - val_mae: 0.1048\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0409 - mae: 0.2274 - val_loss: 0.0211 - val_mae: 0.1045\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0331 - mae: 0.2044 - val_loss: 0.0210 - val_mae: 0.1043\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0308 - mae: 0.1949 - val_loss: 0.0210 - val_mae: 0.1040\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0387 - mae: 0.2181 - val_loss: 0.0209 - val_mae: 0.1038\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0379 - mae: 0.2266 - val_loss: 0.0209 - val_mae: 0.1035\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0285 - mae: 0.1822 - val_loss: 0.0208 - val_mae: 0.1033\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0362 - mae: 0.2043 - val_loss: 0.0208 - val_mae: 0.1031\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0344 - mae: 0.2014 - val_loss: 0.0207 - val_mae: 0.1028\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0349 - mae: 0.2029 - val_loss: 0.0207 - val_mae: 0.1026\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0354 - mae: 0.2133 - val_loss: 0.0207 - val_mae: 0.1024\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0326 - mae: 0.2006 - val_loss: 0.0206 - val_mae: 0.1022\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - mae: 0.2057 - val_loss: 0.0206 - val_mae: 0.1020\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0340 - mae: 0.2056 - val_loss: 0.0205 - val_mae: 0.1018\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0331 - mae: 0.2021 - val_loss: 0.0205 - val_mae: 0.1017\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0339 - mae: 0.2035 - val_loss: 0.0205 - val_mae: 0.1015\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0336 - mae: 0.2011 - val_loss: 0.0204 - val_mae: 0.1013\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0316 - mae: 0.2035 - val_loss: 0.0204 - val_mae: 0.1012\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0348 - mae: 0.2031 - val_loss: 0.0204 - val_mae: 0.1010\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0315 - mae: 0.1994 - val_loss: 0.0203 - val_mae: 0.1008\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0266 - mae: 0.1830 - val_loss: 0.0203 - val_mae: 0.1006\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0288 - mae: 0.1809 - val_loss: 0.0203 - val_mae: 0.1005\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0253 - mae: 0.1741 - val_loss: 0.0202 - val_mae: 0.1003\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0297 - mae: 0.1951 - val_loss: 0.0202 - val_mae: 0.1002\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0338 - mae: 0.2107 - val_loss: 0.0202 - val_mae: 0.1000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0275 - mae: 0.1867 - val_loss: 0.0201 - val_mae: 0.0999\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0294 - mae: 0.1917 - val_loss: 0.0201 - val_mae: 0.0997\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0292 - mae: 0.1904 - val_loss: 0.0201 - val_mae: 0.0995\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0409 - mae: 0.2225 - val_loss: 0.0200 - val_mae: 0.0993\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0319 - mae: 0.1973 - val_loss: 0.0200 - val_mae: 0.0992\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0339 - mae: 0.2004 - val_loss: 0.0199 - val_mae: 0.0990\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0284 - mae: 0.1859 - val_loss: 0.0199 - val_mae: 0.0988\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0284 - mae: 0.1916 - val_loss: 0.0199 - val_mae: 0.0986\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0297 - mae: 0.1968 - val_loss: 0.0198 - val_mae: 0.0985\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - mae: 0.2032 - val_loss: 0.0198 - val_mae: 0.0983\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0333 - mae: 0.1948 - val_loss: 0.0197 - val_mae: 0.0981\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0322 - mae: 0.2041 - val_loss: 0.0197 - val_mae: 0.0980\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0279 - mae: 0.1858 - val_loss: 0.0197 - val_mae: 0.0978\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0251 - mae: 0.1784 - val_loss: 0.0196 - val_mae: 0.0976\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0274 - mae: 0.1873 - val_loss: 0.0196 - val_mae: 0.0975\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0269 - mae: 0.1837 - val_loss: 0.0196 - val_mae: 0.0973\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0359 - mae: 0.2134 - val_loss: 0.0196 - val_mae: 0.0972\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0254 - mae: 0.1808 - val_loss: 0.0195 - val_mae: 0.0970\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0331 - mae: 0.1962 - val_loss: 0.0195 - val_mae: 0.0969\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0260 - mae: 0.1815 - val_loss: 0.0195 - val_mae: 0.0967\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0266 - mae: 0.1801 - val_loss: 0.0195 - val_mae: 0.0966\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0331 - mae: 0.1947 - val_loss: 0.0194 - val_mae: 0.0964\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - mae: 0.2054 - val_loss: 0.0194 - val_mae: 0.0963\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0279 - mae: 0.1934 - val_loss: 0.0194 - val_mae: 0.0961\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0275 - mae: 0.1893 - val_loss: 0.0193 - val_mae: 0.0960\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0293 - mae: 0.1976 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0272 - mae: 0.1856 - val_loss: 0.0193 - val_mae: 0.0957\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0287 - mae: 0.1866 - val_loss: 0.0193 - val_mae: 0.0955\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0276 - mae: 0.1934 - val_loss: 0.0192 - val_mae: 0.0954\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0369 - mae: 0.2111 - val_loss: 0.0192 - val_mae: 0.0953\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0353 - mae: 0.2037 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - mae: 0.1944 - val_loss: 0.0192 - val_mae: 0.0951\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0294 - mae: 0.1983 - val_loss: 0.0192 - val_mae: 0.0949\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0273 - mae: 0.1852 - val_loss: 0.0191 - val_mae: 0.0948\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0275 - mae: 0.1807 - val_loss: 0.0191 - val_mae: 0.0947\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0216 - mae: 0.1624 - val_loss: 0.0191 - val_mae: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:02,718] Trial 1 finished with value: 0.09461578726768494 and parameters: {'learning_rate': 7.173612948658869e-06, 'weight_decay': 0.0001298913434059281}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0935 - mae: 0.3552 - val_loss: 0.0544 - val_mae: 0.2537\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0792 - mae: 0.3169 - val_loss: 0.0500 - val_mae: 0.2403\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0748 - mae: 0.3143 - val_loss: 0.0459 - val_mae: 0.2268\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0768 - mae: 0.3101 - val_loss: 0.0422 - val_mae: 0.2144\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0657 - mae: 0.2847 - val_loss: 0.0388 - val_mae: 0.2029\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0630 - mae: 0.2756 - val_loss: 0.0357 - val_mae: 0.1919\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0559 - mae: 0.2635 - val_loss: 0.0331 - val_mae: 0.1812\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0553 - mae: 0.2614 - val_loss: 0.0309 - val_mae: 0.1710\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0397 - mae: 0.2235 - val_loss: 0.0289 - val_mae: 0.1613\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0398 - mae: 0.2287 - val_loss: 0.0273 - val_mae: 0.1523\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0376 - mae: 0.2269 - val_loss: 0.0259 - val_mae: 0.1448\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0351 - mae: 0.2128 - val_loss: 0.0248 - val_mae: 0.1387\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0394 - mae: 0.2216 - val_loss: 0.0238 - val_mae: 0.1335\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0370 - mae: 0.2143 - val_loss: 0.0230 - val_mae: 0.1294\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0340 - mae: 0.2164 - val_loss: 0.0223 - val_mae: 0.1255\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0323 - mae: 0.2025 - val_loss: 0.0218 - val_mae: 0.1219\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0291 - mae: 0.1889 - val_loss: 0.0214 - val_mae: 0.1187\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0317 - mae: 0.2051 - val_loss: 0.0210 - val_mae: 0.1155\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0283 - mae: 0.1808 - val_loss: 0.0208 - val_mae: 0.1126\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0327 - mae: 0.1992 - val_loss: 0.0206 - val_mae: 0.1105\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0276 - mae: 0.1927 - val_loss: 0.0204 - val_mae: 0.1086\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0235 - mae: 0.1736 - val_loss: 0.0203 - val_mae: 0.1072\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - mae: 0.1719 - val_loss: 0.0202 - val_mae: 0.1060\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0282 - mae: 0.1819 - val_loss: 0.0201 - val_mae: 0.1050\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0258 - mae: 0.1788 - val_loss: 0.0200 - val_mae: 0.1040\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0258 - mae: 0.1844 - val_loss: 0.0200 - val_mae: 0.1035\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0189 - mae: 0.1594 - val_loss: 0.0199 - val_mae: 0.1033\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0201 - mae: 0.1578 - val_loss: 0.0198 - val_mae: 0.1032\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0270 - mae: 0.1836 - val_loss: 0.0198 - val_mae: 0.1030\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0263 - mae: 0.1842 - val_loss: 0.0198 - val_mae: 0.1028\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0225 - mae: 0.1714 - val_loss: 0.0198 - val_mae: 0.1027\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0231 - mae: 0.1631 - val_loss: 0.0198 - val_mae: 0.1025\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0191 - mae: 0.1489 - val_loss: 0.0198 - val_mae: 0.1024\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0165 - mae: 0.1438 - val_loss: 0.0199 - val_mae: 0.1022\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0195 - mae: 0.1545 - val_loss: 0.0199 - val_mae: 0.1020\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0225 - mae: 0.1699 - val_loss: 0.0199 - val_mae: 0.1019\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0187 - mae: 0.1511 - val_loss: 0.0199 - val_mae: 0.1017\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0203 - mae: 0.1575 - val_loss: 0.0199 - val_mae: 0.1015\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0180 - mae: 0.1529 - val_loss: 0.0199 - val_mae: 0.1013\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - mae: 0.1455 - val_loss: 0.0199 - val_mae: 0.1010\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0173 - mae: 0.1525 - val_loss: 0.0198 - val_mae: 0.1007\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0163 - mae: 0.1456 - val_loss: 0.0198 - val_mae: 0.1005\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0183 - mae: 0.1581 - val_loss: 0.0197 - val_mae: 0.1002\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0195 - mae: 0.1519 - val_loss: 0.0197 - val_mae: 0.1000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0142 - mae: 0.1301 - val_loss: 0.0196 - val_mae: 0.0997\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0189 - mae: 0.1506 - val_loss: 0.0196 - val_mae: 0.0995\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0177 - mae: 0.1519 - val_loss: 0.0196 - val_mae: 0.0993\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0160 - mae: 0.1404 - val_loss: 0.0196 - val_mae: 0.0991\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0152 - mae: 0.1384 - val_loss: 0.0196 - val_mae: 0.0989\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0181 - mae: 0.1489 - val_loss: 0.0196 - val_mae: 0.0987\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - mae: 0.1476 - val_loss: 0.0195 - val_mae: 0.0986\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0133 - mae: 0.1326 - val_loss: 0.0195 - val_mae: 0.0985\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0149 - mae: 0.1397 - val_loss: 0.0195 - val_mae: 0.0983\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - mae: 0.1365 - val_loss: 0.0195 - val_mae: 0.0982\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0162 - mae: 0.1460 - val_loss: 0.0195 - val_mae: 0.0981\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0168 - mae: 0.1477 - val_loss: 0.0195 - val_mae: 0.0980\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0112 - mae: 0.1209 - val_loss: 0.0195 - val_mae: 0.0979\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1254 - val_loss: 0.0194 - val_mae: 0.0977\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0144 - mae: 0.1260 - val_loss: 0.0194 - val_mae: 0.0974\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0129 - mae: 0.1251 - val_loss: 0.0194 - val_mae: 0.0971\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0127 - mae: 0.1243 - val_loss: 0.0194 - val_mae: 0.0966\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0134 - mae: 0.1265 - val_loss: 0.0194 - val_mae: 0.0963\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0146 - mae: 0.1398 - val_loss: 0.0194 - val_mae: 0.0962\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0137 - mae: 0.1309 - val_loss: 0.0194 - val_mae: 0.0960\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0132 - mae: 0.1243 - val_loss: 0.0194 - val_mae: 0.0959\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0113 - mae: 0.1200 - val_loss: 0.0194 - val_mae: 0.0957\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - mae: 0.1228 - val_loss: 0.0194 - val_mae: 0.0955\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0142 - mae: 0.1302 - val_loss: 0.0194 - val_mae: 0.0954\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0116 - mae: 0.1207 - val_loss: 0.0194 - val_mae: 0.0953\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mae: 0.1200 - val_loss: 0.0194 - val_mae: 0.0952\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0153 - mae: 0.1424 - val_loss: 0.0194 - val_mae: 0.0951\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0137 - mae: 0.1260 - val_loss: 0.0194 - val_mae: 0.0950\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - mae: 0.1165 - val_loss: 0.0194 - val_mae: 0.0950\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0119 - mae: 0.1235 - val_loss: 0.0194 - val_mae: 0.0949\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0130 - mae: 0.1257 - val_loss: 0.0193 - val_mae: 0.0948\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0123 - mae: 0.1169 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0112 - mae: 0.1201 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0140 - mae: 0.1271 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0116 - mae: 0.1190 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0109 - mae: 0.1169 - val_loss: 0.0192 - val_mae: 0.0948\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - mae: 0.1117 - val_loss: 0.0192 - val_mae: 0.0949\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0137 - mae: 0.1246 - val_loss: 0.0192 - val_mae: 0.0950\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0108 - mae: 0.1137 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0103 - mae: 0.1155 - val_loss: 0.0192 - val_mae: 0.0954\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0192 - val_mae: 0.0955\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1161 - val_loss: 0.0191 - val_mae: 0.0957\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0191 - val_mae: 0.0960\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1041 - val_loss: 0.0191 - val_mae: 0.0963\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0191 - val_mae: 0.0965\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0191 - val_mae: 0.0968\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0191 - val_mae: 0.0971\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - mae: 0.1075 - val_loss: 0.0191 - val_mae: 0.0973\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - mae: 0.1093 - val_loss: 0.0191 - val_mae: 0.0974\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0101 - mae: 0.1134 - val_loss: 0.0191 - val_mae: 0.0976\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0191 - val_mae: 0.0978\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0191 - val_mae: 0.0979\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0077 - mae: 0.0983 - val_loss: 0.0191 - val_mae: 0.0980\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0077 - mae: 0.0980 - val_loss: 0.0192 - val_mae: 0.0982\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0081 - mae: 0.1026 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - mae: 0.1119 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.1013 - val_loss: 0.0192 - val_mae: 0.0985\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0966 - val_loss: 0.0191 - val_mae: 0.0988\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0192 - val_mae: 0.0990\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0960 - val_loss: 0.0192 - val_mae: 0.0993\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0922 - val_loss: 0.0192 - val_mae: 0.0995\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0069 - mae: 0.0929 - val_loss: 0.0192 - val_mae: 0.0997\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - mae: 0.0968 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0964 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.1028 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0080 - mae: 0.1018 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0986 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - mae: 0.0963 - val_loss: 0.0191 - val_mae: 0.0997\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0080 - mae: 0.0951 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0086 - mae: 0.1062 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0086 - mae: 0.1029 - val_loss: 0.0191 - val_mae: 0.0995\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0079 - mae: 0.0990 - val_loss: 0.0191 - val_mae: 0.0995\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0077 - mae: 0.0946 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0967 - val_loss: 0.0191 - val_mae: 0.0997\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0925 - val_loss: 0.0191 - val_mae: 0.0998\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0921 - val_loss: 0.0191 - val_mae: 0.0999\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0062 - mae: 0.0873 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.1030 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0903 - val_loss: 0.0191 - val_mae: 0.1001\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0902 - val_loss: 0.0190 - val_mae: 0.1000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0933 - val_loss: 0.0190 - val_mae: 0.0999\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0900 - val_loss: 0.0190 - val_mae: 0.0998\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - mae: 0.0945 - val_loss: 0.0189 - val_mae: 0.0997\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0080 - mae: 0.0991 - val_loss: 0.0189 - val_mae: 0.0997\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0071 - mae: 0.0956 - val_loss: 0.0189 - val_mae: 0.0996\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0066 - mae: 0.0883 - val_loss: 0.0189 - val_mae: 0.0994\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0073 - mae: 0.0952 - val_loss: 0.0189 - val_mae: 0.0993\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0068 - mae: 0.0899 - val_loss: 0.0188 - val_mae: 0.0992\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0872 - val_loss: 0.0188 - val_mae: 0.0991\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0868 - val_loss: 0.0188 - val_mae: 0.0990\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0889 - val_loss: 0.0188 - val_mae: 0.0990\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0057 - mae: 0.0830 - val_loss: 0.0188 - val_mae: 0.0989\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0062 - mae: 0.0869 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - mae: 0.0869 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0787 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0860 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0836 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0065 - mae: 0.0869 - val_loss: 0.0186 - val_mae: 0.0988\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0059 - mae: 0.0840 - val_loss: 0.0186 - val_mae: 0.0988\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - mae: 0.0802 - val_loss: 0.0186 - val_mae: 0.0987\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0066 - mae: 0.0881 - val_loss: 0.0186 - val_mae: 0.0986\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0899 - val_loss: 0.0186 - val_mae: 0.0985\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0065 - mae: 0.0903 - val_loss: 0.0186 - val_mae: 0.0984\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0868 - val_loss: 0.0186 - val_mae: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:13,940] Trial 2 finished with value: 0.09827699512243271 and parameters: {'learning_rate': 8.184076241648664e-05, 'weight_decay': 4.822966418376956e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0534 - mae: 0.2611 - val_loss: 0.0410 - val_mae: 0.2294\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0456 - mae: 0.2423 - val_loss: 0.0172 - val_mae: 0.1052\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0835 - val_loss: 0.0194 - val_mae: 0.0874\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0192 - val_mae: 0.0845\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0188 - val_mae: 0.0842\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0182 - val_mae: 0.0860\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0888\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0718 - val_loss: 0.0176 - val_mae: 0.0933\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0929\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0688 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0866\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0906\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0162 - val_mae: 0.0961\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0158 - val_mae: 0.0992\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0156 - val_mae: 0.0951\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0155 - val_mae: 0.0909\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0870\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0152 - val_mae: 0.0856\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0545 - val_loss: 0.0149 - val_mae: 0.0878\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0147 - val_mae: 0.0938\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0147 - val_mae: 0.0915\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0147 - val_mae: 0.0888\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0148 - val_mae: 0.0884\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0512 - val_loss: 0.0149 - val_mae: 0.0877\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0148 - val_mae: 0.0897\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0146 - val_mae: 0.0903\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0145 - val_mae: 0.0903\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0143 - val_mae: 0.0903\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0143 - val_mae: 0.0881\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0145 - val_mae: 0.0855\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0146 - val_mae: 0.0855\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.0904\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0146 - val_mae: 0.0925\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0496 - val_loss: 0.0148 - val_mae: 0.0923\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0147 - val_mae: 0.0959\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0152 - val_mae: 0.0884\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0157 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0143 - val_mae: 0.0939\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0140 - val_mae: 0.0972\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0144 - val_mae: 0.0886\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0144 - val_mae: 0.0913\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0143 - val_mae: 0.0930\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0145 - val_mae: 0.0898\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0148 - val_mae: 0.0861\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0145 - val_mae: 0.0884\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0142 - val_mae: 0.0941\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0141 - val_mae: 0.1056\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0143 - val_mae: 0.1044\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0410 - val_loss: 0.0147 - val_mae: 0.0909\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0158 - val_mae: 0.0821\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0414 - val_loss: 0.0157 - val_mae: 0.0824\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0151 - val_mae: 0.0846\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0144 - val_mae: 0.0902\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0142 - val_mae: 0.0966\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0151 - val_mae: 0.0896\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0160 - val_mae: 0.0887\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0161 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0158 - val_mae: 0.0884\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0150 - val_mae: 0.0899\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0441 - val_loss: 0.0146 - val_mae: 0.0926\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0919\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0491 - val_loss: 0.0151 - val_mae: 0.0821\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0159 - val_mae: 0.0788\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0389 - val_loss: 0.0162 - val_mae: 0.0801\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0158 - val_mae: 0.0837\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0152 - val_mae: 0.0879\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 0.0148 - val_mae: 0.0937\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0147 - val_mae: 0.0976\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0147 - val_mae: 0.0924\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0442 - val_loss: 0.0148 - val_mae: 0.0874\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0149 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0417 - val_loss: 0.0150 - val_mae: 0.0839\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.0152 - val_mae: 0.0857\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0153 - val_mae: 0.0871\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0155 - val_mae: 0.0864\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.9650e-04 - mae: 0.0340 - val_loss: 0.0157 - val_mae: 0.0860\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0405 - val_loss: 0.0156 - val_mae: 0.0889\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0156 - val_mae: 0.0948\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0156 - val_mae: 0.1002\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0449 - val_loss: 0.0155 - val_mae: 0.1000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0153 - val_mae: 0.0964\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0150 - val_mae: 0.0933\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0150 - val_mae: 0.0867\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0153 - val_mae: 0.0818\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0154 - val_mae: 0.0821\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0154 - val_mae: 0.0845\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0155 - val_mae: 0.0888\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0155 - val_mae: 0.0878\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0155 - val_mae: 0.0849\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - mae: 0.0370 - val_loss: 0.0155 - val_mae: 0.0828\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0154 - val_mae: 0.0855\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0155 - val_mae: 0.0888\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0734e-04 - mae: 0.0291 - val_loss: 0.0153 - val_mae: 0.0886\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0151 - val_mae: 0.0873\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0155 - val_mae: 0.0866\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0154 - val_mae: 0.0851\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 0.0151 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0401 - val_loss: 0.0151 - val_mae: 0.0850\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.0153 - val_mae: 0.0858\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 0.0160 - val_mae: 0.0874\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.5995e-04 - mae: 0.0325 - val_loss: 0.0162 - val_mae: 0.0881\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0164 - val_mae: 0.0853\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0407 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0153 - val_mae: 0.0818\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0584e-04 - mae: 0.0314 - val_loss: 0.0150 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0147 - val_mae: 0.0851\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0010 - mae: 0.0342 - val_loss: 0.0146 - val_mae: 0.0883\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 0.0143 - val_mae: 0.0912\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5716e-04 - mae: 0.0334 - val_loss: 0.0145 - val_mae: 0.0925\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0155 - val_mae: 0.0890\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0160 - val_mae: 0.0867\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.0860\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 0.0160 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6734e-04 - mae: 0.0315 - val_loss: 0.0157 - val_mae: 0.0839\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4555e-04 - mae: 0.0292 - val_loss: 0.0155 - val_mae: 0.0849\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.1791e-04 - mae: 0.0292 - val_loss: 0.0156 - val_mae: 0.0870\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7401e-04 - mae: 0.0282 - val_loss: 0.0157 - val_mae: 0.0869\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.4249e-04 - mae: 0.0310 - val_loss: 0.0156 - val_mae: 0.0840\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.3223e-04 - mae: 0.0307 - val_loss: 0.0155 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.9203e-04 - mae: 0.0326 - val_loss: 0.0153 - val_mae: 0.0835\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0319 - val_loss: 0.0152 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0369 - val_loss: 0.0153 - val_mae: 0.0870\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.8086e-04 - mae: 0.0302 - val_loss: 0.0155 - val_mae: 0.0889\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.2615e-04 - mae: 0.0313 - val_loss: 0.0157 - val_mae: 0.0907\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0159 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.4576e-04 - mae: 0.0248 - val_loss: 0.0161 - val_mae: 0.0816\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0826e-04 - mae: 0.0309 - val_loss: 0.0163 - val_mae: 0.0799\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1577e-04 - mae: 0.0273 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0156 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 0.0148 - val_mae: 0.0819\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.5525e-04 - mae: 0.0324 - val_loss: 0.0147 - val_mae: 0.0862\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.5865e-04 - mae: 0.0322 - val_loss: 0.0148 - val_mae: 0.0886\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.8138e-04 - mae: 0.0307 - val_loss: 0.0152 - val_mae: 0.0881\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0159 - val_mae: 0.0883\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.7982e-04 - mae: 0.0284 - val_loss: 0.0163 - val_mae: 0.0881\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.4630e-04 - mae: 0.0284 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.0576e-04 - mae: 0.0286 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.9681e-04 - mae: 0.0273 - val_loss: 0.0156 - val_mae: 0.0832\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.3356e-04 - mae: 0.0267 - val_loss: 0.0154 - val_mae: 0.0828\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.2626e-04 - mae: 0.0269 - val_loss: 0.0152 - val_mae: 0.0834\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7851e-04 - mae: 0.0285 - val_loss: 0.0154 - val_mae: 0.0847\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.2351e-04 - mae: 0.0282 - val_loss: 0.0157 - val_mae: 0.0861\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5528e-04 - mae: 0.0246 - val_loss: 0.0158 - val_mae: 0.0888\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0158 - val_mae: 0.0878\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.0166e-04 - mae: 0.0315 - val_loss: 0.0155 - val_mae: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:25,280] Trial 3 finished with value: 0.08510519564151764 and parameters: {'learning_rate': 0.003630024147729035, 'weight_decay': 0.000312443332199213}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0547 - mae: 0.2608 - val_loss: 0.0310 - val_mae: 0.1710\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0379 - mae: 0.2123 - val_loss: 0.0272 - val_mae: 0.1556\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0478 - mae: 0.2415 - val_loss: 0.0244 - val_mae: 0.1419\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0333 - mae: 0.2098 - val_loss: 0.0225 - val_mae: 0.1315\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0323 - mae: 0.1944 - val_loss: 0.0212 - val_mae: 0.1242\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0286 - mae: 0.1853 - val_loss: 0.0206 - val_mae: 0.1196\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0254 - mae: 0.1759 - val_loss: 0.0204 - val_mae: 0.1165\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0223 - mae: 0.1623 - val_loss: 0.0204 - val_mae: 0.1142\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1611 - val_loss: 0.0205 - val_mae: 0.1130\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0200 - mae: 0.1572 - val_loss: 0.0205 - val_mae: 0.1118\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0182 - mae: 0.1493 - val_loss: 0.0206 - val_mae: 0.1105\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0183 - mae: 0.1510 - val_loss: 0.0206 - val_mae: 0.1091\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0179 - mae: 0.1458 - val_loss: 0.0205 - val_mae: 0.1076\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0137 - mae: 0.1276 - val_loss: 0.0204 - val_mae: 0.1060\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0143 - mae: 0.1320 - val_loss: 0.0202 - val_mae: 0.1048\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0133 - mae: 0.1287 - val_loss: 0.0200 - val_mae: 0.1034\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0170 - mae: 0.1394 - val_loss: 0.0197 - val_mae: 0.1019\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0163 - mae: 0.1426 - val_loss: 0.0194 - val_mae: 0.1002\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0192 - val_mae: 0.0985\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0133 - mae: 0.1294 - val_loss: 0.0190 - val_mae: 0.0969\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0119 - mae: 0.1193 - val_loss: 0.0189 - val_mae: 0.0956\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0125 - mae: 0.1202 - val_loss: 0.0187 - val_mae: 0.0944\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0118 - mae: 0.1183 - val_loss: 0.0186 - val_mae: 0.0934\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0111 - mae: 0.1190 - val_loss: 0.0185 - val_mae: 0.0925\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0106 - mae: 0.1175 - val_loss: 0.0184 - val_mae: 0.0917\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0113 - mae: 0.1170 - val_loss: 0.0183 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1058 - val_loss: 0.0183 - val_mae: 0.0905\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0093 - mae: 0.1085 - val_loss: 0.0182 - val_mae: 0.0901\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0182 - val_mae: 0.0901\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1087 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0110 - mae: 0.1120 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0181 - val_mae: 0.0901\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - mae: 0.0996 - val_loss: 0.0181 - val_mae: 0.0899\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0960 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0948 - val_loss: 0.0180 - val_mae: 0.0903\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0942 - val_loss: 0.0180 - val_mae: 0.0906\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0072 - mae: 0.0925 - val_loss: 0.0179 - val_mae: 0.0910\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0907 - val_loss: 0.0179 - val_mae: 0.0913\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0076 - mae: 0.0930 - val_loss: 0.0179 - val_mae: 0.0916\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0071 - mae: 0.0903 - val_loss: 0.0179 - val_mae: 0.0919\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0896 - val_loss: 0.0178 - val_mae: 0.0920\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0876 - val_loss: 0.0178 - val_mae: 0.0921\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0062 - mae: 0.0865 - val_loss: 0.0177 - val_mae: 0.0920\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - mae: 0.0865 - val_loss: 0.0177 - val_mae: 0.0918\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0851 - val_loss: 0.0176 - val_mae: 0.0916\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0868 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0059 - mae: 0.0825 - val_loss: 0.0176 - val_mae: 0.0912\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0059 - mae: 0.0812 - val_loss: 0.0175 - val_mae: 0.0909\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0052 - mae: 0.0776 - val_loss: 0.0175 - val_mae: 0.0906\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0061 - mae: 0.0846 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0794 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0833 - val_loss: 0.0174 - val_mae: 0.0896\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - mae: 0.0793 - val_loss: 0.0173 - val_mae: 0.0894\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0770 - val_loss: 0.0173 - val_mae: 0.0891\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0051 - mae: 0.0752 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0705 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0050 - mae: 0.0733 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0704 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0723 - val_loss: 0.0171 - val_mae: 0.0889\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0774 - val_loss: 0.0171 - val_mae: 0.0887\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.0886\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0724 - val_loss: 0.0171 - val_mae: 0.0883\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0171 - val_mae: 0.0881\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0880\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0719 - val_loss: 0.0171 - val_mae: 0.0881\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0735 - val_loss: 0.0171 - val_mae: 0.0883\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0171 - val_mae: 0.0889\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0655 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0038 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - mae: 0.0714 - val_loss: 0.0171 - val_mae: 0.0895\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0706 - val_loss: 0.0171 - val_mae: 0.0899\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0171 - val_mae: 0.0903\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - mae: 0.0702 - val_loss: 0.0171 - val_mae: 0.0906\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - mae: 0.0728 - val_loss: 0.0171 - val_mae: 0.0909\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0672 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0723 - val_loss: 0.0169 - val_mae: 0.0914\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0661 - val_loss: 0.0169 - val_mae: 0.0912\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - mae: 0.0691 - val_loss: 0.0169 - val_mae: 0.0911\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0169 - val_mae: 0.0910\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0648 - val_loss: 0.0168 - val_mae: 0.0909\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - mae: 0.0689 - val_loss: 0.0168 - val_mae: 0.0907\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0632 - val_loss: 0.0168 - val_mae: 0.0905\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0901\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0899\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0167 - val_mae: 0.0898\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0897\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0898\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0900\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0902\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0904\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0905\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0906\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0165 - val_mae: 0.0908\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0165 - val_mae: 0.0910\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0165 - val_mae: 0.0912\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0595 - val_loss: 0.0165 - val_mae: 0.0912\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0165 - val_mae: 0.0914\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0916\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0918\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0918\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0165 - val_mae: 0.0917\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0166 - val_mae: 0.0915\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0559 - val_loss: 0.0166 - val_mae: 0.0915\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0166 - val_mae: 0.0917\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0166 - val_mae: 0.0919\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0921\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - mae: 0.0587 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0166 - val_mae: 0.0925\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0166 - val_mae: 0.0926\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0165 - val_mae: 0.0926\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.0927\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0165 - val_mae: 0.0928\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.0930\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0165 - val_mae: 0.0933\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0165 - val_mae: 0.0939\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0165 - val_mae: 0.0943\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0947\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0165 - val_mae: 0.0951\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0573 - val_loss: 0.0165 - val_mae: 0.0954\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0165 - val_mae: 0.0955\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0957\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0165 - val_mae: 0.0960\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - mae: 0.0523 - val_loss: 0.0165 - val_mae: 0.0963\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0967\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0165 - val_mae: 0.0970\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0024 - mae: 0.0533 - val_loss: 0.0165 - val_mae: 0.0971\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0973\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.0972\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0510 - val_loss: 0.0164 - val_mae: 0.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:37,179] Trial 4 finished with value: 0.09693402051925659 and parameters: {'learning_rate': 0.00017596799005821075, 'weight_decay': 7.223387288213484e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0963 - mae: 0.3558 - val_loss: 0.0520 - val_mae: 0.2416\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0843 - mae: 0.3243 - val_loss: 0.0512 - val_mae: 0.2394\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0879 - mae: 0.3303 - val_loss: 0.0504 - val_mae: 0.2371\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0827 - mae: 0.3227 - val_loss: 0.0496 - val_mae: 0.2348\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0941 - mae: 0.3552 - val_loss: 0.0488 - val_mae: 0.2324\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0847 - mae: 0.3231 - val_loss: 0.0480 - val_mae: 0.2301\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0762 - mae: 0.2953 - val_loss: 0.0472 - val_mae: 0.2278\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0727 - mae: 0.3036 - val_loss: 0.0464 - val_mae: 0.2255\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0710 - mae: 0.3038 - val_loss: 0.0457 - val_mae: 0.2233\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0807 - mae: 0.3156 - val_loss: 0.0450 - val_mae: 0.2212\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0552 - mae: 0.2661 - val_loss: 0.0443 - val_mae: 0.2191\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0792 - mae: 0.3185 - val_loss: 0.0436 - val_mae: 0.2169\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0703 - mae: 0.2999 - val_loss: 0.0429 - val_mae: 0.2149\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0759 - mae: 0.3051 - val_loss: 0.0422 - val_mae: 0.2128\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0610 - mae: 0.2803 - val_loss: 0.0415 - val_mae: 0.2107\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0740 - mae: 0.3112 - val_loss: 0.0409 - val_mae: 0.2088\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0661 - mae: 0.2797 - val_loss: 0.0403 - val_mae: 0.2068\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0677 - mae: 0.2915 - val_loss: 0.0397 - val_mae: 0.2049\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0644 - mae: 0.2860 - val_loss: 0.0391 - val_mae: 0.2030\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0719 - mae: 0.2975 - val_loss: 0.0386 - val_mae: 0.2011\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0632 - mae: 0.2690 - val_loss: 0.0380 - val_mae: 0.1992\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0585 - mae: 0.2723 - val_loss: 0.0375 - val_mae: 0.1974\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0704 - mae: 0.3038 - val_loss: 0.0370 - val_mae: 0.1957\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0621 - mae: 0.2732 - val_loss: 0.0365 - val_mae: 0.1939\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0525 - mae: 0.2618 - val_loss: 0.0360 - val_mae: 0.1921\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0649 - mae: 0.2821 - val_loss: 0.0355 - val_mae: 0.1904\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0629 - mae: 0.2763 - val_loss: 0.0351 - val_mae: 0.1887\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0501 - mae: 0.2551 - val_loss: 0.0346 - val_mae: 0.1870\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0564 - mae: 0.2534 - val_loss: 0.0342 - val_mae: 0.1854\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0559 - mae: 0.2631 - val_loss: 0.0338 - val_mae: 0.1838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0635 - mae: 0.2691 - val_loss: 0.0334 - val_mae: 0.1823\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0489 - mae: 0.2479 - val_loss: 0.0330 - val_mae: 0.1808\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0563 - mae: 0.2698 - val_loss: 0.0326 - val_mae: 0.1793\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0591 - mae: 0.2676 - val_loss: 0.0323 - val_mae: 0.1778\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0611 - mae: 0.2768 - val_loss: 0.0319 - val_mae: 0.1763\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0494 - mae: 0.2485 - val_loss: 0.0316 - val_mae: 0.1749\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0540 - mae: 0.2622 - val_loss: 0.0312 - val_mae: 0.1734\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0476 - mae: 0.2409 - val_loss: 0.0309 - val_mae: 0.1720\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0563 - mae: 0.2641 - val_loss: 0.0306 - val_mae: 0.1706\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0512 - mae: 0.2450 - val_loss: 0.0303 - val_mae: 0.1692\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0569 - mae: 0.2705 - val_loss: 0.0300 - val_mae: 0.1678\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0514 - mae: 0.2552 - val_loss: 0.0297 - val_mae: 0.1664\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0425 - mae: 0.2330 - val_loss: 0.0294 - val_mae: 0.1651\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0465 - mae: 0.2453 - val_loss: 0.0291 - val_mae: 0.1637\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0480 - mae: 0.2490 - val_loss: 0.0289 - val_mae: 0.1624\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0478 - mae: 0.2366 - val_loss: 0.0286 - val_mae: 0.1611\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0518 - mae: 0.2566 - val_loss: 0.0284 - val_mae: 0.1598\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0471 - mae: 0.2481 - val_loss: 0.0281 - val_mae: 0.1586\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0422 - mae: 0.2269 - val_loss: 0.0279 - val_mae: 0.1574\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0546 - mae: 0.2616 - val_loss: 0.0276 - val_mae: 0.1562\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0475 - mae: 0.2450 - val_loss: 0.0274 - val_mae: 0.1550\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0421 - mae: 0.2330 - val_loss: 0.0272 - val_mae: 0.1539\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0399 - mae: 0.2214 - val_loss: 0.0270 - val_mae: 0.1529\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0488 - mae: 0.2468 - val_loss: 0.0268 - val_mae: 0.1518\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0417 - mae: 0.2203 - val_loss: 0.0266 - val_mae: 0.1508\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0505 - mae: 0.2533 - val_loss: 0.0264 - val_mae: 0.1498\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0506 - mae: 0.2455 - val_loss: 0.0262 - val_mae: 0.1488\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0391 - mae: 0.2165 - val_loss: 0.0260 - val_mae: 0.1479\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0417 - mae: 0.2203 - val_loss: 0.0258 - val_mae: 0.1469\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0379 - mae: 0.2160 - val_loss: 0.0257 - val_mae: 0.1460\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0377 - mae: 0.2214 - val_loss: 0.0255 - val_mae: 0.1451\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0388 - mae: 0.2215 - val_loss: 0.0253 - val_mae: 0.1442\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0380 - mae: 0.2226 - val_loss: 0.0252 - val_mae: 0.1433\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0335 - mae: 0.2042 - val_loss: 0.0250 - val_mae: 0.1424\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0432 - mae: 0.2307 - val_loss: 0.0249 - val_mae: 0.1416\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0410 - mae: 0.2339 - val_loss: 0.0247 - val_mae: 0.1408\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0353 - mae: 0.2101 - val_loss: 0.0246 - val_mae: 0.1400\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0392 - mae: 0.2249 - val_loss: 0.0244 - val_mae: 0.1392\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0349 - mae: 0.2048 - val_loss: 0.0243 - val_mae: 0.1384\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0349 - mae: 0.2067 - val_loss: 0.0242 - val_mae: 0.1376\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0388 - mae: 0.2264 - val_loss: 0.0241 - val_mae: 0.1369\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0431 - mae: 0.2289 - val_loss: 0.0239 - val_mae: 0.1362\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0463 - mae: 0.2342 - val_loss: 0.0238 - val_mae: 0.1355\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0315 - mae: 0.2005 - val_loss: 0.0237 - val_mae: 0.1347\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0361 - mae: 0.2153 - val_loss: 0.0236 - val_mae: 0.1340\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0380 - mae: 0.2137 - val_loss: 0.0235 - val_mae: 0.1333\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0320 - mae: 0.2013 - val_loss: 0.0233 - val_mae: 0.1326\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0338 - mae: 0.2037 - val_loss: 0.0232 - val_mae: 0.1319\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0401 - mae: 0.2292 - val_loss: 0.0231 - val_mae: 0.1311\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0444 - mae: 0.2310 - val_loss: 0.0230 - val_mae: 0.1305\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0348 - mae: 0.2127 - val_loss: 0.0229 - val_mae: 0.1298\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0319 - mae: 0.1967 - val_loss: 0.0228 - val_mae: 0.1292\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0354 - mae: 0.2094 - val_loss: 0.0227 - val_mae: 0.1286\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0345 - mae: 0.2034 - val_loss: 0.0226 - val_mae: 0.1281\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0415 - mae: 0.2268 - val_loss: 0.0225 - val_mae: 0.1276\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0357 - mae: 0.2096 - val_loss: 0.0225 - val_mae: 0.1271\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0380 - mae: 0.2186 - val_loss: 0.0224 - val_mae: 0.1266\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0334 - mae: 0.2071 - val_loss: 0.0223 - val_mae: 0.1261\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0362 - mae: 0.2101 - val_loss: 0.0222 - val_mae: 0.1255\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0282 - mae: 0.1845 - val_loss: 0.0221 - val_mae: 0.1250\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0419 - mae: 0.2278 - val_loss: 0.0220 - val_mae: 0.1245\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - mae: 0.2030 - val_loss: 0.0220 - val_mae: 0.1239\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0306 - mae: 0.1997 - val_loss: 0.0219 - val_mae: 0.1234\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0321 - mae: 0.1980 - val_loss: 0.0218 - val_mae: 0.1229\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0459 - mae: 0.2367 - val_loss: 0.0217 - val_mae: 0.1223\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0343 - mae: 0.2088 - val_loss: 0.0216 - val_mae: 0.1218\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0370 - mae: 0.2168 - val_loss: 0.0215 - val_mae: 0.1213\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0388 - mae: 0.2188 - val_loss: 0.0215 - val_mae: 0.1207\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0331 - mae: 0.1970 - val_loss: 0.0214 - val_mae: 0.1202\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - mae: 0.2005 - val_loss: 0.0213 - val_mae: 0.1197\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0381 - mae: 0.2143 - val_loss: 0.0212 - val_mae: 0.1191\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0346 - mae: 0.2114 - val_loss: 0.0212 - val_mae: 0.1187\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0308 - mae: 0.1950 - val_loss: 0.0211 - val_mae: 0.1182\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0324 - mae: 0.2009 - val_loss: 0.0210 - val_mae: 0.1177\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0299 - mae: 0.1976 - val_loss: 0.0209 - val_mae: 0.1173\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - mae: 0.1982 - val_loss: 0.0209 - val_mae: 0.1169\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0303 - mae: 0.1942 - val_loss: 0.0208 - val_mae: 0.1165\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0293 - mae: 0.1925 - val_loss: 0.0208 - val_mae: 0.1160\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0273 - mae: 0.1877 - val_loss: 0.0207 - val_mae: 0.1156\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0331 - mae: 0.2023 - val_loss: 0.0207 - val_mae: 0.1153\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0326 - mae: 0.2050 - val_loss: 0.0206 - val_mae: 0.1149\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0318 - mae: 0.1991 - val_loss: 0.0206 - val_mae: 0.1146\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.2008 - val_loss: 0.0205 - val_mae: 0.1143\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0302 - mae: 0.2004 - val_loss: 0.0204 - val_mae: 0.1140\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0313 - mae: 0.1996 - val_loss: 0.0204 - val_mae: 0.1137\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0275 - mae: 0.1872 - val_loss: 0.0203 - val_mae: 0.1134\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0332 - mae: 0.2039 - val_loss: 0.0203 - val_mae: 0.1131\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0290 - mae: 0.1919 - val_loss: 0.0202 - val_mae: 0.1128\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0314 - mae: 0.1970 - val_loss: 0.0202 - val_mae: 0.1125\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0319 - mae: 0.2041 - val_loss: 0.0201 - val_mae: 0.1122\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0293 - mae: 0.1910 - val_loss: 0.0201 - val_mae: 0.1119\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0264 - mae: 0.1789 - val_loss: 0.0201 - val_mae: 0.1117\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0302 - mae: 0.1963 - val_loss: 0.0200 - val_mae: 0.1115\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0265 - mae: 0.1839 - val_loss: 0.0200 - val_mae: 0.1113\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0311 - mae: 0.1963 - val_loss: 0.0200 - val_mae: 0.1111\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0313 - mae: 0.1941 - val_loss: 0.0200 - val_mae: 0.1109\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0267 - mae: 0.1838 - val_loss: 0.0199 - val_mae: 0.1107\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0314 - mae: 0.2025 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0254 - mae: 0.1751 - val_loss: 0.0199 - val_mae: 0.1103\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0246 - mae: 0.1741 - val_loss: 0.0199 - val_mae: 0.1101\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.1979 - val_loss: 0.0199 - val_mae: 0.1100\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0275 - mae: 0.1890 - val_loss: 0.0199 - val_mae: 0.1098\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0256 - mae: 0.1816 - val_loss: 0.0198 - val_mae: 0.1096\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0267 - mae: 0.1824 - val_loss: 0.0198 - val_mae: 0.1094\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0284 - mae: 0.1883 - val_loss: 0.0198 - val_mae: 0.1092\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0267 - mae: 0.1872 - val_loss: 0.0198 - val_mae: 0.1091\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0314 - mae: 0.2004 - val_loss: 0.0197 - val_mae: 0.1090\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0236 - mae: 0.1726 - val_loss: 0.0197 - val_mae: 0.1088\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0277 - mae: 0.1967 - val_loss: 0.0197 - val_mae: 0.1087\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0234 - mae: 0.1779 - val_loss: 0.0197 - val_mae: 0.1085\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0322 - mae: 0.1957 - val_loss: 0.0197 - val_mae: 0.1084\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0285 - mae: 0.1846 - val_loss: 0.0196 - val_mae: 0.1082\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - mae: 0.1836 - val_loss: 0.0196 - val_mae: 0.1081\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0253 - mae: 0.1791 - val_loss: 0.0196 - val_mae: 0.1080\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0313 - mae: 0.1971 - val_loss: 0.0196 - val_mae: 0.1079\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0313 - mae: 0.1954 - val_loss: 0.0196 - val_mae: 0.1077\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0324 - mae: 0.1935 - val_loss: 0.0195 - val_mae: 0.1076\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0267 - mae: 0.1789 - val_loss: 0.0195 - val_mae: 0.1075\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0285 - mae: 0.1854 - val_loss: 0.0195 - val_mae: 0.1074\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0247 - mae: 0.1748 - val_loss: 0.0195 - val_mae: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:48,311] Trial 5 finished with value: 0.10726500302553177 and parameters: {'learning_rate': 1.4198047141564276e-05, 'weight_decay': 5.9621886024668284e-05}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0779 - mae: 0.3096 - val_loss: 0.0482 - val_mae: 0.2300\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0649 - mae: 0.2962 - val_loss: 0.0480 - val_mae: 0.2291\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0649 - mae: 0.2913 - val_loss: 0.0477 - val_mae: 0.2282\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0731 - mae: 0.3073 - val_loss: 0.0474 - val_mae: 0.2273\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0711 - mae: 0.3013 - val_loss: 0.0471 - val_mae: 0.2263\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0696 - mae: 0.2870 - val_loss: 0.0469 - val_mae: 0.2254\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0759 - mae: 0.3015 - val_loss: 0.0466 - val_mae: 0.2245\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0657 - mae: 0.2853 - val_loss: 0.0463 - val_mae: 0.2236\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0634 - mae: 0.2815 - val_loss: 0.0460 - val_mae: 0.2226\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0679 - mae: 0.2853 - val_loss: 0.0458 - val_mae: 0.2217\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0624 - mae: 0.2895 - val_loss: 0.0455 - val_mae: 0.2207\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0680 - mae: 0.2967 - val_loss: 0.0453 - val_mae: 0.2198\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0601 - mae: 0.2715 - val_loss: 0.0450 - val_mae: 0.2189\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0776 - mae: 0.3061 - val_loss: 0.0447 - val_mae: 0.2179\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0680 - mae: 0.2838 - val_loss: 0.0445 - val_mae: 0.2170\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0808 - mae: 0.3190 - val_loss: 0.0442 - val_mae: 0.2160\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0698 - mae: 0.2793 - val_loss: 0.0439 - val_mae: 0.2151\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0740 - mae: 0.3102 - val_loss: 0.0437 - val_mae: 0.2142\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0704 - mae: 0.2972 - val_loss: 0.0434 - val_mae: 0.2132\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0572 - mae: 0.2676 - val_loss: 0.0432 - val_mae: 0.2123\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0630 - mae: 0.2835 - val_loss: 0.0429 - val_mae: 0.2114\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0755 - mae: 0.3115 - val_loss: 0.0427 - val_mae: 0.2105\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0664 - mae: 0.2941 - val_loss: 0.0424 - val_mae: 0.2096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0658 - mae: 0.2868 - val_loss: 0.0422 - val_mae: 0.2087\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0651 - mae: 0.2825 - val_loss: 0.0419 - val_mae: 0.2078\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0639 - mae: 0.2895 - val_loss: 0.0417 - val_mae: 0.2068\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0677 - mae: 0.2855 - val_loss: 0.0414 - val_mae: 0.2060\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0601 - mae: 0.2716 - val_loss: 0.0412 - val_mae: 0.2051\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0641 - mae: 0.2818 - val_loss: 0.0409 - val_mae: 0.2042\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0583 - mae: 0.2714 - val_loss: 0.0407 - val_mae: 0.2034\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0662 - mae: 0.2885 - val_loss: 0.0405 - val_mae: 0.2025\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0526 - mae: 0.2529 - val_loss: 0.0403 - val_mae: 0.2017\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0613 - mae: 0.2757 - val_loss: 0.0400 - val_mae: 0.2009\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0592 - mae: 0.2689 - val_loss: 0.0398 - val_mae: 0.2000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0615 - mae: 0.2823 - val_loss: 0.0396 - val_mae: 0.1992\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0570 - mae: 0.2710 - val_loss: 0.0394 - val_mae: 0.1984\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0646 - mae: 0.2847 - val_loss: 0.0391 - val_mae: 0.1976\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0509 - mae: 0.2509 - val_loss: 0.0389 - val_mae: 0.1968\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0631 - mae: 0.2914 - val_loss: 0.0387 - val_mae: 0.1960\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0653 - mae: 0.2871 - val_loss: 0.0385 - val_mae: 0.1952\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0598 - mae: 0.2776 - val_loss: 0.0383 - val_mae: 0.1944\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0583 - mae: 0.2676 - val_loss: 0.0381 - val_mae: 0.1936\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0670 - mae: 0.2905 - val_loss: 0.0379 - val_mae: 0.1928\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0625 - mae: 0.2746 - val_loss: 0.0376 - val_mae: 0.1920\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0548 - mae: 0.2578 - val_loss: 0.0374 - val_mae: 0.1913\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0616 - mae: 0.2824 - val_loss: 0.0372 - val_mae: 0.1905\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0574 - mae: 0.2677 - val_loss: 0.0370 - val_mae: 0.1897\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0573 - mae: 0.2754 - val_loss: 0.0369 - val_mae: 0.1890\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0501 - mae: 0.2492 - val_loss: 0.0367 - val_mae: 0.1882\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0532 - mae: 0.2617 - val_loss: 0.0365 - val_mae: 0.1875\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0597 - mae: 0.2764 - val_loss: 0.0363 - val_mae: 0.1867\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0485 - mae: 0.2528 - val_loss: 0.0361 - val_mae: 0.1860\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0578 - mae: 0.2668 - val_loss: 0.0359 - val_mae: 0.1852\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0607 - mae: 0.2786 - val_loss: 0.0357 - val_mae: 0.1845\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0491 - mae: 0.2535 - val_loss: 0.0355 - val_mae: 0.1838\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0622 - mae: 0.2669 - val_loss: 0.0353 - val_mae: 0.1830\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0645 - mae: 0.2836 - val_loss: 0.0352 - val_mae: 0.1823\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0536 - mae: 0.2652 - val_loss: 0.0350 - val_mae: 0.1815\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0601 - mae: 0.2708 - val_loss: 0.0348 - val_mae: 0.1808\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0558 - mae: 0.2621 - val_loss: 0.0346 - val_mae: 0.1801\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0580 - mae: 0.2668 - val_loss: 0.0345 - val_mae: 0.1794\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0462 - mae: 0.2368 - val_loss: 0.0343 - val_mae: 0.1786\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0470 - mae: 0.2399 - val_loss: 0.0341 - val_mae: 0.1779\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0546 - mae: 0.2594 - val_loss: 0.0340 - val_mae: 0.1772\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0527 - mae: 0.2611 - val_loss: 0.0338 - val_mae: 0.1765\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0469 - mae: 0.2476 - val_loss: 0.0336 - val_mae: 0.1758\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0522 - mae: 0.2545 - val_loss: 0.0335 - val_mae: 0.1751\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0461 - mae: 0.2455 - val_loss: 0.0333 - val_mae: 0.1744\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0509 - mae: 0.2504 - val_loss: 0.0332 - val_mae: 0.1738\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0532 - mae: 0.2584 - val_loss: 0.0330 - val_mae: 0.1732\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0475 - mae: 0.2426 - val_loss: 0.0329 - val_mae: 0.1725\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0443 - mae: 0.2337 - val_loss: 0.0327 - val_mae: 0.1719\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0603 - mae: 0.2720 - val_loss: 0.0326 - val_mae: 0.1713\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0513 - mae: 0.2477 - val_loss: 0.0324 - val_mae: 0.1706\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0553 - mae: 0.2636 - val_loss: 0.0323 - val_mae: 0.1700\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0503 - mae: 0.2468 - val_loss: 0.0322 - val_mae: 0.1694\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0490 - mae: 0.2442 - val_loss: 0.0320 - val_mae: 0.1687\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0571 - mae: 0.2697 - val_loss: 0.0319 - val_mae: 0.1681\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0460 - mae: 0.2359 - val_loss: 0.0317 - val_mae: 0.1675\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0511 - mae: 0.2462 - val_loss: 0.0316 - val_mae: 0.1668\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0547 - mae: 0.2633 - val_loss: 0.0315 - val_mae: 0.1662\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0553 - mae: 0.2574 - val_loss: 0.0313 - val_mae: 0.1656\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0543 - mae: 0.2578 - val_loss: 0.0312 - val_mae: 0.1650\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0495 - mae: 0.2505 - val_loss: 0.0311 - val_mae: 0.1643\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0405 - mae: 0.2340 - val_loss: 0.0309 - val_mae: 0.1637\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0456 - mae: 0.2251 - val_loss: 0.0308 - val_mae: 0.1631\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0589 - mae: 0.2760 - val_loss: 0.0307 - val_mae: 0.1625\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0578 - mae: 0.2739 - val_loss: 0.0306 - val_mae: 0.1619\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0458 - mae: 0.2446 - val_loss: 0.0304 - val_mae: 0.1613\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0532 - mae: 0.2521 - val_loss: 0.0303 - val_mae: 0.1608\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0522 - mae: 0.2607 - val_loss: 0.0302 - val_mae: 0.1602\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0555 - mae: 0.2649 - val_loss: 0.0301 - val_mae: 0.1597\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0528 - mae: 0.2546 - val_loss: 0.0300 - val_mae: 0.1591\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0453 - mae: 0.2339 - val_loss: 0.0298 - val_mae: 0.1586\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0398 - mae: 0.2231 - val_loss: 0.0297 - val_mae: 0.1581\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0436 - mae: 0.2286 - val_loss: 0.0296 - val_mae: 0.1575\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0470 - mae: 0.2458 - val_loss: 0.0295 - val_mae: 0.1570\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0463 - mae: 0.2354 - val_loss: 0.0294 - val_mae: 0.1565\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0433 - mae: 0.2283 - val_loss: 0.0293 - val_mae: 0.1560\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0473 - mae: 0.2490 - val_loss: 0.0292 - val_mae: 0.1555\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0463 - mae: 0.2365 - val_loss: 0.0290 - val_mae: 0.1550\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0519 - mae: 0.2464 - val_loss: 0.0289 - val_mae: 0.1546\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0516 - mae: 0.2565 - val_loss: 0.0288 - val_mae: 0.1541\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0502 - mae: 0.2442 - val_loss: 0.0287 - val_mae: 0.1536\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0429 - mae: 0.2301 - val_loss: 0.0286 - val_mae: 0.1531\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0448 - mae: 0.2401 - val_loss: 0.0285 - val_mae: 0.1527\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0439 - mae: 0.2312 - val_loss: 0.0284 - val_mae: 0.1522\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0486 - mae: 0.2315 - val_loss: 0.0283 - val_mae: 0.1517\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2301 - val_loss: 0.0282 - val_mae: 0.1513\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0423 - mae: 0.2397 - val_loss: 0.0281 - val_mae: 0.1508\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0430 - mae: 0.2279 - val_loss: 0.0280 - val_mae: 0.1504\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0470 - mae: 0.2440 - val_loss: 0.0279 - val_mae: 0.1499\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0492 - mae: 0.2485 - val_loss: 0.0278 - val_mae: 0.1495\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0427 - mae: 0.2277 - val_loss: 0.0278 - val_mae: 0.1490\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0512 - mae: 0.2443 - val_loss: 0.0277 - val_mae: 0.1486\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0373 - mae: 0.2208 - val_loss: 0.0276 - val_mae: 0.1481\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0395 - mae: 0.2247 - val_loss: 0.0275 - val_mae: 0.1477\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0499 - mae: 0.2507 - val_loss: 0.0274 - val_mae: 0.1472\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0412 - mae: 0.2248 - val_loss: 0.0273 - val_mae: 0.1468\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0403 - mae: 0.2298 - val_loss: 0.0272 - val_mae: 0.1464\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0401 - mae: 0.2179 - val_loss: 0.0271 - val_mae: 0.1459\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0434 - mae: 0.2279 - val_loss: 0.0271 - val_mae: 0.1455\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0382 - mae: 0.2163 - val_loss: 0.0270 - val_mae: 0.1451\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0432 - mae: 0.2258 - val_loss: 0.0269 - val_mae: 0.1446\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0463 - mae: 0.2355 - val_loss: 0.0268 - val_mae: 0.1442\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0381 - mae: 0.2132 - val_loss: 0.0267 - val_mae: 0.1437\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0432 - mae: 0.2273 - val_loss: 0.0267 - val_mae: 0.1433\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0390 - mae: 0.2203 - val_loss: 0.0266 - val_mae: 0.1429\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0407 - mae: 0.2153 - val_loss: 0.0265 - val_mae: 0.1425\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0384 - mae: 0.2216 - val_loss: 0.0264 - val_mae: 0.1420\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0485 - mae: 0.2528 - val_loss: 0.0264 - val_mae: 0.1416\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0415 - mae: 0.2260 - val_loss: 0.0263 - val_mae: 0.1412\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0454 - mae: 0.2440 - val_loss: 0.0262 - val_mae: 0.1408\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0365 - mae: 0.2119 - val_loss: 0.0261 - val_mae: 0.1404\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0416 - mae: 0.2262 - val_loss: 0.0261 - val_mae: 0.1401\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0427 - mae: 0.2304 - val_loss: 0.0260 - val_mae: 0.1397\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0491 - mae: 0.2495 - val_loss: 0.0259 - val_mae: 0.1393\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0401 - mae: 0.2216 - val_loss: 0.0258 - val_mae: 0.1389\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0443 - mae: 0.2301 - val_loss: 0.0258 - val_mae: 0.1385\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0425 - mae: 0.2289 - val_loss: 0.0257 - val_mae: 0.1381\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0393 - mae: 0.2224 - val_loss: 0.0256 - val_mae: 0.1377\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0401 - mae: 0.2221 - val_loss: 0.0255 - val_mae: 0.1373\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0382 - mae: 0.2226 - val_loss: 0.0255 - val_mae: 0.1368\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0456 - mae: 0.2413 - val_loss: 0.0254 - val_mae: 0.1364\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0410 - mae: 0.2230 - val_loss: 0.0253 - val_mae: 0.1360\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0314 - mae: 0.2048 - val_loss: 0.0253 - val_mae: 0.1356\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0397 - mae: 0.2212 - val_loss: 0.0252 - val_mae: 0.1353\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0370 - mae: 0.2217 - val_loss: 0.0251 - val_mae: 0.1349\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0383 - mae: 0.2137 - val_loss: 0.0251 - val_mae: 0.1346\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0357 - mae: 0.2165 - val_loss: 0.0250 - val_mae: 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:59,681] Trial 6 finished with value: 0.13425305485725403 and parameters: {'learning_rate': 5.1964494607677525e-06, 'weight_decay': 1.0486107471664106e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1062 - mae: 0.3705 - val_loss: 1.5243 - val_mae: 1.9996\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8264 - mae: 2.2930 - val_loss: 0.0635 - val_mae: 0.2880\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0838 - mae: 0.3260 - val_loss: 0.0300 - val_mae: 0.1425\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0191 - mae: 0.1566 - val_loss: 0.0252 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0115 - mae: 0.1190 - val_loss: 0.0211 - val_mae: 0.0966\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0918 - val_loss: 0.0205 - val_mae: 0.0931\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mae: 0.0770 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0060 - mae: 0.0794 - val_loss: 0.0219 - val_mae: 0.0997\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0198 - val_mae: 0.0906\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0713 - val_loss: 0.0187 - val_mae: 0.0982\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0847 - val_loss: 0.0196 - val_mae: 0.0855\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0218 - val_mae: 0.1035\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0744 - val_loss: 0.0197 - val_mae: 0.0844\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0630 - val_loss: 0.0194 - val_mae: 0.0817\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0634 - val_loss: 0.0191 - val_mae: 0.0836\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0666 - val_loss: 0.0188 - val_mae: 0.0853\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0185 - val_mae: 0.0868\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0181 - val_mae: 0.0872\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0865\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0305 - val_mae: 0.1862\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0214 - mae: 0.1595 - val_loss: 0.0177 - val_mae: 0.0961\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0755 - val_loss: 0.0183 - val_mae: 0.1086\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0813 - val_loss: 0.0182 - val_mae: 0.1076\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0843 - val_loss: 0.0179 - val_mae: 0.1061\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0825 - val_loss: 0.0173 - val_mae: 0.1012\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0046 - mae: 0.0785 - val_loss: 0.0168 - val_mae: 0.0941\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0717 - val_loss: 0.0164 - val_mae: 0.0886\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - mae: 0.0674 - val_loss: 0.0163 - val_mae: 0.0856\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0708 - val_loss: 0.0165 - val_mae: 0.0837\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0164 - val_mae: 0.0824\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0899\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0915\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0683 - val_loss: 0.0175 - val_mae: 0.0907\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0881\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0805\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0795\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0565 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0857\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0660 - val_loss: 0.0172 - val_mae: 0.0881\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0171 - val_mae: 0.0878\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0869\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:10,611] Trial 7 finished with value: 0.08398724347352982 and parameters: {'learning_rate': 0.014184182629741164, 'weight_decay': 0.005230149332101854}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1280 - mae: 0.4122 - val_loss: 0.0680 - val_mae: 0.2694\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1083 - mae: 0.3602 - val_loss: 0.0672 - val_mae: 0.2674\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1044 - mae: 0.3699 - val_loss: 0.0664 - val_mae: 0.2653\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1272 - mae: 0.4184 - val_loss: 0.0656 - val_mae: 0.2632\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1139 - mae: 0.3810 - val_loss: 0.0648 - val_mae: 0.2610\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1068 - mae: 0.3695 - val_loss: 0.0640 - val_mae: 0.2589\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1002 - mae: 0.3545 - val_loss: 0.0632 - val_mae: 0.2567\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1106 - mae: 0.3768 - val_loss: 0.0624 - val_mae: 0.2545\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1033 - mae: 0.3462 - val_loss: 0.0617 - val_mae: 0.2523\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0907 - mae: 0.3380 - val_loss: 0.0609 - val_mae: 0.2501\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0968 - mae: 0.3494 - val_loss: 0.0601 - val_mae: 0.2480\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0958 - mae: 0.3487 - val_loss: 0.0594 - val_mae: 0.2459\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1001 - mae: 0.3583 - val_loss: 0.0587 - val_mae: 0.2438\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1226 - mae: 0.3895 - val_loss: 0.0579 - val_mae: 0.2416\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0986 - mae: 0.3643 - val_loss: 0.0572 - val_mae: 0.2395\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1103 - mae: 0.3717 - val_loss: 0.0565 - val_mae: 0.2375\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0844 - mae: 0.3307 - val_loss: 0.0558 - val_mae: 0.2355\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1103 - mae: 0.3777 - val_loss: 0.0551 - val_mae: 0.2334\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1081 - mae: 0.3633 - val_loss: 0.0544 - val_mae: 0.2314\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1128 - mae: 0.3735 - val_loss: 0.0537 - val_mae: 0.2295\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0970 - mae: 0.3542 - val_loss: 0.0531 - val_mae: 0.2277\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0890 - mae: 0.3282 - val_loss: 0.0524 - val_mae: 0.2258\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0993 - mae: 0.3564 - val_loss: 0.0518 - val_mae: 0.2240\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0979 - mae: 0.3591 - val_loss: 0.0512 - val_mae: 0.2222\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1025 - mae: 0.3642 - val_loss: 0.0506 - val_mae: 0.2203\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0779 - mae: 0.3143 - val_loss: 0.0500 - val_mae: 0.2185\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0859 - mae: 0.3358 - val_loss: 0.0494 - val_mae: 0.2167\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0952 - mae: 0.3490 - val_loss: 0.0488 - val_mae: 0.2149\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0870 - mae: 0.3291 - val_loss: 0.0482 - val_mae: 0.2131\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0756 - mae: 0.3048 - val_loss: 0.0477 - val_mae: 0.2114\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0949 - mae: 0.3471 - val_loss: 0.0471 - val_mae: 0.2097\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0852 - mae: 0.3271 - val_loss: 0.0466 - val_mae: 0.2080\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0961 - mae: 0.3453 - val_loss: 0.0461 - val_mae: 0.2063\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0791 - mae: 0.3282 - val_loss: 0.0456 - val_mae: 0.2047\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0833 - mae: 0.3293 - val_loss: 0.0451 - val_mae: 0.2030\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0791 - mae: 0.3125 - val_loss: 0.0446 - val_mae: 0.2014\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0780 - mae: 0.3062 - val_loss: 0.0441 - val_mae: 0.1999\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0784 - mae: 0.3052 - val_loss: 0.0437 - val_mae: 0.1983\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0776 - mae: 0.3163 - val_loss: 0.0432 - val_mae: 0.1968\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0798 - mae: 0.3222 - val_loss: 0.0428 - val_mae: 0.1954\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0718 - mae: 0.3006 - val_loss: 0.0424 - val_mae: 0.1939\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0686 - mae: 0.2934 - val_loss: 0.0420 - val_mae: 0.1925\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0849 - mae: 0.3256 - val_loss: 0.0416 - val_mae: 0.1911\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0800 - mae: 0.3244 - val_loss: 0.0412 - val_mae: 0.1897\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0889 - mae: 0.3347 - val_loss: 0.0408 - val_mae: 0.1883\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0827 - mae: 0.3322 - val_loss: 0.0404 - val_mae: 0.1869\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0906 - mae: 0.3501 - val_loss: 0.0400 - val_mae: 0.1856\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0772 - mae: 0.3225 - val_loss: 0.0397 - val_mae: 0.1842\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0780 - mae: 0.3125 - val_loss: 0.0393 - val_mae: 0.1829\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0810 - mae: 0.3194 - val_loss: 0.0389 - val_mae: 0.1816\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0903 - mae: 0.3428 - val_loss: 0.0386 - val_mae: 0.1803\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0758 - mae: 0.3102 - val_loss: 0.0383 - val_mae: 0.1790\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0761 - mae: 0.3155 - val_loss: 0.0379 - val_mae: 0.1776\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0650 - mae: 0.2860 - val_loss: 0.0376 - val_mae: 0.1764\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0816 - mae: 0.3103 - val_loss: 0.0373 - val_mae: 0.1751\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0704 - mae: 0.2967 - val_loss: 0.0370 - val_mae: 0.1738\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0744 - mae: 0.3052 - val_loss: 0.0367 - val_mae: 0.1726\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0804 - mae: 0.3269 - val_loss: 0.0364 - val_mae: 0.1714\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0828 - mae: 0.3176 - val_loss: 0.0361 - val_mae: 0.1703\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0746 - mae: 0.2933 - val_loss: 0.0358 - val_mae: 0.1691\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0750 - mae: 0.3099 - val_loss: 0.0355 - val_mae: 0.1679\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0812 - mae: 0.3206 - val_loss: 0.0352 - val_mae: 0.1668\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0729 - mae: 0.3129 - val_loss: 0.0349 - val_mae: 0.1657\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0707 - mae: 0.2940 - val_loss: 0.0346 - val_mae: 0.1645\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0716 - mae: 0.2991 - val_loss: 0.0343 - val_mae: 0.1634\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0680 - mae: 0.2973 - val_loss: 0.0340 - val_mae: 0.1623\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0612 - mae: 0.2814 - val_loss: 0.0338 - val_mae: 0.1612\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0679 - mae: 0.2945 - val_loss: 0.0335 - val_mae: 0.1601\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0668 - mae: 0.2900 - val_loss: 0.0333 - val_mae: 0.1591\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0695 - mae: 0.2870 - val_loss: 0.0330 - val_mae: 0.1581\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0582 - mae: 0.2646 - val_loss: 0.0328 - val_mae: 0.1571\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0616 - mae: 0.2812 - val_loss: 0.0325 - val_mae: 0.1561\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0700 - mae: 0.3017 - val_loss: 0.0323 - val_mae: 0.1551\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0616 - mae: 0.2787 - val_loss: 0.0321 - val_mae: 0.1541\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0671 - mae: 0.2853 - val_loss: 0.0319 - val_mae: 0.1532\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0596 - mae: 0.2795 - val_loss: 0.0316 - val_mae: 0.1522\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0622 - mae: 0.2823 - val_loss: 0.0314 - val_mae: 0.1513\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0735 - mae: 0.3065 - val_loss: 0.0312 - val_mae: 0.1504\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0635 - mae: 0.2795 - val_loss: 0.0310 - val_mae: 0.1495\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2749 - val_loss: 0.0308 - val_mae: 0.1486\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0662 - mae: 0.2838 - val_loss: 0.0306 - val_mae: 0.1477\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0534 - mae: 0.2544 - val_loss: 0.0304 - val_mae: 0.1469\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0828 - mae: 0.3290 - val_loss: 0.0302 - val_mae: 0.1461\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0675 - mae: 0.2992 - val_loss: 0.0300 - val_mae: 0.1454\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0686 - mae: 0.2989 - val_loss: 0.0298 - val_mae: 0.1446\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0649 - mae: 0.2956 - val_loss: 0.0297 - val_mae: 0.1438\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0565 - mae: 0.2603 - val_loss: 0.0295 - val_mae: 0.1431\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0536 - mae: 0.2631 - val_loss: 0.0293 - val_mae: 0.1424\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0722 - mae: 0.3071 - val_loss: 0.0291 - val_mae: 0.1418\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0728 - mae: 0.3090 - val_loss: 0.0290 - val_mae: 0.1410\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0600 - mae: 0.2791 - val_loss: 0.0288 - val_mae: 0.1403\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0579 - mae: 0.2718 - val_loss: 0.0287 - val_mae: 0.1396\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0608 - mae: 0.2904 - val_loss: 0.0285 - val_mae: 0.1390\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0554 - mae: 0.2578 - val_loss: 0.0284 - val_mae: 0.1383\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0625 - mae: 0.2777 - val_loss: 0.0282 - val_mae: 0.1377\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0525 - mae: 0.2536 - val_loss: 0.0281 - val_mae: 0.1372\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0600 - mae: 0.2790 - val_loss: 0.0279 - val_mae: 0.1366\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0613 - mae: 0.2781 - val_loss: 0.0278 - val_mae: 0.1361\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0551 - mae: 0.2625 - val_loss: 0.0277 - val_mae: 0.1356\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0541 - mae: 0.2593 - val_loss: 0.0275 - val_mae: 0.1351\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0633 - mae: 0.2854 - val_loss: 0.0274 - val_mae: 0.1345\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0544 - mae: 0.2611 - val_loss: 0.0273 - val_mae: 0.1339\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0584 - mae: 0.2786 - val_loss: 0.0271 - val_mae: 0.1333\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0602 - mae: 0.2728 - val_loss: 0.0270 - val_mae: 0.1327\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0623 - mae: 0.2835 - val_loss: 0.0269 - val_mae: 0.1321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0490 - mae: 0.2462 - val_loss: 0.0267 - val_mae: 0.1315\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0558 - mae: 0.2694 - val_loss: 0.0266 - val_mae: 0.1310\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0554 - mae: 0.2739 - val_loss: 0.0265 - val_mae: 0.1305\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0525 - mae: 0.2659 - val_loss: 0.0263 - val_mae: 0.1300\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0554 - mae: 0.2656 - val_loss: 0.0262 - val_mae: 0.1295\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0541 - mae: 0.2641 - val_loss: 0.0261 - val_mae: 0.1290\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0604 - mae: 0.2775 - val_loss: 0.0259 - val_mae: 0.1285\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2733 - val_loss: 0.0258 - val_mae: 0.1281\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0635 - mae: 0.2840 - val_loss: 0.0257 - val_mae: 0.1276\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0585 - mae: 0.2707 - val_loss: 0.0256 - val_mae: 0.1271\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0603 - mae: 0.2846 - val_loss: 0.0255 - val_mae: 0.1267\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0529 - mae: 0.2594 - val_loss: 0.0254 - val_mae: 0.1262\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0613 - mae: 0.2813 - val_loss: 0.0253 - val_mae: 0.1257\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0532 - mae: 0.2652 - val_loss: 0.0252 - val_mae: 0.1252\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0534 - mae: 0.2563 - val_loss: 0.0251 - val_mae: 0.1247\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0626 - mae: 0.2752 - val_loss: 0.0250 - val_mae: 0.1243\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0533 - mae: 0.2634 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0483 - mae: 0.2409 - val_loss: 0.0248 - val_mae: 0.1235\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0619 - mae: 0.2803 - val_loss: 0.0247 - val_mae: 0.1231\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0604 - mae: 0.2747 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0522 - mae: 0.2580 - val_loss: 0.0246 - val_mae: 0.1224\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0550 - mae: 0.2568 - val_loss: 0.0245 - val_mae: 0.1220\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0447 - mae: 0.2404 - val_loss: 0.0244 - val_mae: 0.1217\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0522 - mae: 0.2591 - val_loss: 0.0243 - val_mae: 0.1214\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0522 - mae: 0.2580 - val_loss: 0.0242 - val_mae: 0.1210\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0541 - mae: 0.2671 - val_loss: 0.0242 - val_mae: 0.1206\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0595 - mae: 0.2750 - val_loss: 0.0241 - val_mae: 0.1203\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0484 - mae: 0.2490 - val_loss: 0.0240 - val_mae: 0.1199\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0416 - mae: 0.2360 - val_loss: 0.0239 - val_mae: 0.1196\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0623 - mae: 0.2877 - val_loss: 0.0238 - val_mae: 0.1192\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0524 - mae: 0.2535 - val_loss: 0.0237 - val_mae: 0.1188\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0596 - mae: 0.2739 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0472 - mae: 0.2404 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0548 - mae: 0.2718 - val_loss: 0.0234 - val_mae: 0.1177\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0454 - mae: 0.2365 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0532 - mae: 0.2636 - val_loss: 0.0233 - val_mae: 0.1170\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0552 - mae: 0.2608 - val_loss: 0.0232 - val_mae: 0.1167\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0472 - mae: 0.2383 - val_loss: 0.0232 - val_mae: 0.1163\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0506 - mae: 0.2535 - val_loss: 0.0231 - val_mae: 0.1160\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0421 - mae: 0.2259 - val_loss: 0.0230 - val_mae: 0.1157\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0583 - mae: 0.2675 - val_loss: 0.0230 - val_mae: 0.1153\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0521 - mae: 0.2593 - val_loss: 0.0229 - val_mae: 0.1150\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0511 - mae: 0.2540 - val_loss: 0.0228 - val_mae: 0.1147\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0452 - mae: 0.2469 - val_loss: 0.0228 - val_mae: 0.1144\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0500 - mae: 0.2484 - val_loss: 0.0227 - val_mae: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:21,584] Trial 8 finished with value: 0.11417494714260101 and parameters: {'learning_rate': 9.723330078432912e-06, 'weight_decay': 0.006508443549129702}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0577 - mae: 0.2716 - val_loss: 0.9041 - val_mae: 1.3223\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0780 - mae: 1.5172 - val_loss: 0.3775 - val_mae: 0.7531\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4531 - mae: 0.8440 - val_loss: 0.0386 - val_mae: 0.1921\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0256 - mae: 0.1799 - val_loss: 1.2638 - val_mae: 1.7166\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5144 - mae: 1.9834 - val_loss: 0.1351 - val_mae: 0.4643\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0939 - mae: 0.3779 - val_loss: 0.1173 - val_mae: 0.4360\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1504 - mae: 0.4936 - val_loss: 0.0260 - val_mae: 0.1139\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1060\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0073 - mae: 0.0881 - val_loss: 0.0239 - val_mae: 0.1014\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.0972\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0217 - val_mae: 0.0935\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0767 - val_loss: 0.0205 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0869\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0691 - val_loss: 0.0185 - val_mae: 0.0839\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0177 - val_mae: 0.0829\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0720 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0719 - val_loss: 0.0163 - val_mae: 0.0879\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0711 - val_loss: 0.0160 - val_mae: 0.0899\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0044 - mae: 0.0722 - val_loss: 0.0159 - val_mae: 0.0913\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0723 - val_loss: 0.0159 - val_mae: 0.0926\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0735 - val_loss: 0.0161 - val_mae: 0.0936\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0735 - val_loss: 0.0164 - val_mae: 0.0957\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0043 - mae: 0.0743 - val_loss: 0.0168 - val_mae: 0.0984\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0753 - val_loss: 0.0173 - val_mae: 0.1007\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0047 - mae: 0.0787 - val_loss: 0.0176 - val_mae: 0.1019\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0177 - val_mae: 0.1021\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0733 - val_loss: 0.0177 - val_mae: 0.1011\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0746 - val_loss: 0.0176 - val_mae: 0.0990\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0705 - val_loss: 0.0173 - val_mae: 0.0965\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0695 - val_loss: 0.0171 - val_mae: 0.0937\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0669 - val_loss: 0.0169 - val_mae: 0.0911\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - mae: 0.0677 - val_loss: 0.0168 - val_mae: 0.0884\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0637 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0585 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0824\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0173 - val_mae: 0.0856\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0853\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0831\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:32,995] Trial 9 finished with value: 0.08421843498945236 and parameters: {'learning_rate': 0.023987288201424622, 'weight_decay': 8.744533594516013e-09}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1150 - mae: 0.3878 - val_loss: 0.1797 - val_mae: 0.4984\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2460 - mae: 0.5834 - val_loss: 0.0543 - val_mae: 0.2495\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0716 - mae: 0.2905 - val_loss: 0.0282 - val_mae: 0.1518\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0209 - mae: 0.1603 - val_loss: 0.0235 - val_mae: 0.1187\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - mae: 0.1123 - val_loss: 0.0226 - val_mae: 0.1073\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0223 - val_mae: 0.1040\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1032\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0222 - val_mae: 0.1021\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.0994\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0219 - val_mae: 0.0974\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0066 - mae: 0.0815 - val_loss: 0.0214 - val_mae: 0.0949\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0785 - val_loss: 0.0207 - val_mae: 0.0920\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0194 - val_mae: 0.0892\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0815 - val_loss: 0.0189 - val_mae: 0.0879\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0049 - mae: 0.0712 - val_loss: 0.0187 - val_mae: 0.0862\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0702 - val_loss: 0.0185 - val_mae: 0.0848\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0182 - val_mae: 0.0837\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0179 - val_mae: 0.0814\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0797\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0795\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0790\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0789\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0160 - val_mae: 0.0792\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0529 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0779\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0157 - val_mae: 0.0783\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0152 - val_mae: 0.0797\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0153 - val_mae: 0.0792\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0158 - val_mae: 0.0779\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0508 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0511 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0154 - val_mae: 0.0781\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0150 - val_mae: 0.0783\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0155 - val_mae: 0.0779\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0155 - val_mae: 0.0777\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0155 - val_mae: 0.0772\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0152 - val_mae: 0.0770\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0149 - val_mae: 0.0770\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0145 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0146 - val_mae: 0.0777\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0147 - val_mae: 0.0772\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0504 - val_loss: 0.0147 - val_mae: 0.0767\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0146 - val_mae: 0.0770\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0493 - val_loss: 0.0146 - val_mae: 0.0772\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - mae: 0.0441 - val_loss: 0.0148 - val_mae: 0.0766\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0460 - val_loss: 0.0149 - val_mae: 0.0763\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0148 - val_mae: 0.0759\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0144 - val_mae: 0.0778\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0779\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0456 - val_loss: 0.0146 - val_mae: 0.0770\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0149 - val_mae: 0.0765\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0147 - val_mae: 0.0769\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0146 - val_mae: 0.0774\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0143 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0141 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0139 - val_mae: 0.0811\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0140 - val_mae: 0.0802\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0449 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0154 - val_mae: 0.0784\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0436 - val_loss: 0.0152 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0144 - val_mae: 0.0787\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0398 - val_loss: 0.0138 - val_mae: 0.0819\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0136 - val_mae: 0.0837\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0142 - val_mae: 0.0788\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0155 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0425 - val_loss: 0.0161 - val_mae: 0.0808\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0017 - mae: 0.0374 - val_loss: 0.0163 - val_mae: 0.0814\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0422 - val_loss: 0.0160 - val_mae: 0.0807\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0417 - val_loss: 0.0153 - val_mae: 0.0788\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0140 - val_mae: 0.0791\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0135 - val_mae: 0.0834\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0134 - val_mae: 0.0845\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0135 - val_mae: 0.0835\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0360 - val_loss: 0.0140 - val_mae: 0.0798\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0146 - val_mae: 0.0783\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0385 - val_loss: 0.0149 - val_mae: 0.0785\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0371 - val_loss: 0.0150 - val_mae: 0.0788\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0389 - val_loss: 0.0145 - val_mae: 0.0784\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0329 - val_loss: 0.0142 - val_mae: 0.0790\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0385 - val_loss: 0.0139 - val_mae: 0.0804\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0140 - val_mae: 0.0804\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0141 - val_mae: 0.0803\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0140 - val_mae: 0.0803\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0355 - val_loss: 0.0142 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0393 - val_loss: 0.0146 - val_mae: 0.0797\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0367 - val_loss: 0.0147 - val_mae: 0.0803\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0144 - val_mae: 0.0810\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0138 - val_mae: 0.0828\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0141 - val_mae: 0.0814\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0371 - val_loss: 0.0144 - val_mae: 0.0802\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0150 - val_mae: 0.0808\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0150 - val_mae: 0.0813\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0338 - val_loss: 0.0143 - val_mae: 0.0814\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.0140 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0380 - val_loss: 0.0140 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0442 - val_loss: 0.0144 - val_mae: 0.0803\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0146 - val_mae: 0.0801\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0144 - val_mae: 0.0803\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0340 - val_loss: 0.0141 - val_mae: 0.0812\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0138 - val_mae: 0.0824\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0141 - val_mae: 0.0819\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0368 - val_loss: 0.0141 - val_mae: 0.0823\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0323 - val_loss: 0.0142 - val_mae: 0.0823\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0144 - val_mae: 0.0820\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0328 - val_loss: 0.0144 - val_mae: 0.0823\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0014 - mae: 0.0352 - val_loss: 0.0145 - val_mae: 0.0827\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0366 - val_loss: 0.0144 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0365 - val_loss: 0.0143 - val_mae: 0.0832\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0141 - val_mae: 0.0831\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0345 - val_loss: 0.0147 - val_mae: 0.0823\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0014 - mae: 0.0345 - val_loss: 0.0152 - val_mae: 0.0829\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0152 - val_mae: 0.0826\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0379 - val_loss: 0.0145 - val_mae: 0.0816\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - mae: 0.0347 - val_loss: 0.0142 - val_mae: 0.0823\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0139 - val_mae: 0.0848\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0138 - val_mae: 0.0868\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0138 - val_mae: 0.0867\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0141 - val_mae: 0.0841\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0148 - val_mae: 0.0827\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0155 - val_mae: 0.0836\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0337 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0318 - val_loss: 0.0160 - val_mae: 0.0845\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0385 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.0153 - val_mae: 0.0832\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0379 - val_loss: 0.0142 - val_mae: 0.0830\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7203e-04 - mae: 0.0290 - val_loss: 0.0138 - val_mae: 0.0857\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - mae: 0.0386 - val_loss: 0.0143 - val_mae: 0.0831\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0339 - val_loss: 0.0150 - val_mae: 0.0831\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0348 - val_loss: 0.0153 - val_mae: 0.0841\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0371 - val_loss: 0.0150 - val_mae: 0.0838\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0340 - val_loss: 0.0144 - val_mae: 0.0840\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.0141 - val_mae: 0.0858\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0411 - val_loss: 0.0147 - val_mae: 0.0846\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - mae: 0.0336 - val_loss: 0.0156 - val_mae: 0.0859\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0158 - val_mae: 0.0863\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0156 - val_mae: 0.0852\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0418 - val_loss: 0.0150 - val_mae: 0.0832\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0142 - val_mae: 0.0847\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0350 - val_loss: 0.0139 - val_mae: 0.0867\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0138 - val_mae: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:43,908] Trial 10 finished with value: 0.08719658851623535 and parameters: {'learning_rate': 0.0031618314586241364, 'weight_decay': 0.004302204021535236}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0557 - mae: 0.2719 - val_loss: 2.4155 - val_mae: 2.9046\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.5804 - mae: 3.0568 - val_loss: 0.1307 - val_mae: 0.4471\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1478 - mae: 0.4526 - val_loss: 0.0511 - val_mae: 0.2507\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0636 - mae: 0.2854 - val_loss: 0.0323 - val_mae: 0.1698\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0184 - mae: 0.1540 - val_loss: 0.0270 - val_mae: 0.1373\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1103\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0228 - val_mae: 0.1041\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0216 - val_mae: 0.0968\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0065 - mae: 0.0808 - val_loss: 0.0206 - val_mae: 0.0970\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0059 - mae: 0.0787 - val_loss: 0.0201 - val_mae: 0.1028\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.1100\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0792 - val_loss: 0.0203 - val_mae: 0.1197\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0051 - mae: 0.0782 - val_loss: 0.0191 - val_mae: 0.1128\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - mae: 0.0775 - val_loss: 0.0171 - val_mae: 0.0931\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0721 - val_loss: 0.0173 - val_mae: 0.1015\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.1065\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0171 - val_mae: 0.1036\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0704 - val_loss: 0.0166 - val_mae: 0.0942\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0703 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0165 - val_mae: 0.0907\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0629 - val_loss: 0.0179 - val_mae: 0.1157\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0809 - val_loss: 0.0175 - val_mae: 0.1100\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0756 - val_loss: 0.0167 - val_mae: 0.0886\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0730 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0998\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0993\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0929\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0919\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0665 - val_loss: 0.0169 - val_mae: 0.0951\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0965\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0969\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0984\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.1000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0956\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0895\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.1011\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.1014\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0999\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0955\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0932\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0898\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0882\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0170 - val_mae: 0.0889\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0906\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0170 - val_mae: 0.0963\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0170 - val_mae: 0.1021\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.1000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0974\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0692 - val_loss: 0.0169 - val_mae: 0.0977\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0984\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0672 - val_loss: 0.0168 - val_mae: 0.0993\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0710 - val_loss: 0.0167 - val_mae: 0.0970\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0681 - val_loss: 0.0167 - val_mae: 0.0925\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0541 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0166 - val_mae: 0.0873\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0898\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0877\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0527 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0168 - val_mae: 0.0924\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0934\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0169 - val_mae: 0.0935\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0508 - val_loss: 0.0169 - val_mae: 0.0938\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0949\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0170 - val_mae: 0.0957\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0971\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0988\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0994\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.0973\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0949\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0918\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0167 - val_mae: 0.0926\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0970\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0166 - val_mae: 0.0943\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0166 - val_mae: 0.0929\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0166 - val_mae: 0.0923\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0166 - val_mae: 0.0929\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0950\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0964\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.0985\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0981\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0170 - val_mae: 0.0954\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0170 - val_mae: 0.0945\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0943\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0957\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0171 - val_mae: 0.1003\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.1020\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0982\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0166 - val_mae: 0.0945\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0166 - val_mae: 0.0937\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0166 - val_mae: 0.0946\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0987\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0170 - val_mae: 0.1030\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0998\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0167 - val_mae: 0.0960\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0167 - val_mae: 0.0935\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0168 - val_mae: 0.0948\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0169 - val_mae: 0.0959\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0965\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0171 - val_mae: 0.0955\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0171 - val_mae: 0.0950\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0171 - val_mae: 0.0950\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0171 - val_mae: 0.0934\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0924\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0171 - val_mae: 0.0943\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0172 - val_mae: 0.0987\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0173 - val_mae: 0.1021\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0994\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0962\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0167 - val_mae: 0.0949\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.0970\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.1014\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0168 - val_mae: 0.1014\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0167 - val_mae: 0.0983\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0958\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0167 - val_mae: 0.0941\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0942\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0526 - val_loss: 0.0168 - val_mae: 0.0980\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0998\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0969\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0170 - val_mae: 0.0944\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.0932\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0171 - val_mae: 0.0928\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0173 - val_mae: 0.0997\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0997\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0172 - val_mae: 0.0966\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0539 - val_loss: 0.0172 - val_mae: 0.0966\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0172 - val_mae: 0.0967\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0173 - val_mae: 0.0967\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.0968\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0174 - val_mae: 0.1019\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0175 - val_mae: 0.1040\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.1001\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:54,915] Trial 11 finished with value: 0.09484092891216278 and parameters: {'learning_rate': 0.020044232494369173, 'weight_decay': 7.740953401860817e-09}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0445 - mae: 0.2293 - val_loss: 1.9428 - val_mae: 2.3706\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2644 - mae: 2.7229 - val_loss: 0.3995 - val_mae: 0.8313\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5026 - mae: 0.9245 - val_loss: 0.0725 - val_mae: 0.2917\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1012 - mae: 0.3625 - val_loss: 0.0332 - val_mae: 0.1811\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0305 - mae: 0.1900 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0159 - mae: 0.1334 - val_loss: 0.0222 - val_mae: 0.1045\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0193 - val_mae: 0.0887\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - mae: 0.0856 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0785 - val_loss: 0.0180 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0048 - mae: 0.0697 - val_loss: 0.0186 - val_mae: 0.0957\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0894 - val_loss: 0.0190 - val_mae: 0.1207\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0074 - mae: 0.1001 - val_loss: 0.0179 - val_mae: 0.1071\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0049 - mae: 0.0789 - val_loss: 0.0169 - val_mae: 0.0892\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0816 - val_loss: 0.0173 - val_mae: 0.0891\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0764 - val_loss: 0.0178 - val_mae: 0.0967\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0055 - mae: 0.0821 - val_loss: 0.0179 - val_mae: 0.1001\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - mae: 0.0861 - val_loss: 0.0170 - val_mae: 0.0874\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0733 - val_loss: 0.0170 - val_mae: 0.0892\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0055 - mae: 0.0792 - val_loss: 0.0184 - val_mae: 0.1144\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.1012 - val_loss: 0.0172 - val_mae: 0.1005\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0053 - mae: 0.0817 - val_loss: 0.0175 - val_mae: 0.0902\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0058 - mae: 0.0839 - val_loss: 0.0171 - val_mae: 0.0861\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0656 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0177 - val_mae: 0.0970\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0766 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0831\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0047 - mae: 0.0707 - val_loss: 0.0183 - val_mae: 0.0856\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0707 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0885\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0871\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0171 - val_mae: 0.0861\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0665 - val_loss: 0.0173 - val_mae: 0.0889\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0716 - val_loss: 0.0169 - val_mae: 0.0884\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0699 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - mae: 0.0674 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0710 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0707 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0169 - val_mae: 0.0879\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0662 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0166 - val_mae: 0.0876\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0869\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0881\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0884\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0895\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0914\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0910\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0903\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0907\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0917\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0925\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0913\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0168 - val_mae: 0.0898\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0890\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0896\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0916\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0927\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0930\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0924\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0168 - val_mae: 0.0919\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0925\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0947\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0967\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0169 - val_mae: 0.0976\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0981\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0958\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0551 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0958\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0170 - val_mae: 0.0972\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0992\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0981\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0172 - val_mae: 0.0967\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0972\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0995\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.1006\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0994\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0174 - val_mae: 0.0990\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0175 - val_mae: 0.0992\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0173 - val_mae: 0.1004\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.1010\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0174 - val_mae: 0.1015\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0173 - val_mae: 0.0998\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0173 - val_mae: 0.0994\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0995\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0174 - val_mae: 0.0990\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0173 - val_mae: 0.0983\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0550 - val_loss: 0.0171 - val_mae: 0.0982\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.0993\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0171 - val_mae: 0.0984\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0170 - val_mae: 0.0971\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0172 - val_mae: 0.0973\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0985\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0511 - val_loss: 0.0171 - val_mae: 0.1000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.1008\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0994\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0173 - val_mae: 0.0989\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - mae: 0.0535 - val_loss: 0.0174 - val_mae: 0.0987\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0174 - val_mae: 0.0983\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0495 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0172 - val_mae: 0.0985\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0173 - val_mae: 0.0984\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0173 - val_mae: 0.0978\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0976\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0970\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0173 - val_mae: 0.0974\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0174 - val_mae: 0.0982\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0174 - val_mae: 0.0974\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0175 - val_mae: 0.0973\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0179 - val_mae: 0.0981\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0177 - val_mae: 0.0973\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0490 - val_loss: 0.0175 - val_mae: 0.0986\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0180 - val_mae: 0.1044\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0595 - val_loss: 0.0176 - val_mae: 0.0999\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0578 - val_loss: 0.0175 - val_mae: 0.0967\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0497 - val_loss: 0.0179 - val_mae: 0.0982\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0960\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0990\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0587 - val_loss: 0.0175 - val_mae: 0.1028\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0954\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0952\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0187 - val_mae: 0.1024\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0185 - val_mae: 0.1008\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0958\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0982\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0965\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0558 - val_loss: 0.0178 - val_mae: 0.0974\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0026 - mae: 0.0534 - val_loss: 0.0177 - val_mae: 0.0955\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0172 - val_mae: 0.0931\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0929\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0523 - val_loss: 0.0171 - val_mae: 0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:06,648] Trial 12 finished with value: 0.09233224391937256 and parameters: {'learning_rate': 0.02287608448294248, 'weight_decay': 0.005543414928351051}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0572 - mae: 0.2693 - val_loss: 0.0904 - val_mae: 0.3380\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0917 - mae: 0.3289 - val_loss: 0.0193 - val_mae: 0.1032\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0231 - val_mae: 0.1065\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0827 - val_loss: 0.0213 - val_mae: 0.0941\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0203 - val_mae: 0.0892\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0195 - val_mae: 0.0894\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0813 - val_loss: 0.0189 - val_mae: 0.0884\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - mae: 0.0806 - val_loss: 0.0186 - val_mae: 0.0851\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0185 - val_mae: 0.0837\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0184 - val_mae: 0.0835\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0182 - val_mae: 0.0835\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0180 - val_mae: 0.0837\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0860\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0683 - val_loss: 0.0174 - val_mae: 0.0877\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0655 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0896\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0601 - val_loss: 0.0164 - val_mae: 0.0955\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0801\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0803\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0816\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0161 - val_mae: 0.0851\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0612 - val_loss: 0.0157 - val_mae: 0.0959\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0655 - val_loss: 0.0157 - val_mae: 0.0905\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0668 - val_loss: 0.0162 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0156 - val_mae: 0.0910\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0650 - val_loss: 0.0155 - val_mae: 0.0948\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0639 - val_loss: 0.0156 - val_mae: 0.0878\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0161 - val_mae: 0.0821\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0155 - val_mae: 0.0886\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0029 - mae: 0.0587 - val_loss: 0.0154 - val_mae: 0.0898\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0575 - val_loss: 0.0153 - val_mae: 0.0918\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0618 - val_loss: 0.0154 - val_mae: 0.0880\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0579 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0157 - val_mae: 0.0820\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0156 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0153 - val_mae: 0.0872\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0559 - val_loss: 0.0152 - val_mae: 0.0904\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0152 - val_mae: 0.0899\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0587 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0157 - val_mae: 0.0796\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0156 - val_mae: 0.0807\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0152 - val_mae: 0.0873\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0519 - val_loss: 0.0152 - val_mae: 0.0982\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0549 - val_loss: 0.0150 - val_mae: 0.0942\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0152 - val_mae: 0.0836\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0154 - val_mae: 0.0791\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0512 - val_loss: 0.0151 - val_mae: 0.0813\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0148 - val_mae: 0.0909\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0541 - val_loss: 0.0148 - val_mae: 0.0883\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0506 - val_loss: 0.0149 - val_mae: 0.0835\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0149 - val_mae: 0.0834\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0148 - val_mae: 0.0855\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0496 - val_loss: 0.0147 - val_mae: 0.0901\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0497 - val_loss: 0.0148 - val_mae: 0.0919\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0147 - val_mae: 0.0904\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0147 - val_mae: 0.0867\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - mae: 0.0495 - val_loss: 0.0147 - val_mae: 0.0848\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0146 - val_mae: 0.0861\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0516 - val_loss: 0.0145 - val_mae: 0.0899\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0144 - val_mae: 0.0889\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0143 - val_mae: 0.0863\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0437 - val_loss: 0.0143 - val_mae: 0.0904\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0143 - val_mae: 0.0941\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0142 - val_mae: 0.0896\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0142 - val_mae: 0.0849\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0142 - val_mae: 0.0847\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0143 - val_mae: 0.0942\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0143 - val_mae: 0.0905\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0144 - val_mae: 0.0843\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0450 - val_loss: 0.0145 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0147 - val_mae: 0.0969\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0499 - val_loss: 0.0146 - val_mae: 0.0946\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0145 - val_mae: 0.0880\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0144 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0144 - val_mae: 0.0913\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0142 - val_mae: 0.0898\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0019 - mae: 0.0443 - val_loss: 0.0143 - val_mae: 0.0960\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0147 - val_mae: 0.1022\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0145 - val_mae: 0.0964\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0144 - val_mae: 0.0919\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0412 - val_loss: 0.0145 - val_mae: 0.0913\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0145 - val_mae: 0.0936\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0146 - val_mae: 0.0970\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0144 - val_mae: 0.0974\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0138 - val_mae: 0.0867\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0138 - val_mae: 0.0910\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0137 - val_mae: 0.0889\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0139 - val_mae: 0.0953\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0137 - val_mae: 0.0914\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0138 - val_mae: 0.0929\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0143 - val_mae: 0.1002\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0139 - val_mae: 0.0913\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0143 - val_mae: 0.0940\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0144 - val_mae: 0.0950\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0150 - val_mae: 0.1015\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0942\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0138 - val_mae: 0.0874\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0442 - val_loss: 0.0139 - val_mae: 0.0923\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0148 - val_mae: 0.1044\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0435 - val_loss: 0.0167 - val_mae: 0.1214\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0141 - val_mae: 0.0957\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0412 - val_loss: 0.0137 - val_mae: 0.0879\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0139 - val_mae: 0.0904\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0374 - val_loss: 0.0149 - val_mae: 0.1032\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0393 - val_loss: 0.0165 - val_mae: 0.1161\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0147 - val_mae: 0.0966\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0441 - val_loss: 0.0143 - val_mae: 0.0792\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0473 - val_loss: 0.0146 - val_mae: 0.0768\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0471 - val_loss: 0.0143 - val_mae: 0.0855\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0162 - val_mae: 0.1088\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0166 - val_mae: 0.1104\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0153 - val_mae: 0.0952\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0148 - val_mae: 0.0858\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0405 - val_loss: 0.0149 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0456 - val_loss: 0.0154 - val_mae: 0.0918\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0161 - val_mae: 0.0987\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.1041\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0463 - val_loss: 0.0165 - val_mae: 0.1022\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0447 - val_loss: 0.0160 - val_mae: 0.0968\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0368 - val_loss: 0.0156 - val_mae: 0.0921\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0154 - val_mae: 0.0903\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.0154 - val_mae: 0.0918\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0156 - val_mae: 0.0949\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0389 - val_loss: 0.0161 - val_mae: 0.1011\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0426 - val_loss: 0.0157 - val_mae: 0.0981\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0410 - val_loss: 0.0155 - val_mae: 0.0966\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0453 - val_loss: 0.0152 - val_mae: 0.0942\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0154 - val_mae: 0.0972\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0422 - val_loss: 0.0160 - val_mae: 0.1036\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - mae: 0.0417 - val_loss: 0.0163 - val_mae: 0.1059\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0160 - val_mae: 0.1032\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.6676e-04 - mae: 0.0342 - val_loss: 0.0149 - val_mae: 0.0920\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0145 - val_mae: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:17,676] Trial 13 finished with value: 0.08677712082862854 and parameters: {'learning_rate': 0.004268080954194253, 'weight_decay': 2.9168736693655427e-08}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - mae: 0.2696 - val_loss: 0.1955 - val_mae: 0.5337\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2288 - mae: 0.5750 - val_loss: 0.0328 - val_mae: 0.1664\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0227 - mae: 0.1695 - val_loss: 0.0274 - val_mae: 0.1473\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0159 - mae: 0.1398 - val_loss: 0.0231 - val_mae: 0.1166\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0232 - val_mae: 0.1090\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0213 - val_mae: 0.0948\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0191 - val_mae: 0.0938\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - mae: 0.0848 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0168 - val_mae: 0.0915\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0716 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0674 - val_loss: 0.0162 - val_mae: 0.0890\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0160 - val_mae: 0.0842\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0582 - val_loss: 0.0153 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0606 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0155 - val_mae: 0.0878\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0158 - val_mae: 0.0887\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0157 - val_mae: 0.0958\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0154 - val_mae: 0.0836\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0148 - val_mae: 0.0932\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0646 - val_loss: 0.0159 - val_mae: 0.0816\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0578 - val_loss: 0.0158 - val_mae: 0.0813\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0151 - val_mae: 0.0861\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0149 - val_mae: 0.0945\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0648 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0547 - val_loss: 0.0160 - val_mae: 0.0811\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0160 - val_mae: 0.0811\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0570 - val_loss: 0.0153 - val_mae: 0.0835\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0531 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0504 - val_loss: 0.0148 - val_mae: 0.0875\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - mae: 0.0563 - val_loss: 0.0146 - val_mae: 0.0892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0559 - val_loss: 0.0148 - val_mae: 0.0840\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0149 - val_mae: 0.0816\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0147 - val_mae: 0.0829\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0143 - val_mae: 0.0875\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0149 - val_mae: 0.0799\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0153 - val_mae: 0.0787\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0150 - val_mae: 0.0794\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0144 - val_mae: 0.0839\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0141 - val_mae: 0.0911\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0159 - val_mae: 0.0786\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0510 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0149 - val_mae: 0.0799\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0144 - val_mae: 0.0953\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0145 - val_mae: 0.0860\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0145 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0153 - val_mae: 0.0776\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0154 - val_mae: 0.0776\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0149 - val_mae: 0.0800\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0147 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.0858\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0147 - val_mae: 0.0924\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0147 - val_mae: 0.0890\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0162 - val_mae: 0.0817\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - mae: 0.0495 - val_loss: 0.0156 - val_mae: 0.0824\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0473 - val_loss: 0.0149 - val_mae: 0.0903\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0151 - val_mae: 0.0871\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0151 - val_mae: 0.0874\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0475 - val_loss: 0.0151 - val_mae: 0.0871\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0151 - val_mae: 0.0872\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0150 - val_mae: 0.0863\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0156 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0453 - val_loss: 0.0152 - val_mae: 0.0820\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0445 - val_loss: 0.0147 - val_mae: 0.0879\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0148 - val_mae: 0.0849\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0154 - val_mae: 0.0794\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0401 - val_loss: 0.0160 - val_mae: 0.0785\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0463 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0151 - val_mae: 0.0801\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0150 - val_mae: 0.0834\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0152 - val_mae: 0.0810\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0155 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0155 - val_mae: 0.0808\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0163 - val_mae: 0.0806\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0548 - val_loss: 0.0164 - val_mae: 0.0805\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0465 - val_loss: 0.0155 - val_mae: 0.0815\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0152 - val_mae: 0.0866\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0152 - val_mae: 0.0842\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0159 - val_mae: 0.0813\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0814\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0441 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0152 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0151 - val_mae: 0.0905\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0153 - val_mae: 0.0824\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0157 - val_mae: 0.0811\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0455 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0151 - val_mae: 0.0849\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0026 - mae: 0.0512 - val_loss: 0.0150 - val_mae: 0.0856\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0155 - val_mae: 0.0817\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0456 - val_loss: 0.0162 - val_mae: 0.0810\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0506 - val_loss: 0.0160 - val_mae: 0.0817\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0151 - val_mae: 0.0863\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0444 - val_loss: 0.0163 - val_mae: 0.0809\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0444 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0510 - val_loss: 0.0158 - val_mae: 0.0802\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0476 - val_loss: 0.0151 - val_mae: 0.0831\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0023 - mae: 0.0462 - val_loss: 0.0148 - val_mae: 0.0899\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0147 - val_mae: 0.0903\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0147 - val_mae: 0.0873\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0158 - val_mae: 0.0823\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0163 - val_mae: 0.0816\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0163 - val_mae: 0.0827\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0159 - val_mae: 0.0851\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0147 - val_mae: 0.0914\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0493 - val_loss: 0.0146 - val_mae: 0.0967\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0521 - val_loss: 0.0150 - val_mae: 0.0871\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0161 - val_mae: 0.0839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0155 - val_mae: 0.0825\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0169 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0023 - mae: 0.0464 - val_loss: 0.0158 - val_mae: 0.0811\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0154 - val_mae: 0.0824\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - mae: 0.0413 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - mae: 0.0507 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0445 - val_loss: 0.0152 - val_mae: 0.0834\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0419 - val_loss: 0.0152 - val_mae: 0.0839\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0155 - val_mae: 0.0822\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0456 - val_loss: 0.0157 - val_mae: 0.0821\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0370 - val_loss: 0.0158 - val_mae: 0.0816\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0154 - val_mae: 0.0818\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0153 - val_mae: 0.0821\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0014 - mae: 0.0393 - val_loss: 0.0160 - val_mae: 0.0807\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - mae: 0.0423 - val_loss: 0.0163 - val_mae: 0.0802\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0156 - val_mae: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:28,806] Trial 14 finished with value: 0.08045151829719543 and parameters: {'learning_rate': 0.006547253161581226, 'weight_decay': 7.622534278615785e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1125 - mae: 0.3892 - val_loss: 1.4176 - val_mae: 1.8714\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7655 - mae: 2.2012 - val_loss: 0.1602 - val_mae: 0.4591\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1732 - mae: 0.4910 - val_loss: 0.0674 - val_mae: 0.2943\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0663 - mae: 0.2961 - val_loss: 0.0703 - val_mae: 0.2943\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0797 - mae: 0.3258 - val_loss: 0.0726 - val_mae: 0.3541\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0627 - mae: 0.3180 - val_loss: 0.0318 - val_mae: 0.1874\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - mae: 0.1868 - val_loss: 0.0301 - val_mae: 0.1790\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0313 - mae: 0.1915 - val_loss: 0.0259 - val_mae: 0.1485\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0122 - mae: 0.1247 - val_loss: 0.0245 - val_mae: 0.1405\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0216 - val_mae: 0.1182\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0990 - val_loss: 0.0188 - val_mae: 0.0893\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0180 - val_mae: 0.0879\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0711 - val_loss: 0.0195 - val_mae: 0.1104\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.1308\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0995 - val_loss: 0.0207 - val_mae: 0.1282\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.1034 - val_loss: 0.0182 - val_mae: 0.1068\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0061 - mae: 0.0902 - val_loss: 0.0166 - val_mae: 0.0916\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0731 - val_loss: 0.0177 - val_mae: 0.1016\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0781 - val_loss: 0.0200 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0995 - val_loss: 0.0199 - val_mae: 0.1207\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0082 - mae: 0.1017 - val_loss: 0.0177 - val_mae: 0.1029\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0870 - val_loss: 0.0169 - val_mae: 0.0947\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0765 - val_loss: 0.0179 - val_mae: 0.1008\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0053 - mae: 0.0814 - val_loss: 0.0198 - val_mae: 0.1158\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0963 - val_loss: 0.0187 - val_mae: 0.1042\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0055 - mae: 0.0825 - val_loss: 0.2936 - val_mae: 0.7344\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3212 - mae: 0.7591 - val_loss: 0.0303 - val_mae: 0.1895\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0167 - mae: 0.1581 - val_loss: 0.0496 - val_mae: 0.2760\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0362 - mae: 0.2500 - val_loss: 0.0562 - val_mae: 0.2991\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0453 - mae: 0.2819 - val_loss: 0.0455 - val_mae: 0.2604\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - mae: 0.2426 - val_loss: 0.0288 - val_mae: 0.1817\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1501 - val_loss: 0.0181 - val_mae: 0.0976\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0819 - val_loss: 0.0184 - val_mae: 0.0992\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - mae: 0.0832 - val_loss: 0.0264 - val_mae: 0.1678\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0140 - mae: 0.1429 - val_loss: 0.0340 - val_mae: 0.2108\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0218 - mae: 0.1869 - val_loss: 0.0350 - val_mae: 0.2155\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0210 - mae: 0.1815 - val_loss: 0.0296 - val_mae: 0.1872\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0146 - mae: 0.1478 - val_loss: 0.0222 - val_mae: 0.1367\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0118 - mae: 0.1277 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0699 - val_loss: 0.0174 - val_mae: 0.0908\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0775 - val_loss: 0.0217 - val_mae: 0.1357\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0107 - mae: 0.1206 - val_loss: 0.0255 - val_mae: 0.1636\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0122 - mae: 0.1317 - val_loss: 0.0261 - val_mae: 0.1677\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0127 - mae: 0.1337 - val_loss: 0.0235 - val_mae: 0.1495\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - mae: 0.1122 - val_loss: 0.0198 - val_mae: 0.1168\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0999 - val_loss: 0.0171 - val_mae: 0.0863\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0046 - mae: 0.0722 - val_loss: 0.0188 - val_mae: 0.1028\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0073 - mae: 0.0944 - val_loss: 0.0204 - val_mae: 0.1195\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0076 - mae: 0.0959 - val_loss: 0.0207 - val_mae: 0.1214\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0073 - mae: 0.0955 - val_loss: 0.0196 - val_mae: 0.1106\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0071 - mae: 0.0931 - val_loss: 0.0181 - val_mae: 0.0939\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0706 - val_loss: 0.0172 - val_mae: 0.0881\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0685 - val_loss: 0.0184 - val_mae: 0.0992\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0754 - val_loss: 0.0196 - val_mae: 0.1120\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0066 - mae: 0.0905 - val_loss: 0.0197 - val_mae: 0.1128\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0899 - val_loss: 0.0188 - val_mae: 0.1039\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0811 - val_loss: 0.0177 - val_mae: 0.0927\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0724 - val_loss: 0.0170 - val_mae: 0.0869\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - mae: 0.0732 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0672 - val_loss: 0.0174 - val_mae: 0.0880\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0740 - val_loss: 0.0178 - val_mae: 0.0907\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0729 - val_loss: 0.0179 - val_mae: 0.0910\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0732 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0694 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0678 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0665 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0177 - val_mae: 0.0929\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - mae: 0.0712 - val_loss: 0.0176 - val_mae: 0.0915\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0728 - val_loss: 0.0171 - val_mae: 0.0871\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0634 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0171 - val_mae: 0.0868\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0042 - mae: 0.0677 - val_loss: 0.0172 - val_mae: 0.0875\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0171 - val_mae: 0.0872\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0678 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0861\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:39,843] Trial 15 finished with value: 0.084881991147995 and parameters: {'learning_rate': 0.025777226607309283, 'weight_decay': 1.597843996967042e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0796 - mae: 0.3166 - val_loss: 0.0240 - val_mae: 0.1482\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0380 - mae: 0.2174 - val_loss: 0.0258 - val_mae: 0.1619\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0343 - mae: 0.2099 - val_loss: 0.0258 - val_mae: 0.1606\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0308 - mae: 0.2005 - val_loss: 0.0220 - val_mae: 0.1367\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1662 - val_loss: 0.0192 - val_mae: 0.1119\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0154 - mae: 0.1437 - val_loss: 0.0184 - val_mae: 0.1002\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1180 - val_loss: 0.0186 - val_mae: 0.0964\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0190 - val_mae: 0.0960\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0194 - val_mae: 0.0973\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.0999 - val_loss: 0.0198 - val_mae: 0.0978\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0068 - mae: 0.0914 - val_loss: 0.0200 - val_mae: 0.0976\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0075 - mae: 0.0917 - val_loss: 0.0202 - val_mae: 0.0964\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0897 - val_loss: 0.0203 - val_mae: 0.0949\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0901 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0057 - mae: 0.0792 - val_loss: 0.0201 - val_mae: 0.0904\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0058 - mae: 0.0782 - val_loss: 0.0199 - val_mae: 0.0877\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0797 - val_loss: 0.0195 - val_mae: 0.0851\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0751 - val_loss: 0.0190 - val_mae: 0.0832\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0715 - val_loss: 0.0185 - val_mae: 0.0818\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0809\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0703 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0692 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0643 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0029 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0758\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0506 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0168 - val_mae: 0.0764\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0166 - val_mae: 0.0763\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0544 - val_loss: 0.0166 - val_mae: 0.0760\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0165 - val_mae: 0.0757\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0165 - val_mae: 0.0757\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0163 - val_mae: 0.0765\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0162 - val_mae: 0.0765\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0490 - val_loss: 0.0160 - val_mae: 0.0766\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0417 - val_loss: 0.0158 - val_mae: 0.0769\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0158 - val_mae: 0.0772\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0158 - val_mae: 0.0775\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0159 - val_mae: 0.0774\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0161 - val_mae: 0.0771\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0161 - val_mae: 0.0772\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0159 - val_mae: 0.0778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0157 - val_mae: 0.0784\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0157 - val_mae: 0.0777\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0157 - val_mae: 0.0774\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0156 - val_mae: 0.0778\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0156 - val_mae: 0.0776\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0157 - val_mae: 0.0769\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0158 - val_mae: 0.0765\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0159 - val_mae: 0.0766\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0159 - val_mae: 0.0771\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0394 - val_loss: 0.0158 - val_mae: 0.0779\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0157 - val_mae: 0.0789\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0157 - val_mae: 0.0799\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - mae: 0.0383 - val_loss: 0.0157 - val_mae: 0.0805\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0400 - val_loss: 0.0156 - val_mae: 0.0814\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0811\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0794\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8238e-04 - mae: 0.0337 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0423 - val_loss: 0.0155 - val_mae: 0.0869\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0355 - val_loss: 0.0155 - val_mae: 0.0881\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0155 - val_mae: 0.0875\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0159 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0338 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0163 - val_mae: 0.0825\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0162 - val_mae: 0.0826\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0332 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9398e-04 - mae: 0.0348 - val_loss: 0.0160 - val_mae: 0.0837\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0158 - val_mae: 0.0847\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0158 - val_mae: 0.0840\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2569e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1618e-04 - mae: 0.0313 - val_loss: 0.0159 - val_mae: 0.0813\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0159 - val_mae: 0.0798\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 9.1125e-04 - mae: 0.0328 - val_loss: 0.0158 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.4902e-04 - mae: 0.0323 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.0572e-04 - mae: 0.0311 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.5991e-04 - mae: 0.0318 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8142e-04 - mae: 0.0303 - val_loss: 0.0157 - val_mae: 0.0811\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9651e-04 - mae: 0.0324 - val_loss: 0.0157 - val_mae: 0.0824\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1164e-04 - mae: 0.0303 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0500e-04 - mae: 0.0311 - val_loss: 0.0156 - val_mae: 0.0837\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3532e-04 - mae: 0.0327 - val_loss: 0.0154 - val_mae: 0.0826\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0437e-04 - mae: 0.0329 - val_loss: 0.0154 - val_mae: 0.0819\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7837e-04 - mae: 0.0331 - val_loss: 0.0153 - val_mae: 0.0819\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.9532e-04 - mae: 0.0356 - val_loss: 0.0154 - val_mae: 0.0819\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1271e-04 - mae: 0.0322 - val_loss: 0.0154 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3654e-04 - mae: 0.0297 - val_loss: 0.0155 - val_mae: 0.0824\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3293e-04 - mae: 0.0295 - val_loss: 0.0156 - val_mae: 0.0809\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7395e-04 - mae: 0.0309 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4667e-04 - mae: 0.0305 - val_loss: 0.0158 - val_mae: 0.0803\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.0296e-04 - mae: 0.0313 - val_loss: 0.0160 - val_mae: 0.0798\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5750e-04 - mae: 0.0278 - val_loss: 0.0162 - val_mae: 0.0797\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4266e-04 - mae: 0.0314 - val_loss: 0.0163 - val_mae: 0.0798\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0166e-04 - mae: 0.0314 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2888e-04 - mae: 0.0302 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.4189e-04 - mae: 0.0307 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.9594e-04 - mae: 0.0328 - val_loss: 0.0161 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2949e-04 - mae: 0.0298 - val_loss: 0.0161 - val_mae: 0.0822\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9086e-04 - mae: 0.0306 - val_loss: 0.0163 - val_mae: 0.0804\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5318e-04 - mae: 0.0302 - val_loss: 0.0164 - val_mae: 0.0789\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0763e-04 - mae: 0.0318 - val_loss: 0.0164 - val_mae: 0.0790\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3541e-04 - mae: 0.0297 - val_loss: 0.0162 - val_mae: 0.0804\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 6.5052e-04 - mae: 0.0273 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0900e-04 - mae: 0.0285 - val_loss: 0.0158 - val_mae: 0.0843\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.1849e-04 - mae: 0.0302 - val_loss: 0.0159 - val_mae: 0.0842\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2135e-04 - mae: 0.0291 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.0939e-04 - mae: 0.0270 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.7565e-04 - mae: 0.0298 - val_loss: 0.0161 - val_mae: 0.0811\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5062e-04 - mae: 0.0308 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8188e-04 - mae: 0.0295 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.4702e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.0808\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0161 - val_mae: 0.0798\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4676e-04 - mae: 0.0284 - val_loss: 0.0164 - val_mae: 0.0796\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.1028e-04 - mae: 0.0267 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8837e-04 - mae: 0.0296 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7658e-04 - mae: 0.0308 - val_loss: 0.0166 - val_mae: 0.0801\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1671e-04 - mae: 0.0274 - val_loss: 0.0163 - val_mae: 0.0810\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6747e-04 - mae: 0.0317 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.8661e-04 - mae: 0.0284 - val_loss: 0.0158 - val_mae: 0.0833\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.2170e-04 - mae: 0.0318 - val_loss: 0.0158 - val_mae: 0.0834\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0513e-04 - mae: 0.0314 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1425e-04 - mae: 0.0295 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9581e-04 - mae: 0.0303 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8668e-04 - mae: 0.0281 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.2252e-04 - mae: 0.0301 - val_loss: 0.0160 - val_mae: 0.0802\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5226e-04 - mae: 0.0243 - val_loss: 0.0159 - val_mae: 0.0805\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0159e-04 - mae: 0.0307 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 8.6975e-04 - mae: 0.0319 - val_loss: 0.0160 - val_mae: 0.0819\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6923e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0761e-04 - mae: 0.0321 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9108e-04 - mae: 0.0261 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8752e-04 - mae: 0.0261 - val_loss: 0.0163 - val_mae: 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:50,890] Trial 16 finished with value: 0.08356054872274399 and parameters: {'learning_rate': 0.0011066168053900564, 'weight_decay': 1.4116108524414525e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0873 - mae: 0.3384 - val_loss: 0.0605 - val_mae: 0.2777\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0812 - mae: 0.3327 - val_loss: 0.0305 - val_mae: 0.1893\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0412 - mae: 0.2314 - val_loss: 0.0187 - val_mae: 0.1160\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0161 - mae: 0.1376 - val_loss: 0.0196 - val_mae: 0.1077\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0132 - mae: 0.1272 - val_loss: 0.0215 - val_mae: 0.1175\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0117 - mae: 0.1197 - val_loss: 0.0223 - val_mae: 0.1172\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1135 - val_loss: 0.0222 - val_mae: 0.1133\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0219 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - mae: 0.0928 - val_loss: 0.0216 - val_mae: 0.1033\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0211 - val_mae: 0.0970\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0204 - val_mae: 0.0893\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0196 - val_mae: 0.0832\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0723 - val_loss: 0.0188 - val_mae: 0.0828\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - mae: 0.0778 - val_loss: 0.0184 - val_mae: 0.0871\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0725 - val_loss: 0.0181 - val_mae: 0.0923\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0973\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0733 - val_loss: 0.0178 - val_mae: 0.0975\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0696 - val_loss: 0.0176 - val_mae: 0.0926\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0176 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0164 - val_mae: 0.0849\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0161 - val_mae: 0.0899\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0161 - val_mae: 0.0896\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0161 - val_mae: 0.0865\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0164 - val_mae: 0.0822\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0524 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0510 - val_loss: 0.0163 - val_mae: 0.0841\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0161 - val_mae: 0.0876\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0511 - val_loss: 0.0160 - val_mae: 0.0891\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0506 - val_loss: 0.0160 - val_mae: 0.0910\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0542 - val_loss: 0.0160 - val_mae: 0.0896\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0161 - val_mae: 0.0893\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0160 - val_mae: 0.0902\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0910\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0521 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0486 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0160 - val_mae: 0.0872\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0160 - val_mae: 0.0871\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0159 - val_mae: 0.0884\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0488 - val_loss: 0.0158 - val_mae: 0.0926\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0159 - val_mae: 0.0858\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0160 - val_mae: 0.0846\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0158 - val_mae: 0.0883\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0158 - val_mae: 0.0902\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0015 - mae: 0.0439 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0159 - val_mae: 0.0895\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0888\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0159 - val_mae: 0.0868\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0160 - val_mae: 0.0900\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0930\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0161 - val_mae: 0.0951\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0441 - val_loss: 0.0160 - val_mae: 0.0917\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0161 - val_mae: 0.0913\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0381 - val_loss: 0.0162 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0163 - val_mae: 0.0928\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0164 - val_mae: 0.0958\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0161 - val_mae: 0.0953\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0160 - val_mae: 0.0908\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0159 - val_mae: 0.0874\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0160 - val_mae: 0.0866\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0162 - val_mae: 0.0887\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0164 - val_mae: 0.0927\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0165 - val_mae: 0.0972\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0165 - val_mae: 0.0985\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0355 - val_loss: 0.0162 - val_mae: 0.0928\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0160 - val_mae: 0.0899\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7863e-04 - mae: 0.0327 - val_loss: 0.0159 - val_mae: 0.0890\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2947e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0900\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.0915\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 0.0163 - val_mae: 0.0962\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.8414e-04 - mae: 0.0344 - val_loss: 0.0166 - val_mae: 0.0985\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.6218e-04 - mae: 0.0335 - val_loss: 0.0167 - val_mae: 0.0986\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 0.0161 - val_mae: 0.0877\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.3258e-04 - mae: 0.0288 - val_loss: 0.0161 - val_mae: 0.0873\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.7629e-04 - mae: 0.0299 - val_loss: 0.0163 - val_mae: 0.0894\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.4500e-04 - mae: 0.0269 - val_loss: 0.0164 - val_mae: 0.0901\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.9060e-04 - mae: 0.0342 - val_loss: 0.0166 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0372 - val_loss: 0.0167 - val_mae: 0.0962\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3813e-04 - mae: 0.0287 - val_loss: 0.0167 - val_mae: 0.0976\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - mae: 0.0346 - val_loss: 0.0162 - val_mae: 0.0875\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8498e-04 - mae: 0.0305 - val_loss: 0.0161 - val_mae: 0.0834\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0161 - val_mae: 0.0849\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5736e-04 - mae: 0.0320 - val_loss: 0.0162 - val_mae: 0.0890\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8647e-04 - mae: 0.0285 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.0611e-04 - mae: 0.0301 - val_loss: 0.0165 - val_mae: 0.0969\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0163 - val_mae: 0.0968\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5689e-04 - mae: 0.0309 - val_loss: 0.0163 - val_mae: 0.0966\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1246e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.0933\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.6205e-04 - mae: 0.0308 - val_loss: 0.0161 - val_mae: 0.0904\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2664e-04 - mae: 0.0310 - val_loss: 0.0161 - val_mae: 0.0894\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0822e-04 - mae: 0.0315 - val_loss: 0.0161 - val_mae: 0.0896\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7665e-04 - mae: 0.0299 - val_loss: 0.0161 - val_mae: 0.0901\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.2212e-04 - mae: 0.0294 - val_loss: 0.0161 - val_mae: 0.0881\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8926e-04 - mae: 0.0294 - val_loss: 0.0162 - val_mae: 0.0892\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6202e-04 - mae: 0.0281 - val_loss: 0.0163 - val_mae: 0.0905\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1513e-04 - mae: 0.0288 - val_loss: 0.0163 - val_mae: 0.0881\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.8462e-04 - mae: 0.0318 - val_loss: 0.0163 - val_mae: 0.0884\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2901e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.0882\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3477e-04 - mae: 0.0313 - val_loss: 0.0160 - val_mae: 0.0836\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4294e-04 - mae: 0.0279 - val_loss: 0.0159 - val_mae: 0.0809\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0162 - val_mae: 0.0848\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3464e-04 - mae: 0.0268 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8327e-04 - mae: 0.0320 - val_loss: 0.0171 - val_mae: 0.0959\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3934e-04 - mae: 0.0279 - val_loss: 0.0173 - val_mae: 0.0987\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0163 - val_mae: 0.0893\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7401e-04 - mae: 0.0287 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0336 - val_loss: 0.0160 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0157 - val_mae: 0.0759\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - mae: 0.0357 - val_loss: 0.0153 - val_mae: 0.0793\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0152 - val_mae: 0.0866\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7391e-04 - mae: 0.0285 - val_loss: 0.0157 - val_mae: 0.0971\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0161 - val_mae: 0.0995\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3934e-04 - mae: 0.0327 - val_loss: 0.0160 - val_mae: 0.0950\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.0864\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8823e-04 - mae: 0.0265 - val_loss: 0.0159 - val_mae: 0.0805\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1045e-04 - mae: 0.0325 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9729e-04 - mae: 0.0328 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.8555e-04 - mae: 0.0332 - val_loss: 0.0160 - val_mae: 0.0836\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 5.3875e-04 - mae: 0.0247 - val_loss: 0.0162 - val_mae: 0.0900\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2926e-04 - mae: 0.0291 - val_loss: 0.0162 - val_mae: 0.0931\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.9051e-04 - mae: 0.0309 - val_loss: 0.0159 - val_mae: 0.0912\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4828e-04 - mae: 0.0276 - val_loss: 0.0157 - val_mae: 0.0857\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6069e-04 - mae: 0.0271 - val_loss: 0.0156 - val_mae: 0.0797\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0000e-04 - mae: 0.0310 - val_loss: 0.0156 - val_mae: 0.0781\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0337 - val_loss: 0.0155 - val_mae: 0.0790\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0467e-04 - mae: 0.0297 - val_loss: 0.0155 - val_mae: 0.0827\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2753e-04 - mae: 0.0273 - val_loss: 0.0156 - val_mae: 0.0873\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6854e-04 - mae: 0.0284 - val_loss: 0.0156 - val_mae: 0.0882\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0672e-04 - mae: 0.0325 - val_loss: 0.0154 - val_mae: 0.0856\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1059e-04 - mae: 0.0292 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3222e-04 - mae: 0.0258 - val_loss: 0.0154 - val_mae: 0.0807\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8047e-04 - mae: 0.0295 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7435e-04 - mae: 0.0273 - val_loss: 0.0155 - val_mae: 0.0810\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 0.0154 - val_mae: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:02,071] Trial 17 finished with value: 0.08329557627439499 and parameters: {'learning_rate': 0.0019742146903142703, 'weight_decay': 8.307434620137046e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1289 - mae: 0.4142 - val_loss: 0.0462 - val_mae: 0.2258\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0709 - mae: 0.2967 - val_loss: 0.0323 - val_mae: 0.1684\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0557 - mae: 0.2676 - val_loss: 0.0254 - val_mae: 0.1329\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0457 - mae: 0.2420 - val_loss: 0.0225 - val_mae: 0.1156\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0364 - mae: 0.2120 - val_loss: 0.0207 - val_mae: 0.1135\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0343 - mae: 0.2118 - val_loss: 0.0199 - val_mae: 0.1107\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0297 - mae: 0.1931 - val_loss: 0.0191 - val_mae: 0.1081\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0283 - mae: 0.1874 - val_loss: 0.0184 - val_mae: 0.1036\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0265 - mae: 0.1831 - val_loss: 0.0181 - val_mae: 0.1003\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0203 - mae: 0.1574 - val_loss: 0.0180 - val_mae: 0.0977\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0227 - mae: 0.1699 - val_loss: 0.0181 - val_mae: 0.0985\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - mae: 0.1401 - val_loss: 0.0183 - val_mae: 0.0995\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0175 - mae: 0.1487 - val_loss: 0.0188 - val_mae: 0.1006\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1311 - val_loss: 0.0194 - val_mae: 0.1023\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0155 - mae: 0.1407 - val_loss: 0.0197 - val_mae: 0.1029\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0117 - mae: 0.1237 - val_loss: 0.0200 - val_mae: 0.1029\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1207 - val_loss: 0.0203 - val_mae: 0.1027\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1076 - val_loss: 0.0205 - val_mae: 0.1024\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - mae: 0.1036 - val_loss: 0.0206 - val_mae: 0.1020\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0207 - val_mae: 0.1012\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0206 - val_mae: 0.1004\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0079 - mae: 0.1001 - val_loss: 0.0206 - val_mae: 0.0996\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0940 - val_loss: 0.0205 - val_mae: 0.0987\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0204 - val_mae: 0.0977\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0885 - val_loss: 0.0203 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0202 - val_mae: 0.0960\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0901 - val_loss: 0.0200 - val_mae: 0.0951\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0069 - mae: 0.0856 - val_loss: 0.0198 - val_mae: 0.0939\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0196 - val_mae: 0.0925\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - mae: 0.0793 - val_loss: 0.0194 - val_mae: 0.0913\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0806 - val_loss: 0.0192 - val_mae: 0.0902\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0767 - val_loss: 0.0189 - val_mae: 0.0891\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0056 - mae: 0.0803 - val_loss: 0.0187 - val_mae: 0.0882\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0803 - val_loss: 0.0186 - val_mae: 0.0875\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0747 - val_loss: 0.0184 - val_mae: 0.0870\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0182 - val_mae: 0.0866\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0181 - val_mae: 0.0864\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0721 - val_loss: 0.0179 - val_mae: 0.0862\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0743 - val_loss: 0.0177 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0680 - val_loss: 0.0176 - val_mae: 0.0857\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0708 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0049 - mae: 0.0730 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0856\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0674 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0673 - val_loss: 0.0171 - val_mae: 0.0865\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - mae: 0.0692 - val_loss: 0.0171 - val_mae: 0.0872\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0659 - val_loss: 0.0171 - val_mae: 0.0878\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0894\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0637 - val_loss: 0.0171 - val_mae: 0.0895\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0894\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0895\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0172 - val_mae: 0.0897\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0901\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0904\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0172 - val_mae: 0.0909\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0172 - val_mae: 0.0914\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0540 - val_loss: 0.0172 - val_mae: 0.0918\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0921\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0924\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0923\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0923\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0171 - val_mae: 0.0922\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0917\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0912\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0907\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0899\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0899\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0164 - val_mae: 0.0901\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0164 - val_mae: 0.0904\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0163 - val_mae: 0.0917\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0475 - val_loss: 0.0163 - val_mae: 0.0925\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0162 - val_mae: 0.0930\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0596 - val_loss: 0.0162 - val_mae: 0.0927\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0162 - val_mae: 0.0924\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0163 - val_mae: 0.0918\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0163 - val_mae: 0.0914\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0504 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0512 - val_loss: 0.0163 - val_mae: 0.0912\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0163 - val_mae: 0.0913\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0162 - val_mae: 0.0912\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0518 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0497 - val_loss: 0.0162 - val_mae: 0.0912\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0162 - val_mae: 0.0919\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0502 - val_loss: 0.0162 - val_mae: 0.0922\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0491 - val_loss: 0.0162 - val_mae: 0.0922\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0163 - val_mae: 0.0920\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0163 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0164 - val_mae: 0.0916\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0513 - val_loss: 0.0164 - val_mae: 0.0917\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0164 - val_mae: 0.0920\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - mae: 0.0495 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0165 - val_mae: 0.0925\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0483 - val_loss: 0.0165 - val_mae: 0.0932\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0461 - val_loss: 0.0165 - val_mae: 0.0936\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0165 - val_mae: 0.0942\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0443 - val_loss: 0.0165 - val_mae: 0.0942\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0163 - val_mae: 0.0950\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0483 - val_loss: 0.0163 - val_mae: 0.0950\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0474 - val_loss: 0.0162 - val_mae: 0.0951\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0485 - val_loss: 0.0162 - val_mae: 0.0951\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0451 - val_loss: 0.0161 - val_mae: 0.0946\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0161 - val_mae: 0.0944\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0444 - val_loss: 0.0160 - val_mae: 0.0946\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0160 - val_mae: 0.0947\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0160 - val_mae: 0.0945\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0159 - val_mae: 0.0946\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0159 - val_mae: 0.0949\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0159 - val_mae: 0.0952\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0159 - val_mae: 0.0957\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0159 - val_mae: 0.0966\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0159 - val_mae: 0.0972\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0976\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0421 - val_loss: 0.0159 - val_mae: 0.0972\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0158 - val_mae: 0.0964\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0158 - val_mae: 0.0955\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0157 - val_mae: 0.0945\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0410 - val_loss: 0.0156 - val_mae: 0.0933\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0420 - val_loss: 0.0156 - val_mae: 0.0922\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0156 - val_mae: 0.0921\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0156 - val_mae: 0.0925\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0156 - val_mae: 0.0924\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0156 - val_mae: 0.0923\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0156 - val_mae: 0.0925\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0156 - val_mae: 0.0930\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0399 - val_loss: 0.0156 - val_mae: 0.0935\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0156 - val_mae: 0.0944\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0156 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0156 - val_mae: 0.0959\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0156 - val_mae: 0.0964\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0156 - val_mae: 0.0966\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0156 - val_mae: 0.0962\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0156 - val_mae: 0.0962\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0404 - val_loss: 0.0156 - val_mae: 0.0959\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0409 - val_loss: 0.0156 - val_mae: 0.0960\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0156 - val_mae: 0.0949\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0156 - val_mae: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:12,933] Trial 18 finished with value: 0.09377338737249374 and parameters: {'learning_rate': 0.0004362029281454469, 'weight_decay': 3.297981168995382e-08}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0672 - mae: 0.2985 - val_loss: 0.0834 - val_mae: 0.3432\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1108 - mae: 0.3908 - val_loss: 0.0344 - val_mae: 0.1836\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0312 - mae: 0.1955 - val_loss: 0.0236 - val_mae: 0.1250\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0124 - mae: 0.1241 - val_loss: 0.0235 - val_mae: 0.1080\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0236 - val_mae: 0.1067\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1050\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0220 - val_mae: 0.1013\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0203 - val_mae: 0.0911\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0837 - val_loss: 0.0185 - val_mae: 0.0826\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0762 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mae: 0.0717 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0694 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0669 - val_loss: 0.0184 - val_mae: 0.0764\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0185 - val_mae: 0.0766\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0178 - val_mae: 0.0784\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0162 - val_mae: 0.0820\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0164 - val_mae: 0.0791\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0168 - val_mae: 0.0766\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0166 - val_mae: 0.0760\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0773\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0164 - val_mae: 0.0755\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0163 - val_mae: 0.0750\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0156 - val_mae: 0.0778\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0152 - val_mae: 0.0813\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0152 - val_mae: 0.0792\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0483 - val_loss: 0.0155 - val_mae: 0.0771\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0772\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0435 - val_loss: 0.0153 - val_mae: 0.0795\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0155 - val_mae: 0.0792\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0158 - val_mae: 0.0802\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0461 - val_loss: 0.0159 - val_mae: 0.0815\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0471 - val_loss: 0.0161 - val_mae: 0.0805\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0166 - val_mae: 0.0782\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0403 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0156 - val_mae: 0.0838\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0154 - val_mae: 0.0859\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0512 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0160 - val_mae: 0.0782\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0162 - val_mae: 0.0780\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0162 - val_mae: 0.0785\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0158 - val_mae: 0.0794\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0155 - val_mae: 0.0808\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0374 - val_loss: 0.0155 - val_mae: 0.0816\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0155 - val_mae: 0.0811\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0159 - val_mae: 0.0785\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0161 - val_mae: 0.0778\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0160 - val_mae: 0.0783\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0374 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0157 - val_mae: 0.0799\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0158 - val_mae: 0.0800\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0159 - val_mae: 0.0804\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0161 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0161 - val_mae: 0.0809\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0157e-04 - mae: 0.0318 - val_loss: 0.0159 - val_mae: 0.0814\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0379 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5946e-04 - mae: 0.0313 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0162 - val_mae: 0.0799\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1119e-04 - mae: 0.0330 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1617e-04 - mae: 0.0317 - val_loss: 0.0157 - val_mae: 0.0828\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.4289e-04 - mae: 0.0316 - val_loss: 0.0155 - val_mae: 0.0864\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0154 - val_mae: 0.0867\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0340 - val_loss: 0.0157 - val_mae: 0.0812\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0158 - val_mae: 0.0797\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0156 - val_mae: 0.0810\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1904e-04 - mae: 0.0333 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - mae: 0.0318 - val_loss: 0.0157 - val_mae: 0.0810\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0156 - val_mae: 0.0828\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0132e-04 - mae: 0.0320 - val_loss: 0.0155 - val_mae: 0.0841\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0348 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8334e-04 - mae: 0.0317 - val_loss: 0.0162 - val_mae: 0.0813\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1275e-04 - mae: 0.0309 - val_loss: 0.0165 - val_mae: 0.0800\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0299 - val_loss: 0.0165 - val_mae: 0.0806\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0010 - mae: 0.0319 - val_loss: 0.0163 - val_mae: 0.0836\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 0.0159 - val_mae: 0.0869\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.7616e-04 - mae: 0.0330 - val_loss: 0.0156 - val_mae: 0.0881\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0156 - val_mae: 0.0845\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0162 - val_mae: 0.0774\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0373 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0163 - val_mae: 0.0792\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0092e-04 - mae: 0.0306 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8452e-04 - mae: 0.0321 - val_loss: 0.0160 - val_mae: 0.0874\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.4955e-04 - mae: 0.0330 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8418e-04 - mae: 0.0312 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.3604e-04 - mae: 0.0301 - val_loss: 0.0166 - val_mae: 0.0800\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0341 - val_loss: 0.0166 - val_mae: 0.0801\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0719e-04 - mae: 0.0314 - val_loss: 0.0165 - val_mae: 0.0809\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3962e-04 - mae: 0.0270 - val_loss: 0.0162 - val_mae: 0.0826\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3298e-04 - mae: 0.0278 - val_loss: 0.0161 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5243e-04 - mae: 0.0301 - val_loss: 0.0161 - val_mae: 0.0852\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.8487e-04 - mae: 0.0296 - val_loss: 0.0159 - val_mae: 0.0855\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7290e-04 - mae: 0.0266 - val_loss: 0.0158 - val_mae: 0.0840\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6957e-04 - mae: 0.0275 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.4641e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4780e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7889e-04 - mae: 0.0272 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0485e-04 - mae: 0.0307 - val_loss: 0.0158 - val_mae: 0.0808\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.6290e-04 - mae: 0.0294 - val_loss: 0.0158 - val_mae: 0.0809\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0320 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.7413e-04 - mae: 0.0292 - val_loss: 0.0160 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.2966e-04 - mae: 0.0296 - val_loss: 0.0162 - val_mae: 0.0832\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4266e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1527e-04 - mae: 0.0286 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.5429e-04 - mae: 0.0294 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9068e-04 - mae: 0.0280 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9713e-04 - mae: 0.0269 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.3843e-04 - mae: 0.0272 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0903e-04 - mae: 0.0289 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0157 - val_mae: 0.0835\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1527e-04 - mae: 0.0303 - val_loss: 0.0158 - val_mae: 0.0831\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 8.4490e-04 - mae: 0.0291 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9105e-04 - mae: 0.0295 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.5196e-04 - mae: 0.0294 - val_loss: 0.0161 - val_mae: 0.0775\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1163e-04 - mae: 0.0256 - val_loss: 0.0161 - val_mae: 0.0773\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8121e-04 - mae: 0.0291 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.2508e-04 - mae: 0.0301 - val_loss: 0.0157 - val_mae: 0.0807\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.2273e-04 - mae: 0.0245 - val_loss: 0.0155 - val_mae: 0.0841\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.3877e-04 - mae: 0.0295 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.3860e-04 - mae: 0.0329 - val_loss: 0.0154 - val_mae: 0.0853\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.9672e-04 - mae: 0.0287 - val_loss: 0.0154 - val_mae: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:23,893] Trial 19 finished with value: 0.08468662202358246 and parameters: {'learning_rate': 0.0027804327827490043, 'weight_decay': 4.517394395575848e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0619 - mae: 0.2805 - val_loss: 0.0329 - val_mae: 0.1782\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0452 - mae: 0.2402 - val_loss: 0.0284 - val_mae: 0.1605\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0355 - mae: 0.2131 - val_loss: 0.0249 - val_mae: 0.1454\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0324 - mae: 0.2046 - val_loss: 0.0222 - val_mae: 0.1335\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0340 - mae: 0.2109 - val_loss: 0.0201 - val_mae: 0.1228\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0273 - mae: 0.1879 - val_loss: 0.0186 - val_mae: 0.1141\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0250 - mae: 0.1755 - val_loss: 0.0175 - val_mae: 0.1070\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0222 - mae: 0.1663 - val_loss: 0.0168 - val_mae: 0.1021\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0216 - mae: 0.1652 - val_loss: 0.0162 - val_mae: 0.0993\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0211 - mae: 0.1650 - val_loss: 0.0160 - val_mae: 0.0974\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0214 - mae: 0.1655 - val_loss: 0.0159 - val_mae: 0.0968\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0209 - mae: 0.1655 - val_loss: 0.0158 - val_mae: 0.0973\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0201 - mae: 0.1539 - val_loss: 0.0158 - val_mae: 0.0980\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0226 - mae: 0.1696 - val_loss: 0.0158 - val_mae: 0.0988\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0205 - mae: 0.1609 - val_loss: 0.0160 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0208 - mae: 0.1626 - val_loss: 0.0161 - val_mae: 0.1000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0167 - mae: 0.1421 - val_loss: 0.0162 - val_mae: 0.1004\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0175 - mae: 0.1504 - val_loss: 0.0163 - val_mae: 0.1010\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0189 - mae: 0.1530 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0138 - mae: 0.1314 - val_loss: 0.0166 - val_mae: 0.1019\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0147 - mae: 0.1315 - val_loss: 0.0167 - val_mae: 0.1020\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - mae: 0.1305 - val_loss: 0.0168 - val_mae: 0.1022\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0126 - mae: 0.1271 - val_loss: 0.0170 - val_mae: 0.1023\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0127 - mae: 0.1248 - val_loss: 0.0172 - val_mae: 0.1028\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0102 - mae: 0.1163 - val_loss: 0.0173 - val_mae: 0.1030\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0122 - mae: 0.1217 - val_loss: 0.0173 - val_mae: 0.1033\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0124 - mae: 0.1298 - val_loss: 0.0173 - val_mae: 0.1032\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0127 - mae: 0.1235 - val_loss: 0.0173 - val_mae: 0.1027\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0174 - val_mae: 0.1022\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - mae: 0.1241 - val_loss: 0.0173 - val_mae: 0.1018\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mae: 0.1111 - val_loss: 0.0173 - val_mae: 0.1015\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0094 - mae: 0.1123 - val_loss: 0.0173 - val_mae: 0.1012\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0107 - mae: 0.1201 - val_loss: 0.0173 - val_mae: 0.1010\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0097 - mae: 0.1106 - val_loss: 0.0173 - val_mae: 0.1003\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0094 - mae: 0.1094 - val_loss: 0.0174 - val_mae: 0.0998\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0174 - val_mae: 0.0992\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1152 - val_loss: 0.0174 - val_mae: 0.0987\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.1022 - val_loss: 0.0175 - val_mae: 0.0982\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1054 - val_loss: 0.0175 - val_mae: 0.0979\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.1051 - val_loss: 0.0175 - val_mae: 0.0977\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0947 - val_loss: 0.0176 - val_mae: 0.0978\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0935 - val_loss: 0.0176 - val_mae: 0.0979\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0065 - mae: 0.0911 - val_loss: 0.0177 - val_mae: 0.0981\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0074 - mae: 0.0965 - val_loss: 0.0178 - val_mae: 0.0983\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - mae: 0.0920 - val_loss: 0.0178 - val_mae: 0.0985\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0058 - mae: 0.0857 - val_loss: 0.0179 - val_mae: 0.0987\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0918 - val_loss: 0.0180 - val_mae: 0.0989\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0880 - val_loss: 0.0180 - val_mae: 0.0991\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0908 - val_loss: 0.0181 - val_mae: 0.0993\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0072 - mae: 0.0957 - val_loss: 0.0181 - val_mae: 0.0994\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - mae: 0.0873 - val_loss: 0.0182 - val_mae: 0.0992\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0068 - mae: 0.0921 - val_loss: 0.0182 - val_mae: 0.0991\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0936 - val_loss: 0.0182 - val_mae: 0.0988\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - mae: 0.0909 - val_loss: 0.0182 - val_mae: 0.0985\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0787 - val_loss: 0.0181 - val_mae: 0.0983\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0873 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0808 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.0980\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0865 - val_loss: 0.0180 - val_mae: 0.0978\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0870 - val_loss: 0.0180 - val_mae: 0.0975\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0791 - val_loss: 0.0180 - val_mae: 0.0972\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0823 - val_loss: 0.0180 - val_mae: 0.0969\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0757 - val_loss: 0.0180 - val_mae: 0.0967\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0820 - val_loss: 0.0179 - val_mae: 0.0965\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0824 - val_loss: 0.0179 - val_mae: 0.0963\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0788 - val_loss: 0.0179 - val_mae: 0.0961\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0790 - val_loss: 0.0179 - val_mae: 0.0958\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0776 - val_loss: 0.0179 - val_mae: 0.0956\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0767 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - mae: 0.0810 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0783 - val_loss: 0.0178 - val_mae: 0.0956\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0052 - mae: 0.0777 - val_loss: 0.0178 - val_mae: 0.0957\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0707 - val_loss: 0.0178 - val_mae: 0.0959\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0827 - val_loss: 0.0178 - val_mae: 0.0959\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0740 - val_loss: 0.0178 - val_mae: 0.0960\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0713 - val_loss: 0.0178 - val_mae: 0.0961\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0763 - val_loss: 0.0178 - val_mae: 0.0961\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0682 - val_loss: 0.0177 - val_mae: 0.0962\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0963\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0711 - val_loss: 0.0177 - val_mae: 0.0962\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0734 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0741 - val_loss: 0.0176 - val_mae: 0.0960\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0694 - val_loss: 0.0176 - val_mae: 0.0959\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0701 - val_loss: 0.0176 - val_mae: 0.0956\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0720 - val_loss: 0.0176 - val_mae: 0.0955\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0700 - val_loss: 0.0175 - val_mae: 0.0954\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0953\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0710 - val_loss: 0.0175 - val_mae: 0.0951\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0730 - val_loss: 0.0175 - val_mae: 0.0949\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0698 - val_loss: 0.0175 - val_mae: 0.0946\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0647 - val_loss: 0.0175 - val_mae: 0.0944\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0942\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0940\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0939\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0938\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0937\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0707 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0659 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0938\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0939\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0941\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0176 - val_mae: 0.0942\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0572 - val_loss: 0.0177 - val_mae: 0.0943\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0621 - val_loss: 0.0177 - val_mae: 0.0944\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0944\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0945\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0177 - val_mae: 0.0946\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0947\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0949\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0590 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0176 - val_mae: 0.0952\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0032 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0588 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0608 - val_loss: 0.0176 - val_mae: 0.0952\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0651 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0562 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0594 - val_loss: 0.0176 - val_mae: 0.0949\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0948\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0579 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0594 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0176 - val_mae: 0.0949\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0527 - val_loss: 0.0177 - val_mae: 0.0951\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0506 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0554 - val_loss: 0.0176 - val_mae: 0.0956\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0557 - val_loss: 0.0176 - val_mae: 0.0958\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0541 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0565 - val_loss: 0.0176 - val_mae: 0.0963\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0965\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0540 - val_loss: 0.0176 - val_mae: 0.0966\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0551 - val_loss: 0.0176 - val_mae: 0.0967\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0511 - val_loss: 0.0176 - val_mae: 0.0967\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0177 - val_mae: 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:35,213] Trial 20 finished with value: 0.09668686985969543 and parameters: {'learning_rate': 0.0001683163977248562, 'weight_decay': 2.048318699209433e-09}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - mae: 0.2471 - val_loss: 0.0224 - val_mae: 0.1401\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0272 - mae: 0.1847 - val_loss: 0.0218 - val_mae: 0.1265\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0218 - mae: 0.1678 - val_loss: 0.0203 - val_mae: 0.1145\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0153 - mae: 0.1380 - val_loss: 0.0203 - val_mae: 0.1135\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0205 - val_mae: 0.1147\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - mae: 0.1054 - val_loss: 0.0203 - val_mae: 0.1122\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0083 - mae: 0.1046 - val_loss: 0.0201 - val_mae: 0.1090\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0926 - val_loss: 0.0198 - val_mae: 0.1045\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0822 - val_loss: 0.0195 - val_mae: 0.1006\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0192 - val_mae: 0.0976\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - mae: 0.0808 - val_loss: 0.0191 - val_mae: 0.0958\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0791 - val_loss: 0.0188 - val_mae: 0.0953\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - mae: 0.0721 - val_loss: 0.0184 - val_mae: 0.0962\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0177 - val_mae: 0.1005\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.1035\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0048 - mae: 0.0698 - val_loss: 0.0173 - val_mae: 0.1062\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0043 - mae: 0.0683 - val_loss: 0.0173 - val_mae: 0.1081\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0172 - val_mae: 0.1082\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.1053\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0655 - val_loss: 0.0165 - val_mae: 0.1010\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0163 - val_mae: 0.0973\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0162 - val_mae: 0.0953\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0162 - val_mae: 0.0953\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0161 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.0995\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.1031\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0161 - val_mae: 0.1056\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0161 - val_mae: 0.1079\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0161 - val_mae: 0.1081\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.1077\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0161 - val_mae: 0.1071\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0160 - val_mae: 0.1060\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0160 - val_mae: 0.1060\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0160 - val_mae: 0.1069\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0492 - val_loss: 0.0160 - val_mae: 0.1083\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0161 - val_mae: 0.1095\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0162 - val_mae: 0.1110\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0161 - val_mae: 0.1106\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0160 - val_mae: 0.1104\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0160 - val_mae: 0.1109\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0159 - val_mae: 0.1117\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0158 - val_mae: 0.1121\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0462 - val_loss: 0.0157 - val_mae: 0.1100\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0155 - val_mae: 0.1084\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0448 - val_loss: 0.0155 - val_mae: 0.1082\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0157 - val_mae: 0.1105\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0159 - val_mae: 0.1127\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0162 - val_mae: 0.1134\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0412 - val_loss: 0.0163 - val_mae: 0.1120\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.1089\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0162 - val_mae: 0.1090\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.1126\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0418 - val_loss: 0.0162 - val_mae: 0.1144\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0161 - val_mae: 0.1156\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0159 - val_mae: 0.1147\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0156 - val_mae: 0.1113\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0155 - val_mae: 0.1083\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0156 - val_mae: 0.1096\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0379 - val_loss: 0.0157 - val_mae: 0.1105\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0158 - val_mae: 0.1110\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0158 - val_mae: 0.1112\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0158 - val_mae: 0.1107\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0157 - val_mae: 0.1113\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.1106\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0157 - val_mae: 0.1111\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0156 - val_mae: 0.1076\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0157 - val_mae: 0.1075\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0326 - val_loss: 0.0159 - val_mae: 0.1092\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0160 - val_mae: 0.1096\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0161 - val_mae: 0.1099\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3661e-04 - mae: 0.0319 - val_loss: 0.0160 - val_mae: 0.1093\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6040e-04 - mae: 0.0300 - val_loss: 0.0160 - val_mae: 0.1075\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.1058\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6177e-04 - mae: 0.0336 - val_loss: 0.0160 - val_mae: 0.1046\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 0.0160 - val_mae: 0.1067\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1074e-04 - mae: 0.0292 - val_loss: 0.0161 - val_mae: 0.1096\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5140e-04 - mae: 0.0325 - val_loss: 0.0162 - val_mae: 0.1117\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.9192e-04 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.1114\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 8.7086e-04 - mae: 0.0325 - val_loss: 0.0160 - val_mae: 0.1112\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.8187e-04 - mae: 0.0346 - val_loss: 0.0158 - val_mae: 0.1061\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0158 - val_mae: 0.1018\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0158 - val_mae: 0.1009\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0358 - val_loss: 0.0158 - val_mae: 0.1016\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9911e-04 - mae: 0.0323 - val_loss: 0.0159 - val_mae: 0.1065\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8157e-04 - mae: 0.0303 - val_loss: 0.0161 - val_mae: 0.1124\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.1186e-04 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.1147\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.9962e-04 - mae: 0.0329 - val_loss: 0.0159 - val_mae: 0.1130\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2614e-04 - mae: 0.0291 - val_loss: 0.0157 - val_mae: 0.1083\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6704e-04 - mae: 0.0336 - val_loss: 0.0156 - val_mae: 0.1012\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4648e-04 - mae: 0.0302 - val_loss: 0.0157 - val_mae: 0.0994\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0159 - val_mae: 0.1028\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7001e-04 - mae: 0.0277 - val_loss: 0.0161 - val_mae: 0.1070\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1939e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.1130\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1273e-04 - mae: 0.0311 - val_loss: 0.0163 - val_mae: 0.1136\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.1888e-04 - mae: 0.0317 - val_loss: 0.0160 - val_mae: 0.1107\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.3832e-04 - mae: 0.0288 - val_loss: 0.0157 - val_mae: 0.1055\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9812e-04 - mae: 0.0282 - val_loss: 0.0156 - val_mae: 0.1029\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7109e-04 - mae: 0.0262 - val_loss: 0.0156 - val_mae: 0.1021\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.2528e-04 - mae: 0.0296 - val_loss: 0.0156 - val_mae: 0.1032\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2988e-04 - mae: 0.0286 - val_loss: 0.0157 - val_mae: 0.1065\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0149e-04 - mae: 0.0286 - val_loss: 0.0158 - val_mae: 0.1107\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0775e-04 - mae: 0.0304 - val_loss: 0.0159 - val_mae: 0.1145\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4829e-04 - mae: 0.0296 - val_loss: 0.0158 - val_mae: 0.1148\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1548e-04 - mae: 0.0297 - val_loss: 0.0156 - val_mae: 0.1108\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0154 - val_mae: 0.1036\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9259e-04 - mae: 0.0265 - val_loss: 0.0155 - val_mae: 0.0999\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5344e-04 - mae: 0.0301 - val_loss: 0.0157 - val_mae: 0.0997\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6130e-04 - mae: 0.0291 - val_loss: 0.0158 - val_mae: 0.0999\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.8288e-04 - mae: 0.0305 - val_loss: 0.0159 - val_mae: 0.1023\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.7071e-04 - mae: 0.0305 - val_loss: 0.0161 - val_mae: 0.1076\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8210e-04 - mae: 0.0280 - val_loss: 0.0162 - val_mae: 0.1138\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5928e-04 - mae: 0.0298 - val_loss: 0.0163 - val_mae: 0.1152\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.0839e-04 - mae: 0.0323 - val_loss: 0.0162 - val_mae: 0.1143\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.8889e-04 - mae: 0.0299 - val_loss: 0.0160 - val_mae: 0.1125\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6993e-04 - mae: 0.0326 - val_loss: 0.0157 - val_mae: 0.1081\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7192e-04 - mae: 0.0287 - val_loss: 0.0153 - val_mae: 0.1020\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3000e-04 - mae: 0.0306 - val_loss: 0.0152 - val_mae: 0.0988\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.5920e-04 - mae: 0.0271 - val_loss: 0.0153 - val_mae: 0.0975\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.8530e-04 - mae: 0.0284 - val_loss: 0.0154 - val_mae: 0.0987\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8123e-04 - mae: 0.0314 - val_loss: 0.0155 - val_mae: 0.1013\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.4251e-04 - mae: 0.0270 - val_loss: 0.0158 - val_mae: 0.1035\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0820e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.1040\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4343e-04 - mae: 0.0273 - val_loss: 0.0158 - val_mae: 0.1038\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2685e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.1041\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0143e-04 - mae: 0.0262 - val_loss: 0.0158 - val_mae: 0.1042\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9596e-04 - mae: 0.0276 - val_loss: 0.0158 - val_mae: 0.1029\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8081e-04 - mae: 0.0288 - val_loss: 0.0157 - val_mae: 0.1015\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6594e-04 - mae: 0.0273 - val_loss: 0.0157 - val_mae: 0.1019\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2871e-04 - mae: 0.0265 - val_loss: 0.0156 - val_mae: 0.1014\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3656e-04 - mae: 0.0244 - val_loss: 0.0157 - val_mae: 0.1004\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.8692e-04 - mae: 0.0234 - val_loss: 0.0157 - val_mae: 0.0991\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4406e-04 - mae: 0.0297 - val_loss: 0.0157 - val_mae: 0.0986\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7310e-04 - mae: 0.0294 - val_loss: 0.0156 - val_mae: 0.0991\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1644e-04 - mae: 0.0280 - val_loss: 0.0157 - val_mae: 0.1010\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5947e-04 - mae: 0.0266 - val_loss: 0.0159 - val_mae: 0.1036\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.4708e-04 - mae: 0.0233 - val_loss: 0.0159 - val_mae: 0.1039\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.4017e-04 - mae: 0.0274 - val_loss: 0.0160 - val_mae: 0.1032\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6329e-04 - mae: 0.0274 - val_loss: 0.0160 - val_mae: 0.1024\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6477e-04 - mae: 0.0280 - val_loss: 0.0160 - val_mae: 0.1018\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8968e-04 - mae: 0.0290 - val_loss: 0.0161 - val_mae: 0.1043\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5880e-04 - mae: 0.0256 - val_loss: 0.0162 - val_mae: 0.1077\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.7631e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.1057\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2652e-04 - mae: 0.0265 - val_loss: 0.0162 - val_mae: 0.1037\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9962e-04 - mae: 0.0244 - val_loss: 0.0162 - val_mae: 0.1015\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9768e-04 - mae: 0.0283 - val_loss: 0.0162 - val_mae: 0.1012\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9414e-04 - mae: 0.0244 - val_loss: 0.0162 - val_mae: 0.1014\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.0767e-04 - mae: 0.0259 - val_loss: 0.0162 - val_mae: 0.1024\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.5467e-04 - mae: 0.0238 - val_loss: 0.0161 - val_mae: 0.1017\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6036e-04 - mae: 0.0300 - val_loss: 0.0160 - val_mae: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:46,363] Trial 21 finished with value: 0.10334796458482742 and parameters: {'learning_rate': 0.0011424595761808235, 'weight_decay': 3.2719522473580964e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1391 - mae: 0.4121 - val_loss: 0.3061 - val_mae: 0.6788\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3887 - mae: 0.7678 - val_loss: 0.0311 - val_mae: 0.1889\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0240 - mae: 0.1734 - val_loss: 0.0242 - val_mae: 0.1154\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0111 - mae: 0.1137 - val_loss: 0.0238 - val_mae: 0.1077\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0230 - val_mae: 0.1051\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0217 - val_mae: 0.0969\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0199 - val_mae: 0.0863\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0773 - val_loss: 0.0186 - val_mae: 0.0953\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0955\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0723 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0687 - val_loss: 0.0169 - val_mae: 0.0960\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0167 - val_mae: 0.0919\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0871\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0164 - val_mae: 0.0925\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0163 - val_mae: 0.0957\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0670 - val_loss: 0.0164 - val_mae: 0.0847\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0812\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0552 - val_loss: 0.0158 - val_mae: 0.0954\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0601 - val_loss: 0.0157 - val_mae: 0.0921\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0159 - val_mae: 0.0851\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0157 - val_mae: 0.0870\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0952\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0164 - val_mae: 0.0800\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0035 - mae: 0.0557 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0543 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0516 - val_loss: 0.0170 - val_mae: 0.0845\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0152 - val_mae: 0.0919\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0157 - val_mae: 0.1197\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0736 - val_loss: 0.0160 - val_mae: 0.0831\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0863\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0167 - val_mae: 0.0826\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0166 - val_mae: 0.0821\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - mae: 0.0543 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0178 - val_mae: 0.0926\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:58,250] Trial 22 finished with value: 0.08396507054567337 and parameters: {'learning_rate': 0.005754092520191024, 'weight_decay': 1.8448355981529016e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0503 - mae: 0.2544 - val_loss: 0.0239 - val_mae: 0.1249\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0294 - mae: 0.1978 - val_loss: 0.0196 - val_mae: 0.1045\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0227 - mae: 0.1691 - val_loss: 0.0187 - val_mae: 0.1093\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0221 - mae: 0.1707 - val_loss: 0.0193 - val_mae: 0.1163\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0177 - mae: 0.1516 - val_loss: 0.0201 - val_mae: 0.1178\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0190 - mae: 0.1597 - val_loss: 0.0204 - val_mae: 0.1149\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0139 - mae: 0.1328 - val_loss: 0.0204 - val_mae: 0.1101\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0136 - mae: 0.1279 - val_loss: 0.0203 - val_mae: 0.1055\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1240 - val_loss: 0.0202 - val_mae: 0.1019\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0115 - mae: 0.1154 - val_loss: 0.0202 - val_mae: 0.0997\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1063 - val_loss: 0.0202 - val_mae: 0.0981\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - mae: 0.1001 - val_loss: 0.0203 - val_mae: 0.0975\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1041 - val_loss: 0.0204 - val_mae: 0.0974\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0924 - val_loss: 0.0203 - val_mae: 0.0969\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mae: 0.0946 - val_loss: 0.0202 - val_mae: 0.0958\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0078 - mae: 0.0952 - val_loss: 0.0200 - val_mae: 0.0948\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0075 - mae: 0.0934 - val_loss: 0.0198 - val_mae: 0.0932\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - mae: 0.0875 - val_loss: 0.0197 - val_mae: 0.0918\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0824 - val_loss: 0.0195 - val_mae: 0.0904\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0801 - val_loss: 0.0192 - val_mae: 0.0888\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0792 - val_loss: 0.0190 - val_mae: 0.0875\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0051 - mae: 0.0742 - val_loss: 0.0188 - val_mae: 0.0863\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0726 - val_loss: 0.0185 - val_mae: 0.0853\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - mae: 0.0762 - val_loss: 0.0183 - val_mae: 0.0845\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0840\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0751 - val_loss: 0.0179 - val_mae: 0.0842\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0844\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0723 - val_loss: 0.0176 - val_mae: 0.0845\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0846\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0576 - val_loss: 0.0164 - val_mae: 0.0834\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0164 - val_mae: 0.0832\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0163 - val_mae: 0.0829\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0163 - val_mae: 0.0829\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0162 - val_mae: 0.0827\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0162 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0162 - val_mae: 0.0818\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0162 - val_mae: 0.0814\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0161 - val_mae: 0.0812\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0160 - val_mae: 0.0813\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0160 - val_mae: 0.0814\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0534 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0160 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0160 - val_mae: 0.0825\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0160 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0514 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0159 - val_mae: 0.0835\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0159 - val_mae: 0.0836\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0021 - mae: 0.0497 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0160 - val_mae: 0.0829\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0160 - val_mae: 0.0825\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0458 - val_loss: 0.0160 - val_mae: 0.0823\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0159 - val_mae: 0.0825\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0158 - val_mae: 0.0826\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0158 - val_mae: 0.0828\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0157 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0156 - val_mae: 0.0835\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0500 - val_loss: 0.0155 - val_mae: 0.0838\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0835\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0155 - val_mae: 0.0827\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0824\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0156 - val_mae: 0.0822\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0442 - val_loss: 0.0156 - val_mae: 0.0826\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0154 - val_mae: 0.0837\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0153 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0463 - val_loss: 0.0152 - val_mae: 0.0841\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0431 - val_loss: 0.0152 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0153 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0456 - val_loss: 0.0154 - val_mae: 0.0808\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0155 - val_mae: 0.0804\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0155 - val_mae: 0.0806\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0441 - val_loss: 0.0154 - val_mae: 0.0815\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0153 - val_mae: 0.0825\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0152 - val_mae: 0.0845\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0152 - val_mae: 0.0850\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0152 - val_mae: 0.0851\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0153 - val_mae: 0.0850\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0154 - val_mae: 0.0844\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0423 - val_loss: 0.0154 - val_mae: 0.0842\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0154 - val_mae: 0.0840\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0443 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0152 - val_mae: 0.0842\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0434 - val_loss: 0.0151 - val_mae: 0.0850\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0150 - val_mae: 0.0861\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0449 - val_loss: 0.0149 - val_mae: 0.0861\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0386 - val_loss: 0.0150 - val_mae: 0.0854\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0416 - val_loss: 0.0152 - val_mae: 0.0841\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0155 - val_mae: 0.0829\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.0823\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0157 - val_mae: 0.0823\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0392 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0415 - val_loss: 0.0153 - val_mae: 0.0861\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0152 - val_mae: 0.0874\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0389 - val_loss: 0.0151 - val_mae: 0.0881\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0150 - val_mae: 0.0882\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0151 - val_mae: 0.0875\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0845\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0152 - val_mae: 0.0833\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0825\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0327 - val_loss: 0.0152 - val_mae: 0.0820\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0151 - val_mae: 0.0822\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0150 - val_mae: 0.0831\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0149 - val_mae: 0.0839\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0148 - val_mae: 0.0848\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.0148 - val_mae: 0.0852\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0149 - val_mae: 0.0851\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0013 - mae: 0.0397 - val_loss: 0.0151 - val_mae: 0.0846\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0012 - mae: 0.0390 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0153 - val_mae: 0.0841\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0154 - val_mae: 0.0842\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0154 - val_mae: 0.0844\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0356 - val_loss: 0.0153 - val_mae: 0.0848\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0385 - val_loss: 0.0152 - val_mae: 0.0857\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.0151 - val_mae: 0.0872\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0150 - val_mae: 0.0883\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0403 - val_loss: 0.0150 - val_mae: 0.0886\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0150 - val_mae: 0.0878\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.4606e-04 - mae: 0.0332 - val_loss: 0.0152 - val_mae: 0.0865\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.5957e-04 - mae: 0.0331 - val_loss: 0.0153 - val_mae: 0.0858\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0350 - val_loss: 0.0154 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0154 - val_mae: 0.0866\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0357 - val_loss: 0.0154 - val_mae: 0.0869\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0372 - val_loss: 0.0154 - val_mae: 0.0873\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0153 - val_mae: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:09,400] Trial 23 finished with value: 0.08773404359817505 and parameters: {'learning_rate': 0.0005455532692229183, 'weight_decay': 6.283510497269223e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0923 - mae: 0.3431 - val_loss: 0.0602 - val_mae: 0.2595\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0992 - mae: 0.3477 - val_loss: 0.0601 - val_mae: 0.2593\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0906 - mae: 0.3360 - val_loss: 0.0600 - val_mae: 0.2590\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0730 - mae: 0.3011 - val_loss: 0.0599 - val_mae: 0.2587\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0996 - mae: 0.3532 - val_loss: 0.0598 - val_mae: 0.2585\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0928 - mae: 0.3332 - val_loss: 0.0597 - val_mae: 0.2582\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1045 - mae: 0.3556 - val_loss: 0.0596 - val_mae: 0.2579\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0888 - mae: 0.3302 - val_loss: 0.0595 - val_mae: 0.2576\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1058 - mae: 0.3804 - val_loss: 0.0593 - val_mae: 0.2573\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0906 - mae: 0.3407 - val_loss: 0.0592 - val_mae: 0.2570\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0900 - mae: 0.3376 - val_loss: 0.0591 - val_mae: 0.2568\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1104 - mae: 0.3608 - val_loss: 0.0590 - val_mae: 0.2565\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1077 - mae: 0.3623 - val_loss: 0.0589 - val_mae: 0.2562\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0927 - mae: 0.3500 - val_loss: 0.0588 - val_mae: 0.2559\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1001 - mae: 0.3546 - val_loss: 0.0587 - val_mae: 0.2556\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0977 - mae: 0.3360 - val_loss: 0.0585 - val_mae: 0.2553\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1076 - mae: 0.3656 - val_loss: 0.0584 - val_mae: 0.2550\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1050 - mae: 0.3651 - val_loss: 0.0583 - val_mae: 0.2548\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0923 - mae: 0.3434 - val_loss: 0.0582 - val_mae: 0.2545\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0958 - mae: 0.3437 - val_loss: 0.0581 - val_mae: 0.2542\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0888 - mae: 0.3339 - val_loss: 0.0580 - val_mae: 0.2539\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0850 - mae: 0.3325 - val_loss: 0.0579 - val_mae: 0.2536\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1042 - mae: 0.3600 - val_loss: 0.0578 - val_mae: 0.2534\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0959 - mae: 0.3382 - val_loss: 0.0577 - val_mae: 0.2531\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1088 - mae: 0.3729 - val_loss: 0.0575 - val_mae: 0.2528\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0920 - mae: 0.3448 - val_loss: 0.0574 - val_mae: 0.2525\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0964 - mae: 0.3471 - val_loss: 0.0573 - val_mae: 0.2523\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0985 - mae: 0.3554 - val_loss: 0.0572 - val_mae: 0.2520\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0980 - mae: 0.3594 - val_loss: 0.0571 - val_mae: 0.2517\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0828 - mae: 0.3317 - val_loss: 0.0570 - val_mae: 0.2514\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1029 - mae: 0.3663 - val_loss: 0.0569 - val_mae: 0.2511\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0954 - mae: 0.3416 - val_loss: 0.0568 - val_mae: 0.2509\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0845 - mae: 0.3279 - val_loss: 0.0567 - val_mae: 0.2506\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0901 - mae: 0.3410 - val_loss: 0.0566 - val_mae: 0.2503\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0872 - mae: 0.3334 - val_loss: 0.0565 - val_mae: 0.2500\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0878 - mae: 0.3370 - val_loss: 0.0564 - val_mae: 0.2498\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1022 - mae: 0.3581 - val_loss: 0.0563 - val_mae: 0.2495\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0772 - mae: 0.3036 - val_loss: 0.0562 - val_mae: 0.2492\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1033 - mae: 0.3526 - val_loss: 0.0561 - val_mae: 0.2490\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1080 - mae: 0.3736 - val_loss: 0.0560 - val_mae: 0.2487\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0959 - mae: 0.3481 - val_loss: 0.0559 - val_mae: 0.2484\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0902 - mae: 0.3311 - val_loss: 0.0558 - val_mae: 0.2482\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0920 - mae: 0.3447 - val_loss: 0.0557 - val_mae: 0.2479\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1020 - mae: 0.3535 - val_loss: 0.0556 - val_mae: 0.2477\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0890 - mae: 0.3305 - val_loss: 0.0554 - val_mae: 0.2474\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0821 - mae: 0.3336 - val_loss: 0.0553 - val_mae: 0.2471\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0861 - mae: 0.3361 - val_loss: 0.0552 - val_mae: 0.2469\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1045 - mae: 0.3700 - val_loss: 0.0551 - val_mae: 0.2466\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0892 - mae: 0.3376 - val_loss: 0.0550 - val_mae: 0.2464\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0835 - mae: 0.3191 - val_loss: 0.0549 - val_mae: 0.2461\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0802 - mae: 0.3233 - val_loss: 0.0549 - val_mae: 0.2458\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0838 - mae: 0.3262 - val_loss: 0.0548 - val_mae: 0.2456\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0959 - mae: 0.3552 - val_loss: 0.0547 - val_mae: 0.2453\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0954 - mae: 0.3450 - val_loss: 0.0546 - val_mae: 0.2451\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0932 - mae: 0.3435 - val_loss: 0.0545 - val_mae: 0.2448\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0953 - mae: 0.3556 - val_loss: 0.0544 - val_mae: 0.2446\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0846 - mae: 0.3308 - val_loss: 0.0543 - val_mae: 0.2443\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0905 - mae: 0.3408 - val_loss: 0.0542 - val_mae: 0.2440\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0963 - mae: 0.3475 - val_loss: 0.0541 - val_mae: 0.2438\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0887 - mae: 0.3309 - val_loss: 0.0540 - val_mae: 0.2435\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0801 - mae: 0.3072 - val_loss: 0.0539 - val_mae: 0.2433\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0903 - mae: 0.3499 - val_loss: 0.0538 - val_mae: 0.2430\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0886 - mae: 0.3309 - val_loss: 0.0537 - val_mae: 0.2428\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0769 - mae: 0.3213 - val_loss: 0.0536 - val_mae: 0.2425\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0915 - mae: 0.3374 - val_loss: 0.0535 - val_mae: 0.2423\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1015 - mae: 0.3543 - val_loss: 0.0534 - val_mae: 0.2420\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0888 - mae: 0.3350 - val_loss: 0.0533 - val_mae: 0.2418\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0791 - mae: 0.3249 - val_loss: 0.0532 - val_mae: 0.2415\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1146 - mae: 0.3887 - val_loss: 0.0531 - val_mae: 0.2413\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0832 - mae: 0.3323 - val_loss: 0.0530 - val_mae: 0.2410\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0918 - mae: 0.3478 - val_loss: 0.0529 - val_mae: 0.2408\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0853 - mae: 0.3240 - val_loss: 0.0528 - val_mae: 0.2405\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0842 - mae: 0.3222 - val_loss: 0.0527 - val_mae: 0.2403\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0809 - mae: 0.3228 - val_loss: 0.0526 - val_mae: 0.2400\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1003 - mae: 0.3455 - val_loss: 0.0526 - val_mae: 0.2397\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0997 - mae: 0.3525 - val_loss: 0.0525 - val_mae: 0.2395\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0701 - mae: 0.3080 - val_loss: 0.0524 - val_mae: 0.2392\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0878 - mae: 0.3289 - val_loss: 0.0523 - val_mae: 0.2390\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0890 - mae: 0.3359 - val_loss: 0.0522 - val_mae: 0.2387\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0968 - mae: 0.3581 - val_loss: 0.0521 - val_mae: 0.2385\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0823 - mae: 0.3258 - val_loss: 0.0520 - val_mae: 0.2382\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0812 - mae: 0.3196 - val_loss: 0.0519 - val_mae: 0.2379\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0853 - mae: 0.3360 - val_loss: 0.0518 - val_mae: 0.2377\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0852 - mae: 0.3306 - val_loss: 0.0517 - val_mae: 0.2374\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0907 - mae: 0.3459 - val_loss: 0.0516 - val_mae: 0.2372\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0826 - mae: 0.3289 - val_loss: 0.0516 - val_mae: 0.2369\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0986 - mae: 0.3562 - val_loss: 0.0515 - val_mae: 0.2367\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0737 - mae: 0.3054 - val_loss: 0.0514 - val_mae: 0.2364\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0912 - mae: 0.3473 - val_loss: 0.0513 - val_mae: 0.2362\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1028 - mae: 0.3511 - val_loss: 0.0512 - val_mae: 0.2359\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0953 - mae: 0.3441 - val_loss: 0.0511 - val_mae: 0.2356\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0879 - mae: 0.3349 - val_loss: 0.0510 - val_mae: 0.2354\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0699 - mae: 0.2964 - val_loss: 0.0509 - val_mae: 0.2351\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0952 - mae: 0.3428 - val_loss: 0.0508 - val_mae: 0.2349\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0861 - mae: 0.3224 - val_loss: 0.0507 - val_mae: 0.2346\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0996 - mae: 0.3556 - val_loss: 0.0507 - val_mae: 0.2344\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0823 - mae: 0.3328 - val_loss: 0.0506 - val_mae: 0.2341\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0841 - mae: 0.3342 - val_loss: 0.0505 - val_mae: 0.2339\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0915 - mae: 0.3445 - val_loss: 0.0504 - val_mae: 0.2336\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0946 - mae: 0.3487 - val_loss: 0.0503 - val_mae: 0.2334\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0920 - mae: 0.3424 - val_loss: 0.0502 - val_mae: 0.2331\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0748 - mae: 0.3048 - val_loss: 0.0501 - val_mae: 0.2329\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0776 - mae: 0.3091 - val_loss: 0.0500 - val_mae: 0.2326\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0839 - mae: 0.3271 - val_loss: 0.0500 - val_mae: 0.2324\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0688 - mae: 0.2903 - val_loss: 0.0499 - val_mae: 0.2321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0802 - mae: 0.3207 - val_loss: 0.0498 - val_mae: 0.2319\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0837 - mae: 0.3335 - val_loss: 0.0497 - val_mae: 0.2316\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0760 - mae: 0.3092 - val_loss: 0.0496 - val_mae: 0.2314\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0953 - mae: 0.3413 - val_loss: 0.0495 - val_mae: 0.2312\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0808 - mae: 0.3183 - val_loss: 0.0495 - val_mae: 0.2309\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0839 - mae: 0.3234 - val_loss: 0.0494 - val_mae: 0.2307\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0755 - mae: 0.3061 - val_loss: 0.0493 - val_mae: 0.2304\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0924 - mae: 0.3474 - val_loss: 0.0492 - val_mae: 0.2302\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0910 - mae: 0.3291 - val_loss: 0.0491 - val_mae: 0.2300\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0651 - mae: 0.2946 - val_loss: 0.0491 - val_mae: 0.2297\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0879 - mae: 0.3365 - val_loss: 0.0490 - val_mae: 0.2295\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0781 - mae: 0.3156 - val_loss: 0.0489 - val_mae: 0.2293\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0849 - mae: 0.3257 - val_loss: 0.0488 - val_mae: 0.2290\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0744 - mae: 0.3038 - val_loss: 0.0487 - val_mae: 0.2288\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0773 - mae: 0.3221 - val_loss: 0.0487 - val_mae: 0.2286\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0740 - mae: 0.3049 - val_loss: 0.0486 - val_mae: 0.2283\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0852 - mae: 0.3236 - val_loss: 0.0485 - val_mae: 0.2281\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0827 - mae: 0.3206 - val_loss: 0.0484 - val_mae: 0.2279\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0923 - mae: 0.3536 - val_loss: 0.0484 - val_mae: 0.2276\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0870 - mae: 0.3326 - val_loss: 0.0483 - val_mae: 0.2274\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0906 - mae: 0.3383 - val_loss: 0.0482 - val_mae: 0.2272\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0844 - mae: 0.3231 - val_loss: 0.0481 - val_mae: 0.2269\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0786 - mae: 0.3111 - val_loss: 0.0481 - val_mae: 0.2267\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0809 - mae: 0.3190 - val_loss: 0.0480 - val_mae: 0.2265\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0793 - mae: 0.3198 - val_loss: 0.0479 - val_mae: 0.2262\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0944 - mae: 0.3461 - val_loss: 0.0478 - val_mae: 0.2260\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0903 - mae: 0.3308 - val_loss: 0.0478 - val_mae: 0.2258\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0848 - mae: 0.3230 - val_loss: 0.0477 - val_mae: 0.2256\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0791 - mae: 0.3087 - val_loss: 0.0476 - val_mae: 0.2253\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0845 - mae: 0.3187 - val_loss: 0.0475 - val_mae: 0.2251\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0793 - mae: 0.3196 - val_loss: 0.0475 - val_mae: 0.2249\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0794 - mae: 0.3206 - val_loss: 0.0474 - val_mae: 0.2246\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0806 - mae: 0.3214 - val_loss: 0.0473 - val_mae: 0.2244\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0774 - mae: 0.3169 - val_loss: 0.0472 - val_mae: 0.2242\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0776 - mae: 0.3097 - val_loss: 0.0472 - val_mae: 0.2240\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0708 - mae: 0.2971 - val_loss: 0.0471 - val_mae: 0.2238\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0697 - mae: 0.3014 - val_loss: 0.0470 - val_mae: 0.2235\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0713 - mae: 0.3036 - val_loss: 0.0469 - val_mae: 0.2233\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0976 - mae: 0.3473 - val_loss: 0.0469 - val_mae: 0.2231\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0781 - mae: 0.3221 - val_loss: 0.0468 - val_mae: 0.2229\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0883 - mae: 0.3361 - val_loss: 0.0467 - val_mae: 0.2227\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0862 - mae: 0.3267 - val_loss: 0.0466 - val_mae: 0.2224\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0760 - mae: 0.3068 - val_loss: 0.0466 - val_mae: 0.2222\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0741 - mae: 0.3027 - val_loss: 0.0465 - val_mae: 0.2220\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0745 - mae: 0.3069 - val_loss: 0.0464 - val_mae: 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:20,450] Trial 24 finished with value: 0.22176793217658997 and parameters: {'learning_rate': 1.4277721913203198e-06, 'weight_decay': 7.468173516712232e-09}. Best is trial 14 with value: 0.08045151829719543.\n",
      "[I 2023-12-04 18:47:20,495] A new study created in RDB with name: no-name-750299b0-0b4e-4bf8-b195-df9d3e9aaffd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0240 - val_mae: 0.1185\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0240 - val_mae: 0.1185\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1054 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0100 - mae: 0.1096 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0097 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1059 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0096 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1098 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1026 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1091 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0099 - mae: 0.1056 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0101 - mae: 0.1081 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1113 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0095 - mae: 0.1038 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1072 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1058 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1043 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1061 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0096 - mae: 0.1045 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0100 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1123 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0095 - mae: 0.1031 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1075 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1096 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1028 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1027 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0095 - mae: 0.1041 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0238 - val_mae: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:40,387] Trial 0 finished with value: 0.11750979721546173 and parameters: {'learning_rate': 1.1943576480019415e-06, 'weight_decay': 4.8151753602524324e-05}. Best is trial 0 with value: 0.11750979721546173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1030 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1170\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0992 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0086 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1044 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:59,645] Trial 1 finished with value: 0.11665796488523483 and parameters: {'learning_rate': 5.12932979719174e-07, 'weight_decay': 0.0010695835611072054}. Best is trial 1 with value: 0.11665796488523483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1018\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0961\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0839 - val_loss: 0.0209 - val_mae: 0.0917\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0201 - val_mae: 0.0889\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0193 - val_mae: 0.0876\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0692 - val_loss: 0.0185 - val_mae: 0.0876\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0180 - val_mae: 0.0890\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0745 - val_loss: 0.0176 - val_mae: 0.0901\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0706 - val_loss: 0.0173 - val_mae: 0.0886\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0715 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0752 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0641 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0176 - val_mae: 0.0776\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0037 - mae: 0.0560 - val_loss: 0.0176 - val_mae: 0.0775\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0038 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0544 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0802\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0550 - val_loss: 0.0174 - val_mae: 0.0816\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0555 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0542 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0832\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0176 - val_mae: 0.0830\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0176 - val_mae: 0.0829\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0175 - val_mae: 0.0830\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0512 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0175 - val_mae: 0.0844\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0175 - val_mae: 0.0849\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0174 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0178 - val_mae: 0.0860\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0177 - val_mae: 0.0845\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0468 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - mae: 0.0522 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0025 - mae: 0.0542 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0484 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0545 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0510 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0515 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0170 - val_mae: 0.0803\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0165 - val_mae: 0.0801\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0017 - mae: 0.0413 - val_loss: 0.0161 - val_mae: 0.0805\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0161 - val_mae: 0.0807\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0165 - val_mae: 0.0805\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0167 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - mae: 0.0396 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0431 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0157 - val_mae: 0.0848\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0157 - val_mae: 0.0845\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0158 - val_mae: 0.0838\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0159 - val_mae: 0.0839\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0014 - mae: 0.0401 - val_loss: 0.0161 - val_mae: 0.0835\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0160 - val_mae: 0.0873\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0159 - val_mae: 0.0897\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0384 - val_loss: 0.0161 - val_mae: 0.0903\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - mae: 0.0407 - val_loss: 0.0163 - val_mae: 0.0890\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 0.0165 - val_mae: 0.0883\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0166 - val_mae: 0.0884\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0165 - val_mae: 0.0889\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0166 - val_mae: 0.0900\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0166 - val_mae: 0.0909\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0165 - val_mae: 0.0926\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 0.0165 - val_mae: 0.0938\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0010 - mae: 0.0336 - val_loss: 0.0166 - val_mae: 0.0928\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0168 - val_mae: 0.0935\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0171 - val_mae: 0.0925\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0170 - val_mae: 0.0918\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0169 - val_mae: 0.0903\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0167 - val_mae: 0.0893\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0167 - val_mae: 0.0875\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0357 - val_loss: 0.0169 - val_mae: 0.0881\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0170 - val_mae: 0.0890\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 0.0170 - val_mae: 0.0907\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0172 - val_mae: 0.0917\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0172 - val_mae: 0.0910\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0173 - val_mae: 0.0890\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0171 - val_mae: 0.0880\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.1855e-04 - mae: 0.0326 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0167 - val_mae: 0.0878\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0166 - val_mae: 0.0912\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0167 - val_mae: 0.0922\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0168 - val_mae: 0.0932\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0171 - val_mae: 0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:18,808] Trial 2 finished with value: 0.09247967600822449 and parameters: {'learning_rate': 0.0015159481638367005, 'weight_decay': 1.772040457956272e-07}. Best is trial 2 with value: 0.09247967600822449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0119 - mae: 0.1248 - val_loss: 0.0228 - val_mae: 0.1082\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0217 - val_mae: 0.0961\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0201 - val_mae: 0.0862\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0839\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0174 - val_mae: 0.0871\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0707 - val_loss: 0.0171 - val_mae: 0.0860\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0641 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0866\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0029 - mae: 0.0576 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0840\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0826\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0181 - val_mae: 0.0813\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0181 - val_mae: 0.0802\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0179 - val_mae: 0.0797\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0173 - val_mae: 0.0853\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0500 - val_loss: 0.0177 - val_mae: 0.0857\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0178 - val_mae: 0.0837\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0178 - val_mae: 0.0817\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0455 - val_loss: 0.0178 - val_mae: 0.0804\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0492 - val_loss: 0.0178 - val_mae: 0.0796\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - mae: 0.0488 - val_loss: 0.0178 - val_mae: 0.0795\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0484 - val_loss: 0.0178 - val_mae: 0.0801\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0451 - val_loss: 0.0176 - val_mae: 0.0806\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0514 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0459 - val_loss: 0.0182 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0182 - val_mae: 0.0832\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0181 - val_mae: 0.0843\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0180 - val_mae: 0.0851\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0178 - val_mae: 0.0855\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0020 - mae: 0.0459 - val_loss: 0.0176 - val_mae: 0.0862\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0462 - val_loss: 0.0176 - val_mae: 0.0861\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0178 - val_mae: 0.0854\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0179 - val_mae: 0.0846\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0181 - val_mae: 0.0840\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0182 - val_mae: 0.0844\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0184 - val_mae: 0.0852\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0186 - val_mae: 0.0868\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0432 - val_loss: 0.0188 - val_mae: 0.0890\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0191 - val_mae: 0.0916\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0190 - val_mae: 0.0914\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0187 - val_mae: 0.0904\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0182 - val_mae: 0.0891\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0180 - val_mae: 0.0863\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0404 - val_loss: 0.0180 - val_mae: 0.0847\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0180 - val_mae: 0.0845\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0441 - val_loss: 0.0181 - val_mae: 0.0860\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0430 - val_loss: 0.0183 - val_mae: 0.0878\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0185 - val_mae: 0.0905\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0411 - val_loss: 0.0190 - val_mae: 0.0938\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0192 - val_mae: 0.0965\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0193 - val_mae: 0.0982\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0189 - val_mae: 0.0972\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0183 - val_mae: 0.0949\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - mae: 0.0442 - val_loss: 0.0177 - val_mae: 0.0912\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 9.8541e-04 - mae: 0.0324 - val_loss: 0.0174 - val_mae: 0.0841\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0176 - val_mae: 0.0836\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0017 - mae: 0.0382 - val_loss: 0.0178 - val_mae: 0.0851\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0181 - val_mae: 0.0873\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.9041e-04 - mae: 0.0337 - val_loss: 0.0184 - val_mae: 0.0896\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0188 - val_mae: 0.0908\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0187 - val_mae: 0.0905\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0185 - val_mae: 0.0890\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0380 - val_loss: 0.0184 - val_mae: 0.0886\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0015 - mae: 0.0331 - val_loss: 0.0184 - val_mae: 0.0880\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0185 - val_mae: 0.0885\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0187 - val_mae: 0.0908\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0016 - mae: 0.0379 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0198 - val_mae: 0.1003\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0206 - val_mae: 0.1053\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0212 - val_mae: 0.1074\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0214 - val_mae: 0.1070\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0211 - val_mae: 0.1035\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0199 - val_mae: 0.0964\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.1787e-04 - mae: 0.0302 - val_loss: 0.0191 - val_mae: 0.0927\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0358 - val_loss: 0.0187 - val_mae: 0.0909\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.6127e-04 - mae: 0.0314 - val_loss: 0.0182 - val_mae: 0.0881\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0180 - val_mae: 0.0868\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0179 - val_mae: 0.0864\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 0.0180 - val_mae: 0.0868\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0429 - val_loss: 0.0183 - val_mae: 0.0874\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0185 - val_mae: 0.0882\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3382 - mae: 1.4741 - val_loss: 0.0196 - val_mae: 0.0938\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0458 - val_loss: 0.0194 - val_mae: 0.0920\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0413 - val_loss: 0.0191 - val_mae: 0.0903\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0190 - val_mae: 0.0903\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0196 - val_mae: 0.0958\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0490 - val_loss: 0.0200 - val_mae: 0.0987\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0209 - val_mae: 0.1029\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0196 - val_mae: 0.1011\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0537 - val_loss: 0.0178 - val_mae: 0.0871\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0173 - val_mae: 0.0740\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0442 - val_loss: 0.0168 - val_mae: 0.0733\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0420 - val_loss: 0.0167 - val_mae: 0.0740\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0169 - val_mae: 0.0748\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0527 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0560 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0038 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0527 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.0875\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0166 - val_mae: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:38,462] Trial 3 finished with value: 0.08855739235877991 and parameters: {'learning_rate': 0.005614884881432066, 'weight_decay': 0.0001579756451304208}. Best is trial 3 with value: 0.08855739235877991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0111 - mae: 0.1157 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1141\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0232 - val_mae: 0.1102\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0227 - val_mae: 0.1063\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0222 - val_mae: 0.1023\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0985\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0071 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0944\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0074 - mae: 0.0860 - val_loss: 0.0206 - val_mae: 0.0905\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0201 - val_mae: 0.0870\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0196 - val_mae: 0.0843\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0737 - val_loss: 0.0192 - val_mae: 0.0820\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0721 - val_loss: 0.0187 - val_mae: 0.0803\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0055 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0053 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0048 - mae: 0.0665 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0682 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0693 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0778\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0804\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0806\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0807\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0166 - val_mae: 0.0805\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0802\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0796\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0788\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0798\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0800\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0802\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0801\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0798\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0167 - val_mae: 0.0802\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0802\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0801\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0167 - val_mae: 0.0794\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0539 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0165 - val_mae: 0.0799\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0163 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0533 - val_loss: 0.0163 - val_mae: 0.0800\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0162 - val_mae: 0.0798\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0162 - val_mae: 0.0800\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0161 - val_mae: 0.0799\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0161 - val_mae: 0.0798\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0027 - mae: 0.0511 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0027 - mae: 0.0514 - val_loss: 0.0160 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0159 - val_mae: 0.0796\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0819\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0154 - val_mae: 0.0836\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0154 - val_mae: 0.0830\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0155 - val_mae: 0.0825\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0156 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0520 - val_loss: 0.0156 - val_mae: 0.0831\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0157 - val_mae: 0.0821\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0158 - val_mae: 0.0813\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0490 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0160 - val_mae: 0.0802\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0480 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0828\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0159 - val_mae: 0.0810\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0453 - val_loss: 0.0160 - val_mae: 0.0803\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0457 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0485 - val_loss: 0.0158 - val_mae: 0.0833\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0477 - val_loss: 0.0156 - val_mae: 0.0869\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0894\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0878\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0841\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0459 - val_loss: 0.0160 - val_mae: 0.0808\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0022 - mae: 0.0454 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0026 - mae: 0.0491 - val_loss: 0.0162 - val_mae: 0.0789\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0021 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0020 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0789\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0426 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0162 - val_mae: 0.0803\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0162 - val_mae: 0.0810\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0164 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0464 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0166 - val_mae: 0.0793\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0164 - val_mae: 0.0803\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0163 - val_mae: 0.0814\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0455 - val_loss: 0.0162 - val_mae: 0.0822\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0162 - val_mae: 0.0831\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0161 - val_mae: 0.0846\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0160 - val_mae: 0.0862\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0160 - val_mae: 0.0876\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0159 - val_mae: 0.0881\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0160 - val_mae: 0.0840\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0162 - val_mae: 0.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:57,909] Trial 4 finished with value: 0.08233408629894257 and parameters: {'learning_rate': 0.0008503898313401599, 'weight_decay': 0.0005064752003096145}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1076 - val_loss: 0.0216 - val_mae: 0.0890\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0061 - mae: 0.0782 - val_loss: 0.0188 - val_mae: 0.0837\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0780 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0676 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0169 - val_mae: 0.0808\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0816\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0022 - mae: 0.0450 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0468 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0769\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0181 - val_mae: 0.0791\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0184 - val_mae: 0.0806\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0464 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.0805\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0513 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0472 - val_loss: 0.0181 - val_mae: 0.0858\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0186 - val_mae: 0.0883\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0185 - val_mae: 0.0888\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0179 - val_mae: 0.0847\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0168 - val_mae: 0.0804\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0028 - mae: 0.0512 - val_loss: 0.0168 - val_mae: 0.0798\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0170 - val_mae: 0.0798\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0178 - val_mae: 0.0800\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0409 - val_loss: 0.0179 - val_mae: 0.0813\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0432 - val_loss: 0.0180 - val_mae: 0.0827\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0181 - val_mae: 0.0839\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0182 - val_mae: 0.0846\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0184 - val_mae: 0.0855\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0186 - val_mae: 0.0856\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 0.0186 - val_mae: 0.0854\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0185 - val_mae: 0.0859\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0184 - val_mae: 0.0864\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0180 - val_mae: 0.0867\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0178 - val_mae: 0.0879\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.0181 - val_mae: 0.0936\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0186 - val_mae: 0.0983\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0417 - val_loss: 0.0197 - val_mae: 0.1021\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0189 - val_mae: 0.0919\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0364 - val_loss: 0.0184 - val_mae: 0.0849\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0367 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0426 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0023 - mae: 0.0449 - val_loss: 0.0178 - val_mae: 0.0813\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0023 - mae: 0.0463 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0374 - val_loss: 0.0178 - val_mae: 0.0842\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0395 - val_loss: 0.0180 - val_mae: 0.0854\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0181 - val_mae: 0.0868\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - mae: 0.0432 - val_loss: 0.0181 - val_mae: 0.0888\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0181 - val_mae: 0.0914\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0180 - val_mae: 0.0874\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0010 - mae: 0.0354 - val_loss: 0.0178 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0178 - val_mae: 0.0839\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0178 - val_mae: 0.0845\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0178 - val_mae: 0.0858\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0179 - val_mae: 0.0861\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.9292e-04 - mae: 0.0337 - val_loss: 0.0180 - val_mae: 0.0862\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0180 - val_mae: 0.0860\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - mae: 0.0363 - val_loss: 0.0182 - val_mae: 0.0864\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0183 - val_mae: 0.0875\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.0891e-04 - mae: 0.0299 - val_loss: 0.0185 - val_mae: 0.0894\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.5995e-04 - mae: 0.0301 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 0.0188 - val_mae: 0.0931\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 0.0192 - val_mae: 0.0958\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0195 - val_mae: 0.0984\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0416 - val_loss: 0.0195 - val_mae: 0.0973\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0197 - val_mae: 0.0959\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - mae: 0.0326 - val_loss: 0.0196 - val_mae: 0.0943\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0193 - val_mae: 0.0920\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0190 - val_mae: 0.0902\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.3080e-04 - mae: 0.0306 - val_loss: 0.0183 - val_mae: 0.0877\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0181 - val_mae: 0.0883\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0012 - mae: 0.0327 - val_loss: 0.0182 - val_mae: 0.0904\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0185 - val_mae: 0.0935\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.4379e-04 - mae: 0.0306 - val_loss: 0.0188 - val_mae: 0.0950\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.8408e-04 - mae: 0.0319 - val_loss: 0.0191 - val_mae: 0.0975\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.7720e-04 - mae: 0.0339 - val_loss: 0.0189 - val_mae: 0.0957\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0186 - val_mae: 0.0923\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 9.4327e-04 - mae: 0.0323 - val_loss: 0.0182 - val_mae: 0.0894\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0177 - val_mae: 0.0838\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0178 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0181 - val_mae: 0.0853\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0401 - val_loss: 0.0184 - val_mae: 0.0881\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 0.0189 - val_mae: 0.0929\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 7.6897e-04 - mae: 0.0295 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0196 - val_mae: 0.0975\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0195 - val_mae: 0.0959\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0192 - val_mae: 0.0932\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0190 - val_mae: 0.0901\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0190 - val_mae: 0.0886\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0010 - mae: 0.0328 - val_loss: 0.0189 - val_mae: 0.0876\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 0.0189 - val_mae: 0.0876\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.9464e-04 - mae: 0.0274 - val_loss: 0.0188 - val_mae: 0.0876\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 0.0187 - val_mae: 0.0877\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.9107e-04 - mae: 0.0263 - val_loss: 0.0186 - val_mae: 0.0881\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0011 - mae: 0.0299 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.1058e-04 - mae: 0.0257 - val_loss: 0.0187 - val_mae: 0.0915\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0189 - val_mae: 0.0934\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 0.0191 - val_mae: 0.0952\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0352 - val_loss: 0.0195 - val_mae: 0.0968\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0338 - val_loss: 0.0192 - val_mae: 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:17,005] Trial 5 finished with value: 0.09466227144002914 and parameters: {'learning_rate': 0.005760987449990455, 'weight_decay': 9.096804077211612e-08}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1096 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1092 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0103 - mae: 0.1096 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1144 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1073 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1085 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1070 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0106 - mae: 0.1100 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1079 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1113 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1086 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0101 - mae: 0.1077 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1089 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0105 - mae: 0.1094 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0101 - mae: 0.1106 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1119 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0101 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0101 - mae: 0.1097 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0104 - mae: 0.1097 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0106 - mae: 0.1112 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0103 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1099 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1068 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1038 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1089 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1080 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0101 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1061 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0105 - mae: 0.1116 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1112 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1094 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1104 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1085 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1069 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0105 - mae: 0.1119 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1094 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0254 - val_mae: 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:36,536] Trial 6 finished with value: 0.12064401060342789 and parameters: {'learning_rate': 1.3782835654620857e-06, 'weight_decay': 2.7815292215940956e-09}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1071 - val_loss: 0.0231 - val_mae: 0.1130\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0231 - val_mae: 0.1129\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1032 - val_loss: 0.0230 - val_mae: 0.1128\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1031 - val_loss: 0.0230 - val_mae: 0.1126\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1069 - val_loss: 0.0230 - val_mae: 0.1124\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0230 - val_mae: 0.1123\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0229 - val_mae: 0.1121\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1052 - val_loss: 0.0229 - val_mae: 0.1120\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1026 - val_loss: 0.0229 - val_mae: 0.1118\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0229 - val_mae: 0.1117\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0229 - val_mae: 0.1115\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1046 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1035 - val_loss: 0.0228 - val_mae: 0.1110\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1011 - val_loss: 0.0228 - val_mae: 0.1109\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0227 - val_mae: 0.1104\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1017 - val_loss: 0.0227 - val_mae: 0.1103\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.1000 - val_loss: 0.0226 - val_mae: 0.1101\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0226 - val_mae: 0.1099\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0226 - val_mae: 0.1098\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0226 - val_mae: 0.1096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1029 - val_loss: 0.0225 - val_mae: 0.1095\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0225 - val_mae: 0.1093\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.0997 - val_loss: 0.0225 - val_mae: 0.1092\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1009 - val_loss: 0.0225 - val_mae: 0.1090\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0224 - val_mae: 0.1089\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085 - mae: 0.0999 - val_loss: 0.0224 - val_mae: 0.1087\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0083 - mae: 0.0988 - val_loss: 0.0224 - val_mae: 0.1085\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0224 - val_mae: 0.1084\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1022 - val_loss: 0.0224 - val_mae: 0.1082\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0223 - val_mae: 0.1081\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0993 - val_loss: 0.0223 - val_mae: 0.1079\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0223 - val_mae: 0.1078\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0223 - val_mae: 0.1076\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0222 - val_mae: 0.1075\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0222 - val_mae: 0.1073\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0222 - val_mae: 0.1072\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1006 - val_loss: 0.0222 - val_mae: 0.1070\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0222 - val_mae: 0.1069\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0221 - val_mae: 0.1067\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0973 - val_loss: 0.0221 - val_mae: 0.1066\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1018 - val_loss: 0.0221 - val_mae: 0.1064\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0221 - val_mae: 0.1063\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0967 - val_loss: 0.0220 - val_mae: 0.1061\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0220 - val_mae: 0.1060\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0979 - val_loss: 0.0220 - val_mae: 0.1058\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0220 - val_mae: 0.1057\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0962 - val_loss: 0.0220 - val_mae: 0.1056\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0219 - val_mae: 0.1054\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0957 - val_loss: 0.0219 - val_mae: 0.1053\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0219 - val_mae: 0.1051\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0219 - val_mae: 0.1050\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0218 - val_mae: 0.1048\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0963 - val_loss: 0.0218 - val_mae: 0.1047\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0218 - val_mae: 0.1045\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0922 - val_loss: 0.0218 - val_mae: 0.1044\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0218 - val_mae: 0.1043\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0217 - val_mae: 0.1041\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0940 - val_loss: 0.0217 - val_mae: 0.1040\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0979 - val_loss: 0.0217 - val_mae: 0.1038\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0217 - val_mae: 0.1037\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0217 - val_mae: 0.1035\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0216 - val_mae: 0.1034\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0964 - val_loss: 0.0216 - val_mae: 0.1032\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0216 - val_mae: 0.1031\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0216 - val_mae: 0.1030\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0216 - val_mae: 0.1028\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0215 - val_mae: 0.1027\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0933 - val_loss: 0.0215 - val_mae: 0.1025\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0215 - val_mae: 0.1024\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0215 - val_mae: 0.1022\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0215 - val_mae: 0.1021\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0949 - val_loss: 0.0214 - val_mae: 0.1020\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0214 - val_mae: 0.1018\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0214 - val_mae: 0.1017\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0214 - val_mae: 0.1016\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0214 - val_mae: 0.1014\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0213 - val_mae: 0.1013\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0213 - val_mae: 0.1012\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0213 - val_mae: 0.1010\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0213 - val_mae: 0.1009\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0213 - val_mae: 0.1008\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0213 - val_mae: 0.1006\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0212 - val_mae: 0.1005\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0212 - val_mae: 0.1004\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0212 - val_mae: 0.1002\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0918 - val_loss: 0.0212 - val_mae: 0.1001\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0212 - val_mae: 0.1000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0080 - mae: 0.0915 - val_loss: 0.0211 - val_mae: 0.0999\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0211 - val_mae: 0.0997\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0211 - val_mae: 0.0996\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0211 - val_mae: 0.0995\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0930 - val_loss: 0.0211 - val_mae: 0.0993\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0211 - val_mae: 0.0992\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0076 - mae: 0.0914 - val_loss: 0.0210 - val_mae: 0.0991\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0210 - val_mae: 0.0990\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0877 - val_loss: 0.0210 - val_mae: 0.0988\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0210 - val_mae: 0.0987\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0923 - val_loss: 0.0210 - val_mae: 0.0986\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0210 - val_mae: 0.0984\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0209 - val_mae: 0.0983\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0074 - mae: 0.0904 - val_loss: 0.0209 - val_mae: 0.0982\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0066 - mae: 0.0857 - val_loss: 0.0209 - val_mae: 0.0980\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0910 - val_loss: 0.0209 - val_mae: 0.0979\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0209 - val_mae: 0.0978\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0849 - val_loss: 0.0209 - val_mae: 0.0976\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0208 - val_mae: 0.0975\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0208 - val_mae: 0.0973\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0848 - val_loss: 0.0208 - val_mae: 0.0972\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0208 - val_mae: 0.0971\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0208 - val_mae: 0.0969\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0207 - val_mae: 0.0968\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0207 - val_mae: 0.0966\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0207 - val_mae: 0.0965\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0869 - val_loss: 0.0207 - val_mae: 0.0964\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0916 - val_loss: 0.0207 - val_mae: 0.0962\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0206 - val_mae: 0.0961\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0206 - val_mae: 0.0960\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0068 - mae: 0.0873 - val_loss: 0.0206 - val_mae: 0.0958\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0206 - val_mae: 0.0957\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0866 - val_loss: 0.0206 - val_mae: 0.0955\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0867 - val_loss: 0.0205 - val_mae: 0.0954\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0205 - val_mae: 0.0953\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0205 - val_mae: 0.0951\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0893 - val_loss: 0.0205 - val_mae: 0.0950\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0924 - val_loss: 0.0205 - val_mae: 0.0948\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0205 - val_mae: 0.0947\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0204 - val_mae: 0.0946\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0860 - val_loss: 0.0204 - val_mae: 0.0944\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0869 - val_loss: 0.0204 - val_mae: 0.0943\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0818 - val_loss: 0.0204 - val_mae: 0.0941\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0204 - val_mae: 0.0940\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0891 - val_loss: 0.0203 - val_mae: 0.0938\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0203 - val_mae: 0.0937\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0203 - val_mae: 0.0936\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0203 - val_mae: 0.0934\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0203 - val_mae: 0.0933\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0071 - mae: 0.0840 - val_loss: 0.0202 - val_mae: 0.0931\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0839 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0202 - val_mae: 0.0929\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0806 - val_loss: 0.0202 - val_mae: 0.0927\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0202 - val_mae: 0.0926\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0850 - val_loss: 0.0202 - val_mae: 0.0924\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0849 - val_loss: 0.0201 - val_mae: 0.0923\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0854 - val_loss: 0.0201 - val_mae: 0.0922\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0861 - val_loss: 0.0201 - val_mae: 0.0921\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0834 - val_loss: 0.0201 - val_mae: 0.0919\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0201 - val_mae: 0.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:55,719] Trial 7 finished with value: 0.09181176871061325 and parameters: {'learning_rate': 2.72024464004361e-05, 'weight_decay': 7.212864515446065e-09}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1079 - val_loss: 0.0245 - val_mae: 0.1174\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0243 - val_mae: 0.1158\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1142\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1111\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0235 - val_mae: 0.1095\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1078\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0936 - val_loss: 0.0230 - val_mae: 0.1061\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0228 - val_mae: 0.1043\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0913 - val_loss: 0.0226 - val_mae: 0.1025\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0890 - val_loss: 0.0224 - val_mae: 0.1007\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0221 - val_mae: 0.0990\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0867 - val_loss: 0.0219 - val_mae: 0.0971\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0217 - val_mae: 0.0953\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0826 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0922\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0209 - val_mae: 0.0909\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0063 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0204 - val_mae: 0.0888\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0202 - val_mae: 0.0878\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063 - mae: 0.0805 - val_loss: 0.0199 - val_mae: 0.0870\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0731 - val_loss: 0.0197 - val_mae: 0.0862\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0856\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0193 - val_mae: 0.0852\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0850\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0189 - val_mae: 0.0848\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0186 - val_mae: 0.0845\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0184 - val_mae: 0.0844\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0183 - val_mae: 0.0842\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0047 - mae: 0.0703 - val_loss: 0.0182 - val_mae: 0.0839\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0047 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0836\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0179 - val_mae: 0.0830\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0813\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0683 - val_loss: 0.0176 - val_mae: 0.0807\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0041 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0175 - val_mae: 0.0795\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0768\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0044 - mae: 0.0673 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0768\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0172 - val_mae: 0.0770\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0771\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0770\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0173 - val_mae: 0.0768\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0649 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0762\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0539 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0760\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0758\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0756\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0753\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0751\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0749\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0746\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0512 - val_loss: 0.0170 - val_mae: 0.0745\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0744\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0744\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0169 - val_mae: 0.0743\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0168 - val_mae: 0.0742\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0505 - val_loss: 0.0167 - val_mae: 0.0742\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0164 - val_mae: 0.0742\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0162 - val_mae: 0.0743\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0539 - val_loss: 0.0160 - val_mae: 0.0744\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0160 - val_mae: 0.0743\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0160 - val_mae: 0.0740\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0162 - val_mae: 0.0739\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0164 - val_mae: 0.0739\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0165 - val_mae: 0.0740\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.0741\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0488 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0164 - val_mae: 0.0741\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0162 - val_mae: 0.0739\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0508 - val_loss: 0.0159 - val_mae: 0.0737\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0157 - val_mae: 0.0735\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0155 - val_mae: 0.0734\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0155 - val_mae: 0.0734\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0157 - val_mae: 0.0735\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0160 - val_mae: 0.0737\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0027 - mae: 0.0523 - val_loss: 0.0163 - val_mae: 0.0740\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0501 - val_loss: 0.0163 - val_mae: 0.0741\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0489 - val_loss: 0.0162 - val_mae: 0.0740\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0025 - mae: 0.0472 - val_loss: 0.0160 - val_mae: 0.0738\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0157 - val_mae: 0.0734\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0157 - val_mae: 0.0734\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0478 - val_loss: 0.0160 - val_mae: 0.0737\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0487 - val_loss: 0.0163 - val_mae: 0.0741\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0165 - val_mae: 0.0744\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0470 - val_loss: 0.0165 - val_mae: 0.0745\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0164 - val_mae: 0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:16,002] Trial 8 finished with value: 0.07435319572687149 and parameters: {'learning_rate': 0.0003352877092827578, 'weight_decay': 0.005234392960100975}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1155\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.0992 - val_loss: 0.0242 - val_mae: 0.1120\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0238 - val_mae: 0.1083\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0233 - val_mae: 0.1044\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1005\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0829 - val_loss: 0.0223 - val_mae: 0.0967\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0219 - val_mae: 0.0936\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0214 - val_mae: 0.0908\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0771 - val_loss: 0.0210 - val_mae: 0.0886\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0775 - val_loss: 0.0207 - val_mae: 0.0879\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0203 - val_mae: 0.0881\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0058 - mae: 0.0771 - val_loss: 0.0200 - val_mae: 0.0878\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0197 - val_mae: 0.0869\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0193 - val_mae: 0.0855\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0840\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0187 - val_mae: 0.0826\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0185 - val_mae: 0.0815\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0789\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0181 - val_mae: 0.0784\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0643 - val_loss: 0.0180 - val_mae: 0.0775\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0179 - val_mae: 0.0771\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0569 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0175 - val_mae: 0.0796\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0554 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - mae: 0.0581 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0176 - val_mae: 0.0786\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0800\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0812\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0169 - val_mae: 0.0810\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0800\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0168 - val_mae: 0.0800\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0799\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0166 - val_mae: 0.0803\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0165 - val_mae: 0.0799\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0164 - val_mae: 0.0790\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0166 - val_mae: 0.0775\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0165 - val_mae: 0.0773\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0024 - mae: 0.0509 - val_loss: 0.0163 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0027 - mae: 0.0526 - val_loss: 0.0162 - val_mae: 0.0773\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0161 - val_mae: 0.0777\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0163 - val_mae: 0.0769\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0165 - val_mae: 0.0771\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0026 - mae: 0.0499 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0161 - val_mae: 0.0811\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0501 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0501 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0024 - mae: 0.0475 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0506 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0436 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0457 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0164 - val_mae: 0.0868\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0458 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0171 - val_mae: 0.0854\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - mae: 0.0387 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.0172 - val_mae: 0.0869\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0172 - val_mae: 0.0884\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0892\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0174 - val_mae: 0.0897\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - mae: 0.0399 - val_loss: 0.0174 - val_mae: 0.0910\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0433 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0458 - val_loss: 0.0176 - val_mae: 0.0960\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0175 - val_mae: 0.0963\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0174 - val_mae: 0.0937\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0178 - val_mae: 0.0895\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0180 - val_mae: 0.0893\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 0.0182 - val_mae: 0.0908\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0184 - val_mae: 0.0934\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0183 - val_mae: 0.0944\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0016 - mae: 0.0388 - val_loss: 0.0182 - val_mae: 0.0953\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0180 - val_mae: 0.0954\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0511 - val_loss: 0.0181 - val_mae: 0.0923\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0182 - val_mae: 0.0905\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0183 - val_mae: 0.0900\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0185 - val_mae: 0.0901\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0351 - val_loss: 0.0186 - val_mae: 0.0911\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0188 - val_mae: 0.0933\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0190 - val_mae: 0.0960\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0193 - val_mae: 0.0988\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0014 - mae: 0.0387 - val_loss: 0.0192 - val_mae: 0.1016\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0189 - val_mae: 0.1002\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0188 - val_mae: 0.0983\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0013 - mae: 0.0383 - val_loss: 0.0187 - val_mae: 0.0966\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0187 - val_mae: 0.0955\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0188 - val_mae: 0.0954\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0190 - val_mae: 0.0967\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0390 - val_loss: 0.0194 - val_mae: 0.0995\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - mae: 0.0390 - val_loss: 0.0198 - val_mae: 0.1027\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0197 - val_mae: 0.1029\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0193 - val_mae: 0.1006\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0387 - val_loss: 0.0190 - val_mae: 0.0998\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0189 - val_mae: 0.0992\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0191 - val_mae: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:35,641] Trial 9 finished with value: 0.09938155114650726 and parameters: {'learning_rate': 0.000914675241246063, 'weight_decay': 0.0027154426589994975}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1212\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1077 - val_loss: 0.0252 - val_mae: 0.1210\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0251 - val_mae: 0.1207\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0251 - val_mae: 0.1204\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1055 - val_loss: 0.0250 - val_mae: 0.1202\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0250 - val_mae: 0.1199\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1185\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1178\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1175\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1172\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1169\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1012 - val_loss: 0.0244 - val_mae: 0.1166\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0244 - val_mae: 0.1163\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1160\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1156\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0242 - val_mae: 0.1153\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1150\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0241 - val_mae: 0.1144\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1141\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0239 - val_mae: 0.1135\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1132\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0238 - val_mae: 0.1125\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1118\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0950 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0946 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0227 - val_mae: 0.1054\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0075 - mae: 0.0901 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0959 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0225 - val_mae: 0.1044\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0076 - mae: 0.0925 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0224 - val_mae: 0.1038\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0223 - val_mae: 0.1035\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0223 - val_mae: 0.1032\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0222 - val_mae: 0.1029\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0894 - val_loss: 0.0222 - val_mae: 0.1026\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0221 - val_mae: 0.1023\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0221 - val_mae: 0.1020\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0882 - val_loss: 0.0220 - val_mae: 0.1017\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0219 - val_mae: 0.1015\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0219 - val_mae: 0.1012\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0218 - val_mae: 0.1010\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.1007\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0217 - val_mae: 0.1005\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0217 - val_mae: 0.1003\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.1000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0910 - val_loss: 0.0216 - val_mae: 0.0998\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0215 - val_mae: 0.0995\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0215 - val_mae: 0.0993\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0214 - val_mae: 0.0991\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0214 - val_mae: 0.0988\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0213 - val_mae: 0.0986\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0213 - val_mae: 0.0984\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0066 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0981\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0212 - val_mae: 0.0979\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0868 - val_loss: 0.0211 - val_mae: 0.0977\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0070 - mae: 0.0863 - val_loss: 0.0211 - val_mae: 0.0974\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0210 - val_mae: 0.0972\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0840 - val_loss: 0.0210 - val_mae: 0.0970\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0210 - val_mae: 0.0968\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0855 - val_loss: 0.0209 - val_mae: 0.0965\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0209 - val_mae: 0.0963\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0208 - val_mae: 0.0961\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0208 - val_mae: 0.0959\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0956\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0207 - val_mae: 0.0954\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0826 - val_loss: 0.0206 - val_mae: 0.0952\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0950\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0206 - val_mae: 0.0948\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0816 - val_loss: 0.0205 - val_mae: 0.0946\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0205 - val_mae: 0.0944\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0204 - val_mae: 0.0942\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0822 - val_loss: 0.0204 - val_mae: 0.0940\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0062 - mae: 0.0815 - val_loss: 0.0204 - val_mae: 0.0938\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0203 - val_mae: 0.0936\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0935\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0202 - val_mae: 0.0933\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0807 - val_loss: 0.0202 - val_mae: 0.0931\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0789 - val_loss: 0.0201 - val_mae: 0.0928\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0781 - val_loss: 0.0201 - val_mae: 0.0926\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061 - mae: 0.0781 - val_loss: 0.0200 - val_mae: 0.0925\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0200 - val_mae: 0.0923\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0062 - mae: 0.0792 - val_loss: 0.0200 - val_mae: 0.0921\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0920\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0809 - val_loss: 0.0199 - val_mae: 0.0918\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0789 - val_loss: 0.0199 - val_mae: 0.0916\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0198 - val_mae: 0.0915\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - mae: 0.0784 - val_loss: 0.0198 - val_mae: 0.0913\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0799 - val_loss: 0.0198 - val_mae: 0.0912\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0197 - val_mae: 0.0910\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0058 - mae: 0.0790 - val_loss: 0.0197 - val_mae: 0.0908\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0197 - val_mae: 0.0907\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - mae: 0.0777 - val_loss: 0.0196 - val_mae: 0.0905\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0062 - mae: 0.0805 - val_loss: 0.0196 - val_mae: 0.0903\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0196 - val_mae: 0.0902\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0900\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0899\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0897\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0777 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0760 - val_loss: 0.0194 - val_mae: 0.0894\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0194 - val_mae: 0.0893\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0787 - val_loss: 0.0194 - val_mae: 0.0891\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0767 - val_loss: 0.0193 - val_mae: 0.0890\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0770 - val_loss: 0.0193 - val_mae: 0.0889\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0193 - val_mae: 0.0887\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0058 - mae: 0.0767 - val_loss: 0.0193 - val_mae: 0.0886\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0192 - val_mae: 0.0884\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0883\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0192 - val_mae: 0.0882\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0796 - val_loss: 0.0191 - val_mae: 0.0880\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0191 - val_mae: 0.0879\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0191 - val_mae: 0.0877\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0060 - mae: 0.0802 - val_loss: 0.0191 - val_mae: 0.0876\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0757 - val_loss: 0.0191 - val_mae: 0.0875\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0735 - val_loss: 0.0190 - val_mae: 0.0873\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0765 - val_loss: 0.0190 - val_mae: 0.0872\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0190 - val_mae: 0.0870\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0868\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0867\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0189 - val_mae: 0.0865\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0059 - mae: 0.0765 - val_loss: 0.0189 - val_mae: 0.0864\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0189 - val_mae: 0.0862\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0189 - val_mae: 0.0861\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0189 - val_mae: 0.0859\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0057 - mae: 0.0734 - val_loss: 0.0189 - val_mae: 0.0858\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0767 - val_loss: 0.0188 - val_mae: 0.0856\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0720 - val_loss: 0.0188 - val_mae: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:55,140] Trial 10 finished with value: 0.0854678675532341 and parameters: {'learning_rate': 4.289683716756164e-05, 'weight_decay': 0.00028284680352012095}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0104 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1157\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0097 - mae: 0.1033 - val_loss: 0.0235 - val_mae: 0.1128\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0231 - val_mae: 0.1101\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0985 - val_loss: 0.0228 - val_mae: 0.1075\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0951 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0911 - val_loss: 0.0221 - val_mae: 0.1000\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0219 - val_mae: 0.0979\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0874 - val_loss: 0.0218 - val_mae: 0.0958\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0216 - val_mae: 0.0936\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0214 - val_mae: 0.0914\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0212 - val_mae: 0.0892\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0210 - val_mae: 0.0873\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0208 - val_mae: 0.0855\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0205 - val_mae: 0.0840\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0753 - val_loss: 0.0203 - val_mae: 0.0827\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0200 - val_mae: 0.0814\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0197 - val_mae: 0.0803\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0195 - val_mae: 0.0792\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0710 - val_loss: 0.0192 - val_mae: 0.0785\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0704 - val_loss: 0.0190 - val_mae: 0.0780\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0715 - val_loss: 0.0187 - val_mae: 0.0776\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0185 - val_mae: 0.0774\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0182 - val_mae: 0.0772\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0704 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0716 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0773\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0674 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0670 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0777\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0780\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0783\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0772\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0547 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0784\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0786\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0788\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.0165 - val_mae: 0.0788\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0166 - val_mae: 0.0783\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0029 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0162 - val_mae: 0.0787\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0027 - mae: 0.0565 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0023 - mae: 0.0517 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0166 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0164 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0160 - val_mae: 0.0777\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0157 - val_mae: 0.0778\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0157 - val_mae: 0.0776\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0158 - val_mae: 0.0771\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0026 - mae: 0.0501 - val_loss: 0.0158 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0155 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0155 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0157 - val_mae: 0.0765\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0157 - val_mae: 0.0761\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0156 - val_mae: 0.0761\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0474 - val_loss: 0.0152 - val_mae: 0.0765\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0150 - val_mae: 0.0769\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0146 - val_mae: 0.0782\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0154 - val_mae: 0.0750\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0158 - val_mae: 0.0750\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0029 - mae: 0.0501 - val_loss: 0.0157 - val_mae: 0.0748\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0154 - val_mae: 0.0748\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0150 - val_mae: 0.0753\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0145 - val_mae: 0.0765\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0767\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0028 - mae: 0.0575 - val_loss: 0.0148 - val_mae: 0.0756\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0022 - mae: 0.0453 - val_loss: 0.0153 - val_mae: 0.0750\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0021 - mae: 0.0444 - val_loss: 0.0152 - val_mae: 0.0752\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0150 - val_mae: 0.0756\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0151 - val_mae: 0.0757\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0154 - val_mae: 0.0756\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.0155 - val_mae: 0.0756\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0452 - val_loss: 0.0155 - val_mae: 0.0756\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - mae: 0.0457 - val_loss: 0.0154 - val_mae: 0.0757\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0152 - val_mae: 0.0760\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0149 - val_mae: 0.0766\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0146 - val_mae: 0.0775\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0444 - val_loss: 0.0148 - val_mae: 0.0764\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0150 - val_mae: 0.0754\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0153 - val_mae: 0.0752\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0419 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0149 - val_mae: 0.0752\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0149 - val_mae: 0.0755\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0147 - val_mae: 0.0761\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:15,144] Trial 11 finished with value: 0.07798068970441818 and parameters: {'learning_rate': 0.0005590431010763924, 'weight_decay': 0.0025714834255179736}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0242 - val_mae: 0.1115\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0239 - val_mae: 0.1091\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1065\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0930 - val_loss: 0.0231 - val_mae: 0.1038\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0227 - val_mae: 0.1012\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0224 - val_mae: 0.0987\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0862 - val_loss: 0.0221 - val_mae: 0.0963\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0071 - mae: 0.0861 - val_loss: 0.0217 - val_mae: 0.0941\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0214 - val_mae: 0.0922\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0812 - val_loss: 0.0211 - val_mae: 0.0906\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0208 - val_mae: 0.0892\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0814 - val_loss: 0.0205 - val_mae: 0.0879\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0202 - val_mae: 0.0868\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0709 - val_loss: 0.0199 - val_mae: 0.0859\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0197 - val_mae: 0.0852\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0194 - val_mae: 0.0846\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0192 - val_mae: 0.0840\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0747 - val_loss: 0.0190 - val_mae: 0.0835\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0188 - val_mae: 0.0829\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0187 - val_mae: 0.0823\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0185 - val_mae: 0.0817\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0042 - mae: 0.0683 - val_loss: 0.0184 - val_mae: 0.0811\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0182 - val_mae: 0.0806\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0692 - val_loss: 0.0181 - val_mae: 0.0804\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0718 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0179 - val_mae: 0.0798\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0796\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0714 - val_loss: 0.0177 - val_mae: 0.0794\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0714 - val_loss: 0.0177 - val_mae: 0.0792\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0644 - val_loss: 0.0177 - val_mae: 0.0790\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0177 - val_mae: 0.0787\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0177 - val_mae: 0.0784\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0043 - mae: 0.0615 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0176 - val_mae: 0.0765\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0772\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0169 - val_mae: 0.0777\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0549 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0571 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0770\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0029 - mae: 0.0530 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0786\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0167 - val_mae: 0.0787\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0166 - val_mae: 0.0789\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0166 - val_mae: 0.0790\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.0791\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0166 - val_mae: 0.0788\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0166 - val_mae: 0.0789\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0029 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0163 - val_mae: 0.0796\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0162 - val_mae: 0.0797\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0162 - val_mae: 0.0799\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0495 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0513 - val_loss: 0.0156 - val_mae: 0.0796\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0156 - val_mae: 0.0788\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0487 - val_loss: 0.0154 - val_mae: 0.0786\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0154 - val_mae: 0.0789\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0470 - val_loss: 0.0153 - val_mae: 0.0796\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0154 - val_mae: 0.0794\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0156 - val_mae: 0.0792\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0500 - val_loss: 0.0157 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0157 - val_mae: 0.0785\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0157 - val_mae: 0.0782\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0492 - val_loss: 0.0156 - val_mae: 0.0784\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0155 - val_mae: 0.0793\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0021 - mae: 0.0474 - val_loss: 0.0156 - val_mae: 0.0793\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0520 - val_loss: 0.0158 - val_mae: 0.0794\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0020 - mae: 0.0431 - val_loss: 0.0159 - val_mae: 0.0796\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0494 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0161 - val_mae: 0.0803\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0161 - val_mae: 0.0807\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0159 - val_mae: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:35,158] Trial 12 finished with value: 0.08121491968631744 and parameters: {'learning_rate': 0.00043989489918975344, 'weight_decay': 0.007034459955486363}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0249 - val_mae: 0.1245\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0102 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1243\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - mae: 0.1143 - val_loss: 0.0249 - val_mae: 0.1242\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0249 - val_mae: 0.1240\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0106 - mae: 0.1129 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1123 - val_loss: 0.0249 - val_mae: 0.1238\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1123 - val_loss: 0.0248 - val_mae: 0.1236\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0248 - val_mae: 0.1235\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1233\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0248 - val_mae: 0.1232\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0096 - mae: 0.1092 - val_loss: 0.0248 - val_mae: 0.1230\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0248 - val_mae: 0.1229\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1227\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1226\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1139 - val_loss: 0.0247 - val_mae: 0.1224\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0105 - mae: 0.1119 - val_loss: 0.0247 - val_mae: 0.1223\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1118 - val_loss: 0.0247 - val_mae: 0.1221\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1100 - val_loss: 0.0247 - val_mae: 0.1220\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1080 - val_loss: 0.0247 - val_mae: 0.1217\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1216\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1084 - val_loss: 0.0246 - val_mae: 0.1214\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1213\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1211\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0246 - val_mae: 0.1210\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1209\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0246 - val_mae: 0.1207\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0245 - val_mae: 0.1205\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1203\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1202\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1196\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1194\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1193\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1190\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1189\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1188\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0243 - val_mae: 0.1185\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1184\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1099 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0243 - val_mae: 0.1182\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1066 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0242 - val_mae: 0.1177\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0242 - val_mae: 0.1175\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0241 - val_mae: 0.1166\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1161\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1157\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0240 - val_mae: 0.1156\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1154\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0240 - val_mae: 0.1150\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1148\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1147\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1139\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0239 - val_mae: 0.1138\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1134\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1132\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1012 - val_loss: 0.0238 - val_mae: 0.1131\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0982 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0086 - mae: 0.1008 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1128\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1125\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0237 - val_mae: 0.1121\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1118\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1117\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0236 - val_mae: 0.1114\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0236 - val_mae: 0.1112\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0236 - val_mae: 0.1109\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0236 - val_mae: 0.1106\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1105\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1104\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0235 - val_mae: 0.1101\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1098\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0235 - val_mae: 0.1097\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1096\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1095\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1094\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0234 - val_mae: 0.1093\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0234 - val_mae: 0.1092\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0234 - val_mae: 0.1091\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0234 - val_mae: 0.1090\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1089\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0234 - val_mae: 0.1088\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0234 - val_mae: 0.1087\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1085\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1084\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1083\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0952 - val_loss: 0.0233 - val_mae: 0.1081\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1080\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0977 - val_loss: 0.0233 - val_mae: 0.1079\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0233 - val_mae: 0.1078\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0232 - val_mae: 0.1077\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0232 - val_mae: 0.1076\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0232 - val_mae: 0.1075\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0232 - val_mae: 0.1074\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0232 - val_mae: 0.1073\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1072\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1071\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0232 - val_mae: 0.1070\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0232 - val_mae: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:54,883] Trial 13 finished with value: 0.1069079041481018 and parameters: {'learning_rate': 2.1001119062357468e-05, 'weight_decay': 0.001730172030387585}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0184 - val_mae: 0.0987\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0068 - mae: 0.0917 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0633 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0907\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0688 - val_loss: 0.0172 - val_mae: 0.0941\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0677 - val_loss: 0.0173 - val_mae: 0.0939\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0920\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0881\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0868\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0867\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0029 - mae: 0.0545 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0172 - val_mae: 0.0855\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0852\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0850\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0855\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0174 - val_mae: 0.0847\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0843\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0175 - val_mae: 0.0838\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0833\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0029 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0862\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0869\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0176 - val_mae: 0.0875\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0179 - val_mae: 0.0877\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0178 - val_mae: 0.0866\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0179 - val_mae: 0.0854\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0179 - val_mae: 0.0847\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0180 - val_mae: 0.0846\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0181 - val_mae: 0.0851\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0181 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0180 - val_mae: 0.0836\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0178 - val_mae: 0.0837\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0177 - val_mae: 0.0836\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0541 - val_loss: 0.0177 - val_mae: 0.0836\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0178 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0178 - val_mae: 0.0846\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0178 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0178 - val_mae: 0.0859\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0178 - val_mae: 0.0865\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0179 - val_mae: 0.0866\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0180 - val_mae: 0.0866\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0181 - val_mae: 0.0864\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0178 - val_mae: 0.0844\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0177 - val_mae: 0.0833\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0177 - val_mae: 0.0825\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0177 - val_mae: 0.0822\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0180 - val_mae: 0.0836\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0180 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.0832\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0179 - val_mae: 0.0855\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0179 - val_mae: 0.0861\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0171 - val_mae: 0.0857\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0024 - mae: 0.0526 - val_loss: 0.0173 - val_mae: 0.0871\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0467 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0181 - val_mae: 0.0835\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0024 - mae: 0.0506 - val_loss: 0.0185 - val_mae: 0.0862\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0186 - val_mae: 0.0861\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0021 - mae: 0.0423 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0037 - mae: 0.0585 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - mae: 0.0516 - val_loss: 0.0170 - val_mae: 0.0815\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0516 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0064 - mae: 0.0708 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0020 - mae: 0.0435 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0856\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0175 - val_mae: 0.0851\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0176 - val_mae: 0.0865\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0504 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0173 - val_mae: 0.0835\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0024 - mae: 0.0510 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0530 - val_loss: 0.0179 - val_mae: 0.0872\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0848\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0178 - val_mae: 0.0803\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0182 - val_mae: 0.0815\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0187 - val_mae: 0.0840\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0195 - val_mae: 0.0895\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0197 - val_mae: 0.0920\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0197 - val_mae: 0.0930\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0194 - val_mae: 0.0919\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0197 - val_mae: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:14,656] Trial 14 finished with value: 0.09371820092201233 and parameters: {'learning_rate': 0.011725304429684976, 'weight_decay': 0.0067212838944218254}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0087 - mae: 0.0991 - val_loss: 0.0234 - val_mae: 0.1103\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0081 - mae: 0.0965 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0929 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0077 - mae: 0.0884 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0969\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0214 - val_mae: 0.0950\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.0933\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0209 - val_mae: 0.0915\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0822 - val_loss: 0.0204 - val_mae: 0.0884\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0807 - val_loss: 0.0202 - val_mae: 0.0869\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0199 - val_mae: 0.0855\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0197 - val_mae: 0.0841\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0194 - val_mae: 0.0828\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0192 - val_mae: 0.0817\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0054 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0806\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0051 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0185 - val_mae: 0.0788\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0183 - val_mae: 0.0782\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0740 - val_loss: 0.0181 - val_mae: 0.0776\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0052 - mae: 0.0738 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0175 - val_mae: 0.0769\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0734 - val_loss: 0.0174 - val_mae: 0.0770\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0173 - val_mae: 0.0768\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0672 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0040 - mae: 0.0660 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0039 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0041 - mae: 0.0658 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0795\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0171 - val_mae: 0.0798\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0801\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0633 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0171 - val_mae: 0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:35,304] Trial 15 finished with value: 0.08110315352678299 and parameters: {'learning_rate': 0.0003509553348993356, 'weight_decay': 1.5962506432695974e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0108 - mae: 0.1114 - val_loss: 0.0255 - val_mae: 0.1229\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1107 - val_loss: 0.0253 - val_mae: 0.1223\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0252 - val_mae: 0.1217\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1117 - val_loss: 0.0251 - val_mae: 0.1211\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0250 - val_mae: 0.1204\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0249 - val_mae: 0.1198\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - mae: 0.1072 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1165\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0242 - val_mae: 0.1159\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1153\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1147\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0239 - val_mae: 0.1135\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0990 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0085 - mae: 0.0963 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.0975 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1097\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1087\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1082\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1072\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0084 - mae: 0.0925 - val_loss: 0.0230 - val_mae: 0.1062\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0906 - val_loss: 0.0229 - val_mae: 0.1052\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1036\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0226 - val_mae: 0.1026\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.1021\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0224 - val_mae: 0.1010\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0223 - val_mae: 0.1005\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0223 - val_mae: 0.0999\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0222 - val_mae: 0.0994\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0222 - val_mae: 0.0989\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0221 - val_mae: 0.0983\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0853 - val_loss: 0.0221 - val_mae: 0.0978\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0881 - val_loss: 0.0220 - val_mae: 0.0972\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0220 - val_mae: 0.0967\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0862 - val_loss: 0.0219 - val_mae: 0.0961\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0949\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0064 - mae: 0.0789 - val_loss: 0.0217 - val_mae: 0.0944\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0938\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0070 - mae: 0.0833 - val_loss: 0.0216 - val_mae: 0.0933\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0073 - mae: 0.0852 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0215 - val_mae: 0.0922\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0214 - val_mae: 0.0916\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0911\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071 - mae: 0.0826 - val_loss: 0.0213 - val_mae: 0.0905\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0212 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0065 - mae: 0.0783 - val_loss: 0.0212 - val_mae: 0.0894\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0068 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0884\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0797 - val_loss: 0.0210 - val_mae: 0.0878\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0061 - mae: 0.0773 - val_loss: 0.0209 - val_mae: 0.0873\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0209 - val_mae: 0.0869\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0208 - val_mae: 0.0864\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0207 - val_mae: 0.0860\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0207 - val_mae: 0.0856\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065 - mae: 0.0814 - val_loss: 0.0206 - val_mae: 0.0852\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061 - mae: 0.0761 - val_loss: 0.0205 - val_mae: 0.0846\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0843\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0204 - val_mae: 0.0841\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0775 - val_loss: 0.0204 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0203 - val_mae: 0.0836\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0750 - val_loss: 0.0202 - val_mae: 0.0831\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0725 - val_loss: 0.0202 - val_mae: 0.0828\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0059 - mae: 0.0738 - val_loss: 0.0201 - val_mae: 0.0826\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0767 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0200 - val_mae: 0.0821\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0200 - val_mae: 0.0818\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0199 - val_mae: 0.0816\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0059 - mae: 0.0739 - val_loss: 0.0199 - val_mae: 0.0813\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0060 - mae: 0.0768 - val_loss: 0.0198 - val_mae: 0.0811\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0198 - val_mae: 0.0809\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0056 - mae: 0.0731 - val_loss: 0.0197 - val_mae: 0.0806\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0197 - val_mae: 0.0804\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0197 - val_mae: 0.0802\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0709 - val_loss: 0.0196 - val_mae: 0.0798\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0713 - val_loss: 0.0195 - val_mae: 0.0793\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0194 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0194 - val_mae: 0.0789\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0052 - mae: 0.0687 - val_loss: 0.0193 - val_mae: 0.0787\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0051 - mae: 0.0691 - val_loss: 0.0193 - val_mae: 0.0785\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0192 - val_mae: 0.0783\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0192 - val_mae: 0.0782\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0192 - val_mae: 0.0780\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0191 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0054 - mae: 0.0693 - val_loss: 0.0191 - val_mae: 0.0776\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0190 - val_mae: 0.0774\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0190 - val_mae: 0.0773\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0189 - val_mae: 0.0771\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0734 - val_loss: 0.0189 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0685 - val_loss: 0.0188 - val_mae: 0.0768\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0052 - mae: 0.0705 - val_loss: 0.0188 - val_mae: 0.0766\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0765\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0762 - val_loss: 0.0187 - val_mae: 0.0764\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0763\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0186 - val_mae: 0.0762\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0186 - val_mae: 0.0761\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0185 - val_mae: 0.0760\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0675 - val_loss: 0.0185 - val_mae: 0.0759\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0185 - val_mae: 0.0759\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0184 - val_mae: 0.0758\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0757\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0184 - val_mae: 0.0756\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0688 - val_loss: 0.0184 - val_mae: 0.0756\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0050 - mae: 0.0729 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0742 - val_loss: 0.0183 - val_mae: 0.0754\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0183 - val_mae: 0.0753\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0183 - val_mae: 0.0753\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0183 - val_mae: 0.0752\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0182 - val_mae: 0.0751\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0696 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0182 - val_mae: 0.0749\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0182 - val_mae: 0.0749\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0684 - val_loss: 0.0182 - val_mae: 0.0748\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0182 - val_mae: 0.0748\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0615 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0045 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0650 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0746\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0179 - val_mae: 0.0746\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:55,081] Trial 16 finished with value: 0.07469943165779114 and parameters: {'learning_rate': 0.00011375913831331624, 'weight_decay': 0.006909327268532185}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0242 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0242 - val_mae: 0.1205\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0241 - val_mae: 0.1203\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1078 - val_loss: 0.0241 - val_mae: 0.1201\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1199\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0240 - val_mae: 0.1197\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0240 - val_mae: 0.1195\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0240 - val_mae: 0.1193\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0240 - val_mae: 0.1191\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0239 - val_mae: 0.1189\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1187\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1185\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0238 - val_mae: 0.1181\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0238 - val_mae: 0.1179\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1173\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1171\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0236 - val_mae: 0.1165\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1164\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1162\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0236 - val_mae: 0.1160\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0236 - val_mae: 0.1158\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0235 - val_mae: 0.1157\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0235 - val_mae: 0.1155\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0235 - val_mae: 0.1153\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0235 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0235 - val_mae: 0.1150\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0234 - val_mae: 0.1148\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0234 - val_mae: 0.1146\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0234 - val_mae: 0.1145\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1025 - val_loss: 0.0234 - val_mae: 0.1143\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0234 - val_mae: 0.1141\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0233 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0233 - val_mae: 0.1138\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0233 - val_mae: 0.1137\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0233 - val_mae: 0.1135\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0233 - val_mae: 0.1133\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0232 - val_mae: 0.1132\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0232 - val_mae: 0.1130\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1020 - val_loss: 0.0232 - val_mae: 0.1129\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1127\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0232 - val_mae: 0.1126\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0231 - val_mae: 0.1124\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0231 - val_mae: 0.1122\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1121\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0231 - val_mae: 0.1119\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0231 - val_mae: 0.1118\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1116\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0230 - val_mae: 0.1114\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0230 - val_mae: 0.1113\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0230 - val_mae: 0.1111\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0991 - val_loss: 0.0230 - val_mae: 0.1110\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0229 - val_mae: 0.1108\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0229 - val_mae: 0.1106\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1105\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0229 - val_mae: 0.1103\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0229 - val_mae: 0.1101\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0993 - val_loss: 0.0228 - val_mae: 0.1100\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0228 - val_mae: 0.1098\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0228 - val_mae: 0.1096\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0985 - val_loss: 0.0228 - val_mae: 0.1095\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0228 - val_mae: 0.1093\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0227 - val_mae: 0.1091\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0227 - val_mae: 0.1090\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0227 - val_mae: 0.1088\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0227 - val_mae: 0.1087\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0227 - val_mae: 0.1085\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0226 - val_mae: 0.1083\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0226 - val_mae: 0.1081\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0226 - val_mae: 0.1080\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0226 - val_mae: 0.1078\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0226 - val_mae: 0.1076\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0225 - val_mae: 0.1074\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1073\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0225 - val_mae: 0.1071\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0225 - val_mae: 0.1069\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1067\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0224 - val_mae: 0.1066\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0224 - val_mae: 0.1064\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0224 - val_mae: 0.1062\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0224 - val_mae: 0.1060\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0224 - val_mae: 0.1058\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0917 - val_loss: 0.0223 - val_mae: 0.1057\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0223 - val_mae: 0.1055\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0223 - val_mae: 0.1053\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0223 - val_mae: 0.1051\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0223 - val_mae: 0.1049\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0222 - val_mae: 0.1048\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0082 - mae: 0.0937 - val_loss: 0.0222 - val_mae: 0.1046\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0222 - val_mae: 0.1044\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0222 - val_mae: 0.1042\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0222 - val_mae: 0.1041\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0902 - val_loss: 0.0221 - val_mae: 0.1039\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0221 - val_mae: 0.1037\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0221 - val_mae: 0.1035\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0221 - val_mae: 0.1033\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0221 - val_mae: 0.1032\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0220 - val_mae: 0.1030\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0220 - val_mae: 0.1028\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0220 - val_mae: 0.1026\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0220 - val_mae: 0.1024\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0884 - val_loss: 0.0220 - val_mae: 0.1022\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0219 - val_mae: 0.1020\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0883 - val_loss: 0.0219 - val_mae: 0.1019\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0219 - val_mae: 0.1017\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0219 - val_mae: 0.1015\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0218 - val_mae: 0.1013\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0218 - val_mae: 0.1011\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.1009\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0218 - val_mae: 0.1007\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0218 - val_mae: 0.1005\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0217 - val_mae: 0.1003\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0217 - val_mae: 0.1002\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0217 - val_mae: 0.1000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0217 - val_mae: 0.0998\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0888 - val_loss: 0.0217 - val_mae: 0.0996\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0861 - val_loss: 0.0216 - val_mae: 0.0994\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0216 - val_mae: 0.0992\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0216 - val_mae: 0.0990\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0216 - val_mae: 0.0988\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0215 - val_mae: 0.0986\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0215 - val_mae: 0.0984\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0068 - mae: 0.0823 - val_loss: 0.0215 - val_mae: 0.0982\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0215 - val_mae: 0.0980\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0073 - mae: 0.0881 - val_loss: 0.0215 - val_mae: 0.0978\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0078 - mae: 0.0888 - val_loss: 0.0214 - val_mae: 0.0976\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0071 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0974\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0214 - val_mae: 0.0972\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0214 - val_mae: 0.0970\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0847 - val_loss: 0.0213 - val_mae: 0.0968\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0213 - val_mae: 0.0966\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0213 - val_mae: 0.0964\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0846 - val_loss: 0.0213 - val_mae: 0.0962\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0212 - val_mae: 0.0960\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0958\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0071 - mae: 0.0858 - val_loss: 0.0212 - val_mae: 0.0956\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0212 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0212 - val_mae: 0.0951\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0211 - val_mae: 0.0949\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0211 - val_mae: 0.0947\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0847 - val_loss: 0.0211 - val_mae: 0.0945\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0846 - val_loss: 0.0211 - val_mae: 0.0943\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0210 - val_mae: 0.0941\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0068 - mae: 0.0818 - val_loss: 0.0210 - val_mae: 0.0939\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0075 - mae: 0.0857 - val_loss: 0.0210 - val_mae: 0.0937\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0210 - val_mae: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:14,732] Trial 17 finished with value: 0.09353812783956528 and parameters: {'learning_rate': 3.8861585707874365e-05, 'weight_decay': 0.0061637418399309715}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1057 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:34,268] Trial 18 finished with value: 0.11748065054416656 and parameters: {'learning_rate': 3.9091321312414766e-06, 'weight_decay': 7.95255895567331e-07}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0249 - val_mae: 0.1162\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0248 - val_mae: 0.1156\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1149\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0246 - val_mae: 0.1143\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1137\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1131\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.0987 - val_loss: 0.0244 - val_mae: 0.1124\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0243 - val_mae: 0.1118\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1112\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0241 - val_mae: 0.1106\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0240 - val_mae: 0.1100\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0240 - val_mae: 0.1094\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - mae: 0.0972 - val_loss: 0.0239 - val_mae: 0.1089\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0238 - val_mae: 0.1083\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0237 - val_mae: 0.1078\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0237 - val_mae: 0.1072\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0236 - val_mae: 0.1067\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0235 - val_mae: 0.1061\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0235 - val_mae: 0.1055\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0234 - val_mae: 0.1049\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0233 - val_mae: 0.1044\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0232 - val_mae: 0.1038\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0232 - val_mae: 0.1032\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0231 - val_mae: 0.1027\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0887 - val_loss: 0.0230 - val_mae: 0.1021\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0230 - val_mae: 0.1016\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0229 - val_mae: 0.1011\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0228 - val_mae: 0.1006\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0896 - val_loss: 0.0228 - val_mae: 0.1001\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0227 - val_mae: 0.0996\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0846 - val_loss: 0.0227 - val_mae: 0.0991\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0226 - val_mae: 0.0987\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0226 - val_mae: 0.0983\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0225 - val_mae: 0.0978\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0863 - val_loss: 0.0224 - val_mae: 0.0974\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0224 - val_mae: 0.0969\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0223 - val_mae: 0.0965\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0223 - val_mae: 0.0960\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0222 - val_mae: 0.0955\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0222 - val_mae: 0.0951\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0073 - mae: 0.0865 - val_loss: 0.0221 - val_mae: 0.0946\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0220 - val_mae: 0.0941\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0220 - val_mae: 0.0936\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0065 - mae: 0.0808 - val_loss: 0.0219 - val_mae: 0.0932\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0825 - val_loss: 0.0219 - val_mae: 0.0927\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0218 - val_mae: 0.0922\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0217 - val_mae: 0.0918\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0217 - val_mae: 0.0914\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0797 - val_loss: 0.0216 - val_mae: 0.0910\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0215 - val_mae: 0.0905\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0215 - val_mae: 0.0901\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0214 - val_mae: 0.0897\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0892\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0802 - val_loss: 0.0213 - val_mae: 0.0888\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0212 - val_mae: 0.0884\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0061 - mae: 0.0756 - val_loss: 0.0212 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0761 - val_loss: 0.0211 - val_mae: 0.0876\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0872\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0210 - val_mae: 0.0868\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0209 - val_mae: 0.0864\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063 - mae: 0.0788 - val_loss: 0.0209 - val_mae: 0.0860\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0208 - val_mae: 0.0856\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0766 - val_loss: 0.0208 - val_mae: 0.0852\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0752 - val_loss: 0.0207 - val_mae: 0.0848\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0206 - val_mae: 0.0845\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0206 - val_mae: 0.0842\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0205 - val_mae: 0.0839\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0718 - val_loss: 0.0205 - val_mae: 0.0836\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0763 - val_loss: 0.0204 - val_mae: 0.0833\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0734 - val_loss: 0.0203 - val_mae: 0.0831\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0748 - val_loss: 0.0203 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0813 - val_loss: 0.0202 - val_mae: 0.0827\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0202 - val_mae: 0.0825\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0746 - val_loss: 0.0200 - val_mae: 0.0821\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0696 - val_loss: 0.0200 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0199 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0198 - val_mae: 0.0815\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0198 - val_mae: 0.0814\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0197 - val_mae: 0.0812\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0197 - val_mae: 0.0810\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0196 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0196 - val_mae: 0.0806\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0195 - val_mae: 0.0805\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0056 - mae: 0.0717 - val_loss: 0.0195 - val_mae: 0.0803\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0194 - val_mae: 0.0801\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0715 - val_loss: 0.0194 - val_mae: 0.0799\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0193 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0051 - mae: 0.0712 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0193 - val_mae: 0.0794\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0192 - val_mae: 0.0793\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0192 - val_mae: 0.0791\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0192 - val_mae: 0.0790\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0687 - val_loss: 0.0191 - val_mae: 0.0788\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0191 - val_mae: 0.0787\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0055 - mae: 0.0721 - val_loss: 0.0191 - val_mae: 0.0786\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0190 - val_mae: 0.0785\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0046 - mae: 0.0692 - val_loss: 0.0190 - val_mae: 0.0783\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0190 - val_mae: 0.0782\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0189 - val_mae: 0.0781\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - mae: 0.0723 - val_loss: 0.0189 - val_mae: 0.0779\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - mae: 0.0727 - val_loss: 0.0188 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0050 - mae: 0.0679 - val_loss: 0.0188 - val_mae: 0.0777\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0049 - mae: 0.0708 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0691 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0187 - val_mae: 0.0774\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0186 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0048 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0047 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0687 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0709 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0692 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0043 - mae: 0.0634 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0182 - val_mae: 0.0769\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0182 - val_mae: 0.0768\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0182 - val_mae: 0.0767\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0702 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0763\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0180 - val_mae: 0.0763\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0764\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0180 - val_mae: 0.0764\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0180 - val_mae: 0.0765\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0656 - val_loss: 0.0180 - val_mae: 0.0765\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:54,116] Trial 19 finished with value: 0.07661332190036774 and parameters: {'learning_rate': 0.00010865799893817708, 'weight_decay': 3.7195109665761165e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0109 - mae: 0.1195 - val_loss: 0.0257 - val_mae: 0.1312\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0110 - mae: 0.1159 - val_loss: 0.0257 - val_mae: 0.1312\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0257 - val_mae: 0.1311\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0108 - mae: 0.1164 - val_loss: 0.0256 - val_mae: 0.1311\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0256 - val_mae: 0.1311\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1165 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0108 - mae: 0.1155 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1170 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0110 - mae: 0.1176 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1167 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0110 - mae: 0.1171 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108 - mae: 0.1159 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0116 - mae: 0.1200 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0108 - mae: 0.1173 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0105 - mae: 0.1137 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1115 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0111 - mae: 0.1171 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0113 - mae: 0.1179 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0110 - mae: 0.1164 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0114 - mae: 0.1196 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - mae: 0.1172 - val_loss: 0.0256 - val_mae: 0.1304\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0112 - mae: 0.1205 - val_loss: 0.0255 - val_mae: 0.1304\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0255 - val_mae: 0.1304\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0106 - mae: 0.1147 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0110 - mae: 0.1159 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0105 - mae: 0.1150 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0116 - mae: 0.1233 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0106 - mae: 0.1146 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0106 - mae: 0.1138 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111 - mae: 0.1174 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1158 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0110 - mae: 0.1189 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0109 - mae: 0.1176 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1160 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0117 - mae: 0.1227 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0106 - mae: 0.1154 - val_loss: 0.0255 - val_mae: 0.1297\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0109 - mae: 0.1165 - val_loss: 0.0254 - val_mae: 0.1297\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0112 - mae: 0.1194 - val_loss: 0.0254 - val_mae: 0.1297\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0107 - mae: 0.1167 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0106 - mae: 0.1150 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0107 - mae: 0.1149 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0109 - mae: 0.1186 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1177 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0112 - mae: 0.1196 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1117 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1141 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0110 - mae: 0.1151 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0108 - mae: 0.1134 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0104 - mae: 0.1150 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0111 - mae: 0.1172 - val_loss: 0.0254 - val_mae: 0.1290\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1160 - val_loss: 0.0253 - val_mae: 0.1290\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0253 - val_mae: 0.1290\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0111 - mae: 0.1180 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - mae: 0.1161 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0109 - mae: 0.1163 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - mae: 0.1157 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0103 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1152 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1170 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0102 - mae: 0.1140 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0106 - mae: 0.1145 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0109 - mae: 0.1159 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108 - mae: 0.1158 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0252 - val_mae: 0.1283\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1163 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0106 - mae: 0.1134 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - mae: 0.1145 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1125 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1143 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1121 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1131 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0106 - mae: 0.1141 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0106 - mae: 0.1158 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0103 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0107 - mae: 0.1164 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1111 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0106 - mae: 0.1151 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - mae: 0.1126 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0106 - mae: 0.1136 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1133 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1146 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1133 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106 - mae: 0.1143 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0104 - mae: 0.1111 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0250 - val_mae: 0.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:13,744] Trial 20 finished with value: 0.12655121088027954 and parameters: {'learning_rate': 4.122553152958873e-06, 'weight_decay': 0.004568530675075751}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1026 - val_loss: 0.0245 - val_mae: 0.1154\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1151\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0244 - val_mae: 0.1148\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1021 - val_loss: 0.0244 - val_mae: 0.1145\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0243 - val_mae: 0.1142\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1011 - val_loss: 0.0243 - val_mae: 0.1139\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0242 - val_mae: 0.1132\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1129\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1125\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1122\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0240 - val_mae: 0.1118\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1115\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0090 - mae: 0.0993 - val_loss: 0.0239 - val_mae: 0.1112\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0239 - val_mae: 0.1108\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1105\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0238 - val_mae: 0.1101\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0237 - val_mae: 0.1098\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1095\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0236 - val_mae: 0.1091\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0236 - val_mae: 0.1088\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0235 - val_mae: 0.1084\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0235 - val_mae: 0.1081\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1077\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1073\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0233 - val_mae: 0.1070\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1066\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1062\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0232 - val_mae: 0.1059\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0922 - val_loss: 0.0231 - val_mae: 0.1055\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0231 - val_mae: 0.1052\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.0963 - val_loss: 0.0230 - val_mae: 0.1048\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0229 - val_mae: 0.1044\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1041\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1037\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1033\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0922 - val_loss: 0.0227 - val_mae: 0.1030\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0227 - val_mae: 0.1026\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0079 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.1022\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0226 - val_mae: 0.1019\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0078 - mae: 0.0887 - val_loss: 0.0225 - val_mae: 0.1015\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0895 - val_loss: 0.0225 - val_mae: 0.1011\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0920 - val_loss: 0.0224 - val_mae: 0.1008\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0224 - val_mae: 0.1004\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0223 - val_mae: 0.0996\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0222 - val_mae: 0.0993\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0911 - val_loss: 0.0222 - val_mae: 0.0989\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0878 - val_loss: 0.0221 - val_mae: 0.0985\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.0982\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0220 - val_mae: 0.0978\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0220 - val_mae: 0.0974\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0839 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0219 - val_mae: 0.0967\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0218 - val_mae: 0.0963\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0218 - val_mae: 0.0959\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0217 - val_mae: 0.0956\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0217 - val_mae: 0.0952\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.0948\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0862 - val_loss: 0.0216 - val_mae: 0.0945\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0215 - val_mae: 0.0941\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0215 - val_mae: 0.0937\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0214 - val_mae: 0.0933\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0863 - val_loss: 0.0214 - val_mae: 0.0930\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0850 - val_loss: 0.0213 - val_mae: 0.0926\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0213 - val_mae: 0.0922\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0827 - val_loss: 0.0213 - val_mae: 0.0919\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0068 - mae: 0.0823 - val_loss: 0.0212 - val_mae: 0.0916\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0212 - val_mae: 0.0913\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0800 - val_loss: 0.0211 - val_mae: 0.0909\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0071 - mae: 0.0841 - val_loss: 0.0211 - val_mae: 0.0906\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0903\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0210 - val_mae: 0.0900\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0819 - val_loss: 0.0209 - val_mae: 0.0897\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0816 - val_loss: 0.0209 - val_mae: 0.0894\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0891\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0208 - val_mae: 0.0888\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0208 - val_mae: 0.0885\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0207 - val_mae: 0.0882\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0207 - val_mae: 0.0880\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0206 - val_mae: 0.0877\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0206 - val_mae: 0.0874\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0872\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0205 - val_mae: 0.0869\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0204 - val_mae: 0.0866\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0204 - val_mae: 0.0863\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0063 - mae: 0.0766 - val_loss: 0.0204 - val_mae: 0.0860\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0785 - val_loss: 0.0203 - val_mae: 0.0857\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0203 - val_mae: 0.0855\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0789 - val_loss: 0.0202 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0763 - val_loss: 0.0202 - val_mae: 0.0849\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0201 - val_mae: 0.0846\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0754 - val_loss: 0.0201 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0062 - mae: 0.0752 - val_loss: 0.0200 - val_mae: 0.0840\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0755 - val_loss: 0.0200 - val_mae: 0.0838\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0199 - val_mae: 0.0835\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0059 - mae: 0.0754 - val_loss: 0.0198 - val_mae: 0.0828\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0062 - mae: 0.0768 - val_loss: 0.0197 - val_mae: 0.0826\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0064 - mae: 0.0786 - val_loss: 0.0197 - val_mae: 0.0821\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0765 - val_loss: 0.0196 - val_mae: 0.0819\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0813\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0761 - val_loss: 0.0194 - val_mae: 0.0811\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0194 - val_mae: 0.0810\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0193 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0193 - val_mae: 0.0806\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0749 - val_loss: 0.0193 - val_mae: 0.0804\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0059 - mae: 0.0749 - val_loss: 0.0192 - val_mae: 0.0801\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0057 - mae: 0.0717 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0191 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0052 - mae: 0.0715 - val_loss: 0.0191 - val_mae: 0.0796\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0728 - val_loss: 0.0190 - val_mae: 0.0794\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0738 - val_loss: 0.0190 - val_mae: 0.0792\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0698 - val_loss: 0.0190 - val_mae: 0.0791\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0189 - val_mae: 0.0789\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0189 - val_mae: 0.0788\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0705 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0708 - val_loss: 0.0188 - val_mae: 0.0785\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0688 - val_loss: 0.0188 - val_mae: 0.0784\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0187 - val_mae: 0.0783\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0695 - val_loss: 0.0187 - val_mae: 0.0781\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0725 - val_loss: 0.0187 - val_mae: 0.0780\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0186 - val_mae: 0.0778\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.0777\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0185 - val_mae: 0.0776\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0057 - mae: 0.0742 - val_loss: 0.0185 - val_mae: 0.0775\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0669 - val_loss: 0.0185 - val_mae: 0.0774\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0695 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0055 - mae: 0.0712 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0058 - mae: 0.0744 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0732 - val_loss: 0.0183 - val_mae: 0.0768\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0183 - val_mae: 0.0767\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0685 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0052 - mae: 0.0732 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0678 - val_loss: 0.0181 - val_mae: 0.0762\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0050 - mae: 0.0668 - val_loss: 0.0179 - val_mae: 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:33,378] Trial 21 finished with value: 0.07620437443256378 and parameters: {'learning_rate': 5.5459229085853306e-05, 'weight_decay': 3.0257277936324145e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1063 - val_loss: 0.0254 - val_mae: 0.1150\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1056 - val_loss: 0.0252 - val_mae: 0.1138\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1127\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1028 - val_loss: 0.0248 - val_mae: 0.1115\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0247 - val_mae: 0.1103\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0245 - val_mae: 0.1091\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0243 - val_mae: 0.1079\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.0981 - val_loss: 0.0242 - val_mae: 0.1069\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0240 - val_mae: 0.1058\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0969 - val_loss: 0.0239 - val_mae: 0.1047\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0081 - mae: 0.0934 - val_loss: 0.0237 - val_mae: 0.1037\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0236 - val_mae: 0.1027\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1017\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0233 - val_mae: 0.1008\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0232 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0230 - val_mae: 0.0989\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0229 - val_mae: 0.0980\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.0972\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0226 - val_mae: 0.0964\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0860 - val_loss: 0.0225 - val_mae: 0.0956\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0224 - val_mae: 0.0948\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0856 - val_loss: 0.0223 - val_mae: 0.0940\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.0932\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0852 - val_loss: 0.0220 - val_mae: 0.0925\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0219 - val_mae: 0.0918\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0217 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0216 - val_mae: 0.0904\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0215 - val_mae: 0.0897\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0214 - val_mae: 0.0890\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0212 - val_mae: 0.0883\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0061 - mae: 0.0797 - val_loss: 0.0211 - val_mae: 0.0877\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0210 - val_mae: 0.0870\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0208 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - mae: 0.0734 - val_loss: 0.0207 - val_mae: 0.0857\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0061 - mae: 0.0771 - val_loss: 0.0206 - val_mae: 0.0851\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0205 - val_mae: 0.0845\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0758 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0724 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0059 - mae: 0.0778 - val_loss: 0.0201 - val_mae: 0.0828\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0777 - val_loss: 0.0199 - val_mae: 0.0818\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0058 - mae: 0.0753 - val_loss: 0.0198 - val_mae: 0.0813\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0197 - val_mae: 0.0808\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0722 - val_loss: 0.0196 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0195 - val_mae: 0.0802\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0194 - val_mae: 0.0799\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0057 - mae: 0.0772 - val_loss: 0.0193 - val_mae: 0.0797\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0049 - mae: 0.0668 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0191 - val_mae: 0.0792\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0190 - val_mae: 0.0790\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0690 - val_loss: 0.0189 - val_mae: 0.0788\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0186 - val_mae: 0.0785\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0784\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0707 - val_loss: 0.0182 - val_mae: 0.0784\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043 - mae: 0.0619 - val_loss: 0.0181 - val_mae: 0.0785\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0181 - val_mae: 0.0786\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - mae: 0.0700 - val_loss: 0.0180 - val_mae: 0.0786\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0696 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0178 - val_mae: 0.0787\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0788\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0788\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0645 - val_loss: 0.0175 - val_mae: 0.0786\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0038 - mae: 0.0592 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0042 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0043 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0641 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0682 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0782\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0038 - mae: 0.0599 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0611 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0045 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0038 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0647 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0634 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0170 - val_mae: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:53,014] Trial 22 finished with value: 0.07842803001403809 and parameters: {'learning_rate': 0.00017642286827236882, 'weight_decay': 4.869910553316675e-06}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1136\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1134\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1131\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0097 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0098 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1127\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0236 - val_mae: 0.1117\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1004 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0235 - val_mae: 0.1109\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0093 - mae: 0.1005 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.0992 - val_loss: 0.0234 - val_mae: 0.1098\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0233 - val_mae: 0.1093\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0091 - mae: 0.0996 - val_loss: 0.0233 - val_mae: 0.1091\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0089 - mae: 0.0987 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.0989 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1082\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.0984 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0088 - mae: 0.0980 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0973 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.0970 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.0976 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0085 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1059\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0228 - val_mae: 0.1057\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0970 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0089 - mae: 0.0978 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0942 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0946 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0226 - val_mae: 0.1044\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0933 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.0971 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0921 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0911 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0912 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0927 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0946 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0919 - val_loss: 0.0222 - val_mae: 0.1017\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0083 - mae: 0.0931 - val_loss: 0.0222 - val_mae: 0.1015\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0222 - val_mae: 0.1013\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0904 - val_loss: 0.0221 - val_mae: 0.1012\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0221 - val_mae: 0.1010\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0081 - mae: 0.0916 - val_loss: 0.0221 - val_mae: 0.1008\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0908 - val_loss: 0.0220 - val_mae: 0.1005\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0220 - val_mae: 0.1003\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0220 - val_mae: 0.1002\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0917 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0912 - val_loss: 0.0220 - val_mae: 0.0998\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0219 - val_mae: 0.0995\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0080 - mae: 0.0895 - val_loss: 0.0219 - val_mae: 0.0991\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0079 - mae: 0.0896 - val_loss: 0.0218 - val_mae: 0.0988\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0218 - val_mae: 0.0986\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0218 - val_mae: 0.0985\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0217 - val_mae: 0.0983\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0904 - val_loss: 0.0217 - val_mae: 0.0980\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0217 - val_mae: 0.0978\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0216 - val_mae: 0.0976\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0216 - val_mae: 0.0975\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0216 - val_mae: 0.0971\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0906 - val_loss: 0.0215 - val_mae: 0.0970\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0873 - val_loss: 0.0215 - val_mae: 0.0968\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0215 - val_mae: 0.0966\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0215 - val_mae: 0.0965\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0215 - val_mae: 0.0963\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0868 - val_loss: 0.0214 - val_mae: 0.0961\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0214 - val_mae: 0.0960\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0858 - val_loss: 0.0214 - val_mae: 0.0958\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0214 - val_mae: 0.0956\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0213 - val_mae: 0.0955\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0895 - val_loss: 0.0213 - val_mae: 0.0953\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0213 - val_mae: 0.0952\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0213 - val_mae: 0.0950\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0213 - val_mae: 0.0948\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.0947\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0212 - val_mae: 0.0945\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.0943\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0842 - val_loss: 0.0212 - val_mae: 0.0942\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0211 - val_mae: 0.0940\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0848 - val_loss: 0.0211 - val_mae: 0.0939\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0211 - val_mae: 0.0937\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0211 - val_mae: 0.0935\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0211 - val_mae: 0.0934\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0210 - val_mae: 0.0932\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0210 - val_mae: 0.0931\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0210 - val_mae: 0.0929\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0210 - val_mae: 0.0928\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0209 - val_mae: 0.0926\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0209 - val_mae: 0.0925\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0845 - val_loss: 0.0209 - val_mae: 0.0923\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0209 - val_mae: 0.0922\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0828 - val_loss: 0.0208 - val_mae: 0.0920\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0815 - val_loss: 0.0208 - val_mae: 0.0919\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0070 - mae: 0.0830 - val_loss: 0.0208 - val_mae: 0.0917\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0208 - val_mae: 0.0916\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0840 - val_loss: 0.0208 - val_mae: 0.0914\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0829 - val_loss: 0.0207 - val_mae: 0.0913\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0067 - mae: 0.0802 - val_loss: 0.0207 - val_mae: 0.0911\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0860 - val_loss: 0.0207 - val_mae: 0.0910\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0207 - val_mae: 0.0908\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0907\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0206 - val_mae: 0.0905\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0065 - mae: 0.0784 - val_loss: 0.0206 - val_mae: 0.0904\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0902\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0206 - val_mae: 0.0900\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0803 - val_loss: 0.0205 - val_mae: 0.0899\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0205 - val_mae: 0.0897\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0811 - val_loss: 0.0205 - val_mae: 0.0896\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0205 - val_mae: 0.0894\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.0892\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0204 - val_mae: 0.0891\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0204 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0204 - val_mae: 0.0888\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0068 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0886\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0857 - val_loss: 0.0203 - val_mae: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:13,487] Trial 23 finished with value: 0.0884561687707901 and parameters: {'learning_rate': 2.7288091431829393e-05, 'weight_decay': 3.910451638426145e-07}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1178\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0244 - val_mae: 0.1177\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0243 - val_mae: 0.1172\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0243 - val_mae: 0.1170\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0243 - val_mae: 0.1169\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0243 - val_mae: 0.1167\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0242 - val_mae: 0.1164\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0242 - val_mae: 0.1163\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1161\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.1009 - val_loss: 0.0242 - val_mae: 0.1160\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0241 - val_mae: 0.1155\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1154\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1147\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0989 - val_loss: 0.0240 - val_mae: 0.1146\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0987 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0239 - val_mae: 0.1138\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1132\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0237 - val_mae: 0.1129\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1127\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0236 - val_mae: 0.1120\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0235 - val_mae: 0.1115\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1113\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1112\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1110\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0984 - val_loss: 0.0235 - val_mae: 0.1109\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0969 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0988 - val_loss: 0.0234 - val_mae: 0.1106\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1103\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1101\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1098\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0978 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0971 - val_loss: 0.0233 - val_mae: 0.1094\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0084 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0947 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0951 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0934 - val_loss: 0.0228 - val_mae: 0.1056\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0954 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0228 - val_mae: 0.1052\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0226 - val_mae: 0.1040\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0226 - val_mae: 0.1039\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0924 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.1032\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0075 - mae: 0.0911 - val_loss: 0.0225 - val_mae: 0.1028\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0928 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0224 - val_mae: 0.1023\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0903 - val_loss: 0.0224 - val_mae: 0.1022\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0224 - val_mae: 0.1020\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.1017\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0223 - val_mae: 0.1015\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0899 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0887 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - mae: 0.0893 - val_loss: 0.0222 - val_mae: 0.1009\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1006\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0221 - val_mae: 0.1003\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.1000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0995\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0889 - val_loss: 0.0220 - val_mae: 0.0993\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0861 - val_loss: 0.0220 - val_mae: 0.0991\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0990\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0878 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0874 - val_loss: 0.0219 - val_mae: 0.0987\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0860 - val_loss: 0.0219 - val_mae: 0.0985\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0219 - val_mae: 0.0983\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0069 - mae: 0.0858 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0218 - val_mae: 0.0978\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0865 - val_loss: 0.0218 - val_mae: 0.0977\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0218 - val_mae: 0.0975\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.0973\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0850 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0826 - val_loss: 0.0217 - val_mae: 0.0970\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0859 - val_loss: 0.0217 - val_mae: 0.0968\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0217 - val_mae: 0.0967\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0071 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0965\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0843 - val_loss: 0.0216 - val_mae: 0.0963\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0875 - val_loss: 0.0216 - val_mae: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:33,217] Trial 24 finished with value: 0.09614313393831253 and parameters: {'learning_rate': 2.773439054168492e-05, 'weight_decay': 4.8348310433217596e-05}. Best is trial 8 with value: 0.07435319572687149.\n",
      "[I 2023-12-04 18:55:33,289] A new study created in RDB with name: no-name-cad62541-f293-4d49-bc69-9590d47d90bf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1091 - val_loss: 0.0193 - val_mae: 0.0869\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0067 - mae: 0.0846 - val_loss: 0.0180 - val_mae: 0.0862\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0745 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0880\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0665 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0851\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0835\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0894\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0166 - val_mae: 0.0919\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0666 - val_loss: 0.0167 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0878\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0165 - val_mae: 0.0851\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0627 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0162 - val_mae: 0.0862\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0860\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0159 - val_mae: 0.0850\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0163 - val_mae: 0.0794\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0831\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0158 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0159 - val_mae: 0.0817\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0153 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0159 - val_mae: 0.0789\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0139 - val_mae: 0.0846\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0156 - val_mae: 0.0784\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0162 - val_mae: 0.0801\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0141 - val_mae: 0.0861\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0028 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0837\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0161 - val_mae: 0.0834\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0153 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0142 - val_mae: 0.0849\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0527 - val_loss: 0.0161 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0162 - val_mae: 0.0779\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0148 - val_mae: 0.0831\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0148 - val_mae: 0.0839\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0149 - val_mae: 0.0836\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0150 - val_mae: 0.0826\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0151 - val_mae: 0.0814\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0156 - val_mae: 0.0804\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0494 - val_loss: 0.0148 - val_mae: 0.0837\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0140 - val_mae: 0.0875\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0153 - val_mae: 0.0817\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0160 - val_mae: 0.0814\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0471 - val_loss: 0.0152 - val_mae: 0.0832\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0452 - val_loss: 0.0140 - val_mae: 0.0874\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0139 - val_mae: 0.0853\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0141 - val_mae: 0.0859\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0146 - val_mae: 0.0847\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0822\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0500 - val_loss: 0.0153 - val_mae: 0.0843\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0148 - val_mae: 0.0854\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0147 - val_mae: 0.0838\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0142 - val_mae: 0.0885\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0147 - val_mae: 0.0878\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0148 - val_mae: 0.0870\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0150 - val_mae: 0.0844\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0151 - val_mae: 0.0826\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0151 - val_mae: 0.0876\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0148 - val_mae: 0.0920\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0481 - val_loss: 0.0150 - val_mae: 0.0909\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0151 - val_mae: 0.0896\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0151 - val_mae: 0.0865\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0149 - val_mae: 0.0887\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0472 - val_loss: 0.0149 - val_mae: 0.0929\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0507 - val_loss: 0.0148 - val_mae: 0.0968\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0148 - val_mae: 0.0943\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0554 - val_loss: 0.0169 - val_mae: 0.0869\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0902\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0593 - val_loss: 0.0156 - val_mae: 0.0919\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0570 - val_loss: 0.0151 - val_mae: 0.0938\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0541 - val_loss: 0.0148 - val_mae: 0.0929\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - mae: 0.0520 - val_loss: 0.0147 - val_mae: 0.0883\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0151 - val_mae: 0.0836\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0153 - val_mae: 0.0832\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - mae: 0.0505 - val_loss: 0.0152 - val_mae: 0.0865\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0153 - val_mae: 0.0883\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0153 - val_mae: 0.0900\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0152 - val_mae: 0.0910\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0149 - val_mae: 0.0908\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0477 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0147 - val_mae: 0.0851\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0143 - val_mae: 0.0856\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0150 - val_mae: 0.0801\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0151 - val_mae: 0.0786\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0145 - val_mae: 0.0824\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0139 - val_mae: 0.0905\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0139 - val_mae: 0.0938\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0874\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0163 - val_mae: 0.0859\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0156 - val_mae: 0.0868\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0147 - val_mae: 0.0893\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0151 - val_mae: 0.0836\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0403 - val_loss: 0.0157 - val_mae: 0.0858\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - mae: 0.0478 - val_loss: 0.0155 - val_mae: 0.0897\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0461 - val_loss: 0.0154 - val_mae: 0.0911\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0488 - val_loss: 0.0153 - val_mae: 0.0901\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0475 - val_loss: 0.0152 - val_mae: 0.0877\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0149 - val_mae: 0.0849\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0144 - val_mae: 0.0843\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0145 - val_mae: 0.0816\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0149 - val_mae: 0.0807\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.0151 - val_mae: 0.0841\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0389 - val_loss: 0.0151 - val_mae: 0.0866\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0150 - val_mae: 0.0899\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0148 - val_mae: 0.0920\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0474 - val_loss: 0.0149 - val_mae: 0.0897\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0150 - val_mae: 0.0872\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0152 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0408 - val_loss: 0.0150 - val_mae: 0.0858\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0391 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0425 - val_loss: 0.0147 - val_mae: 0.0883\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0395 - val_loss: 0.0148 - val_mae: 0.0891\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0147 - val_mae: 0.0898\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0145 - val_mae: 0.0917\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mae: 0.0375 - val_loss: 0.0144 - val_mae: 0.0925\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0393 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - mae: 0.0412 - val_loss: 0.0146 - val_mae: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:48,577] Trial 0 finished with value: 0.09042628854513168 and parameters: {'learning_rate': 0.005428992715125547, 'weight_decay': 1.1721142106834856e-08}. Best is trial 0 with value: 0.09042628854513168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0176 - val_mae: 0.0948\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0909 - val_loss: 0.0192 - val_mae: 0.0831\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0693 - val_loss: 0.0184 - val_mae: 0.0836\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0896\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0695 - val_loss: 0.0168 - val_mae: 0.0934\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0693 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0166 - val_mae: 0.0910\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0674 - val_loss: 0.0166 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0890\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0886\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0886\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0885\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0164 - val_mae: 0.0840\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0162 - val_mae: 0.0840\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0553 - val_loss: 0.0161 - val_mae: 0.0853\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0160 - val_mae: 0.0845\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0155 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0155 - val_mae: 0.0815\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0790\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0158 - val_mae: 0.0784\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0149 - val_mae: 0.0833\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0170 - val_mae: 0.0782\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0510 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0877\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0897\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0635 - val_loss: 0.0167 - val_mae: 0.0907\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0909\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0630 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0855\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0164 - val_mae: 0.0861\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0163 - val_mae: 0.0868\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0161 - val_mae: 0.0867\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0162 - val_mae: 0.0836\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0807\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0146 - val_mae: 0.0901\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0178 - val_mae: 0.0786\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0570 - val_loss: 0.0178 - val_mae: 0.0794\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - mae: 0.0562 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0870\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0906\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0935\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0675 - val_loss: 0.0167 - val_mae: 0.0926\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0659 - val_loss: 0.0166 - val_mae: 0.0889\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0809\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0806\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0878\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0538 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0163 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0165 - val_mae: 0.0860\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0882\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0168 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0557 - val_loss: 0.0169 - val_mae: 0.0803\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0526 - val_loss: 0.0166 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:04,155] Trial 1 finished with value: 0.08078546077013016 and parameters: {'learning_rate': 0.007265683364565975, 'weight_decay': 0.0004977395872680223}. Best is trial 1 with value: 0.08078546077013016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0249 - val_mae: 0.1229\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1224\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1077 - val_loss: 0.0247 - val_mae: 0.1219\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0247 - val_mae: 0.1214\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1208\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1203\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1171\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0238 - val_mae: 0.1150\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1135\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1130\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1120\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1114\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0232 - val_mae: 0.1109\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0915 - val_loss: 0.0231 - val_mae: 0.1099\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0230 - val_mae: 0.1093\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0229 - val_mae: 0.1082\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1076\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0907 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0227 - val_mae: 0.1064\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0226 - val_mae: 0.1058\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0225 - val_mae: 0.1046\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0073 - mae: 0.0874 - val_loss: 0.0224 - val_mae: 0.1040\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.1033\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0223 - val_mae: 0.1027\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0073 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.1020\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0221 - val_mae: 0.1014\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0846 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0219 - val_mae: 0.0994\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0219 - val_mae: 0.0987\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0218 - val_mae: 0.0980\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0216 - val_mae: 0.0965\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0216 - val_mae: 0.0958\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0843 - val_loss: 0.0215 - val_mae: 0.0952\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0945\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0067 - mae: 0.0785 - val_loss: 0.0214 - val_mae: 0.0939\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0212 - val_mae: 0.0927\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0064 - mae: 0.0810 - val_loss: 0.0211 - val_mae: 0.0921\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0845 - val_loss: 0.0210 - val_mae: 0.0909\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0793 - val_loss: 0.0209 - val_mae: 0.0903\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0208 - val_mae: 0.0892\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0207 - val_mae: 0.0886\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0744 - val_loss: 0.0206 - val_mae: 0.0881\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0782 - val_loss: 0.0206 - val_mae: 0.0876\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.0871\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.0866\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0203 - val_mae: 0.0862\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0203 - val_mae: 0.0857\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0767 - val_loss: 0.0202 - val_mae: 0.0853\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0849\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0062 - mae: 0.0764 - val_loss: 0.0201 - val_mae: 0.0845\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0055 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0841\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0724 - val_loss: 0.0200 - val_mae: 0.0837\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0741 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0760 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0198 - val_mae: 0.0827\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0196 - val_mae: 0.0820\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0698 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - mae: 0.0767 - val_loss: 0.0195 - val_mae: 0.0814\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0195 - val_mae: 0.0812\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0194 - val_mae: 0.0809\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0050 - mae: 0.0729 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0193 - val_mae: 0.0805\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0666 - val_loss: 0.0192 - val_mae: 0.0802\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0191 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0190 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0190 - val_mae: 0.0796\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0189 - val_mae: 0.0794\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0799 - val_loss: 0.0189 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0055 - mae: 0.0708 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0188 - val_mae: 0.0789\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0188 - val_mae: 0.0788\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0049 - mae: 0.0678 - val_loss: 0.0187 - val_mae: 0.0784\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0186 - val_mae: 0.0783\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0692 - val_loss: 0.0186 - val_mae: 0.0781\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0713 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0721 - val_loss: 0.0185 - val_mae: 0.0776\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0683 - val_loss: 0.0184 - val_mae: 0.0774\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0690 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0728 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0771\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0644 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0747 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0183 - val_mae: 0.0768\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0182 - val_mae: 0.0767\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0045 - mae: 0.0647 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0182 - val_mae: 0.0763\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0762\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0642 - val_loss: 0.0182 - val_mae: 0.0762\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0761\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0181 - val_mae: 0.0760\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0758\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0704 - val_loss: 0.0181 - val_mae: 0.0757\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0659 - val_loss: 0.0181 - val_mae: 0.0756\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0657 - val_loss: 0.0181 - val_mae: 0.0755\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0711 - val_loss: 0.0181 - val_mae: 0.0755\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0754\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0181 - val_mae: 0.0753\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0181 - val_mae: 0.0753\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0695 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0676 - val_loss: 0.0180 - val_mae: 0.0752\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0180 - val_mae: 0.0751\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - mae: 0.0684 - val_loss: 0.0180 - val_mae: 0.0749\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0179 - val_mae: 0.0749\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0749\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0042 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0629 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0177 - val_mae: 0.0751\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:19,382] Trial 2 finished with value: 0.07521326839923859 and parameters: {'learning_rate': 5.6552381262809115e-05, 'weight_decay': 1.0101788305887493e-08}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0105 - mae: 0.1129 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0104 - mae: 0.1124 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1071 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0107 - mae: 0.1131 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - mae: 0.1162 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1150 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0106 - mae: 0.1135 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1162 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1166 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1105 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0103 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1091 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0106 - mae: 0.1133 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1134 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1135 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1119 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1088 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1208\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0105 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1086 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1149 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1202\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1094 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0103 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0104 - mae: 0.1121 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1104 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0108 - mae: 0.1142 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1107 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0106 - mae: 0.1149 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1123 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1113 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1092 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1099 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1096 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0100 - mae: 0.1090 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:34,824] Trial 3 finished with value: 0.11841195076704025 and parameters: {'learning_rate': 1.8726726900712746e-06, 'weight_decay': 3.794393529925343e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1132\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0233 - val_mae: 0.1112\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0232 - val_mae: 0.1103\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0230 - val_mae: 0.1095\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0229 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0227 - val_mae: 0.1078\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0225 - val_mae: 0.1063\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0941 - val_loss: 0.0224 - val_mae: 0.1056\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0936 - val_loss: 0.0222 - val_mae: 0.1050\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0221 - val_mae: 0.1043\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0220 - val_mae: 0.1036\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0219 - val_mae: 0.1030\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0218 - val_mae: 0.1023\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0217 - val_mae: 0.1017\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.1010\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0215 - val_mae: 0.1003\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0214 - val_mae: 0.0997\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0866 - val_loss: 0.0213 - val_mae: 0.0990\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.0983\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0976\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0209 - val_mae: 0.0962\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0208 - val_mae: 0.0955\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0825 - val_loss: 0.0207 - val_mae: 0.0948\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0206 - val_mae: 0.0941\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0205 - val_mae: 0.0935\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0064 - mae: 0.0772 - val_loss: 0.0204 - val_mae: 0.0929\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0203 - val_mae: 0.0923\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - mae: 0.0814 - val_loss: 0.0202 - val_mae: 0.0917\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0201 - val_mae: 0.0911\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0059 - mae: 0.0745 - val_loss: 0.0200 - val_mae: 0.0906\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0199 - val_mae: 0.0900\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0759 - val_loss: 0.0198 - val_mae: 0.0895\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0197 - val_mae: 0.0889\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0197 - val_mae: 0.0884\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0788 - val_loss: 0.0196 - val_mae: 0.0878\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0777 - val_loss: 0.0195 - val_mae: 0.0873\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0194 - val_mae: 0.0867\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0727 - val_loss: 0.0193 - val_mae: 0.0862\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0857\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0743 - val_loss: 0.0192 - val_mae: 0.0852\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0190 - val_mae: 0.0843\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0839\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0189 - val_mae: 0.0835\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0189 - val_mae: 0.0831\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0712 - val_loss: 0.0188 - val_mae: 0.0827\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0051 - mae: 0.0718 - val_loss: 0.0188 - val_mae: 0.0822\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0188 - val_mae: 0.0818\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0814\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0718 - val_loss: 0.0187 - val_mae: 0.0810\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0186 - val_mae: 0.0806\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0185 - val_mae: 0.0799\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0796\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0184 - val_mae: 0.0790\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0684 - val_loss: 0.0183 - val_mae: 0.0788\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0183 - val_mae: 0.0786\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0784\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0728 - val_loss: 0.0181 - val_mae: 0.0781\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0682 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0684 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0658 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0668 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0717 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0600 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0603 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0772\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0577 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0778\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0779\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0172 - val_mae: 0.0779\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0779\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0780\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0780\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0790\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:49,950] Trial 4 finished with value: 0.07861979305744171 and parameters: {'learning_rate': 0.00011812135409253702, 'weight_decay': 3.7502188217098465e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1121 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1102 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1093 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0103 - mae: 0.1101 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0102 - mae: 0.1101 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1068 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1067 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1068 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1111 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0243 - val_mae: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:05,334] Trial 5 finished with value: 0.1194608062505722 and parameters: {'learning_rate': 4.1754399140450693e-07, 'weight_decay': 1.9546629942638687e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0102 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1167\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1126\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0236 - val_mae: 0.1087\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0232 - val_mae: 0.1054\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.0997\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0877 - val_loss: 0.0221 - val_mae: 0.0966\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0833 - val_loss: 0.0217 - val_mae: 0.0943\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0214 - val_mae: 0.0923\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0819 - val_loss: 0.0211 - val_mae: 0.0905\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0207 - val_mae: 0.0888\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0205 - val_mae: 0.0873\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0751 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0199 - val_mae: 0.0850\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0194 - val_mae: 0.0834\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0046 - mae: 0.0709 - val_loss: 0.0192 - val_mae: 0.0829\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0824\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0050 - mae: 0.0720 - val_loss: 0.0187 - val_mae: 0.0821\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0049 - mae: 0.0721 - val_loss: 0.0186 - val_mae: 0.0817\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0181 - val_mae: 0.0803\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0674 - val_loss: 0.0179 - val_mae: 0.0804\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0178 - val_mae: 0.0806\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0658 - val_loss: 0.0176 - val_mae: 0.0808\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0600 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0813\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0166 - val_mae: 0.0818\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0164 - val_mae: 0.0831\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0163 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0163 - val_mae: 0.0840\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0162 - val_mae: 0.0846\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0161 - val_mae: 0.0850\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0161 - val_mae: 0.0845\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0160 - val_mae: 0.0831\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0561 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0816\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0158 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0157 - val_mae: 0.0863\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0874\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0157 - val_mae: 0.0864\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0156 - val_mae: 0.0860\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0156 - val_mae: 0.0858\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0156 - val_mae: 0.0854\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0512 - val_loss: 0.0156 - val_mae: 0.0864\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0155 - val_mae: 0.0870\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0155 - val_mae: 0.0880\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0154 - val_mae: 0.0889\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0154 - val_mae: 0.0893\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0544 - val_loss: 0.0153 - val_mae: 0.0898\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0153 - val_mae: 0.0894\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0153 - val_mae: 0.0887\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0152 - val_mae: 0.0894\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0152 - val_mae: 0.0892\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0152 - val_mae: 0.0893\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0152 - val_mae: 0.0903\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0152 - val_mae: 0.0904\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0152 - val_mae: 0.0907\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0152 - val_mae: 0.0926\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0151 - val_mae: 0.0946\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0151 - val_mae: 0.0972\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0151 - val_mae: 0.0980\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0546 - val_loss: 0.0150 - val_mae: 0.0952\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0508 - val_loss: 0.0150 - val_mae: 0.0941\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0149 - val_mae: 0.0939\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0149 - val_mae: 0.0955\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0149 - val_mae: 0.1000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0151 - val_mae: 0.1056\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0150 - val_mae: 0.1061\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0148 - val_mae: 0.1030\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0146 - val_mae: 0.0932\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0483 - val_loss: 0.0145 - val_mae: 0.0877\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0462 - val_loss: 0.0145 - val_mae: 0.0854\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0484 - val_loss: 0.0145 - val_mae: 0.0859\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0489 - val_loss: 0.0144 - val_mae: 0.0892\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0947\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0520 - val_loss: 0.0145 - val_mae: 0.1014\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0490 - val_loss: 0.0148 - val_mae: 0.1075\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0146 - val_mae: 0.1031\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0026 - mae: 0.0545 - val_loss: 0.0145 - val_mae: 0.0975\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0144 - val_mae: 0.0935\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0144 - val_mae: 0.0912\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0144 - val_mae: 0.0907\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0488 - val_loss: 0.0144 - val_mae: 0.0922\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0144 - val_mae: 0.0949\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0145 - val_mae: 0.0982\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0146 - val_mae: 0.1014\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0147 - val_mae: 0.1046\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0147 - val_mae: 0.1054\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0148 - val_mae: 0.1067\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0147 - val_mae: 0.1063\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0534 - val_loss: 0.0148 - val_mae: 0.1067\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0501 - val_loss: 0.0145 - val_mae: 0.1020\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0143 - val_mae: 0.0961\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0143 - val_mae: 0.0927\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0492 - val_loss: 0.0143 - val_mae: 0.0937\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0143 - val_mae: 0.0974\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0145 - val_mae: 0.1009\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0146 - val_mae: 0.1049\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.1065\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0144 - val_mae: 0.0990\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0144 - val_mae: 0.0916\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0145 - val_mae: 0.0877\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0486 - val_loss: 0.0145 - val_mae: 0.0873\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0145 - val_mae: 0.0893\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0145 - val_mae: 0.0931\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0146 - val_mae: 0.0979\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0148 - val_mae: 0.1039\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0488 - val_loss: 0.0150 - val_mae: 0.1078\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0149 - val_mae: 0.1076\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0147 - val_mae: 0.1049\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0144 - val_mae: 0.0988\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0939\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0142 - val_mae: 0.0909\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0142 - val_mae: 0.0895\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0142 - val_mae: 0.0897\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0143 - val_mae: 0.0922\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0961\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.1001\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0146 - val_mae: 0.1028\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0148 - val_mae: 0.1047\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0147 - val_mae: 0.1031\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0146 - val_mae: 0.1000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0145 - val_mae: 0.0969\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0144 - val_mae: 0.0943\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0144 - val_mae: 0.0936\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0456 - val_loss: 0.0144 - val_mae: 0.0954\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0503 - val_loss: 0.0145 - val_mae: 0.0991\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0146 - val_mae: 0.1026\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0146 - val_mae: 0.1025\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0146 - val_mae: 0.1027\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0145 - val_mae: 0.1024\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0143 - val_mae: 0.0954\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0142 - val_mae: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:21,449] Trial 6 finished with value: 0.09161888808012009 and parameters: {'learning_rate': 0.0005070288039802264, 'weight_decay': 2.6845325685304623e-08}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0099 - mae: 0.1048 - val_loss: 0.0252 - val_mae: 0.1181\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0252 - val_mae: 0.1180\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0099 - mae: 0.1048 - val_loss: 0.0251 - val_mae: 0.1179\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0251 - val_mae: 0.1178\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0099 - mae: 0.1069 - val_loss: 0.0251 - val_mae: 0.1177\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1065 - val_loss: 0.0251 - val_mae: 0.1176\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1011 - val_loss: 0.0251 - val_mae: 0.1175\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1065 - val_loss: 0.0250 - val_mae: 0.1174\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0250 - val_mae: 0.1173\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1059 - val_loss: 0.0250 - val_mae: 0.1172\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1019 - val_loss: 0.0250 - val_mae: 0.1171\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1022 - val_loss: 0.0250 - val_mae: 0.1170\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0250 - val_mae: 0.1169\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1037 - val_loss: 0.0249 - val_mae: 0.1168\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0249 - val_mae: 0.1167\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1039 - val_loss: 0.0249 - val_mae: 0.1165\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1009 - val_loss: 0.0249 - val_mae: 0.1164\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1009 - val_loss: 0.0249 - val_mae: 0.1163\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1162\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1161\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1160\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0101 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1159\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1044 - val_loss: 0.0248 - val_mae: 0.1158\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0248 - val_mae: 0.1157\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1156\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1155\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1003 - val_loss: 0.0247 - val_mae: 0.1154\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1153\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1152\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1038 - val_loss: 0.0247 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - mae: 0.1098 - val_loss: 0.0247 - val_mae: 0.1150\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0094 - mae: 0.1024 - val_loss: 0.0246 - val_mae: 0.1149\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1148\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0101 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1147\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0091 - mae: 0.1007 - val_loss: 0.0246 - val_mae: 0.1146\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0093 - mae: 0.1006 - val_loss: 0.0246 - val_mae: 0.1145\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1023 - val_loss: 0.0246 - val_mae: 0.1144\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0245 - val_mae: 0.1143\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1142\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1141\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1140\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1139\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1019 - val_loss: 0.0245 - val_mae: 0.1139\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1138\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0989 - val_loss: 0.0244 - val_mae: 0.1137\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1136\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1135\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1013 - val_loss: 0.0244 - val_mae: 0.1134\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.0995 - val_loss: 0.0244 - val_mae: 0.1133\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.0990 - val_loss: 0.0244 - val_mae: 0.1132\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0244 - val_mae: 0.1131\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0098 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1130\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1043 - val_loss: 0.0243 - val_mae: 0.1129\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0243 - val_mae: 0.1128\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1127\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1020 - val_loss: 0.0243 - val_mae: 0.1126\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1000 - val_loss: 0.0243 - val_mae: 0.1125\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1001 - val_loss: 0.0243 - val_mae: 0.1125\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.0992 - val_loss: 0.0242 - val_mae: 0.1124\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1026 - val_loss: 0.0242 - val_mae: 0.1123\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1020 - val_loss: 0.0242 - val_mae: 0.1122\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1007 - val_loss: 0.0242 - val_mae: 0.1121\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.0976 - val_loss: 0.0242 - val_mae: 0.1120\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0242 - val_mae: 0.1119\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0242 - val_mae: 0.1118\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.0998 - val_loss: 0.0241 - val_mae: 0.1117\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0241 - val_mae: 0.1117\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.0989 - val_loss: 0.0241 - val_mae: 0.1116\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1115\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.0994 - val_loss: 0.0241 - val_mae: 0.1114\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.0983 - val_loss: 0.0241 - val_mae: 0.1113\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.0994 - val_loss: 0.0241 - val_mae: 0.1112\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0241 - val_mae: 0.1111\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1111\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1110\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.0991 - val_loss: 0.0240 - val_mae: 0.1109\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0240 - val_mae: 0.1108\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1107\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0979 - val_loss: 0.0240 - val_mae: 0.1106\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1106\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1105\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1104\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0994 - val_loss: 0.0239 - val_mae: 0.1103\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0239 - val_mae: 0.1103\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - mae: 0.0991 - val_loss: 0.0239 - val_mae: 0.1102\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0091 - mae: 0.0988 - val_loss: 0.0239 - val_mae: 0.1101\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0239 - val_mae: 0.1100\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0239 - val_mae: 0.1099\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0979 - val_loss: 0.0239 - val_mae: 0.1099\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0239 - val_mae: 0.1098\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0988 - val_loss: 0.0238 - val_mae: 0.1097\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0238 - val_mae: 0.1096\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0963 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0238 - val_mae: 0.1094\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0972 - val_loss: 0.0238 - val_mae: 0.1093\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0977 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0238 - val_mae: 0.1091\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0238 - val_mae: 0.1090\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0237 - val_mae: 0.1089\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0237 - val_mae: 0.1089\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0985 - val_loss: 0.0237 - val_mae: 0.1088\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1086\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1086\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0955 - val_loss: 0.0237 - val_mae: 0.1085\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0963 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0946 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0940 - val_loss: 0.0237 - val_mae: 0.1083\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0236 - val_mae: 0.1082\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0086 - mae: 0.0967 - val_loss: 0.0236 - val_mae: 0.1082\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1081\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0236 - val_mae: 0.1080\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0927 - val_loss: 0.0236 - val_mae: 0.1080\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0941 - val_loss: 0.0236 - val_mae: 0.1079\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0959 - val_loss: 0.0236 - val_mae: 0.1078\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0236 - val_mae: 0.1077\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0236 - val_mae: 0.1077\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0948 - val_loss: 0.0236 - val_mae: 0.1076\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0235 - val_mae: 0.1075\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0235 - val_mae: 0.1075\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0929 - val_loss: 0.0235 - val_mae: 0.1074\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1073\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0958 - val_loss: 0.0235 - val_mae: 0.1073\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0928 - val_loss: 0.0235 - val_mae: 0.1072\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0235 - val_mae: 0.1071\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0235 - val_mae: 0.1070\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1070\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0945 - val_loss: 0.0235 - val_mae: 0.1069\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1068\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1068\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0077 - mae: 0.0882 - val_loss: 0.0234 - val_mae: 0.1067\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0234 - val_mae: 0.1066\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0234 - val_mae: 0.1066\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0963 - val_loss: 0.0234 - val_mae: 0.1065\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0234 - val_mae: 0.1064\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0923 - val_loss: 0.0234 - val_mae: 0.1064\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1063\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0234 - val_mae: 0.1062\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0907 - val_loss: 0.0233 - val_mae: 0.1062\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0233 - val_mae: 0.1061\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0233 - val_mae: 0.1060\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1060\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1059\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0938 - val_loss: 0.0233 - val_mae: 0.1058\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0920 - val_loss: 0.0233 - val_mae: 0.1058\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0922 - val_loss: 0.0233 - val_mae: 0.1057\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0233 - val_mae: 0.1056\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0944 - val_loss: 0.0233 - val_mae: 0.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:36,649] Trial 7 finished with value: 0.10555362701416016 and parameters: {'learning_rate': 7.033233877060463e-06, 'weight_decay': 1.612821650191405e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1231\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1231\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1229\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1096 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1084 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1125 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1111 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1095 - val_loss: 0.0251 - val_mae: 0.1222\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1222\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0250 - val_mae: 0.1222\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0250 - val_mae: 0.1222\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1125 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0090 - mae: 0.1068 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1094 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0092 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1056 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1098 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0094 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1080 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1099 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1118 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1080 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0098 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:51,938] Trial 8 finished with value: 0.11939509958028793 and parameters: {'learning_rate': 2.080888101485016e-06, 'weight_decay': 2.1126546111542145e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0222 - val_mae: 0.0998\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0190 - val_mae: 0.0848\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0178 - val_mae: 0.0921\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0741 - val_loss: 0.0175 - val_mae: 0.0851\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0888\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0637 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0925\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0686 - val_loss: 0.0166 - val_mae: 0.0874\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0822\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0165 - val_mae: 0.0868\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0645 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0862\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0164 - val_mae: 0.0867\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0875\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0161 - val_mae: 0.0897\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0516 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0843\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0163 - val_mae: 0.0861\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0162 - val_mae: 0.0900\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0619 - val_loss: 0.0162 - val_mae: 0.0895\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0162 - val_mae: 0.0867\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0162 - val_mae: 0.0858\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0160 - val_mae: 0.0858\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0556 - val_loss: 0.0158 - val_mae: 0.0870\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0156 - val_mae: 0.0871\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0154 - val_mae: 0.0859\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0156 - val_mae: 0.0815\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0577 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0153 - val_mae: 0.0861\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0154 - val_mae: 0.0849\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0154 - val_mae: 0.0841\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0151 - val_mae: 0.0848\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0145 - val_mae: 0.0883\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0816\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0164 - val_mae: 0.0816\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0152 - val_mae: 0.0838\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0141 - val_mae: 0.0887\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0166 - val_mae: 0.0893\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0165 - val_mae: 0.0911\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0165 - val_mae: 0.0933\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0165 - val_mae: 0.0952\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0165 - val_mae: 0.0964\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0672 - val_loss: 0.0163 - val_mae: 0.0909\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0932\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0967\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0645 - val_loss: 0.0168 - val_mae: 0.0923\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0628 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0912\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0930\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0921\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0170 - val_mae: 0.0902\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0822\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0164 - val_mae: 0.0855\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0164 - val_mae: 0.0864\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0164 - val_mae: 0.0872\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0628 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0166 - val_mae: 0.0871\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:07,242] Trial 9 finished with value: 0.08507339656352997 and parameters: {'learning_rate': 0.0052334938223625, 'weight_decay': 1.9701345544264473e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1031 - val_loss: 0.0235 - val_mae: 0.1127\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0093 - mae: 0.0997 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0233 - val_mae: 0.1108\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1099\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1090\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0230 - val_mae: 0.1081\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1071\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0227 - val_mae: 0.1061\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0889 - val_loss: 0.0223 - val_mae: 0.1016\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0877 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0219 - val_mae: 0.0981\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0217 - val_mae: 0.0963\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0853 - val_loss: 0.0216 - val_mae: 0.0955\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0071 - mae: 0.0832 - val_loss: 0.0215 - val_mae: 0.0947\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0214 - val_mae: 0.0940\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0212 - val_mae: 0.0926\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0210 - val_mae: 0.0912\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0208 - val_mae: 0.0905\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0801 - val_loss: 0.0206 - val_mae: 0.0892\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0205 - val_mae: 0.0887\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0204 - val_mae: 0.0881\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0823 - val_loss: 0.0203 - val_mae: 0.0875\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0711 - val_loss: 0.0202 - val_mae: 0.0870\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0751 - val_loss: 0.0201 - val_mae: 0.0864\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0765 - val_loss: 0.0200 - val_mae: 0.0859\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0854\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0198 - val_mae: 0.0849\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0738 - val_loss: 0.0197 - val_mae: 0.0845\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0784 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0734 - val_loss: 0.0195 - val_mae: 0.0838\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0788 - val_loss: 0.0194 - val_mae: 0.0834\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0744 - val_loss: 0.0194 - val_mae: 0.0831\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0193 - val_mae: 0.0828\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - mae: 0.0733 - val_loss: 0.0192 - val_mae: 0.0826\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0191 - val_mae: 0.0823\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0191 - val_mae: 0.0821\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0190 - val_mae: 0.0819\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0189 - val_mae: 0.0818\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0189 - val_mae: 0.0816\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - mae: 0.0745 - val_loss: 0.0188 - val_mae: 0.0814\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0187 - val_mae: 0.0813\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0811\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0186 - val_mae: 0.0810\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0185 - val_mae: 0.0809\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0744 - val_loss: 0.0185 - val_mae: 0.0807\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0673 - val_loss: 0.0184 - val_mae: 0.0806\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0184 - val_mae: 0.0804\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0183 - val_mae: 0.0803\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0757 - val_loss: 0.0183 - val_mae: 0.0801\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0183 - val_mae: 0.0799\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0182 - val_mae: 0.0798\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0182 - val_mae: 0.0796\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0180 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - mae: 0.0636 - val_loss: 0.0176 - val_mae: 0.0790\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0656 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0697 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0775\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0775\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0688 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0170 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0169 - val_mae: 0.0772\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0552 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0777\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0166 - val_mae: 0.0777\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0775\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0775\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0164 - val_mae: 0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:22,463] Trial 10 finished with value: 0.0778498575091362 and parameters: {'learning_rate': 0.00010069278459625918, 'weight_decay': 4.335902388646887e-06}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0101 - mae: 0.1094 - val_loss: 0.0244 - val_mae: 0.1211\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0242 - val_mae: 0.1192\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1057 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1138\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0973 - val_loss: 0.0233 - val_mae: 0.1104\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0933 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0076 - mae: 0.0905 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0223 - val_mae: 0.1001\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0221 - val_mae: 0.0986\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0219 - val_mae: 0.0971\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0216 - val_mae: 0.0939\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0923\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0061 - mae: 0.0791 - val_loss: 0.0211 - val_mae: 0.0905\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0209 - val_mae: 0.0889\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0780 - val_loss: 0.0207 - val_mae: 0.0876\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0205 - val_mae: 0.0862\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0850\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0200 - val_mae: 0.0838\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0197 - val_mae: 0.0827\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0195 - val_mae: 0.0819\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0738 - val_loss: 0.0193 - val_mae: 0.0811\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0755 - val_loss: 0.0191 - val_mae: 0.0804\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0185 - val_mae: 0.0788\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0767 - val_loss: 0.0184 - val_mae: 0.0784\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - mae: 0.0699 - val_loss: 0.0182 - val_mae: 0.0782\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0782\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0759 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0706 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0742 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0700 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0751 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0726 - val_loss: 0.0179 - val_mae: 0.0767\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0692 - val_loss: 0.0179 - val_mae: 0.0767\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0658 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0765\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0179 - val_mae: 0.0765\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0179 - val_mae: 0.0764\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0650 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0177 - val_mae: 0.0762\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0770\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0173 - val_mae: 0.0770\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0771\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0661 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0645 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0166 - val_mae: 0.0778\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0164 - val_mae: 0.0784\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0784\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0784\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0786\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0165 - val_mae: 0.0786\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0637 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0795\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0161 - val_mae: 0.0795\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0160 - val_mae: 0.0798\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0523 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0588 - val_loss: 0.0159 - val_mae: 0.0798\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0158 - val_mae: 0.0803\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0158 - val_mae: 0.0803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:37,727] Trial 11 finished with value: 0.0803346261382103 and parameters: {'learning_rate': 0.0001927304968401452, 'weight_decay': 4.947706962106966e-06}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0138 - mae: 0.1324 - val_loss: 0.0270 - val_mae: 0.1429\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0132 - mae: 0.1287 - val_loss: 0.0270 - val_mae: 0.1428\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0123 - mae: 0.1283 - val_loss: 0.0269 - val_mae: 0.1427\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - mae: 0.1284 - val_loss: 0.0269 - val_mae: 0.1425\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0130 - mae: 0.1269 - val_loss: 0.0269 - val_mae: 0.1424\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0148 - mae: 0.1350 - val_loss: 0.0269 - val_mae: 0.1423\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0130 - mae: 0.1280 - val_loss: 0.0269 - val_mae: 0.1422\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0132 - mae: 0.1282 - val_loss: 0.0268 - val_mae: 0.1420\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - mae: 0.1277 - val_loss: 0.0268 - val_mae: 0.1419\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - mae: 0.1277 - val_loss: 0.0268 - val_mae: 0.1418\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0143 - mae: 0.1326 - val_loss: 0.0268 - val_mae: 0.1416\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0140 - mae: 0.1333 - val_loss: 0.0268 - val_mae: 0.1415\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0137 - mae: 0.1350 - val_loss: 0.0268 - val_mae: 0.1414\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - mae: 0.1281 - val_loss: 0.0267 - val_mae: 0.1413\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0126 - mae: 0.1273 - val_loss: 0.0267 - val_mae: 0.1411\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0129 - mae: 0.1305 - val_loss: 0.0267 - val_mae: 0.1410\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0124 - mae: 0.1234 - val_loss: 0.0267 - val_mae: 0.1409\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0130 - mae: 0.1249 - val_loss: 0.0267 - val_mae: 0.1408\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0121 - mae: 0.1255 - val_loss: 0.0266 - val_mae: 0.1406\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0134 - mae: 0.1307 - val_loss: 0.0266 - val_mae: 0.1405\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1249 - val_loss: 0.0266 - val_mae: 0.1404\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0133 - mae: 0.1312 - val_loss: 0.0266 - val_mae: 0.1403\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0148 - mae: 0.1330 - val_loss: 0.0266 - val_mae: 0.1401\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0127 - mae: 0.1266 - val_loss: 0.0265 - val_mae: 0.1400\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0130 - mae: 0.1229 - val_loss: 0.0265 - val_mae: 0.1399\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0127 - mae: 0.1239 - val_loss: 0.0265 - val_mae: 0.1398\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - mae: 0.1307 - val_loss: 0.0265 - val_mae: 0.1396\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0130 - mae: 0.1289 - val_loss: 0.0265 - val_mae: 0.1395\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0124 - mae: 0.1278 - val_loss: 0.0264 - val_mae: 0.1394\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0132 - mae: 0.1309 - val_loss: 0.0264 - val_mae: 0.1393\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0119 - mae: 0.1233 - val_loss: 0.0264 - val_mae: 0.1392\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0129 - mae: 0.1299 - val_loss: 0.0264 - val_mae: 0.1390\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0123 - mae: 0.1232 - val_loss: 0.0264 - val_mae: 0.1389\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0130 - mae: 0.1269 - val_loss: 0.0264 - val_mae: 0.1388\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0132 - mae: 0.1284 - val_loss: 0.0263 - val_mae: 0.1387\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0127 - mae: 0.1266 - val_loss: 0.0263 - val_mae: 0.1386\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0137 - mae: 0.1304 - val_loss: 0.0263 - val_mae: 0.1385\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0129 - mae: 0.1262 - val_loss: 0.0263 - val_mae: 0.1383\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1203 - val_loss: 0.0263 - val_mae: 0.1382\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0124 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1381\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0127 - mae: 0.1262 - val_loss: 0.0262 - val_mae: 0.1380\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0132 - mae: 0.1272 - val_loss: 0.0262 - val_mae: 0.1379\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0123 - mae: 0.1236 - val_loss: 0.0262 - val_mae: 0.1378\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0136 - mae: 0.1296 - val_loss: 0.0262 - val_mae: 0.1376\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0120 - mae: 0.1209 - val_loss: 0.0262 - val_mae: 0.1375\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0122 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1374\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0117 - mae: 0.1211 - val_loss: 0.0261 - val_mae: 0.1373\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0124 - mae: 0.1239 - val_loss: 0.0261 - val_mae: 0.1372\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0130 - mae: 0.1233 - val_loss: 0.0261 - val_mae: 0.1371\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0122 - mae: 0.1266 - val_loss: 0.0261 - val_mae: 0.1370\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0126 - mae: 0.1257 - val_loss: 0.0261 - val_mae: 0.1369\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - mae: 0.1248 - val_loss: 0.0261 - val_mae: 0.1367\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0125 - mae: 0.1263 - val_loss: 0.0260 - val_mae: 0.1366\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1238 - val_loss: 0.0260 - val_mae: 0.1365\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1214 - val_loss: 0.0260 - val_mae: 0.1364\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0124 - mae: 0.1266 - val_loss: 0.0260 - val_mae: 0.1363\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0117 - mae: 0.1202 - val_loss: 0.0260 - val_mae: 0.1362\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0123 - mae: 0.1232 - val_loss: 0.0260 - val_mae: 0.1361\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1209 - val_loss: 0.0259 - val_mae: 0.1360\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0119 - mae: 0.1202 - val_loss: 0.0259 - val_mae: 0.1359\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1233 - val_loss: 0.0259 - val_mae: 0.1358\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0118 - mae: 0.1225 - val_loss: 0.0259 - val_mae: 0.1357\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0117 - mae: 0.1209 - val_loss: 0.0259 - val_mae: 0.1356\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0130 - mae: 0.1266 - val_loss: 0.0259 - val_mae: 0.1355\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1216 - val_loss: 0.0259 - val_mae: 0.1353\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1255 - val_loss: 0.0258 - val_mae: 0.1352\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0118 - mae: 0.1230 - val_loss: 0.0258 - val_mae: 0.1351\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - mae: 0.1186 - val_loss: 0.0258 - val_mae: 0.1350\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0122 - mae: 0.1221 - val_loss: 0.0258 - val_mae: 0.1349\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0122 - mae: 0.1233 - val_loss: 0.0258 - val_mae: 0.1348\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1211 - val_loss: 0.0258 - val_mae: 0.1347\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0120 - mae: 0.1244 - val_loss: 0.0258 - val_mae: 0.1346\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0121 - mae: 0.1230 - val_loss: 0.0257 - val_mae: 0.1345\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0118 - mae: 0.1213 - val_loss: 0.0257 - val_mae: 0.1344\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1188 - val_loss: 0.0257 - val_mae: 0.1343\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0118 - mae: 0.1221 - val_loss: 0.0257 - val_mae: 0.1342\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0122 - mae: 0.1245 - val_loss: 0.0257 - val_mae: 0.1341\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1170 - val_loss: 0.0257 - val_mae: 0.1340\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - mae: 0.1207 - val_loss: 0.0257 - val_mae: 0.1339\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1161 - val_loss: 0.0256 - val_mae: 0.1338\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1192 - val_loss: 0.0256 - val_mae: 0.1337\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1208 - val_loss: 0.0256 - val_mae: 0.1336\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1183 - val_loss: 0.0256 - val_mae: 0.1335\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0124 - mae: 0.1245 - val_loss: 0.0256 - val_mae: 0.1334\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0111 - mae: 0.1178 - val_loss: 0.0256 - val_mae: 0.1333\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1211 - val_loss: 0.0256 - val_mae: 0.1333\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1217 - val_loss: 0.0255 - val_mae: 0.1332\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1147 - val_loss: 0.0255 - val_mae: 0.1331\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0119 - mae: 0.1204 - val_loss: 0.0255 - val_mae: 0.1330\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0118 - mae: 0.1201 - val_loss: 0.0255 - val_mae: 0.1329\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0255 - val_mae: 0.1328\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1202 - val_loss: 0.0255 - val_mae: 0.1327\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1326\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0116 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1325\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0111 - mae: 0.1181 - val_loss: 0.0254 - val_mae: 0.1324\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1188 - val_loss: 0.0254 - val_mae: 0.1323\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0116 - mae: 0.1219 - val_loss: 0.0254 - val_mae: 0.1322\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0111 - mae: 0.1163 - val_loss: 0.0254 - val_mae: 0.1321\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1193 - val_loss: 0.0254 - val_mae: 0.1320\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1319\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1193 - val_loss: 0.0254 - val_mae: 0.1318\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0112 - mae: 0.1176 - val_loss: 0.0254 - val_mae: 0.1317\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1192 - val_loss: 0.0253 - val_mae: 0.1316\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1315\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0110 - mae: 0.1177 - val_loss: 0.0253 - val_mae: 0.1315\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1314\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0109 - mae: 0.1147 - val_loss: 0.0253 - val_mae: 0.1313\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0253 - val_mae: 0.1312\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1201 - val_loss: 0.0253 - val_mae: 0.1311\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1165 - val_loss: 0.0253 - val_mae: 0.1310\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1309\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1142 - val_loss: 0.0252 - val_mae: 0.1308\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0106 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1307\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0252 - val_mae: 0.1306\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1193 - val_loss: 0.0252 - val_mae: 0.1305\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0252 - val_mae: 0.1305\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0252 - val_mae: 0.1304\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0115 - mae: 0.1224 - val_loss: 0.0252 - val_mae: 0.1303\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1157 - val_loss: 0.0252 - val_mae: 0.1302\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0110 - mae: 0.1158 - val_loss: 0.0251 - val_mae: 0.1301\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0106 - mae: 0.1147 - val_loss: 0.0251 - val_mae: 0.1300\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1175 - val_loss: 0.0251 - val_mae: 0.1299\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1157 - val_loss: 0.0251 - val_mae: 0.1298\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - mae: 0.1197 - val_loss: 0.0251 - val_mae: 0.1297\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1161 - val_loss: 0.0251 - val_mae: 0.1297\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - mae: 0.1182 - val_loss: 0.0251 - val_mae: 0.1296\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0251 - val_mae: 0.1295\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - mae: 0.1143 - val_loss: 0.0250 - val_mae: 0.1294\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0113 - mae: 0.1177 - val_loss: 0.0250 - val_mae: 0.1293\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0250 - val_mae: 0.1292\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0250 - val_mae: 0.1291\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1119 - val_loss: 0.0250 - val_mae: 0.1290\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1166 - val_loss: 0.0250 - val_mae: 0.1289\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0250 - val_mae: 0.1289\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0114 - mae: 0.1150 - val_loss: 0.0250 - val_mae: 0.1288\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0111 - mae: 0.1168 - val_loss: 0.0250 - val_mae: 0.1287\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0250 - val_mae: 0.1286\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0249 - val_mae: 0.1285\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0249 - val_mae: 0.1284\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0249 - val_mae: 0.1283\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1168 - val_loss: 0.0249 - val_mae: 0.1282\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - mae: 0.1132 - val_loss: 0.0249 - val_mae: 0.1281\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1115 - val_loss: 0.0249 - val_mae: 0.1281\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0249 - val_mae: 0.1280\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0249 - val_mae: 0.1279\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0249 - val_mae: 0.1278\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - mae: 0.1170 - val_loss: 0.0248 - val_mae: 0.1277\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0106 - mae: 0.1114 - val_loss: 0.0248 - val_mae: 0.1276\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0248 - val_mae: 0.1275\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0248 - val_mae: 0.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:53,062] Trial 12 finished with value: 0.12744535505771637 and parameters: {'learning_rate': 7.546446707754693e-06, 'weight_decay': 3.587578917655504e-07}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0238 - val_mae: 0.1124\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1114\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0236 - val_mae: 0.1110\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0235 - val_mae: 0.1105\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1096\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1091\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0232 - val_mae: 0.1081\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0231 - val_mae: 0.1071\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1051\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0907 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0881 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0225 - val_mae: 0.1026\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0224 - val_mae: 0.1015\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0867 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0079 - mae: 0.0904 - val_loss: 0.0223 - val_mae: 0.1006\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0860 - val_loss: 0.0222 - val_mae: 0.1001\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0859 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0857 - val_loss: 0.0221 - val_mae: 0.0991\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0220 - val_mae: 0.0986\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0219 - val_mae: 0.0977\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0845 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0217 - val_mae: 0.0967\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0815 - val_loss: 0.0217 - val_mae: 0.0962\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0840 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0215 - val_mae: 0.0952\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0215 - val_mae: 0.0947\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0214 - val_mae: 0.0942\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0212 - val_mae: 0.0928\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0824 - val_loss: 0.0212 - val_mae: 0.0924\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0776 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - mae: 0.0793 - val_loss: 0.0210 - val_mae: 0.0910\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0209 - val_mae: 0.0906\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - mae: 0.0839 - val_loss: 0.0209 - val_mae: 0.0902\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0766 - val_loss: 0.0208 - val_mae: 0.0898\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0803 - val_loss: 0.0208 - val_mae: 0.0894\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0207 - val_mae: 0.0891\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0063 - mae: 0.0777 - val_loss: 0.0206 - val_mae: 0.0887\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0064 - mae: 0.0776 - val_loss: 0.0206 - val_mae: 0.0884\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0764 - val_loss: 0.0205 - val_mae: 0.0880\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0204 - val_mae: 0.0874\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0757 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0741 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0202 - val_mae: 0.0861\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0771 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0793 - val_loss: 0.0201 - val_mae: 0.0854\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0720 - val_loss: 0.0201 - val_mae: 0.0851\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0200 - val_mae: 0.0847\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0844\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0732 - val_loss: 0.0199 - val_mae: 0.0841\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0796 - val_loss: 0.0199 - val_mae: 0.0838\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0198 - val_mae: 0.0836\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0775 - val_loss: 0.0198 - val_mae: 0.0833\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0197 - val_mae: 0.0830\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0197 - val_mae: 0.0827\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0196 - val_mae: 0.0825\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0196 - val_mae: 0.0822\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0060 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0819\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0195 - val_mae: 0.0817\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0057 - mae: 0.0722 - val_loss: 0.0194 - val_mae: 0.0815\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0194 - val_mae: 0.0813\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0752 - val_loss: 0.0193 - val_mae: 0.0811\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0193 - val_mae: 0.0809\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0193 - val_mae: 0.0808\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0761 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0192 - val_mae: 0.0806\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0767 - val_loss: 0.0192 - val_mae: 0.0805\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0192 - val_mae: 0.0804\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0686 - val_loss: 0.0192 - val_mae: 0.0802\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0191 - val_mae: 0.0801\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0692 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0191 - val_mae: 0.0798\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0730 - val_loss: 0.0190 - val_mae: 0.0797\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0190 - val_mae: 0.0796\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0055 - mae: 0.0738 - val_loss: 0.0190 - val_mae: 0.0795\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0690 - val_loss: 0.0189 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0729 - val_loss: 0.0189 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0667 - val_loss: 0.0188 - val_mae: 0.0790\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0188 - val_mae: 0.0788\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0187 - val_mae: 0.0786\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0655 - val_loss: 0.0186 - val_mae: 0.0784\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - mae: 0.0683 - val_loss: 0.0186 - val_mae: 0.0783\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0739 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0735 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0685 - val_loss: 0.0186 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0700 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0185 - val_mae: 0.0777\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0619 - val_loss: 0.0185 - val_mae: 0.0777\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0657 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0671 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0657 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0695 - val_loss: 0.0182 - val_mae: 0.0772\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0711 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0051 - mae: 0.0687 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0681 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0668 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - mae: 0.0654 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0179 - val_mae: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:08,831] Trial 13 finished with value: 0.07676756381988525 and parameters: {'learning_rate': 4.867515363143382e-05, 'weight_decay': 1.1172288894024361e-07}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0236 - val_mae: 0.1165\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0236 - val_mae: 0.1161\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1024 - val_loss: 0.0235 - val_mae: 0.1156\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1152\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1147\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0234 - val_mae: 0.1143\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0233 - val_mae: 0.1139\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1003 - val_loss: 0.0232 - val_mae: 0.1134\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1025 - val_loss: 0.0232 - val_mae: 0.1130\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1012 - val_loss: 0.0231 - val_mae: 0.1127\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1123\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1119\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1115\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1112\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0230 - val_mae: 0.1108\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0229 - val_mae: 0.1104\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0229 - val_mae: 0.1101\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0959 - val_loss: 0.0228 - val_mae: 0.1097\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1093\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0228 - val_mae: 0.1089\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0227 - val_mae: 0.1086\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1082\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0227 - val_mae: 0.1078\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0226 - val_mae: 0.1075\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0919 - val_loss: 0.0226 - val_mae: 0.1067\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0225 - val_mae: 0.1064\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0927 - val_loss: 0.0225 - val_mae: 0.1060\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0923 - val_loss: 0.0225 - val_mae: 0.1056\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0892 - val_loss: 0.0224 - val_mae: 0.1053\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0224 - val_mae: 0.1049\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1045\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0223 - val_mae: 0.1042\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0223 - val_mae: 0.1038\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0222 - val_mae: 0.1034\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - mae: 0.0890 - val_loss: 0.0222 - val_mae: 0.1030\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0221 - val_mae: 0.1026\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0221 - val_mae: 0.1022\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0221 - val_mae: 0.1018\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0220 - val_mae: 0.1014\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0883 - val_loss: 0.0220 - val_mae: 0.1010\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0219 - val_mae: 0.1006\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.1002\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0853 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0218 - val_mae: 0.0994\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0986\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0217 - val_mae: 0.0982\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0216 - val_mae: 0.0977\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0215 - val_mae: 0.0969\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - mae: 0.0827 - val_loss: 0.0215 - val_mae: 0.0965\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0960\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0070 - mae: 0.0813 - val_loss: 0.0214 - val_mae: 0.0956\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0065 - mae: 0.0817 - val_loss: 0.0213 - val_mae: 0.0951\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0823 - val_loss: 0.0213 - val_mae: 0.0946\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0069 - mae: 0.0813 - val_loss: 0.0212 - val_mae: 0.0942\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0212 - val_mae: 0.0937\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0211 - val_mae: 0.0932\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0210 - val_mae: 0.0928\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0803 - val_loss: 0.0210 - val_mae: 0.0923\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0209 - val_mae: 0.0918\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0914\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0771 - val_loss: 0.0208 - val_mae: 0.0909\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0208 - val_mae: 0.0904\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0773 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0805 - val_loss: 0.0207 - val_mae: 0.0895\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0206 - val_mae: 0.0890\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0206 - val_mae: 0.0886\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0062 - mae: 0.0753 - val_loss: 0.0205 - val_mae: 0.0881\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0736 - val_loss: 0.0204 - val_mae: 0.0873\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0204 - val_mae: 0.0868\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0754 - val_loss: 0.0203 - val_mae: 0.0860\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066 - mae: 0.0767 - val_loss: 0.0202 - val_mae: 0.0856\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0853\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0755 - val_loss: 0.0201 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0201 - val_mae: 0.0846\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0843\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0779 - val_loss: 0.0200 - val_mae: 0.0840\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - mae: 0.0760 - val_loss: 0.0199 - val_mae: 0.0836\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0732 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - mae: 0.0752 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0694 - val_loss: 0.0198 - val_mae: 0.0827\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0707 - val_loss: 0.0197 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0063 - mae: 0.0760 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0196 - val_mae: 0.0814\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0812\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0195 - val_mae: 0.0809\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0194 - val_mae: 0.0806\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0737 - val_loss: 0.0194 - val_mae: 0.0803\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0713 - val_loss: 0.0193 - val_mae: 0.0800\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0193 - val_mae: 0.0798\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0057 - mae: 0.0745 - val_loss: 0.0192 - val_mae: 0.0795\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0192 - val_mae: 0.0793\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0192 - val_mae: 0.0791\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0191 - val_mae: 0.0789\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0191 - val_mae: 0.0787\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0190 - val_mae: 0.0785\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0737 - val_loss: 0.0190 - val_mae: 0.0784\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0190 - val_mae: 0.0782\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - mae: 0.0734 - val_loss: 0.0190 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0189 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0743 - val_loss: 0.0189 - val_mae: 0.0779\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0189 - val_mae: 0.0778\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0189 - val_mae: 0.0776\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0730 - val_loss: 0.0188 - val_mae: 0.0775\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0188 - val_mae: 0.0775\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0188 - val_mae: 0.0774\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0188 - val_mae: 0.0773\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0188 - val_mae: 0.0772\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0771\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0711 - val_loss: 0.0187 - val_mae: 0.0770\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0187 - val_mae: 0.0769\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0769\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - mae: 0.0702 - val_loss: 0.0186 - val_mae: 0.0768\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0186 - val_mae: 0.0767\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0186 - val_mae: 0.0766\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0186 - val_mae: 0.0766\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0701 - val_loss: 0.0186 - val_mae: 0.0765\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0687 - val_loss: 0.0186 - val_mae: 0.0764\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0185 - val_mae: 0.0764\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0185 - val_mae: 0.0763\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0185 - val_mae: 0.0762\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0185 - val_mae: 0.0761\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0728 - val_loss: 0.0184 - val_mae: 0.0761\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0184 - val_mae: 0.0760\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0184 - val_mae: 0.0760\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0184 - val_mae: 0.0759\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0184 - val_mae: 0.0759\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0184 - val_mae: 0.0758\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0183 - val_mae: 0.0758\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0183 - val_mae: 0.0757\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0052 - mae: 0.0727 - val_loss: 0.0183 - val_mae: 0.0757\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0183 - val_mae: 0.0756\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0183 - val_mae: 0.0756\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0704 - val_loss: 0.0182 - val_mae: 0.0755\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0666 - val_loss: 0.0182 - val_mae: 0.0754\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0182 - val_mae: 0.0754\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0182 - val_mae: 0.0753\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0182 - val_mae: 0.0753\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0182 - val_mae: 0.0752\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0182 - val_mae: 0.0752\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0677 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0181 - val_mae: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:24,498] Trial 14 finished with value: 0.07514270395040512 and parameters: {'learning_rate': 4.3829884598771095e-05, 'weight_decay': 1.0768675501384835e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0252 - val_mae: 0.1202\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0251 - val_mae: 0.1198\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1193\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1189\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1185\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0249 - val_mae: 0.1181\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1176\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0247 - val_mae: 0.1172\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1168\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0246 - val_mae: 0.1164\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1160\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1156\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1152\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1147\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1056 - val_loss: 0.0243 - val_mae: 0.1139\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1131\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1127\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1123\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0240 - val_mae: 0.1119\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0239 - val_mae: 0.1114\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1110\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1106\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.0997 - val_loss: 0.0238 - val_mae: 0.1102\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1098\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.0990 - val_loss: 0.0236 - val_mae: 0.1094\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1090\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0235 - val_mae: 0.1085\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1082\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1078\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1074\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1070\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1066\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0942 - val_loss: 0.0232 - val_mae: 0.1062\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1058\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0925 - val_loss: 0.0231 - val_mae: 0.1054\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1050\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1046\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0940 - val_loss: 0.0230 - val_mae: 0.1043\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0230 - val_mae: 0.1039\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0966 - val_loss: 0.0229 - val_mae: 0.1036\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0229 - val_mae: 0.1032\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0907 - val_loss: 0.0228 - val_mae: 0.1028\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0912 - val_loss: 0.0228 - val_mae: 0.1021\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0928 - val_loss: 0.0227 - val_mae: 0.1018\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0926 - val_loss: 0.0227 - val_mae: 0.1014\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0943 - val_loss: 0.0226 - val_mae: 0.1011\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0226 - val_mae: 0.1008\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0226 - val_mae: 0.1004\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1001\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.0995\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0082 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.0991\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0224 - val_mae: 0.0988\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0223 - val_mae: 0.0985\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0223 - val_mae: 0.0982\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.0979\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0908 - val_loss: 0.0222 - val_mae: 0.0976\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0222 - val_mae: 0.0973\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0221 - val_mae: 0.0970\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - mae: 0.0897 - val_loss: 0.0221 - val_mae: 0.0967\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0221 - val_mae: 0.0964\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0220 - val_mae: 0.0961\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0220 - val_mae: 0.0958\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0899 - val_loss: 0.0220 - val_mae: 0.0955\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0219 - val_mae: 0.0948\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0219 - val_mae: 0.0945\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0218 - val_mae: 0.0942\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.0939\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0218 - val_mae: 0.0937\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0217 - val_mae: 0.0934\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0217 - val_mae: 0.0931\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - mae: 0.0829 - val_loss: 0.0217 - val_mae: 0.0927\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0861 - val_loss: 0.0216 - val_mae: 0.0924\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0216 - val_mae: 0.0921\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0918\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0844 - val_loss: 0.0215 - val_mae: 0.0915\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0215 - val_mae: 0.0912\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0214 - val_mae: 0.0909\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0214 - val_mae: 0.0906\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0214 - val_mae: 0.0903\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0213 - val_mae: 0.0900\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0213 - val_mae: 0.0897\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0213 - val_mae: 0.0894\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0212 - val_mae: 0.0891\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0212 - val_mae: 0.0888\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0794 - val_loss: 0.0212 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0211 - val_mae: 0.0883\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0880\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0878\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0832 - val_loss: 0.0210 - val_mae: 0.0875\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0873\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0840 - val_loss: 0.0209 - val_mae: 0.0870\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0209 - val_mae: 0.0868\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0062 - mae: 0.0755 - val_loss: 0.0209 - val_mae: 0.0865\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0208 - val_mae: 0.0863\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0829 - val_loss: 0.0208 - val_mae: 0.0860\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0208 - val_mae: 0.0858\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0207 - val_mae: 0.0856\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0207 - val_mae: 0.0854\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0206 - val_mae: 0.0851\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0759 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0206 - val_mae: 0.0847\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0205 - val_mae: 0.0845\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0798 - val_loss: 0.0205 - val_mae: 0.0843\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0777 - val_loss: 0.0205 - val_mae: 0.0841\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.0838\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.0836\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0064 - mae: 0.0788 - val_loss: 0.0203 - val_mae: 0.0835\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0832\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0203 - val_mae: 0.0830\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0202 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0202 - val_mae: 0.0827\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0780 - val_loss: 0.0202 - val_mae: 0.0826\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0201 - val_mae: 0.0825\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - mae: 0.0752 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0062 - mae: 0.0773 - val_loss: 0.0201 - val_mae: 0.0822\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0201 - val_mae: 0.0821\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0778 - val_loss: 0.0200 - val_mae: 0.0820\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0200 - val_mae: 0.0818\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0200 - val_mae: 0.0817\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0816\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0199 - val_mae: 0.0815\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0199 - val_mae: 0.0812\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0745 - val_loss: 0.0199 - val_mae: 0.0811\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0810\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0809\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0808\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0794 - val_loss: 0.0198 - val_mae: 0.0807\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0700 - val_loss: 0.0197 - val_mae: 0.0806\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0060 - mae: 0.0791 - val_loss: 0.0197 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0785 - val_loss: 0.0197 - val_mae: 0.0803\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0778 - val_loss: 0.0197 - val_mae: 0.0802\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0064 - mae: 0.0773 - val_loss: 0.0197 - val_mae: 0.0801\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0736 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0718 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.0799\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0701 - val_loss: 0.0196 - val_mae: 0.0798\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0752 - val_loss: 0.0196 - val_mae: 0.0797\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0195 - val_mae: 0.0797\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0723 - val_loss: 0.0195 - val_mae: 0.0795\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0756 - val_loss: 0.0195 - val_mae: 0.0795\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0760 - val_loss: 0.0195 - val_mae: 0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:41,001] Trial 15 finished with value: 0.07944000512361526 and parameters: {'learning_rate': 2.767487152987574e-05, 'weight_decay': 2.91625247096876e-08}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1097 - val_loss: 0.0218 - val_mae: 0.1024\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0077 - mae: 0.0878 - val_loss: 0.0203 - val_mae: 0.0898\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0189 - val_mae: 0.0802\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0689 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0681 - val_loss: 0.0168 - val_mae: 0.0875\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0746 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0697 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0878\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - mae: 0.0653 - val_loss: 0.0166 - val_mae: 0.0873\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0849\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0611 - val_loss: 0.0160 - val_mae: 0.0864\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0159 - val_mae: 0.0866\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0158 - val_mae: 0.0853\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0573 - val_loss: 0.0158 - val_mae: 0.0831\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0154 - val_mae: 0.0874\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0633 - val_loss: 0.0154 - val_mae: 0.0835\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0540 - val_loss: 0.0156 - val_mae: 0.0805\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0154 - val_mae: 0.0814\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0151 - val_mae: 0.0858\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0152 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0151 - val_mae: 0.0822\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0149 - val_mae: 0.0841\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0146 - val_mae: 0.0871\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0145 - val_mae: 0.0890\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0143 - val_mae: 0.0897\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0141 - val_mae: 0.0898\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0139 - val_mae: 0.0897\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - mae: 0.0533 - val_loss: 0.0137 - val_mae: 0.0934\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0507 - val_loss: 0.0140 - val_mae: 0.0839\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0138 - val_mae: 0.0853\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0514 - val_loss: 0.0136 - val_mae: 0.0983\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0539 - val_loss: 0.0138 - val_mae: 0.1029\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0578 - val_loss: 0.0142 - val_mae: 0.0822\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0151 - val_mae: 0.0755\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - mae: 0.0493 - val_loss: 0.0155 - val_mae: 0.0748\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0772\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0149 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0145 - val_mae: 0.0876\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0144 - val_mae: 0.0916\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0146 - val_mae: 0.0871\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0148 - val_mae: 0.0831\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0150 - val_mae: 0.0815\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0150 - val_mae: 0.0814\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0147 - val_mae: 0.0835\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0145 - val_mae: 0.0872\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0144 - val_mae: 0.0907\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - mae: 0.0545 - val_loss: 0.0144 - val_mae: 0.0892\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0523 - val_loss: 0.0147 - val_mae: 0.0835\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.0150 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0020 - mae: 0.0438 - val_loss: 0.0152 - val_mae: 0.0771\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0150 - val_mae: 0.0776\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0147 - val_mae: 0.0799\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0143 - val_mae: 0.0828\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0435 - val_loss: 0.0140 - val_mae: 0.0896\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0476 - val_loss: 0.0138 - val_mae: 0.0924\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0463 - val_loss: 0.0138 - val_mae: 0.0871\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0137 - val_mae: 0.0869\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0139 - val_mae: 0.0820\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0447 - val_loss: 0.0139 - val_mae: 0.0817\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mae: 0.0410 - val_loss: 0.0138 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0138 - val_mae: 0.0886\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - mae: 0.0429 - val_loss: 0.0138 - val_mae: 0.0868\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0139 - val_mae: 0.0826\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0418 - val_loss: 0.0139 - val_mae: 0.0821\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0137 - val_mae: 0.0851\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0137 - val_mae: 0.0893\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - mae: 0.0425 - val_loss: 0.0139 - val_mae: 0.0924\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0141 - val_mae: 0.0889\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0146 - val_mae: 0.0852\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0150 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0403 - val_loss: 0.0151 - val_mae: 0.0875\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0151 - val_mae: 0.0869\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 0.0149 - val_mae: 0.0873\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0147 - val_mae: 0.0856\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0855\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0020 - mae: 0.0438 - val_loss: 0.0142 - val_mae: 0.0892\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - mae: 0.0378 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0020 - mae: 0.0467 - val_loss: 0.0141 - val_mae: 0.0896\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0145 - val_mae: 0.0848\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0149 - val_mae: 0.0824\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0373 - val_loss: 0.0153 - val_mae: 0.0815\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0154 - val_mae: 0.0830\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0157 - val_mae: 0.0842\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - mae: 0.0397 - val_loss: 0.0157 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0156 - val_mae: 0.0887\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0152 - val_mae: 0.0895\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0148 - val_mae: 0.0900\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0145 - val_mae: 0.0904\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0142 - val_mae: 0.0913\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0143 - val_mae: 0.0948\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0144 - val_mae: 0.0861\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0148 - val_mae: 0.0793\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0769\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 0.0152 - val_mae: 0.0777\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0149 - val_mae: 0.0820\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0147 - val_mae: 0.0895\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0148 - val_mae: 0.0930\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0148 - val_mae: 0.0932\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0147 - val_mae: 0.0895\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0148 - val_mae: 0.0881\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0394 - val_loss: 0.0150 - val_mae: 0.0873\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0152 - val_mae: 0.0886\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - mae: 0.0371 - val_loss: 0.0149 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.8490e-04 - mae: 0.0296 - val_loss: 0.0146 - val_mae: 0.0810\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0145 - val_mae: 0.0800\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0145 - val_mae: 0.0819\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0350 - val_loss: 0.0148 - val_mae: 0.0857\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.8548e-04 - mae: 0.0332 - val_loss: 0.0149 - val_mae: 0.0887\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0141 - val_mae: 0.0888\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.9006e-04 - mae: 0.0311 - val_loss: 0.0138 - val_mae: 0.0878\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0140 - val_mae: 0.0883\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.6222e-04 - mae: 0.0343 - val_loss: 0.0146 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.8729e-04 - mae: 0.0326 - val_loss: 0.0151 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.4718e-04 - mae: 0.0299 - val_loss: 0.0155 - val_mae: 0.0844\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0830\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0163 - val_mae: 0.0821\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.6936e-04 - mae: 0.0304 - val_loss: 0.0159 - val_mae: 0.0828\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.7649e-04 - mae: 0.0289 - val_loss: 0.0156 - val_mae: 0.0854\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 0.0152 - val_mae: 0.0916\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1835e-04 - mae: 0.0318 - val_loss: 0.0150 - val_mae: 0.0934\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1148e-04 - mae: 0.0333 - val_loss: 0.0151 - val_mae: 0.0898\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.8539e-04 - mae: 0.0320 - val_loss: 0.0157 - val_mae: 0.0869\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7770e-04 - mae: 0.0307 - val_loss: 0.0161 - val_mae: 0.0858\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0158 - val_mae: 0.0876\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.0528e-04 - mae: 0.0322 - val_loss: 0.0157 - val_mae: 0.0913\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.5622e-04 - mae: 0.0336 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.8016e-04 - mae: 0.0289 - val_loss: 0.0159 - val_mae: 0.0882\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - mae: 0.0327 - val_loss: 0.0159 - val_mae: 0.0876\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0348 - val_loss: 0.0164 - val_mae: 0.0872\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1594e-04 - mae: 0.0295 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.5982e-04 - mae: 0.0311 - val_loss: 0.0174 - val_mae: 0.0897\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.7868e-04 - mae: 0.0301 - val_loss: 0.0182 - val_mae: 0.0938\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.2536e-04 - mae: 0.0321 - val_loss: 0.0171 - val_mae: 0.0965\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 0.0154 - val_mae: 0.0966\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.5818e-04 - mae: 0.0330 - val_loss: 0.0148 - val_mae: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:56,378] Trial 16 finished with value: 0.09393008053302765 and parameters: {'learning_rate': 0.0029239353775467212, 'weight_decay': 2.6027070959021956e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1049\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0223 - val_mae: 0.1026\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0909 - val_loss: 0.0220 - val_mae: 0.1005\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0218 - val_mae: 0.0995\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0876 - val_loss: 0.0217 - val_mae: 0.0987\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0920 - val_loss: 0.0216 - val_mae: 0.0979\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0214 - val_mae: 0.0971\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0071 - mae: 0.0879 - val_loss: 0.0213 - val_mae: 0.0963\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0212 - val_mae: 0.0956\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0072 - mae: 0.0884 - val_loss: 0.0210 - val_mae: 0.0949\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0850 - val_loss: 0.0209 - val_mae: 0.0942\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0208 - val_mae: 0.0936\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - mae: 0.0842 - val_loss: 0.0207 - val_mae: 0.0930\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0811 - val_loss: 0.0205 - val_mae: 0.0925\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0204 - val_mae: 0.0919\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0203 - val_mae: 0.0913\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0202 - val_mae: 0.0908\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0200 - val_mae: 0.0902\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0065 - mae: 0.0843 - val_loss: 0.0199 - val_mae: 0.0896\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0823 - val_loss: 0.0198 - val_mae: 0.0891\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0788 - val_loss: 0.0197 - val_mae: 0.0886\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0824 - val_loss: 0.0196 - val_mae: 0.0880\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0819 - val_loss: 0.0195 - val_mae: 0.0874\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0194 - val_mae: 0.0868\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0194 - val_mae: 0.0862\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0782 - val_loss: 0.0193 - val_mae: 0.0857\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - mae: 0.0782 - val_loss: 0.0192 - val_mae: 0.0851\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0192 - val_mae: 0.0846\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0801 - val_loss: 0.0190 - val_mae: 0.0837\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0190 - val_mae: 0.0832\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0189 - val_mae: 0.0828\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0811 - val_loss: 0.0189 - val_mae: 0.0825\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0189 - val_mae: 0.0821\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0817\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0053 - mae: 0.0729 - val_loss: 0.0188 - val_mae: 0.0814\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0188 - val_mae: 0.0811\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0058 - mae: 0.0748 - val_loss: 0.0188 - val_mae: 0.0809\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0060 - mae: 0.0774 - val_loss: 0.0187 - val_mae: 0.0806\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0187 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0187 - val_mae: 0.0800\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0062 - mae: 0.0762 - val_loss: 0.0186 - val_mae: 0.0798\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0186 - val_mae: 0.0797\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0186 - val_mae: 0.0794\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0051 - mae: 0.0722 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0051 - mae: 0.0700 - val_loss: 0.0185 - val_mae: 0.0791\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0055 - mae: 0.0743 - val_loss: 0.0184 - val_mae: 0.0789\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0055 - mae: 0.0737 - val_loss: 0.0184 - val_mae: 0.0788\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0183 - val_mae: 0.0786\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0183 - val_mae: 0.0785\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0050 - mae: 0.0730 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0182 - val_mae: 0.0782\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0050 - mae: 0.0743 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0180 - val_mae: 0.0777\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0062 - mae: 0.0757 - val_loss: 0.0179 - val_mae: 0.0771\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0178 - val_mae: 0.0767\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0050 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0766\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0178 - val_mae: 0.0764\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0178 - val_mae: 0.0762\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0178 - val_mae: 0.0760\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0054 - mae: 0.0712 - val_loss: 0.0177 - val_mae: 0.0759\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0672 - val_loss: 0.0177 - val_mae: 0.0758\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0757\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0177 - val_mae: 0.0756\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0177 - val_mae: 0.0755\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0176 - val_mae: 0.0754\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0176 - val_mae: 0.0753\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0176 - val_mae: 0.0752\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0175 - val_mae: 0.0752\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0726 - val_loss: 0.0175 - val_mae: 0.0751\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0751\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0175 - val_mae: 0.0750\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0041 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0681 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0719 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0751\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0751\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0752\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0753\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0662 - val_loss: 0.0171 - val_mae: 0.0754\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0170 - val_mae: 0.0754\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0755\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0170 - val_mae: 0.0755\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0170 - val_mae: 0.0756\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0756\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0671 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0763\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0168 - val_mae: 0.0763\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0760\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0168 - val_mae: 0.0758\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0047 - mae: 0.0654 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0662 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:12,281] Trial 17 finished with value: 0.07601465284824371 and parameters: {'learning_rate': 8.53920780601743e-05, 'weight_decay': 1.5440012645274747e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0119 - mae: 0.1236 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0112 - mae: 0.1172 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0110 - mae: 0.1212 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0115 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1188 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0122 - mae: 0.1250 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1216 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1161 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1210 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1215 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0121 - mae: 0.1252 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0116 - mae: 0.1217 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1200 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1195 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1235 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0115 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0111 - mae: 0.1185 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0122 - mae: 0.1234 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1213 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0113 - mae: 0.1196 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0119 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0117 - mae: 0.1229 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1210 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - mae: 0.1227 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0120 - mae: 0.1235 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1211 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0112 - mae: 0.1193 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1168 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1209 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0118 - mae: 0.1212 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1157 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0110 - mae: 0.1189 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0118 - mae: 0.1198 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0119 - mae: 0.1243 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1203 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1253 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - mae: 0.1239 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1269 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0115 - mae: 0.1223 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0119 - mae: 0.1250 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1249 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1163 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1214 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1207 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1217 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1174 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1189 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1215 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1206 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0106 - mae: 0.1168 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1182 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0108 - mae: 0.1163 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - mae: 0.1193 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1197 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1231 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0118 - mae: 0.1219 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1141 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0121 - mae: 0.1245 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1201 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0110 - mae: 0.1170 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1191 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1228 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0116 - mae: 0.1238 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0124 - mae: 0.1251 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0115 - mae: 0.1200 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1208 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1267 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1201 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0116 - mae: 0.1215 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1210 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1167 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0119 - mae: 0.1252 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1224 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0116 - mae: 0.1204 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1241 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1155 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1169 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1151 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0112 - mae: 0.1203 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0123 - mae: 0.1255 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1223 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0115 - mae: 0.1218 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0108 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0114 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0119 - mae: 0.1240 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0107 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0112 - mae: 0.1193 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1218 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1226 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0110 - mae: 0.1180 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0114 - mae: 0.1181 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1184 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1208 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1204 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1199 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1190 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1198 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1152 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1179 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0113 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0113 - mae: 0.1220 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - mae: 0.1239 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0109 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1155 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1215 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0108 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0120 - mae: 0.1246 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1217 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1195 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1217 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1203 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0108 - mae: 0.1150 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1195 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1172 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0119 - mae: 0.1233 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0117 - mae: 0.1196 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1176 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0121 - mae: 0.1251 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0115 - mae: 0.1189 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0114 - mae: 0.1220 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0108 - mae: 0.1177 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0115 - mae: 0.1196 - val_loss: 0.0262 - val_mae: 0.1317\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0262 - val_mae: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:27,718] Trial 18 finished with value: 0.131738543510437 and parameters: {'learning_rate': 3.5226798981107034e-07, 'weight_decay': 2.3544590325283316e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1204\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0238 - val_mae: 0.1203\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0238 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0238 - val_mae: 0.1201\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0237 - val_mae: 0.1200\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1199\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1197\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1196\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0237 - val_mae: 0.1195\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1194\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0237 - val_mae: 0.1193\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1193\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0237 - val_mae: 0.1192\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0236 - val_mae: 0.1191\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0236 - val_mae: 0.1190\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0236 - val_mae: 0.1189\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1189\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0236 - val_mae: 0.1188\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0236 - val_mae: 0.1187\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0236 - val_mae: 0.1186\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0236 - val_mae: 0.1184\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0236 - val_mae: 0.1183\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0235 - val_mae: 0.1182\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0093 - mae: 0.1031 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0235 - val_mae: 0.1180\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0235 - val_mae: 0.1179\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0235 - val_mae: 0.1178\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0235 - val_mae: 0.1177\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0235 - val_mae: 0.1177\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0235 - val_mae: 0.1176\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0235 - val_mae: 0.1175\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0235 - val_mae: 0.1174\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0234 - val_mae: 0.1173\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0234 - val_mae: 0.1172\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0234 - val_mae: 0.1171\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0234 - val_mae: 0.1171\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0234 - val_mae: 0.1170\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0234 - val_mae: 0.1169\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0234 - val_mae: 0.1168\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0234 - val_mae: 0.1168\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1167\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0234 - val_mae: 0.1166\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1165\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0233 - val_mae: 0.1165\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0233 - val_mae: 0.1164\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0233 - val_mae: 0.1163\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0233 - val_mae: 0.1163\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0233 - val_mae: 0.1162\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0233 - val_mae: 0.1161\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1024 - val_loss: 0.0233 - val_mae: 0.1160\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0233 - val_mae: 0.1160\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1012 - val_loss: 0.0233 - val_mae: 0.1159\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0233 - val_mae: 0.1158\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0233 - val_mae: 0.1158\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1007 - val_loss: 0.0233 - val_mae: 0.1157\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0233 - val_mae: 0.1156\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0232 - val_mae: 0.1156\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1155\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0232 - val_mae: 0.1154\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0232 - val_mae: 0.1154\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0232 - val_mae: 0.1153\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0232 - val_mae: 0.1152\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0232 - val_mae: 0.1151\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1001 - val_loss: 0.0232 - val_mae: 0.1151\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0232 - val_mae: 0.1150\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0232 - val_mae: 0.1149\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1149\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0232 - val_mae: 0.1148\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1147\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0231 - val_mae: 0.1147\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0231 - val_mae: 0.1146\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0231 - val_mae: 0.1146\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1145\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0231 - val_mae: 0.1144\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0231 - val_mae: 0.1144\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0231 - val_mae: 0.1143\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0231 - val_mae: 0.1142\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0231 - val_mae: 0.1142\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0231 - val_mae: 0.1141\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0231 - val_mae: 0.1140\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1012 - val_loss: 0.0231 - val_mae: 0.1140\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0231 - val_mae: 0.1139\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0979 - val_loss: 0.0231 - val_mae: 0.1138\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0230 - val_mae: 0.1138\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0230 - val_mae: 0.1137\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1137\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1136\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0230 - val_mae: 0.1135\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0230 - val_mae: 0.1135\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0230 - val_mae: 0.1134\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0987 - val_loss: 0.0230 - val_mae: 0.1133\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1133\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0230 - val_mae: 0.1132\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0230 - val_mae: 0.1132\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1131\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0230 - val_mae: 0.1130\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0229 - val_mae: 0.1130\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0966 - val_loss: 0.0229 - val_mae: 0.1129\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0993 - val_loss: 0.0229 - val_mae: 0.1128\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0229 - val_mae: 0.1128\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0990 - val_loss: 0.0229 - val_mae: 0.1127\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0229 - val_mae: 0.1127\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0229 - val_mae: 0.1126\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0229 - val_mae: 0.1126\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1012 - val_loss: 0.0229 - val_mae: 0.1125\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0986 - val_loss: 0.0229 - val_mae: 0.1124\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1124\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0976 - val_loss: 0.0229 - val_mae: 0.1123\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1123\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0229 - val_mae: 0.1122\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0987 - val_loss: 0.0229 - val_mae: 0.1122\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0229 - val_mae: 0.1121\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0228 - val_mae: 0.1121\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0966 - val_loss: 0.0228 - val_mae: 0.1120\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0228 - val_mae: 0.1119\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0228 - val_mae: 0.1119\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0228 - val_mae: 0.1118\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0228 - val_mae: 0.1118\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0228 - val_mae: 0.1117\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0963 - val_loss: 0.0228 - val_mae: 0.1117\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0228 - val_mae: 0.1116\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0228 - val_mae: 0.1116\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1115\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0228 - val_mae: 0.1114\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0228 - val_mae: 0.1114\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0986 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0227 - val_mae: 0.1111\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0227 - val_mae: 0.1110\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0981 - val_loss: 0.0227 - val_mae: 0.1110\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0227 - val_mae: 0.1109\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0081 - mae: 0.0971 - val_loss: 0.0227 - val_mae: 0.1109\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0227 - val_mae: 0.1108\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0227 - val_mae: 0.1108\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.1013 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0227 - val_mae: 0.1105\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0227 - val_mae: 0.1104\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0227 - val_mae: 0.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:42,926] Trial 19 finished with value: 0.11038880795240402 and parameters: {'learning_rate': 6.2991928017388976e-06, 'weight_decay': 0.0028634289587533748}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1090 - val_loss: 0.0241 - val_mae: 0.1207\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1097 - val_loss: 0.0240 - val_mae: 0.1200\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1192\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0238 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1176\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1160\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.1021 - val_loss: 0.0235 - val_mae: 0.1152\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0234 - val_mae: 0.1145\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0233 - val_mae: 0.1138\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0995 - val_loss: 0.0232 - val_mae: 0.1131\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0231 - val_mae: 0.1123\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0231 - val_mae: 0.1116\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0230 - val_mae: 0.1108\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0229 - val_mae: 0.1100\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1092\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0227 - val_mae: 0.1084\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0965 - val_loss: 0.0226 - val_mae: 0.1076\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0225 - val_mae: 0.1068\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0224 - val_mae: 0.1060\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0924 - val_loss: 0.0223 - val_mae: 0.1052\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0222 - val_mae: 0.1044\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0222 - val_mae: 0.1037\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0221 - val_mae: 0.1029\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0220 - val_mae: 0.1022\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0885 - val_loss: 0.0219 - val_mae: 0.1014\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0218 - val_mae: 0.1006\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0217 - val_mae: 0.0998\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.0990\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0865 - val_loss: 0.0215 - val_mae: 0.0982\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0214 - val_mae: 0.0974\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0839 - val_loss: 0.0212 - val_mae: 0.0965\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0211 - val_mae: 0.0957\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0210 - val_mae: 0.0948\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0824 - val_loss: 0.0209 - val_mae: 0.0939\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - mae: 0.0834 - val_loss: 0.0208 - val_mae: 0.0931\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0804 - val_loss: 0.0207 - val_mae: 0.0923\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0063 - mae: 0.0806 - val_loss: 0.0205 - val_mae: 0.0915\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0808 - val_loss: 0.0204 - val_mae: 0.0907\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0064 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0901\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0793 - val_loss: 0.0202 - val_mae: 0.0896\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0200 - val_mae: 0.0890\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0058 - mae: 0.0786 - val_loss: 0.0199 - val_mae: 0.0885\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0198 - val_mae: 0.0880\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0197 - val_mae: 0.0875\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0778 - val_loss: 0.0196 - val_mae: 0.0870\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0194 - val_mae: 0.0865\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0765 - val_loss: 0.0193 - val_mae: 0.0860\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0855\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0766 - val_loss: 0.0191 - val_mae: 0.0851\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0051 - mae: 0.0726 - val_loss: 0.0190 - val_mae: 0.0847\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0758 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0839\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0188 - val_mae: 0.0837\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0773 - val_loss: 0.0187 - val_mae: 0.0834\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0186 - val_mae: 0.0832\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0186 - val_mae: 0.0830\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0186 - val_mae: 0.0828\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0185 - val_mae: 0.0825\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0823\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0726 - val_loss: 0.0184 - val_mae: 0.0821\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0052 - mae: 0.0767 - val_loss: 0.0184 - val_mae: 0.0819\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0184 - val_mae: 0.0817\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0183 - val_mae: 0.0815\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - mae: 0.0709 - val_loss: 0.0183 - val_mae: 0.0813\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0183 - val_mae: 0.0811\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0182 - val_mae: 0.0810\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0181 - val_mae: 0.0808\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0670 - val_loss: 0.0180 - val_mae: 0.0807\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0692 - val_loss: 0.0180 - val_mae: 0.0806\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0179 - val_mae: 0.0805\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0804\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0178 - val_mae: 0.0803\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0175 - val_mae: 0.0800\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0619 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0660 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0656 - val_loss: 0.0168 - val_mae: 0.0785\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0167 - val_mae: 0.0782\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0653 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - mae: 0.0678 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0783\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0785\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0790\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0792\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0792\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0793\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:58,436] Trial 20 finished with value: 0.07950785011053085 and parameters: {'learning_rate': 0.00010968476219703535, 'weight_decay': 0.0031104598274814352}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1130 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0107 - mae: 0.1132 - val_loss: 0.0250 - val_mae: 0.1189\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1170\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0103 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1152\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1133\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1116\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0959 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1072\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0882 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0220 - val_mae: 0.0999\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0218 - val_mae: 0.0987\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0976\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0215 - val_mae: 0.0964\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0214 - val_mae: 0.0953\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0212 - val_mae: 0.0941\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0070 - mae: 0.0866 - val_loss: 0.0211 - val_mae: 0.0930\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0787 - val_loss: 0.0209 - val_mae: 0.0919\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0828 - val_loss: 0.0208 - val_mae: 0.0910\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0207 - val_mae: 0.0900\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0065 - mae: 0.0799 - val_loss: 0.0205 - val_mae: 0.0890\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0204 - val_mae: 0.0880\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0203 - val_mae: 0.0871\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0753 - val_loss: 0.0201 - val_mae: 0.0862\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0200 - val_mae: 0.0853\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0729 - val_loss: 0.0198 - val_mae: 0.0844\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0197 - val_mae: 0.0836\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0774 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0193 - val_mae: 0.0814\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0709 - val_loss: 0.0192 - val_mae: 0.0808\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0191 - val_mae: 0.0802\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0189 - val_mae: 0.0796\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0791\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0679 - val_loss: 0.0186 - val_mae: 0.0784\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0184 - val_mae: 0.0780\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0183 - val_mae: 0.0781\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0182 - val_mae: 0.0781\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0181 - val_mae: 0.0781\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0741 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0725 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0724 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0686 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0044 - mae: 0.0649 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0178 - val_mae: 0.0772\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0603 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0649 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0655 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0767\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0177 - val_mae: 0.0767\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0642 - val_loss: 0.0177 - val_mae: 0.0766\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0766\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0771\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0170 - val_mae: 0.0779\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0779\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0777\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0649 - val_loss: 0.0167 - val_mae: 0.0775\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0620 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0767\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0771\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0772\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0164 - val_mae: 0.0782\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0565 - val_loss: 0.0164 - val_mae: 0.0784\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0610 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0581 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0162 - val_mae: 0.0786\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0162 - val_mae: 0.0786\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0162 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0162 - val_mae: 0.0789\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0162 - val_mae: 0.0792\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0794\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0590 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0161 - val_mae: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:13,609] Trial 21 finished with value: 0.07987676560878754 and parameters: {'learning_rate': 0.00015760818403581418, 'weight_decay': 2.3508196247321765e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0246 - val_mae: 0.1226\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1224\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0246 - val_mae: 0.1223\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0245 - val_mae: 0.1220\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1218\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1216\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1214\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0244 - val_mae: 0.1212\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1210\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1208\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0243 - val_mae: 0.1206\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1204\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0243 - val_mae: 0.1202\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1074 - val_loss: 0.0243 - val_mae: 0.1201\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0242 - val_mae: 0.1199\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0242 - val_mae: 0.1197\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0242 - val_mae: 0.1195\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0242 - val_mae: 0.1193\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0241 - val_mae: 0.1191\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0241 - val_mae: 0.1190\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0241 - val_mae: 0.1188\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1186\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1183\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1181\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1179\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0240 - val_mae: 0.1178\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1027 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0239 - val_mae: 0.1175\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0239 - val_mae: 0.1173\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1011 - val_loss: 0.0239 - val_mae: 0.1171\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1170\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1168\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1167\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0238 - val_mae: 0.1165\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0238 - val_mae: 0.1164\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0238 - val_mae: 0.1162\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1159\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0238 - val_mae: 0.1158\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1156\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1001 - val_loss: 0.0237 - val_mae: 0.1155\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1153\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1150\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0236 - val_mae: 0.1147\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0236 - val_mae: 0.1146\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.1001 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0236 - val_mae: 0.1143\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.1004 - val_loss: 0.0236 - val_mae: 0.1141\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0236 - val_mae: 0.1138\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0235 - val_mae: 0.1137\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0235 - val_mae: 0.1135\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0235 - val_mae: 0.1134\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1132\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0090 - mae: 0.1011 - val_loss: 0.0235 - val_mae: 0.1131\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1129\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1128\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1126\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1123\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1122\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0234 - val_mae: 0.1121\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1119\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1116\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1115\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1113\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1112\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1110\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1109\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0233 - val_mae: 0.1107\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1106\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0957 - val_loss: 0.0232 - val_mae: 0.1103\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1101\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0232 - val_mae: 0.1100\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0232 - val_mae: 0.1098\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0231 - val_mae: 0.1097\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0231 - val_mae: 0.1095\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0231 - val_mae: 0.1094\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1093\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1091\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0921 - val_loss: 0.0231 - val_mae: 0.1090\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0230 - val_mae: 0.1086\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1085\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0230 - val_mae: 0.1083\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0230 - val_mae: 0.1082\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0229 - val_mae: 0.1080\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0229 - val_mae: 0.1079\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1078\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1076\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0229 - val_mae: 0.1075\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0229 - val_mae: 0.1073\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0228 - val_mae: 0.1072\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0228 - val_mae: 0.1069\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0228 - val_mae: 0.1067\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0228 - val_mae: 0.1064\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1062\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0227 - val_mae: 0.1061\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1058\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1056\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0227 - val_mae: 0.1055\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0226 - val_mae: 0.1053\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0905 - val_loss: 0.0226 - val_mae: 0.1050\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0876 - val_loss: 0.0225 - val_mae: 0.1045\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1044\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0075 - mae: 0.0874 - val_loss: 0.0225 - val_mae: 0.1042\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0887 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0224 - val_mae: 0.1036\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0847 - val_loss: 0.0224 - val_mae: 0.1034\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.1031\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.1029\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0223 - val_mae: 0.1027\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0853 - val_loss: 0.0222 - val_mae: 0.1022\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0222 - val_mae: 0.1020\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.1017\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0075 - mae: 0.0862 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0073 - mae: 0.0883 - val_loss: 0.0221 - val_mae: 0.1013\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0072 - mae: 0.0853 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.1009\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0220 - val_mae: 0.1006\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.1004\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.1002\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0842 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0071 - mae: 0.0864 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0859 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0219 - val_mae: 0.0994\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0830 - val_loss: 0.0218 - val_mae: 0.0988\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0218 - val_mae: 0.0986\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0217 - val_mae: 0.0984\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0217 - val_mae: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:29,019] Trial 22 finished with value: 0.09822196513414383 and parameters: {'learning_rate': 2.1474716435142536e-05, 'weight_decay': 4.968988684168505e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0250 - val_mae: 0.1198\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1196\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0092 - mae: 0.1060 - val_loss: 0.0249 - val_mae: 0.1190\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1186\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0248 - val_mae: 0.1183\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1180\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1168\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1166\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1163\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1160\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0245 - val_mae: 0.1157\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1154\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0244 - val_mae: 0.1151\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0244 - val_mae: 0.1148\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0243 - val_mae: 0.1146\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0243 - val_mae: 0.1140\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0242 - val_mae: 0.1138\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0993 - val_loss: 0.0242 - val_mae: 0.1132\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0241 - val_mae: 0.1130\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0241 - val_mae: 0.1127\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0241 - val_mae: 0.1124\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0241 - val_mae: 0.1122\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0240 - val_mae: 0.1119\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1117\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1114\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0240 - val_mae: 0.1112\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0979 - val_loss: 0.0239 - val_mae: 0.1109\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0239 - val_mae: 0.1106\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0239 - val_mae: 0.1104\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0239 - val_mae: 0.1101\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0238 - val_mae: 0.1098\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0238 - val_mae: 0.1090\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0947 - val_loss: 0.0237 - val_mae: 0.1081\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0237 - val_mae: 0.1078\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1075\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0236 - val_mae: 0.1072\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1069\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0236 - val_mae: 0.1066\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0235 - val_mae: 0.1063\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0235 - val_mae: 0.1060\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0235 - val_mae: 0.1057\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0235 - val_mae: 0.1054\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0927 - val_loss: 0.0234 - val_mae: 0.1051\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0234 - val_mae: 0.1048\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0909 - val_loss: 0.0234 - val_mae: 0.1045\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0234 - val_mae: 0.1042\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0920 - val_loss: 0.0233 - val_mae: 0.1039\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0233 - val_mae: 0.1037\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0233 - val_mae: 0.1034\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0233 - val_mae: 0.1031\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0232 - val_mae: 0.1028\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0232 - val_mae: 0.1026\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0232 - val_mae: 0.1023\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0231 - val_mae: 0.1020\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0231 - val_mae: 0.1017\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0915 - val_loss: 0.0231 - val_mae: 0.1015\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0230 - val_mae: 0.1012\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0230 - val_mae: 0.1009\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0230 - val_mae: 0.1006\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0229 - val_mae: 0.1003\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0229 - val_mae: 0.1000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0888 - val_loss: 0.0229 - val_mae: 0.0998\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.0995\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0228 - val_mae: 0.0992\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0228 - val_mae: 0.0989\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0852 - val_loss: 0.0227 - val_mae: 0.0986\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0227 - val_mae: 0.0983\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0227 - val_mae: 0.0981\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0226 - val_mae: 0.0978\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0226 - val_mae: 0.0975\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0226 - val_mae: 0.0972\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0225 - val_mae: 0.0969\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0850 - val_loss: 0.0225 - val_mae: 0.0966\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0224 - val_mae: 0.0962\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0224 - val_mae: 0.0959\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0842 - val_loss: 0.0224 - val_mae: 0.0956\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0223 - val_mae: 0.0953\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.0950\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0828 - val_loss: 0.0223 - val_mae: 0.0947\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0222 - val_mae: 0.0944\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0222 - val_mae: 0.0941\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0852 - val_loss: 0.0221 - val_mae: 0.0938\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.0935\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0221 - val_mae: 0.0932\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0220 - val_mae: 0.0928\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0220 - val_mae: 0.0925\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.0922\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0781 - val_loss: 0.0219 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0219 - val_mae: 0.0916\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0822 - val_loss: 0.0218 - val_mae: 0.0913\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0910\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0851 - val_loss: 0.0218 - val_mae: 0.0908\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0217 - val_mae: 0.0905\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0833 - val_loss: 0.0217 - val_mae: 0.0903\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0804 - val_loss: 0.0217 - val_mae: 0.0901\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0216 - val_mae: 0.0898\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0216 - val_mae: 0.0896\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0215 - val_mae: 0.0893\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0215 - val_mae: 0.0891\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0215 - val_mae: 0.0888\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0886\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0214 - val_mae: 0.0884\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0062 - mae: 0.0803 - val_loss: 0.0214 - val_mae: 0.0881\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0806 - val_loss: 0.0213 - val_mae: 0.0879\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0768 - val_loss: 0.0213 - val_mae: 0.0877\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0809 - val_loss: 0.0212 - val_mae: 0.0874\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0780 - val_loss: 0.0212 - val_mae: 0.0872\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0212 - val_mae: 0.0870\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0867\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0804 - val_loss: 0.0211 - val_mae: 0.0865\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0211 - val_mae: 0.0863\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0060 - mae: 0.0785 - val_loss: 0.0210 - val_mae: 0.0860\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - mae: 0.0785 - val_loss: 0.0210 - val_mae: 0.0858\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0792 - val_loss: 0.0210 - val_mae: 0.0856\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0782 - val_loss: 0.0209 - val_mae: 0.0854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0209 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0208 - val_mae: 0.0849\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0745 - val_loss: 0.0208 - val_mae: 0.0847\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - mae: 0.0776 - val_loss: 0.0208 - val_mae: 0.0845\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0764 - val_loss: 0.0207 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0207 - val_mae: 0.0840\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0790 - val_loss: 0.0207 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0206 - val_mae: 0.0836\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0765 - val_loss: 0.0206 - val_mae: 0.0834\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0742 - val_loss: 0.0205 - val_mae: 0.0832\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0799 - val_loss: 0.0205 - val_mae: 0.0830\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0205 - val_mae: 0.0828\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0768 - val_loss: 0.0204 - val_mae: 0.0827\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0784 - val_loss: 0.0204 - val_mae: 0.0825\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0749 - val_loss: 0.0204 - val_mae: 0.0823\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0758 - val_loss: 0.0203 - val_mae: 0.0822\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0764 - val_loss: 0.0203 - val_mae: 0.0820\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0819\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0202 - val_mae: 0.0818\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0715 - val_loss: 0.0202 - val_mae: 0.0817\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0202 - val_mae: 0.0816\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0772 - val_loss: 0.0201 - val_mae: 0.0815\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0201 - val_mae: 0.0814\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0813\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0201 - val_mae: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:44,107] Trial 23 finished with value: 0.08120827376842499 and parameters: {'learning_rate': 3.0123667573852025e-05, 'weight_decay': 1.0962226254424494e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0219 - val_mae: 0.1054\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0213 - val_mae: 0.1008\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0871 - val_loss: 0.0206 - val_mae: 0.0960\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0851 - val_loss: 0.0200 - val_mae: 0.0912\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0790 - val_loss: 0.0193 - val_mae: 0.0869\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0070 - mae: 0.0815 - val_loss: 0.0188 - val_mae: 0.0843\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0769 - val_loss: 0.0184 - val_mae: 0.0819\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0780 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0700 - val_loss: 0.0177 - val_mae: 0.0788\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - mae: 0.0695 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0168 - val_mae: 0.0765\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0762\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0166 - val_mae: 0.0758\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0661 - val_loss: 0.0165 - val_mae: 0.0758\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0164 - val_mae: 0.0761\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0163 - val_mae: 0.0766\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0161 - val_mae: 0.0774\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0646 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0162 - val_mae: 0.0781\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0654 - val_loss: 0.0163 - val_mae: 0.0780\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0165 - val_mae: 0.0787\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0164 - val_mae: 0.0801\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0164 - val_mae: 0.0810\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0163 - val_mae: 0.0819\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0163 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0162 - val_mae: 0.0833\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0162 - val_mae: 0.0837\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0161 - val_mae: 0.0836\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0592 - val_loss: 0.0161 - val_mae: 0.0833\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0158 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0155 - val_mae: 0.0837\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0156 - val_mae: 0.0831\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0157 - val_mae: 0.0818\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0157 - val_mae: 0.0813\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0819\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0154 - val_mae: 0.0827\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0152 - val_mae: 0.0849\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0151 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0151 - val_mae: 0.0857\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0151 - val_mae: 0.0852\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0151 - val_mae: 0.0844\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0838\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0151 - val_mae: 0.0840\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0150 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0150 - val_mae: 0.0841\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0149 - val_mae: 0.0854\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0148 - val_mae: 0.0868\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0147 - val_mae: 0.0875\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0146 - val_mae: 0.0887\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0145 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0145 - val_mae: 0.0880\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0145 - val_mae: 0.0863\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0863\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0143 - val_mae: 0.0889\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0141 - val_mae: 0.0927\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0141 - val_mae: 0.0950\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0541 - val_loss: 0.0141 - val_mae: 0.0932\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0142 - val_mae: 0.0893\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0864\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0144 - val_mae: 0.0863\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0535 - val_loss: 0.0142 - val_mae: 0.0888\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0517 - val_loss: 0.0141 - val_mae: 0.0934\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0140 - val_mae: 0.0963\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0140 - val_mae: 0.0966\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0140 - val_mae: 0.0965\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - mae: 0.0537 - val_loss: 0.0140 - val_mae: 0.0939\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0140 - val_mae: 0.0911\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0510 - val_loss: 0.0140 - val_mae: 0.0900\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0479 - val_loss: 0.0139 - val_mae: 0.0918\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0138 - val_mae: 0.0944\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0511 - val_loss: 0.0138 - val_mae: 0.0966\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0498 - val_loss: 0.0138 - val_mae: 0.0989\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0138 - val_mae: 0.0978\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0138 - val_mae: 0.0963\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0506 - val_loss: 0.0139 - val_mae: 0.0936\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0139 - val_mae: 0.0926\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0138 - val_mae: 0.0950\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0477 - val_loss: 0.0138 - val_mae: 0.0992\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0138 - val_mae: 0.1036\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0138 - val_mae: 0.1023\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0530 - val_loss: 0.0138 - val_mae: 0.0958\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0140 - val_mae: 0.0929\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0140 - val_mae: 0.0970\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0140 - val_mae: 0.1019\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0141 - val_mae: 0.0984\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0141 - val_mae: 0.0977\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0478 - val_loss: 0.0141 - val_mae: 0.0993\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0140 - val_mae: 0.0997\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0139 - val_mae: 0.0995\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0139 - val_mae: 0.0984\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0138 - val_mae: 0.1006\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0137 - val_mae: 0.0992\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0455 - val_loss: 0.0137 - val_mae: 0.0967\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0137 - val_mae: 0.0948\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - mae: 0.0422 - val_loss: 0.0138 - val_mae: 0.0931\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0472 - val_loss: 0.0137 - val_mae: 0.0951\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0137 - val_mae: 0.1000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0138 - val_mae: 0.1028\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0139 - val_mae: 0.1061\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0138 - val_mae: 0.1024\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - mae: 0.0490 - val_loss: 0.0137 - val_mae: 0.0981\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0137 - val_mae: 0.0960\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0137 - val_mae: 0.0956\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0464 - val_loss: 0.0137 - val_mae: 0.0988\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0138 - val_mae: 0.1025\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0138 - val_mae: 0.1009\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0467 - val_loss: 0.0139 - val_mae: 0.0976\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0139 - val_mae: 0.0966\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0140 - val_mae: 0.0973\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0141 - val_mae: 0.0975\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0141 - val_mae: 0.1001\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0142 - val_mae: 0.1041\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0142 - val_mae: 0.1070\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0141 - val_mae: 0.1030\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0141 - val_mae: 0.1003\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0017 - mae: 0.0435 - val_loss: 0.0140 - val_mae: 0.0963\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0139 - val_mae: 0.0952\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0138 - val_mae: 0.0962\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0138 - val_mae: 0.0991\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0137 - val_mae: 0.1020\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0137 - val_mae: 0.1051\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0502 - val_loss: 0.0136 - val_mae: 0.0982\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0137 - val_mae: 0.0926\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0139 - val_mae: 0.0923\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0442 - val_loss: 0.0139 - val_mae: 0.0953\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0420 - val_loss: 0.0139 - val_mae: 0.0999\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0140 - val_mae: 0.1031\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0140 - val_mae: 0.1028\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0447 - val_loss: 0.0139 - val_mae: 0.1003\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - mae: 0.0429 - val_loss: 0.0140 - val_mae: 0.0940\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0141 - val_mae: 0.0889\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0428 - val_loss: 0.0142 - val_mae: 0.0872\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0141 - val_mae: 0.0888\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0425 - val_loss: 0.0139 - val_mae: 0.0933\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0139 - val_mae: 0.0992\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0140 - val_mae: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:59,316] Trial 24 finished with value: 0.10374455153942108 and parameters: {'learning_rate': 0.0006066225916548129, 'weight_decay': 1.5656201579880057e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    }
   ],
   "source": [
    "cnn_study = create_study(model_fun=cnn_model,\n",
    "                         train=train_df,\n",
    "                         val=val_df)\n",
    "lstm_study = create_study(model_fun=lstm_model,\n",
    "                          train=train_df,\n",
    "                          val=val_df)\n",
    "stacked_study = create_study(model_fun=lstm_cnn_model,\n",
    "                             train=train_df,\n",
    "                             val=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.08045151829719543\n",
      "\n",
      "LSTM Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07435319572687149\n",
      "\n",
      "LSTM-CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07514270395040512\n"
     ]
    }
   ],
   "source": [
    "print('CNN Study Results')\n",
    "cnn_params = get_optimized_parameters(cnn_study)\n",
    "print('\\nLSTM Study Results')\n",
    "lstm_params = get_optimized_parameters(lstm_study)\n",
    "print('\\nLSTM-CNN Study Results')\n",
    "stacked_params = get_optimized_parameters(stacked_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = dict()\n",
    "path = './src/rv_sentiment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Compile Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            1984      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               123008    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140440 (548.59 KB)\n",
      "Trainable params: 140440 (548.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_model(cnn_params['learning_rate'], cnn_params['weight_decay'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 72, 72)            22464     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55064 (215.09 KB)\n",
      "Trainable params: 55064 (215.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(lstm_params['learning_rate'], lstm_params['weight_decay'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            1984      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 72)            39456     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86392 (337.47 KB)\n",
      "Trainable params: 86392 (337.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked = lstm_cnn_model(stacked_params['learning_rate'], stacked_params['weight_decay'])\n",
    "stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0425 - mae: 0.2344 - val_loss: 0.0963 - val_mae: 0.3516\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1006 - mae: 0.3538 - val_loss: 0.0219 - val_mae: 0.1157\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1148 - val_loss: 0.0213 - val_mae: 0.0946\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0873 - val_loss: 0.0207 - val_mae: 0.0857\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0062 - mae: 0.0762 - val_loss: 0.0186 - val_mae: 0.0804\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0800 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0185 - val_mae: 0.0763\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0185 - val_mae: 0.0773\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0179 - val_mae: 0.0794\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0876\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0710 - val_loss: 0.0171 - val_mae: 0.0877\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - mae: 0.0710 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0533 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0537 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0863\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0164 - val_mae: 0.0887\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0164 - val_mae: 0.0819\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0530 - val_loss: 0.0162 - val_mae: 0.0820\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0161 - val_mae: 0.0830\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0588 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - mae: 0.0519 - val_loss: 0.0165 - val_mae: 0.0847\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0022 - mae: 0.0477 - val_loss: 0.0164 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0403 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0432 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0477 - val_loss: 0.0164 - val_mae: 0.0831\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0412 - val_loss: 0.0165 - val_mae: 0.0849\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0411 - val_loss: 0.0166 - val_mae: 0.0863\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0018 - mae: 0.0398 - val_loss: 0.0160 - val_mae: 0.0808\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0160 - val_mae: 0.0794\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0516 - val_loss: 0.0164 - val_mae: 0.0830\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0166 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0400 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0164 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0163 - val_mae: 0.0869\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0414 - val_loss: 0.0161 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0447 - val_loss: 0.0155 - val_mae: 0.0836\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0480 - val_loss: 0.0154 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0154 - val_mae: 0.0832\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0433 - val_loss: 0.0160 - val_mae: 0.0840\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0162 - val_mae: 0.0847\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - mae: 0.0518 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0426 - val_loss: 0.0162 - val_mae: 0.0821\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0160 - val_mae: 0.0790\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0161 - val_mae: 0.0784\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0441 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - mae: 0.0450 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0164 - val_mae: 0.0856\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0162 - val_mae: 0.0823\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0162 - val_mae: 0.0822\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0164 - val_mae: 0.0835\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - mae: 0.0396 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0398 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0489 - val_loss: 0.0168 - val_mae: 0.0872\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0464 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0162 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0457 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0502 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0159 - val_mae: 0.0832\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0164 - val_mae: 0.0861\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0164 - val_mae: 0.0871\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0164 - val_mae: 0.0866\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0412 - val_loss: 0.0157 - val_mae: 0.0830\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0470 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0408 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0384 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - mae: 0.0488 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0161 - val_mae: 0.0836\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0157 - val_mae: 0.0810\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0819\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0158 - val_mae: 0.0820\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - mae: 0.0404 - val_loss: 0.0163 - val_mae: 0.0843\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0164 - val_mae: 0.0846\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0029 - mae: 0.0501 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0162 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - mae: 0.0425 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0156 - val_mae: 0.0787\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - mae: 0.0416 - val_loss: 0.0159 - val_mae: 0.0866\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0161 - val_mae: 0.0880\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.0886\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0162 - val_mae: 0.0878\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0160 - val_mae: 0.0866\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0158 - val_mae: 0.0849\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0155 - val_mae: 0.0828\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0508 - val_loss: 0.0162 - val_mae: 0.0843\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - mae: 0.0513 - val_loss: 0.0164 - val_mae: 0.0852\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0424 - val_loss: 0.0163 - val_mae: 0.0849\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - mae: 0.0426 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0394 - val_loss: 0.0153 - val_mae: 0.0799\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0151 - val_mae: 0.0792\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0150 - val_mae: 0.0810\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0487 - val_loss: 0.0158 - val_mae: 0.0855\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0466 - val_loss: 0.0163 - val_mae: 0.0880\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0164 - val_mae: 0.0887\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0165 - val_mae: 0.0883\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0163 - val_mae: 0.0865\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0496 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - mae: 0.0377 - val_loss: 0.0155 - val_mae: 0.0804\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0352 - val_loss: 0.0156 - val_mae: 0.0787\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0412 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0418 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0397 - val_loss: 0.0163 - val_mae: 0.0820\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0442 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - mae: 0.0410 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0164 - val_mae: 0.0843\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0159 - val_mae: 0.0846\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0453 - val_loss: 0.0156 - val_mae: 0.0852\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0155 - val_mae: 0.0848\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "--- Training LSTM ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0979 - mae: 0.3572 - val_loss: 0.0512 - val_mae: 0.2330\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0619 - mae: 0.2805 - val_loss: 0.0380 - val_mae: 0.1892\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0546 - mae: 0.2650 - val_loss: 0.0294 - val_mae: 0.1569\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0401 - mae: 0.2240 - val_loss: 0.0244 - val_mae: 0.1370\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0334 - mae: 0.2042 - val_loss: 0.0217 - val_mae: 0.1249\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0289 - mae: 0.1864 - val_loss: 0.0205 - val_mae: 0.1167\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0231 - mae: 0.1781 - val_loss: 0.0198 - val_mae: 0.1122\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0249 - mae: 0.1724 - val_loss: 0.0194 - val_mae: 0.1111\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0195 - mae: 0.1563 - val_loss: 0.0190 - val_mae: 0.1099\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0194 - mae: 0.1545 - val_loss: 0.0187 - val_mae: 0.1078\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0171 - mae: 0.1483 - val_loss: 0.0185 - val_mae: 0.1051\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0179 - mae: 0.1453 - val_loss: 0.0184 - val_mae: 0.1021\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0178 - mae: 0.1474 - val_loss: 0.0184 - val_mae: 0.0991\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1329 - val_loss: 0.0184 - val_mae: 0.0971\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0113 - mae: 0.1181 - val_loss: 0.0184 - val_mae: 0.0959\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - mae: 0.1252 - val_loss: 0.0185 - val_mae: 0.0952\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1146 - val_loss: 0.0186 - val_mae: 0.0945\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0120 - mae: 0.1189 - val_loss: 0.0187 - val_mae: 0.0944\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0188 - val_mae: 0.0939\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0099 - mae: 0.1125 - val_loss: 0.0188 - val_mae: 0.0934\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0960 - val_loss: 0.0188 - val_mae: 0.0929\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1008 - val_loss: 0.0188 - val_mae: 0.0924\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0189 - val_mae: 0.0919\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0957 - val_loss: 0.0189 - val_mae: 0.0915\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - mae: 0.0871 - val_loss: 0.0188 - val_mae: 0.0908\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0916 - val_loss: 0.0187 - val_mae: 0.0903\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - mae: 0.0862 - val_loss: 0.0187 - val_mae: 0.0897\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - mae: 0.0888 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - mae: 0.0820 - val_loss: 0.0185 - val_mae: 0.0883\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - mae: 0.0862 - val_loss: 0.0184 - val_mae: 0.0876\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0803 - val_loss: 0.0183 - val_mae: 0.0870\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0757 - val_loss: 0.0182 - val_mae: 0.0865\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - mae: 0.0816 - val_loss: 0.0181 - val_mae: 0.0860\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0180 - val_mae: 0.0854\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0179 - val_mae: 0.0848\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - mae: 0.0742 - val_loss: 0.0179 - val_mae: 0.0845\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0178 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0718 - val_loss: 0.0177 - val_mae: 0.0842\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0768 - val_loss: 0.0176 - val_mae: 0.0840\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0763 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0175 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0049 - mae: 0.0742 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0750 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - mae: 0.0716 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0702 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0714 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0685 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0656 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0651 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0799\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0820\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0023 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0556 - val_loss: 0.0167 - val_mae: 0.0817\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0023 - mae: 0.0530 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0477 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0462 - val_loss: 0.0166 - val_mae: 0.0819\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0489 - val_loss: 0.0165 - val_mae: 0.0824\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0503 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0484 - val_loss: 0.0165 - val_mae: 0.0829\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - mae: 0.0480 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0473 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0019 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0471 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0164 - val_mae: 0.0827\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0475 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0164 - val_mae: 0.0823\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0456 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - mae: 0.0468 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0165 - val_mae: 0.0823\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0451 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0164 - val_mae: 0.0830\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0451 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0456 - val_loss: 0.0163 - val_mae: 0.0835\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0438 - val_loss: 0.0163 - val_mae: 0.0837\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0417 - val_loss: 0.0164 - val_mae: 0.0836\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0420 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0165 - val_mae: 0.0837\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0013 - mae: 0.0398 - val_loss: 0.0164 - val_mae: 0.0836\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0163 - val_mae: 0.0836\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0162 - val_mae: 0.0841\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0439 - val_loss: 0.0161 - val_mae: 0.0844\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0484 - val_loss: 0.0162 - val_mae: 0.0846\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0412 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0163 - val_mae: 0.0845\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0422 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0449 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "--- Training LSTM-CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0491 - mae: 0.2460 - val_loss: 0.0328 - val_mae: 0.1820\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0495 - mae: 0.2583 - val_loss: 0.0320 - val_mae: 0.1782\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0442 - mae: 0.2414 - val_loss: 0.0312 - val_mae: 0.1739\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0377 - mae: 0.2161 - val_loss: 0.0304 - val_mae: 0.1697\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0425 - mae: 0.2434 - val_loss: 0.0297 - val_mae: 0.1654\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0397 - mae: 0.2259 - val_loss: 0.0290 - val_mae: 0.1614\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0384 - mae: 0.2226 - val_loss: 0.0283 - val_mae: 0.1577\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0369 - mae: 0.2207 - val_loss: 0.0277 - val_mae: 0.1541\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0387 - mae: 0.2289 - val_loss: 0.0271 - val_mae: 0.1509\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0305 - mae: 0.2015 - val_loss: 0.0266 - val_mae: 0.1479\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0314 - mae: 0.2025 - val_loss: 0.0262 - val_mae: 0.1452\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0360 - mae: 0.2187 - val_loss: 0.0257 - val_mae: 0.1424\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0349 - mae: 0.2043 - val_loss: 0.0253 - val_mae: 0.1396\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0325 - mae: 0.2063 - val_loss: 0.0250 - val_mae: 0.1371\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0355 - mae: 0.2154 - val_loss: 0.0246 - val_mae: 0.1346\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0243 - mae: 0.1724 - val_loss: 0.0243 - val_mae: 0.1321\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0257 - mae: 0.1845 - val_loss: 0.0240 - val_mae: 0.1297\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0307 - mae: 0.1981 - val_loss: 0.0237 - val_mae: 0.1274\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0336 - mae: 0.2094 - val_loss: 0.0234 - val_mae: 0.1253\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0247 - mae: 0.1746 - val_loss: 0.0231 - val_mae: 0.1234\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0241 - mae: 0.1792 - val_loss: 0.0229 - val_mae: 0.1216\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0280 - mae: 0.1898 - val_loss: 0.0227 - val_mae: 0.1199\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0271 - mae: 0.1901 - val_loss: 0.0225 - val_mae: 0.1181\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0258 - mae: 0.1797 - val_loss: 0.0222 - val_mae: 0.1164\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0268 - mae: 0.1827 - val_loss: 0.0221 - val_mae: 0.1148\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0224 - mae: 0.1732 - val_loss: 0.0219 - val_mae: 0.1132\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0238 - mae: 0.1734 - val_loss: 0.0217 - val_mae: 0.1117\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0270 - mae: 0.1809 - val_loss: 0.0214 - val_mae: 0.1100\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0219 - mae: 0.1704 - val_loss: 0.0212 - val_mae: 0.1084\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0212 - mae: 0.1626 - val_loss: 0.0210 - val_mae: 0.1069\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0253 - mae: 0.1768 - val_loss: 0.0208 - val_mae: 0.1055\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0219 - mae: 0.1681 - val_loss: 0.0206 - val_mae: 0.1041\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0221 - mae: 0.1683 - val_loss: 0.0204 - val_mae: 0.1027\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0224 - mae: 0.1740 - val_loss: 0.0202 - val_mae: 0.1015\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0171 - mae: 0.1451 - val_loss: 0.0200 - val_mae: 0.1003\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0221 - mae: 0.1633 - val_loss: 0.0199 - val_mae: 0.0993\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0165 - mae: 0.1462 - val_loss: 0.0197 - val_mae: 0.0984\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1679 - val_loss: 0.0196 - val_mae: 0.0977\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0189 - mae: 0.1568 - val_loss: 0.0195 - val_mae: 0.0971\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0203 - mae: 0.1591 - val_loss: 0.0194 - val_mae: 0.0964\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0159 - mae: 0.1392 - val_loss: 0.0192 - val_mae: 0.0958\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0186 - mae: 0.1517 - val_loss: 0.0191 - val_mae: 0.0952\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0195 - mae: 0.1556 - val_loss: 0.0191 - val_mae: 0.0946\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - mae: 0.1552 - val_loss: 0.0190 - val_mae: 0.0941\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0186 - mae: 0.1480 - val_loss: 0.0189 - val_mae: 0.0936\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0184 - mae: 0.1527 - val_loss: 0.0189 - val_mae: 0.0931\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0163 - mae: 0.1425 - val_loss: 0.0188 - val_mae: 0.0925\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0171 - mae: 0.1484 - val_loss: 0.0187 - val_mae: 0.0920\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0219 - mae: 0.1657 - val_loss: 0.0186 - val_mae: 0.0916\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1409 - val_loss: 0.0186 - val_mae: 0.0912\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0157 - mae: 0.1393 - val_loss: 0.0185 - val_mae: 0.0909\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mae: 0.1516 - val_loss: 0.0185 - val_mae: 0.0906\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0177 - mae: 0.1543 - val_loss: 0.0184 - val_mae: 0.0903\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0174 - mae: 0.1486 - val_loss: 0.0184 - val_mae: 0.0900\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0142 - mae: 0.1362 - val_loss: 0.0183 - val_mae: 0.0898\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0184 - mae: 0.1494 - val_loss: 0.0183 - val_mae: 0.0896\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0141 - mae: 0.1352 - val_loss: 0.0182 - val_mae: 0.0895\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0153 - mae: 0.1381 - val_loss: 0.0182 - val_mae: 0.0894\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0171 - mae: 0.1445 - val_loss: 0.0182 - val_mae: 0.0893\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0158 - mae: 0.1410 - val_loss: 0.0181 - val_mae: 0.0893\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0184 - mae: 0.1498 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0148 - mae: 0.1356 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0148 - mae: 0.1360 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - mae: 0.1381 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0144 - mae: 0.1344 - val_loss: 0.0181 - val_mae: 0.0894\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0135 - mae: 0.1329 - val_loss: 0.0181 - val_mae: 0.0895\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0131 - mae: 0.1300 - val_loss: 0.0181 - val_mae: 0.0897\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0144 - mae: 0.1330 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0165 - mae: 0.1481 - val_loss: 0.0182 - val_mae: 0.0903\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - mae: 0.1475 - val_loss: 0.0182 - val_mae: 0.0905\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0139 - mae: 0.1257 - val_loss: 0.0183 - val_mae: 0.0907\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0136 - mae: 0.1309 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0140 - mae: 0.1346 - val_loss: 0.0183 - val_mae: 0.0910\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0121 - mae: 0.1260 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0139 - mae: 0.1328 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0142 - mae: 0.1345 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0136 - mae: 0.1291 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0125 - mae: 0.1258 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0136 - mae: 0.1325 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0117 - mae: 0.1238 - val_loss: 0.0182 - val_mae: 0.0911\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0125 - mae: 0.1242 - val_loss: 0.0182 - val_mae: 0.0910\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0146 - mae: 0.1356 - val_loss: 0.0182 - val_mae: 0.0908\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0134 - mae: 0.1302 - val_loss: 0.0181 - val_mae: 0.0906\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0129 - mae: 0.1269 - val_loss: 0.0181 - val_mae: 0.0905\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0181 - val_mae: 0.0904\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0108 - mae: 0.1206 - val_loss: 0.0181 - val_mae: 0.0903\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0181 - val_mae: 0.0902\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0131 - mae: 0.1257 - val_loss: 0.0180 - val_mae: 0.0900\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0121 - mae: 0.1250 - val_loss: 0.0180 - val_mae: 0.0898\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0112 - mae: 0.1195 - val_loss: 0.0180 - val_mae: 0.0897\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0132 - mae: 0.1316 - val_loss: 0.0180 - val_mae: 0.0896\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0180 - val_mae: 0.0895\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0180 - val_mae: 0.0894\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0124 - mae: 0.1213 - val_loss: 0.0179 - val_mae: 0.0893\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0123 - mae: 0.1246 - val_loss: 0.0179 - val_mae: 0.0891\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0179 - val_mae: 0.0889\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0179 - val_mae: 0.0887\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0124 - mae: 0.1230 - val_loss: 0.0179 - val_mae: 0.0885\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0123 - mae: 0.1248 - val_loss: 0.0179 - val_mae: 0.0884\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1199 - val_loss: 0.0179 - val_mae: 0.0883\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0124 - mae: 0.1251 - val_loss: 0.0179 - val_mae: 0.0881\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1177 - val_loss: 0.0179 - val_mae: 0.0879\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0095 - mae: 0.1093 - val_loss: 0.0179 - val_mae: 0.0877\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1180 - val_loss: 0.0180 - val_mae: 0.0876\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0092 - mae: 0.1104 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0180 - val_mae: 0.0874\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1195 - val_loss: 0.0180 - val_mae: 0.0873\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0180 - val_mae: 0.0873\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0107 - mae: 0.1151 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0115 - mae: 0.1199 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1152 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1149 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1097 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1067 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0106 - mae: 0.1133 - val_loss: 0.0180 - val_mae: 0.0870\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0179 - val_mae: 0.0869\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1201 - val_loss: 0.0179 - val_mae: 0.0868\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0088 - mae: 0.1062 - val_loss: 0.0179 - val_mae: 0.0866\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0179 - val_mae: 0.0865\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0102 - mae: 0.1124 - val_loss: 0.0178 - val_mae: 0.0865\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0090 - mae: 0.1063 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0091 - mae: 0.1071 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0178 - val_mae: 0.0863\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0177 - val_mae: 0.0861\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0176 - val_mae: 0.0860\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0082 - mae: 0.1018 - val_loss: 0.0176 - val_mae: 0.0859\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1021 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0082 - mae: 0.1031 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0074 - mae: 0.0992 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1056 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0102 - mae: 0.1132 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0076 - mae: 0.0953 - val_loss: 0.0175 - val_mae: 0.0855\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1079 - val_loss: 0.0175 - val_mae: 0.0854\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1035 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0080 - mae: 0.0985 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0933 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0089 - mae: 0.1076 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0084 - mae: 0.0998 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0980 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0080 - mae: 0.0982 - val_loss: 0.0173 - val_mae: 0.0849\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0979 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - mae: 0.0956 - val_loss: 0.0173 - val_mae: 0.0847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--- Training CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=cnn_params)\n",
    "print('--- Training LSTM ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=lstm_params)\n",
    "print('--- Training LSTM-CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM-CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=stacked_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Training/Validation Results\n",
    "\n",
    "Loss curves across the models are fairly stable. All models show a decreasing validation curve with different epoch thresholds for when the model stops learning against the validation set. The LSTM appears to begin to have the slowest learning curve, while the CNN takes around 20 epochs to reach a loss close to 0. Some options to help improve this are to introduce learning rate decline, or train on longer input sequences.\n",
    "\n",
    "Plots of the MAE show a similar pattern to the loss plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = list()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "\n",
    "def plot_graphs(metric, val, ax, upper):\n",
    "    ax.plot(val['history'].history[metric])\n",
    "    ax.plot(val['history'].history[f'val_{metric}'])\n",
    "    ax.set_title(key)\n",
    "    ax.legend([metric, f\"val_{metric}\"])\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim([0, upper])\n",
    "    \n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    \n",
    "    plot_graphs('loss', val, ax, 0.05)\n",
    "print(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MAE Curves\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs('mae', val, ax, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Test Results\n",
    "It's surprising to see how well a CNN did. LSTM would be expected to perform well because of its ability to learn and remember longer trends in the data.\n",
    "\n",
    "Putting the models' performance in perspective however the results show how with a limited lookback window, and simple features a lstm, and a cnn stacked with an lstm are a good starting choice for architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0034 - mae: 0.0749\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0038 - mae: 0.0758\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - mae: 0.0640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.074863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.075830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM-CNN</th>\n",
       "      <td>0.063964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae\n",
       "CNN       0.074863\n",
       "LSTM      0.075830\n",
       "LSTM-CNN  0.063964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list()\n",
    "performance = list()\n",
    "\n",
    "for key, value in model_configs.items():\n",
    "    names.append(key)\n",
    "    mae = value['model'].evaluate(value['test_ds'])\n",
    "    performance.append(mae[1])\n",
    "    \n",
    "performance_df = pd.DataFrame(performance, index=names, columns=['mae'])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions\n",
    "\n",
    "Plot the actual and predicted 24 hour intervals. Below is the first 14 days of predictions. Interesting to note how the LSTM appears to oscilate over a longer frequency compared with the other models. The CNN also seems to capture the intra day oscillations (within the 24 hour period). Looking at the CNN stacked LSTM we can see how these two characteristics of the model's learning combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(18, 10))\n",
    "days = 5\n",
    "\n",
    "vline = np.linspace(0, days*24, days+1)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "\n",
    "    test = val['test_ds']\n",
    "    preds = val['model'].predict(test)\n",
    "\n",
    "    xbatch, ybatch = iter(test).get_next()\n",
    "\n",
    "    ax.plot(ybatch.numpy()[:days].reshape(-1))\n",
    "    ax.plot(preds[:days].reshape(-1))\n",
    "    ax.set_title(key)\n",
    "    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "    ax.legend([\"Actual RV\", \"Predicted RV\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
