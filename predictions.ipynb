{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 13:54:36.165624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from handler import build_dataset\n",
    "from models import cnn_model, lstm_model, lstm_cnn_model, run_model\n",
    "from tuning import create_study, get_optimized_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "N_STEPS = 72\n",
    "N_HORIZON = 24\n",
    "N_FEATURES = 2\n",
    "train_df, val_df, test_df = build_dataset(path='./src/rv_sentiment.csv', n_steps=N_STEPS, n_horizon=N_HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:295: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2023-12-05 13:54:39,399] A new study created in RDB with name: no-name-5c8b25c3-8cc1-4586-8bc7-f50e207e5cef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0325 - mae: 0.2079 - val_loss: 0.0189 - val_mae: 0.1108\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0144 - mae: 0.1353 - val_loss: 0.0189 - val_mae: 0.1123\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0133 - mae: 0.1257 - val_loss: 0.0189 - val_mae: 0.1036\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0092 - mae: 0.1062 - val_loss: 0.0191 - val_mae: 0.0952\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0946 - val_loss: 0.0194 - val_mae: 0.0897\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0870 - val_loss: 0.0196 - val_mae: 0.0862\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - mae: 0.0807 - val_loss: 0.0197 - val_mae: 0.0851\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0059 - mae: 0.0761 - val_loss: 0.0197 - val_mae: 0.0838\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - mae: 0.0742 - val_loss: 0.0194 - val_mae: 0.0824\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0190 - val_mae: 0.0814\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0050 - mae: 0.0684 - val_loss: 0.0186 - val_mae: 0.0810\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0658 - val_loss: 0.0181 - val_mae: 0.0818\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - mae: 0.0685 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0663 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0809\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0168 - val_mae: 0.0824\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0814\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0165 - val_mae: 0.0848\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0163 - val_mae: 0.0865\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0163 - val_mae: 0.0857\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0164 - val_mae: 0.0822\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0772\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0515 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0533 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0164 - val_mae: 0.0812\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0162 - val_mae: 0.0850\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0620 - val_loss: 0.0162 - val_mae: 0.0851\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0583 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0166 - val_mae: 0.0796\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0028 - mae: 0.0515 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0167 - val_mae: 0.0806\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0166 - val_mae: 0.0824\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0165 - val_mae: 0.0832\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0819\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0168 - val_mae: 0.0812\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0797\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0502 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0514 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0511 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0490 - val_loss: 0.0167 - val_mae: 0.0807\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0471 - val_loss: 0.0167 - val_mae: 0.0805\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0023 - mae: 0.0470 - val_loss: 0.0166 - val_mae: 0.0810\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0164 - val_mae: 0.0822\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0019 - mae: 0.0434 - val_loss: 0.0164 - val_mae: 0.0815\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0164 - val_mae: 0.0817\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0165 - val_mae: 0.0815\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0166 - val_mae: 0.0812\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0166 - val_mae: 0.0821\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0430 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0433 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0165 - val_mae: 0.0838\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 0.0164 - val_mae: 0.0835\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0164 - val_mae: 0.0823\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0163 - val_mae: 0.0825\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - mae: 0.0428 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0429 - val_loss: 0.0165 - val_mae: 0.0814\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0447 - val_loss: 0.0167 - val_mae: 0.0805\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0403 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0407 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0428 - val_loss: 0.0164 - val_mae: 0.0849\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - mae: 0.0351 - val_loss: 0.0164 - val_mae: 0.0843\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0420 - val_loss: 0.0166 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.0166 - val_mae: 0.0790\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0362 - val_loss: 0.0164 - val_mae: 0.0813\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0162 - val_mae: 0.0835\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0163 - val_mae: 0.0864\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.8902e-04 - mae: 0.0350 - val_loss: 0.0164 - val_mae: 0.0834\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0340 - val_loss: 0.0165 - val_mae: 0.0819\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5912e-04 - mae: 0.0334 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0163 - val_mae: 0.0810\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9475e-04 - mae: 0.0326 - val_loss: 0.0162 - val_mae: 0.0814\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.8328e-04 - mae: 0.0316 - val_loss: 0.0161 - val_mae: 0.0828\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.3456e-04 - mae: 0.0335 - val_loss: 0.0161 - val_mae: 0.0831\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.5392e-04 - mae: 0.0308 - val_loss: 0.0161 - val_mae: 0.0855\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0162 - val_mae: 0.0852\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0385 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9418e-04 - mae: 0.0352 - val_loss: 0.0170 - val_mae: 0.0797\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7409e-04 - mae: 0.0288 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.7811e-04 - mae: 0.0337 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8069e-04 - mae: 0.0308 - val_loss: 0.0167 - val_mae: 0.0885\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.9671e-04 - mae: 0.0326 - val_loss: 0.0167 - val_mae: 0.0931\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0392 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.9093e-04 - mae: 0.0324 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9427e-04 - mae: 0.0306 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.7147e-04 - mae: 0.0335 - val_loss: 0.0168 - val_mae: 0.0776\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0164 - val_mae: 0.0816\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.7235e-04 - mae: 0.0306 - val_loss: 0.0161 - val_mae: 0.0872\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.7223e-04 - mae: 0.0349 - val_loss: 0.0160 - val_mae: 0.0906\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0378 - val_loss: 0.0159 - val_mae: 0.0873\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.9634e-04 - mae: 0.0332 - val_loss: 0.0160 - val_mae: 0.0810\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.2482e-04 - mae: 0.0328 - val_loss: 0.0162 - val_mae: 0.0781\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.2734e-04 - mae: 0.0296 - val_loss: 0.0164 - val_mae: 0.0779\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6831e-04 - mae: 0.0305 - val_loss: 0.0165 - val_mae: 0.0787\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.4139e-04 - mae: 0.0316 - val_loss: 0.0164 - val_mae: 0.0804\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1637e-04 - mae: 0.0316 - val_loss: 0.0162 - val_mae: 0.0839\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8894e-04 - mae: 0.0315 - val_loss: 0.0162 - val_mae: 0.0892\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.7412e-04 - mae: 0.0313 - val_loss: 0.0163 - val_mae: 0.0916\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - mae: 0.0354 - val_loss: 0.0165 - val_mae: 0.0866\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 8.5977e-04 - mae: 0.0324 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9163e-04 - mae: 0.0305 - val_loss: 0.0170 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mae: 0.0326 - val_loss: 0.0170 - val_mae: 0.0798\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7603e-04 - mae: 0.0314 - val_loss: 0.0167 - val_mae: 0.0811\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.1895e-04 - mae: 0.0287 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.5857e-04 - mae: 0.0294 - val_loss: 0.0165 - val_mae: 0.0870\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.9614e-04 - mae: 0.0289 - val_loss: 0.0164 - val_mae: 0.0900\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8066e-04 - mae: 0.0332 - val_loss: 0.0163 - val_mae: 0.0877\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.4571e-04 - mae: 0.0322 - val_loss: 0.0163 - val_mae: 0.0802\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0317 - val_loss: 0.0162 - val_mae: 0.0782\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.0226e-04 - mae: 0.0262 - val_loss: 0.0162 - val_mae: 0.0781\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2142e-04 - mae: 0.0266 - val_loss: 0.0161 - val_mae: 0.0789\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.8313e-04 - mae: 0.0305 - val_loss: 0.0160 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.2149e-04 - mae: 0.0307 - val_loss: 0.0160 - val_mae: 0.0841\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.0087e-04 - mae: 0.0254 - val_loss: 0.0161 - val_mae: 0.0855\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.4959e-04 - mae: 0.0274 - val_loss: 0.0162 - val_mae: 0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:54:50,833] Trial 0 finished with value: 0.08522693067789078 and parameters: {'learning_rate': 0.0012621137363312872, 'weight_decay': 0.0021441046263193}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0139 - mae: 0.1332 - val_loss: 0.0251 - val_mae: 0.1363\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0148 - mae: 0.1332 - val_loss: 0.0250 - val_mae: 0.1362\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0159 - mae: 0.1390 - val_loss: 0.0250 - val_mae: 0.1361\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0172 - mae: 0.1461 - val_loss: 0.0250 - val_mae: 0.1359\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0150 - mae: 0.1369 - val_loss: 0.0250 - val_mae: 0.1358\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0153 - mae: 0.1396 - val_loss: 0.0250 - val_mae: 0.1357\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0162 - mae: 0.1388 - val_loss: 0.0250 - val_mae: 0.1356\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1407 - val_loss: 0.0249 - val_mae: 0.1354\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1498 - val_loss: 0.0249 - val_mae: 0.1353\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0157 - mae: 0.1419 - val_loss: 0.0249 - val_mae: 0.1352\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1253 - val_loss: 0.0249 - val_mae: 0.1351\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0126 - mae: 0.1323 - val_loss: 0.0249 - val_mae: 0.1349\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0169 - mae: 0.1486 - val_loss: 0.0248 - val_mae: 0.1348\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - mae: 0.1315 - val_loss: 0.0248 - val_mae: 0.1347\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0151 - mae: 0.1345 - val_loss: 0.0248 - val_mae: 0.1345\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0152 - mae: 0.1374 - val_loss: 0.0248 - val_mae: 0.1344\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0165 - mae: 0.1456 - val_loss: 0.0248 - val_mae: 0.1343\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0173 - mae: 0.1528 - val_loss: 0.0247 - val_mae: 0.1342\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0167 - mae: 0.1472 - val_loss: 0.0247 - val_mae: 0.1340\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0148 - mae: 0.1412 - val_loss: 0.0247 - val_mae: 0.1339\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0168 - mae: 0.1409 - val_loss: 0.0247 - val_mae: 0.1338\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0150 - mae: 0.1343 - val_loss: 0.0247 - val_mae: 0.1336\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0160 - mae: 0.1439 - val_loss: 0.0246 - val_mae: 0.1335\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0152 - mae: 0.1341 - val_loss: 0.0246 - val_mae: 0.1334\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0149 - mae: 0.1365 - val_loss: 0.0246 - val_mae: 0.1332\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0143 - mae: 0.1322 - val_loss: 0.0246 - val_mae: 0.1331\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0161 - mae: 0.1437 - val_loss: 0.0246 - val_mae: 0.1330\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0134 - mae: 0.1261 - val_loss: 0.0245 - val_mae: 0.1328\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0152 - mae: 0.1363 - val_loss: 0.0245 - val_mae: 0.1327\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0147 - mae: 0.1369 - val_loss: 0.0245 - val_mae: 0.1326\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0146 - mae: 0.1336 - val_loss: 0.0245 - val_mae: 0.1324\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0151 - mae: 0.1422 - val_loss: 0.0245 - val_mae: 0.1323\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0166 - mae: 0.1444 - val_loss: 0.0244 - val_mae: 0.1322\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0128 - mae: 0.1290 - val_loss: 0.0244 - val_mae: 0.1321\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0141 - mae: 0.1319 - val_loss: 0.0244 - val_mae: 0.1319\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0140 - mae: 0.1321 - val_loss: 0.0244 - val_mae: 0.1318\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0146 - mae: 0.1309 - val_loss: 0.0244 - val_mae: 0.1317\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0154 - mae: 0.1388 - val_loss: 0.0244 - val_mae: 0.1316\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0157 - mae: 0.1432 - val_loss: 0.0243 - val_mae: 0.1314\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1363 - val_loss: 0.0243 - val_mae: 0.1313\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0165 - mae: 0.1459 - val_loss: 0.0243 - val_mae: 0.1312\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0158 - mae: 0.1434 - val_loss: 0.0243 - val_mae: 0.1311\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141 - mae: 0.1320 - val_loss: 0.0243 - val_mae: 0.1309\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0144 - mae: 0.1256 - val_loss: 0.0242 - val_mae: 0.1308\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1261 - val_loss: 0.0242 - val_mae: 0.1307\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0149 - mae: 0.1326 - val_loss: 0.0242 - val_mae: 0.1306\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0158 - mae: 0.1363 - val_loss: 0.0242 - val_mae: 0.1304\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0129 - mae: 0.1236 - val_loss: 0.0242 - val_mae: 0.1303\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0163 - mae: 0.1438 - val_loss: 0.0242 - val_mae: 0.1302\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0140 - mae: 0.1310 - val_loss: 0.0241 - val_mae: 0.1301\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0133 - mae: 0.1288 - val_loss: 0.0241 - val_mae: 0.1300\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0137 - mae: 0.1280 - val_loss: 0.0241 - val_mae: 0.1298\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0134 - mae: 0.1292 - val_loss: 0.0241 - val_mae: 0.1297\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0146 - mae: 0.1341 - val_loss: 0.0241 - val_mae: 0.1296\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0145 - mae: 0.1325 - val_loss: 0.0241 - val_mae: 0.1295\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0157 - mae: 0.1409 - val_loss: 0.0240 - val_mae: 0.1294\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0147 - mae: 0.1401 - val_loss: 0.0240 - val_mae: 0.1292\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0150 - mae: 0.1361 - val_loss: 0.0240 - val_mae: 0.1291\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0143 - mae: 0.1359 - val_loss: 0.0240 - val_mae: 0.1290\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0141 - mae: 0.1298 - val_loss: 0.0240 - val_mae: 0.1289\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0135 - mae: 0.1315 - val_loss: 0.0239 - val_mae: 0.1288\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1360 - val_loss: 0.0239 - val_mae: 0.1287\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0156 - mae: 0.1405 - val_loss: 0.0239 - val_mae: 0.1285\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - mae: 0.1407 - val_loss: 0.0239 - val_mae: 0.1284\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - mae: 0.1361 - val_loss: 0.0239 - val_mae: 0.1283\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - mae: 0.1233 - val_loss: 0.0239 - val_mae: 0.1282\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0160 - mae: 0.1410 - val_loss: 0.0238 - val_mae: 0.1281\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1286 - val_loss: 0.0238 - val_mae: 0.1279\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0116 - mae: 0.1218 - val_loss: 0.0238 - val_mae: 0.1278\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0131 - mae: 0.1266 - val_loss: 0.0238 - val_mae: 0.1277\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0127 - mae: 0.1257 - val_loss: 0.0238 - val_mae: 0.1276\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0133 - mae: 0.1306 - val_loss: 0.0238 - val_mae: 0.1275\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0133 - mae: 0.1244 - val_loss: 0.0237 - val_mae: 0.1274\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0148 - mae: 0.1354 - val_loss: 0.0237 - val_mae: 0.1272\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - mae: 0.1358 - val_loss: 0.0237 - val_mae: 0.1271\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0140 - mae: 0.1319 - val_loss: 0.0237 - val_mae: 0.1270\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0144 - mae: 0.1394 - val_loss: 0.0237 - val_mae: 0.1269\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1203 - val_loss: 0.0237 - val_mae: 0.1268\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141 - mae: 0.1312 - val_loss: 0.0236 - val_mae: 0.1266\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0156 - mae: 0.1426 - val_loss: 0.0236 - val_mae: 0.1265\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0122 - mae: 0.1258 - val_loss: 0.0236 - val_mae: 0.1264\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0153 - mae: 0.1400 - val_loss: 0.0236 - val_mae: 0.1263\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0140 - mae: 0.1270 - val_loss: 0.0236 - val_mae: 0.1262\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1242 - val_loss: 0.0236 - val_mae: 0.1261\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0135 - mae: 0.1308 - val_loss: 0.0236 - val_mae: 0.1259\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1370 - val_loss: 0.0235 - val_mae: 0.1258\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0149 - mae: 0.1369 - val_loss: 0.0235 - val_mae: 0.1257\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0143 - mae: 0.1325 - val_loss: 0.0235 - val_mae: 0.1256\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0123 - mae: 0.1230 - val_loss: 0.0235 - val_mae: 0.1255\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0131 - mae: 0.1248 - val_loss: 0.0235 - val_mae: 0.1254\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0147 - mae: 0.1376 - val_loss: 0.0235 - val_mae: 0.1252\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0142 - mae: 0.1302 - val_loss: 0.0234 - val_mae: 0.1251\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0126 - mae: 0.1229 - val_loss: 0.0234 - val_mae: 0.1250\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0140 - mae: 0.1337 - val_loss: 0.0234 - val_mae: 0.1249\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0139 - mae: 0.1316 - val_loss: 0.0234 - val_mae: 0.1248\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0129 - mae: 0.1258 - val_loss: 0.0234 - val_mae: 0.1247\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0134 - mae: 0.1286 - val_loss: 0.0234 - val_mae: 0.1246\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0128 - mae: 0.1260 - val_loss: 0.0233 - val_mae: 0.1244\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1327 - val_loss: 0.0233 - val_mae: 0.1243\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0150 - mae: 0.1391 - val_loss: 0.0233 - val_mae: 0.1242\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0149 - mae: 0.1350 - val_loss: 0.0233 - val_mae: 0.1241\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0131 - mae: 0.1264 - val_loss: 0.0233 - val_mae: 0.1240\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0135 - mae: 0.1271 - val_loss: 0.0233 - val_mae: 0.1239\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0130 - mae: 0.1295 - val_loss: 0.0233 - val_mae: 0.1238\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1165 - val_loss: 0.0232 - val_mae: 0.1237\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0147 - mae: 0.1352 - val_loss: 0.0232 - val_mae: 0.1236\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0128 - mae: 0.1250 - val_loss: 0.0232 - val_mae: 0.1234\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0130 - mae: 0.1259 - val_loss: 0.0232 - val_mae: 0.1233\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0132 - mae: 0.1266 - val_loss: 0.0232 - val_mae: 0.1232\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0121 - mae: 0.1251 - val_loss: 0.0232 - val_mae: 0.1231\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1264 - val_loss: 0.0231 - val_mae: 0.1230\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0151 - mae: 0.1359 - val_loss: 0.0231 - val_mae: 0.1229\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0146 - mae: 0.1356 - val_loss: 0.0231 - val_mae: 0.1228\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1292 - val_loss: 0.0231 - val_mae: 0.1227\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0152 - mae: 0.1362 - val_loss: 0.0231 - val_mae: 0.1226\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0139 - mae: 0.1301 - val_loss: 0.0231 - val_mae: 0.1225\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0141 - mae: 0.1316 - val_loss: 0.0231 - val_mae: 0.1224\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0135 - mae: 0.1326 - val_loss: 0.0230 - val_mae: 0.1223\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0123 - mae: 0.1242 - val_loss: 0.0230 - val_mae: 0.1221\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1218 - val_loss: 0.0230 - val_mae: 0.1220\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0123 - mae: 0.1254 - val_loss: 0.0230 - val_mae: 0.1219\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - mae: 0.1291 - val_loss: 0.0230 - val_mae: 0.1218\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1319 - val_loss: 0.0230 - val_mae: 0.1217\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0148 - mae: 0.1384 - val_loss: 0.0230 - val_mae: 0.1216\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0125 - mae: 0.1230 - val_loss: 0.0229 - val_mae: 0.1215\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0150 - mae: 0.1321 - val_loss: 0.0229 - val_mae: 0.1214\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0132 - mae: 0.1284 - val_loss: 0.0229 - val_mae: 0.1212\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0118 - mae: 0.1229 - val_loss: 0.0229 - val_mae: 0.1211\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0117 - mae: 0.1190 - val_loss: 0.0229 - val_mae: 0.1210\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - mae: 0.1205 - val_loss: 0.0229 - val_mae: 0.1209\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1400 - val_loss: 0.0228 - val_mae: 0.1208\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0124 - mae: 0.1231 - val_loss: 0.0228 - val_mae: 0.1207\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0137 - mae: 0.1314 - val_loss: 0.0228 - val_mae: 0.1206\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0121 - mae: 0.1197 - val_loss: 0.0228 - val_mae: 0.1205\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0128 - mae: 0.1262 - val_loss: 0.0228 - val_mae: 0.1204\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0120 - mae: 0.1238 - val_loss: 0.0228 - val_mae: 0.1203\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0142 - mae: 0.1294 - val_loss: 0.0228 - val_mae: 0.1202\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - mae: 0.1296 - val_loss: 0.0227 - val_mae: 0.1200\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0129 - mae: 0.1300 - val_loss: 0.0227 - val_mae: 0.1199\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0128 - mae: 0.1280 - val_loss: 0.0227 - val_mae: 0.1198\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0130 - mae: 0.1298 - val_loss: 0.0227 - val_mae: 0.1197\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0120 - mae: 0.1236 - val_loss: 0.0227 - val_mae: 0.1196\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0120 - mae: 0.1227 - val_loss: 0.0227 - val_mae: 0.1195\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0117 - mae: 0.1167 - val_loss: 0.0227 - val_mae: 0.1194\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0134 - mae: 0.1265 - val_loss: 0.0227 - val_mae: 0.1193\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0138 - mae: 0.1343 - val_loss: 0.0226 - val_mae: 0.1192\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1185 - val_loss: 0.0226 - val_mae: 0.1191\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0144 - mae: 0.1340 - val_loss: 0.0226 - val_mae: 0.1190\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0134 - mae: 0.1313 - val_loss: 0.0226 - val_mae: 0.1189\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0128 - mae: 0.1251 - val_loss: 0.0226 - val_mae: 0.1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:01,516] Trial 1 finished with value: 0.11880970001220703 and parameters: {'learning_rate': 1.6200303767871414e-06, 'weight_decay': 0.005790892783214982}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0312 - mae: 0.1959 - val_loss: 0.0219 - val_mae: 0.1356\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1499 - val_loss: 0.0186 - val_mae: 0.1150\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0124 - mae: 0.1260 - val_loss: 0.0178 - val_mae: 0.1011\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.1016 - val_loss: 0.0187 - val_mae: 0.0949\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0958 - val_loss: 0.0196 - val_mae: 0.0884\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0810 - val_loss: 0.0202 - val_mae: 0.0873\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0839 - val_loss: 0.0204 - val_mae: 0.0862\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0200 - val_mae: 0.0825\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - mae: 0.0709 - val_loss: 0.0195 - val_mae: 0.0803\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0637 - val_loss: 0.0187 - val_mae: 0.0824\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0179 - val_mae: 0.0842\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0173 - val_mae: 0.0852\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0666 - val_loss: 0.0170 - val_mae: 0.0872\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0738 - val_loss: 0.0170 - val_mae: 0.0865\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0045 - mae: 0.0721 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0663 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0177 - val_mae: 0.0811\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0179 - val_mae: 0.0805\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0039 - mae: 0.0613 - val_loss: 0.0179 - val_mae: 0.0808\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0177 - val_mae: 0.0821\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0847\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0882\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0879\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0831\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0175 - val_mae: 0.0810\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0175 - val_mae: 0.0812\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0577 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0876\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0521 - val_loss: 0.0170 - val_mae: 0.0845\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0169 - val_mae: 0.0882\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0557 - val_loss: 0.0171 - val_mae: 0.0869\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0173 - val_mae: 0.0850\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0840\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0173 - val_mae: 0.0858\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0172 - val_mae: 0.0887\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0172 - val_mae: 0.0884\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - mae: 0.0464 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0445 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0440 - val_loss: 0.0171 - val_mae: 0.0882\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0171 - val_mae: 0.0907\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0171 - val_mae: 0.0917\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0172 - val_mae: 0.0903\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0173 - val_mae: 0.0880\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0448 - val_loss: 0.0173 - val_mae: 0.0871\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0173 - val_mae: 0.0877\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0173 - val_mae: 0.0900\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0172 - val_mae: 0.0914\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0457 - val_loss: 0.0172 - val_mae: 0.0915\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0173 - val_mae: 0.0913\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0174 - val_mae: 0.0910\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0175 - val_mae: 0.0910\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0440 - val_loss: 0.0176 - val_mae: 0.0895\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0177 - val_mae: 0.0890\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0177 - val_mae: 0.0896\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0414 - val_loss: 0.0176 - val_mae: 0.0939\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0175 - val_mae: 0.0972\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0175 - val_mae: 0.0965\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0400 - val_loss: 0.0176 - val_mae: 0.0940\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0381 - val_loss: 0.0177 - val_mae: 0.0891\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6875e-04 - mae: 0.0324 - val_loss: 0.0178 - val_mae: 0.0872\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0014 - mae: 0.0379 - val_loss: 0.0178 - val_mae: 0.0878\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0177 - val_mae: 0.0914\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0177 - val_mae: 0.0958\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0374 - val_loss: 0.0178 - val_mae: 0.0984\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0178 - val_mae: 0.0976\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.8976e-04 - mae: 0.0338 - val_loss: 0.0179 - val_mae: 0.0968\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0382 - val_loss: 0.0180 - val_mae: 0.0979\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0338 - val_loss: 0.0181 - val_mae: 0.0985\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0398 - val_loss: 0.0182 - val_mae: 0.0958\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0182 - val_mae: 0.0938\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0312 - val_loss: 0.0181 - val_mae: 0.0930\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0180 - val_mae: 0.0948\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0180 - val_mae: 0.0963\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.9451e-04 - mae: 0.0336 - val_loss: 0.0182 - val_mae: 0.0978\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6102e-04 - mae: 0.0325 - val_loss: 0.0183 - val_mae: 0.0971\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.1273e-04 - mae: 0.0321 - val_loss: 0.0184 - val_mae: 0.0949\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0906e-04 - mae: 0.0329 - val_loss: 0.0184 - val_mae: 0.0949\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0183 - val_mae: 0.0957\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9181e-04 - mae: 0.0310 - val_loss: 0.0182 - val_mae: 0.0961\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.8216e-04 - mae: 0.0308 - val_loss: 0.0182 - val_mae: 0.0964\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.5357e-04 - mae: 0.0291 - val_loss: 0.0183 - val_mae: 0.0986\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 7.7820e-04 - mae: 0.0299 - val_loss: 0.0184 - val_mae: 0.0992\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4876e-04 - mae: 0.0315 - val_loss: 0.0184 - val_mae: 0.0979\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9470e-04 - mae: 0.0296 - val_loss: 0.0185 - val_mae: 0.0980\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7252e-04 - mae: 0.0292 - val_loss: 0.0185 - val_mae: 0.0971\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.5349e-04 - mae: 0.0317 - val_loss: 0.0184 - val_mae: 0.0964\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5173e-04 - mae: 0.0289 - val_loss: 0.0183 - val_mae: 0.0968\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4895e-04 - mae: 0.0278 - val_loss: 0.0183 - val_mae: 0.0959\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.1226e-04 - mae: 0.0296 - val_loss: 0.0182 - val_mae: 0.0952\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.1686e-04 - mae: 0.0280 - val_loss: 0.0180 - val_mae: 0.0933\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.7223e-04 - mae: 0.0321 - val_loss: 0.0180 - val_mae: 0.0945\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 8.4699e-04 - mae: 0.0304 - val_loss: 0.0181 - val_mae: 0.0960\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6492e-04 - mae: 0.0331 - val_loss: 0.0183 - val_mae: 0.0964\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.5018e-04 - mae: 0.0315 - val_loss: 0.0186 - val_mae: 0.0984\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2859e-04 - mae: 0.0263 - val_loss: 0.0187 - val_mae: 0.1007\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.0622e-04 - mae: 0.0321 - val_loss: 0.0187 - val_mae: 0.1019\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.4205e-04 - mae: 0.0315 - val_loss: 0.0187 - val_mae: 0.1008\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7396e-04 - mae: 0.0296 - val_loss: 0.0188 - val_mae: 0.0967\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.2020e-04 - mae: 0.0296 - val_loss: 0.0188 - val_mae: 0.0957\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6739e-04 - mae: 0.0268 - val_loss: 0.0186 - val_mae: 0.0963\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1294e-04 - mae: 0.0291 - val_loss: 0.0185 - val_mae: 0.0973\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8921e-04 - mae: 0.0303 - val_loss: 0.0183 - val_mae: 0.0998\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2494e-04 - mae: 0.0296 - val_loss: 0.0183 - val_mae: 0.1005\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.6881e-04 - mae: 0.0308 - val_loss: 0.0183 - val_mae: 0.0976\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.9507e-04 - mae: 0.0266 - val_loss: 0.0184 - val_mae: 0.0954\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.0445e-04 - mae: 0.0254 - val_loss: 0.0185 - val_mae: 0.0943\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.1859e-04 - mae: 0.0248 - val_loss: 0.0186 - val_mae: 0.0942\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.2227e-04 - mae: 0.0306 - val_loss: 0.0187 - val_mae: 0.0953\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.9611e-04 - mae: 0.0304 - val_loss: 0.0186 - val_mae: 0.0982\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6587e-04 - mae: 0.0241 - val_loss: 0.0186 - val_mae: 0.1007\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3092e-04 - mae: 0.0284 - val_loss: 0.0185 - val_mae: 0.1014\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.0482e-04 - mae: 0.0265 - val_loss: 0.0183 - val_mae: 0.0990\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.1810e-04 - mae: 0.0219 - val_loss: 0.0181 - val_mae: 0.0960\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8866e-04 - mae: 0.0291 - val_loss: 0.0180 - val_mae: 0.0947\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2974e-04 - mae: 0.0247 - val_loss: 0.0182 - val_mae: 0.0958\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2549e-04 - mae: 0.0274 - val_loss: 0.0184 - val_mae: 0.0991\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1137e-04 - mae: 0.0250 - val_loss: 0.0187 - val_mae: 0.1021\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9669e-04 - mae: 0.0284 - val_loss: 0.0188 - val_mae: 0.1026\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8504e-04 - mae: 0.0306 - val_loss: 0.0187 - val_mae: 0.0985\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.8730e-04 - mae: 0.0259 - val_loss: 0.0185 - val_mae: 0.0951\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 4.3439e-04 - mae: 0.0225 - val_loss: 0.0184 - val_mae: 0.0916\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9812e-04 - mae: 0.0283 - val_loss: 0.0184 - val_mae: 0.0913\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.5615e-04 - mae: 0.0281 - val_loss: 0.0183 - val_mae: 0.0932\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.4965e-04 - mae: 0.0262 - val_loss: 0.0185 - val_mae: 0.0981\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.1158e-04 - mae: 0.0282 - val_loss: 0.0188 - val_mae: 0.1038\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.6589e-04 - mae: 0.0348 - val_loss: 0.0189 - val_mae: 0.1033\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2301e-04 - mae: 0.0276 - val_loss: 0.0188 - val_mae: 0.0999\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.4242e-04 - mae: 0.0250 - val_loss: 0.0187 - val_mae: 0.0982\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.2241e-04 - mae: 0.0266 - val_loss: 0.0187 - val_mae: 0.0976\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 4.9969e-04 - mae: 0.0249 - val_loss: 0.0186 - val_mae: 0.0964\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.8961e-04 - mae: 0.0252 - val_loss: 0.0185 - val_mae: 0.0955\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0187e-04 - mae: 0.0303 - val_loss: 0.0185 - val_mae: 0.0968\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.7208e-04 - mae: 0.0333 - val_loss: 0.0187 - val_mae: 0.0996\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.6168e-04 - mae: 0.0308 - val_loss: 0.0188 - val_mae: 0.1010\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 6.1963e-04 - mae: 0.0264 - val_loss: 0.0188 - val_mae: 0.1022\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.9958e-04 - mae: 0.0295 - val_loss: 0.0188 - val_mae: 0.1032\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.2773e-04 - mae: 0.0315 - val_loss: 0.0185 - val_mae: 0.1006\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 9.1073e-04 - mae: 0.0313 - val_loss: 0.0182 - val_mae: 0.0973\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.0069e-04 - mae: 0.0317 - val_loss: 0.0180 - val_mae: 0.0954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:13,029] Trial 2 finished with value: 0.09544417262077332 and parameters: {'learning_rate': 0.0015388499135113984, 'weight_decay': 9.178330927998499e-05}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0242 - mae: 0.1796 - val_loss: 0.0294 - val_mae: 0.1617\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0247 - mae: 0.1757 - val_loss: 0.0293 - val_mae: 0.1615\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0240 - mae: 0.1727 - val_loss: 0.0293 - val_mae: 0.1613\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0252 - mae: 0.1740 - val_loss: 0.0292 - val_mae: 0.1611\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0245 - mae: 0.1802 - val_loss: 0.0292 - val_mae: 0.1609\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0277 - mae: 0.1828 - val_loss: 0.0291 - val_mae: 0.1606\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0269 - mae: 0.1761 - val_loss: 0.0291 - val_mae: 0.1604\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0248 - mae: 0.1768 - val_loss: 0.0291 - val_mae: 0.1602\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0238 - mae: 0.1741 - val_loss: 0.0290 - val_mae: 0.1599\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0261 - mae: 0.1769 - val_loss: 0.0290 - val_mae: 0.1597\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - mae: 0.1647 - val_loss: 0.0289 - val_mae: 0.1595\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0219 - mae: 0.1578 - val_loss: 0.0289 - val_mae: 0.1593\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0201 - mae: 0.1578 - val_loss: 0.0288 - val_mae: 0.1591\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0225 - mae: 0.1662 - val_loss: 0.0288 - val_mae: 0.1588\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0234 - mae: 0.1681 - val_loss: 0.0287 - val_mae: 0.1586\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0231 - mae: 0.1674 - val_loss: 0.0287 - val_mae: 0.1584\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0215 - mae: 0.1655 - val_loss: 0.0286 - val_mae: 0.1582\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0279 - mae: 0.1876 - val_loss: 0.0286 - val_mae: 0.1580\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0281 - mae: 0.1883 - val_loss: 0.0286 - val_mae: 0.1577\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0229 - mae: 0.1664 - val_loss: 0.0285 - val_mae: 0.1575\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0245 - mae: 0.1670 - val_loss: 0.0285 - val_mae: 0.1573\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0211 - mae: 0.1606 - val_loss: 0.0284 - val_mae: 0.1571\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0253 - mae: 0.1714 - val_loss: 0.0284 - val_mae: 0.1568\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0223 - mae: 0.1700 - val_loss: 0.0283 - val_mae: 0.1566\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0286 - mae: 0.1869 - val_loss: 0.0283 - val_mae: 0.1564\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1580 - val_loss: 0.0282 - val_mae: 0.1562\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0232 - mae: 0.1690 - val_loss: 0.0282 - val_mae: 0.1560\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0265 - mae: 0.1847 - val_loss: 0.0282 - val_mae: 0.1557\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0233 - mae: 0.1742 - val_loss: 0.0281 - val_mae: 0.1555\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0246 - mae: 0.1774 - val_loss: 0.0281 - val_mae: 0.1553\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0226 - mae: 0.1714 - val_loss: 0.0280 - val_mae: 0.1551\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0211 - mae: 0.1667 - val_loss: 0.0280 - val_mae: 0.1548\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0243 - mae: 0.1743 - val_loss: 0.0279 - val_mae: 0.1546\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0262 - mae: 0.1783 - val_loss: 0.0279 - val_mae: 0.1544\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0243 - mae: 0.1769 - val_loss: 0.0279 - val_mae: 0.1542\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0232 - mae: 0.1742 - val_loss: 0.0278 - val_mae: 0.1540\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0217 - mae: 0.1624 - val_loss: 0.0278 - val_mae: 0.1537\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0251 - mae: 0.1782 - val_loss: 0.0277 - val_mae: 0.1535\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0250 - mae: 0.1772 - val_loss: 0.0277 - val_mae: 0.1533\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0256 - mae: 0.1763 - val_loss: 0.0277 - val_mae: 0.1531\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0254 - mae: 0.1796 - val_loss: 0.0276 - val_mae: 0.1529\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0229 - mae: 0.1647 - val_loss: 0.0276 - val_mae: 0.1526\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0221 - mae: 0.1616 - val_loss: 0.0275 - val_mae: 0.1524\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0254 - mae: 0.1802 - val_loss: 0.0275 - val_mae: 0.1522\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1590 - val_loss: 0.0274 - val_mae: 0.1520\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0209 - mae: 0.1552 - val_loss: 0.0274 - val_mae: 0.1518\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0237 - mae: 0.1775 - val_loss: 0.0274 - val_mae: 0.1516\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0219 - mae: 0.1584 - val_loss: 0.0273 - val_mae: 0.1513\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0256 - mae: 0.1773 - val_loss: 0.0273 - val_mae: 0.1511\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0219 - mae: 0.1642 - val_loss: 0.0272 - val_mae: 0.1509\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0256 - mae: 0.1787 - val_loss: 0.0272 - val_mae: 0.1507\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0211 - mae: 0.1645 - val_loss: 0.0272 - val_mae: 0.1505\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0217 - mae: 0.1587 - val_loss: 0.0271 - val_mae: 0.1503\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0240 - mae: 0.1711 - val_loss: 0.0271 - val_mae: 0.1501\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0204 - mae: 0.1518 - val_loss: 0.0270 - val_mae: 0.1499\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0229 - mae: 0.1642 - val_loss: 0.0270 - val_mae: 0.1497\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0245 - mae: 0.1769 - val_loss: 0.0270 - val_mae: 0.1495\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0222 - mae: 0.1686 - val_loss: 0.0269 - val_mae: 0.1493\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0226 - mae: 0.1679 - val_loss: 0.0269 - val_mae: 0.1491\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1633 - val_loss: 0.0269 - val_mae: 0.1489\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0190 - mae: 0.1535 - val_loss: 0.0268 - val_mae: 0.1486\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0217 - mae: 0.1580 - val_loss: 0.0268 - val_mae: 0.1484\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0208 - mae: 0.1647 - val_loss: 0.0267 - val_mae: 0.1482\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0225 - mae: 0.1641 - val_loss: 0.0267 - val_mae: 0.1480\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0224 - mae: 0.1673 - val_loss: 0.0267 - val_mae: 0.1478\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0225 - mae: 0.1678 - val_loss: 0.0266 - val_mae: 0.1476\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0221 - mae: 0.1642 - val_loss: 0.0266 - val_mae: 0.1474\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0226 - mae: 0.1663 - val_loss: 0.0266 - val_mae: 0.1472\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0253 - mae: 0.1769 - val_loss: 0.0265 - val_mae: 0.1470\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0194 - mae: 0.1550 - val_loss: 0.0265 - val_mae: 0.1468\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0251 - mae: 0.1740 - val_loss: 0.0265 - val_mae: 0.1466\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0206 - mae: 0.1558 - val_loss: 0.0264 - val_mae: 0.1464\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0217 - mae: 0.1638 - val_loss: 0.0264 - val_mae: 0.1462\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0201 - mae: 0.1594 - val_loss: 0.0263 - val_mae: 0.1460\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0191 - mae: 0.1567 - val_loss: 0.0263 - val_mae: 0.1458\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0210 - mae: 0.1626 - val_loss: 0.0263 - val_mae: 0.1456\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0226 - mae: 0.1698 - val_loss: 0.0262 - val_mae: 0.1454\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0209 - mae: 0.1580 - val_loss: 0.0262 - val_mae: 0.1452\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0239 - mae: 0.1728 - val_loss: 0.0262 - val_mae: 0.1450\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0220 - mae: 0.1627 - val_loss: 0.0261 - val_mae: 0.1448\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0207 - mae: 0.1579 - val_loss: 0.0261 - val_mae: 0.1446\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0233 - mae: 0.1643 - val_loss: 0.0261 - val_mae: 0.1444\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0239 - mae: 0.1732 - val_loss: 0.0260 - val_mae: 0.1442\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0232 - mae: 0.1733 - val_loss: 0.0260 - val_mae: 0.1440\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0183 - mae: 0.1529 - val_loss: 0.0260 - val_mae: 0.1438\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0179 - mae: 0.1511 - val_loss: 0.0259 - val_mae: 0.1436\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0226 - mae: 0.1646 - val_loss: 0.0259 - val_mae: 0.1434\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0185 - mae: 0.1536 - val_loss: 0.0259 - val_mae: 0.1432\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0225 - mae: 0.1643 - val_loss: 0.0258 - val_mae: 0.1430\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0208 - mae: 0.1689 - val_loss: 0.0258 - val_mae: 0.1428\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0189 - mae: 0.1526 - val_loss: 0.0258 - val_mae: 0.1427\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0203 - mae: 0.1562 - val_loss: 0.0258 - val_mae: 0.1425\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0217 - mae: 0.1606 - val_loss: 0.0257 - val_mae: 0.1423\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0219 - mae: 0.1656 - val_loss: 0.0257 - val_mae: 0.1421\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0257 - mae: 0.1754 - val_loss: 0.0257 - val_mae: 0.1419\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0265 - mae: 0.1752 - val_loss: 0.0256 - val_mae: 0.1417\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0195 - mae: 0.1554 - val_loss: 0.0256 - val_mae: 0.1415\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0190 - mae: 0.1489 - val_loss: 0.0256 - val_mae: 0.1414\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0226 - mae: 0.1670 - val_loss: 0.0255 - val_mae: 0.1412\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0177 - mae: 0.1475 - val_loss: 0.0255 - val_mae: 0.1410\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0186 - mae: 0.1475 - val_loss: 0.0255 - val_mae: 0.1408\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0210 - mae: 0.1616 - val_loss: 0.0254 - val_mae: 0.1406\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0203 - mae: 0.1608 - val_loss: 0.0254 - val_mae: 0.1404\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0216 - mae: 0.1644 - val_loss: 0.0254 - val_mae: 0.1403\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0194 - mae: 0.1566 - val_loss: 0.0253 - val_mae: 0.1401\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0228 - mae: 0.1688 - val_loss: 0.0253 - val_mae: 0.1399\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0187 - mae: 0.1501 - val_loss: 0.0253 - val_mae: 0.1397\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0221 - mae: 0.1635 - val_loss: 0.0253 - val_mae: 0.1395\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0224 - mae: 0.1670 - val_loss: 0.0252 - val_mae: 0.1393\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0179 - mae: 0.1529 - val_loss: 0.0252 - val_mae: 0.1391\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0211 - mae: 0.1620 - val_loss: 0.0252 - val_mae: 0.1390\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0196 - mae: 0.1562 - val_loss: 0.0251 - val_mae: 0.1388\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0202 - mae: 0.1571 - val_loss: 0.0251 - val_mae: 0.1386\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0214 - mae: 0.1642 - val_loss: 0.0251 - val_mae: 0.1384\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0212 - mae: 0.1584 - val_loss: 0.0250 - val_mae: 0.1382\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0199 - mae: 0.1594 - val_loss: 0.0250 - val_mae: 0.1380\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0214 - mae: 0.1632 - val_loss: 0.0250 - val_mae: 0.1379\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0200 - mae: 0.1580 - val_loss: 0.0250 - val_mae: 0.1377\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0198 - mae: 0.1545 - val_loss: 0.0249 - val_mae: 0.1375\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0204 - mae: 0.1578 - val_loss: 0.0249 - val_mae: 0.1373\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - mae: 0.1614 - val_loss: 0.0249 - val_mae: 0.1371\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0216 - mae: 0.1560 - val_loss: 0.0248 - val_mae: 0.1369\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1523 - val_loss: 0.0248 - val_mae: 0.1367\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0180 - mae: 0.1503 - val_loss: 0.0248 - val_mae: 0.1366\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0216 - mae: 0.1649 - val_loss: 0.0248 - val_mae: 0.1364\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - mae: 0.1513 - val_loss: 0.0247 - val_mae: 0.1362\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0168 - mae: 0.1450 - val_loss: 0.0247 - val_mae: 0.1360\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0196 - mae: 0.1544 - val_loss: 0.0247 - val_mae: 0.1358\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0209 - mae: 0.1593 - val_loss: 0.0246 - val_mae: 0.1357\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0208 - mae: 0.1626 - val_loss: 0.0246 - val_mae: 0.1355\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0175 - mae: 0.1473 - val_loss: 0.0246 - val_mae: 0.1353\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0167 - mae: 0.1464 - val_loss: 0.0246 - val_mae: 0.1351\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0184 - mae: 0.1463 - val_loss: 0.0245 - val_mae: 0.1350\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1472 - val_loss: 0.0245 - val_mae: 0.1348\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0223 - mae: 0.1650 - val_loss: 0.0245 - val_mae: 0.1347\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0196 - mae: 0.1552 - val_loss: 0.0245 - val_mae: 0.1345\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0189 - mae: 0.1493 - val_loss: 0.0244 - val_mae: 0.1343\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0177 - mae: 0.1454 - val_loss: 0.0244 - val_mae: 0.1342\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0200 - mae: 0.1506 - val_loss: 0.0244 - val_mae: 0.1340\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0171 - mae: 0.1430 - val_loss: 0.0244 - val_mae: 0.1339\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0189 - mae: 0.1473 - val_loss: 0.0243 - val_mae: 0.1337\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1460 - val_loss: 0.0243 - val_mae: 0.1336\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0188 - mae: 0.1541 - val_loss: 0.0243 - val_mae: 0.1334\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0157 - mae: 0.1431 - val_loss: 0.0243 - val_mae: 0.1333\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0175 - mae: 0.1476 - val_loss: 0.0242 - val_mae: 0.1331\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0202 - mae: 0.1529 - val_loss: 0.0242 - val_mae: 0.1330\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0180 - mae: 0.1466 - val_loss: 0.0242 - val_mae: 0.1328\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0191 - mae: 0.1500 - val_loss: 0.0242 - val_mae: 0.1327\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0203 - mae: 0.1537 - val_loss: 0.0242 - val_mae: 0.1325\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0179 - mae: 0.1480 - val_loss: 0.0241 - val_mae: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:23,357] Trial 3 finished with value: 0.13234838843345642 and parameters: {'learning_rate': 2.3172155882515957e-06, 'weight_decay': 0.005505773370770624}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0316 - mae: 0.2076 - val_loss: 0.0240 - val_mae: 0.1225\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0160 - mae: 0.1385 - val_loss: 0.0193 - val_mae: 0.0913\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0146 - mae: 0.1314 - val_loss: 0.0177 - val_mae: 0.0919\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1149 - val_loss: 0.0170 - val_mae: 0.0963\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0090 - mae: 0.1065 - val_loss: 0.0172 - val_mae: 0.0959\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0982 - val_loss: 0.0176 - val_mae: 0.0931\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0874 - val_loss: 0.0179 - val_mae: 0.0891\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0788 - val_loss: 0.0183 - val_mae: 0.0848\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0806 - val_loss: 0.0187 - val_mae: 0.0821\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - mae: 0.0774 - val_loss: 0.0191 - val_mae: 0.0815\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0700 - val_loss: 0.0192 - val_mae: 0.0815\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0192 - val_mae: 0.0816\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0692 - val_loss: 0.0190 - val_mae: 0.0806\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - mae: 0.0640 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0169 - val_mae: 0.0818\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0544 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0551 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - mae: 0.0584 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0816\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0502 - val_loss: 0.0168 - val_mae: 0.0785\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0502 - val_loss: 0.0167 - val_mae: 0.0795\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0167 - val_mae: 0.0812\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0550 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0168 - val_mae: 0.0804\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0168 - val_mae: 0.0797\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0167 - val_mae: 0.0801\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0510 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0839\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0539 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0477 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mae: 0.0499 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0459 - val_loss: 0.0164 - val_mae: 0.0878\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0163 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0536 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0168 - val_mae: 0.0800\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0168 - val_mae: 0.0804\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0450 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0165 - val_mae: 0.0884\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0456 - val_loss: 0.0166 - val_mae: 0.0882\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0403 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0171 - val_mae: 0.0844\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0170 - val_mae: 0.0883\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0170 - val_mae: 0.0883\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0012 - mae: 0.0367 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0166 - val_mae: 0.0867\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0389 - val_loss: 0.0166 - val_mae: 0.0891\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0166 - val_mae: 0.0903\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0383 - val_loss: 0.0167 - val_mae: 0.0892\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0169 - val_mae: 0.0877\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0375 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0171 - val_mae: 0.0932\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4353e-04 - mae: 0.0341 - val_loss: 0.0171 - val_mae: 0.0930\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0351 - val_loss: 0.0171 - val_mae: 0.0895\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3367e-04 - mae: 0.0301 - val_loss: 0.0173 - val_mae: 0.0857\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0174 - val_mae: 0.0858\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 8.1479e-04 - mae: 0.0317 - val_loss: 0.0173 - val_mae: 0.0864\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0341 - val_loss: 0.0173 - val_mae: 0.0930\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0174 - val_mae: 0.0956\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0435 - val_loss: 0.0173 - val_mae: 0.0930\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0172 - val_mae: 0.0880\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2033e-04 - mae: 0.0336 - val_loss: 0.0172 - val_mae: 0.0846\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0359 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0368 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.7224e-04 - mae: 0.0309 - val_loss: 0.0168 - val_mae: 0.0889\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.3153e-04 - mae: 0.0326 - val_loss: 0.0169 - val_mae: 0.0925\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.6918e-04 - mae: 0.0330 - val_loss: 0.0170 - val_mae: 0.0937\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.5293e-04 - mae: 0.0341 - val_loss: 0.0171 - val_mae: 0.0917\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8242e-04 - mae: 0.0308 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0172 - val_mae: 0.0877\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0172 - val_mae: 0.0871\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0172 - val_mae: 0.0873\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1495e-04 - mae: 0.0327 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6247e-04 - mae: 0.0321 - val_loss: 0.0171 - val_mae: 0.0923\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9472e-04 - mae: 0.0319 - val_loss: 0.0171 - val_mae: 0.0948\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0171 - val_mae: 0.0946\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.5010e-04 - mae: 0.0321 - val_loss: 0.0171 - val_mae: 0.0934\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.2445e-04 - mae: 0.0329 - val_loss: 0.0171 - val_mae: 0.0906\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0172 - val_mae: 0.0884\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0046e-04 - mae: 0.0324 - val_loss: 0.0174 - val_mae: 0.0876\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.6519e-04 - mae: 0.0305 - val_loss: 0.0174 - val_mae: 0.0882\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1407e-04 - mae: 0.0307 - val_loss: 0.0173 - val_mae: 0.0889\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.5461e-04 - mae: 0.0309 - val_loss: 0.0172 - val_mae: 0.0897\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7139e-04 - mae: 0.0282 - val_loss: 0.0172 - val_mae: 0.0906\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8.0096e-04 - mae: 0.0314 - val_loss: 0.0171 - val_mae: 0.0908\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.1701e-04 - mae: 0.0304 - val_loss: 0.0171 - val_mae: 0.0901\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0338 - val_loss: 0.0170 - val_mae: 0.0888\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.5465e-04 - mae: 0.0315 - val_loss: 0.0170 - val_mae: 0.0887\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.2875e-04 - mae: 0.0264 - val_loss: 0.0170 - val_mae: 0.0889\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7683e-04 - mae: 0.0287 - val_loss: 0.0170 - val_mae: 0.0890\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0902e-04 - mae: 0.0292 - val_loss: 0.0171 - val_mae: 0.0894\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5762e-04 - mae: 0.0310 - val_loss: 0.0172 - val_mae: 0.0905\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.8302e-04 - mae: 0.0234 - val_loss: 0.0173 - val_mae: 0.0918\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.5126e-04 - mae: 0.0286 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1505e-04 - mae: 0.0263 - val_loss: 0.0175 - val_mae: 0.0930\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.8825e-04 - mae: 0.0292 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9034e-04 - mae: 0.0275 - val_loss: 0.0175 - val_mae: 0.0928\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3218e-04 - mae: 0.0280 - val_loss: 0.0175 - val_mae: 0.0912\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4471e-04 - mae: 0.0286 - val_loss: 0.0175 - val_mae: 0.0905\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.0726e-04 - mae: 0.0271 - val_loss: 0.0175 - val_mae: 0.0893\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.7801e-04 - mae: 0.0294 - val_loss: 0.0174 - val_mae: 0.0886\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.4832e-04 - mae: 0.0281 - val_loss: 0.0174 - val_mae: 0.0885\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.4313e-04 - mae: 0.0295 - val_loss: 0.0174 - val_mae: 0.0891\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.4595e-04 - mae: 0.0269 - val_loss: 0.0174 - val_mae: 0.0905\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7542e-04 - mae: 0.0257 - val_loss: 0.0175 - val_mae: 0.0924\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7713e-04 - mae: 0.0284 - val_loss: 0.0175 - val_mae: 0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:33,560] Trial 4 finished with value: 0.09442269057035446 and parameters: {'learning_rate': 0.0007615217078388018, 'weight_decay': 1.9994901014411217e-07}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0316 - mae: 0.2011 - val_loss: 0.0225 - val_mae: 0.1195\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0126 - mae: 0.1283 - val_loss: 0.0203 - val_mae: 0.1069\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0190 - val_mae: 0.0966\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0905 - val_loss: 0.0187 - val_mae: 0.0871\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - mae: 0.0834 - val_loss: 0.0190 - val_mae: 0.0863\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0192 - val_mae: 0.0846\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0050 - mae: 0.0721 - val_loss: 0.0193 - val_mae: 0.0828\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0192 - val_mae: 0.0811\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0179 - val_mae: 0.0811\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0676 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - mae: 0.0693 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0645 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - mae: 0.0627 - val_loss: 0.0178 - val_mae: 0.0799\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0180 - val_mae: 0.0800\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0179 - val_mae: 0.0805\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0546 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0848\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0835\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0546 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0513 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0168 - val_mae: 0.0883\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0504 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0497 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0474 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0478 - val_loss: 0.0170 - val_mae: 0.0868\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0171 - val_mae: 0.0866\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0173 - val_mae: 0.0850\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0463 - val_loss: 0.0174 - val_mae: 0.0838\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0175 - val_mae: 0.0833\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0174 - val_mae: 0.0844\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0173 - val_mae: 0.0856\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0415 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0173 - val_mae: 0.0868\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0428 - val_loss: 0.0172 - val_mae: 0.0884\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0173 - val_mae: 0.0883\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.8246e-04 - mae: 0.0352 - val_loss: 0.0176 - val_mae: 0.0857\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0175 - val_mae: 0.0870\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0421 - val_loss: 0.0176 - val_mae: 0.0871\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0175 - val_mae: 0.0887\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0174 - val_mae: 0.0917\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0176 - val_mae: 0.0908\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0180 - val_mae: 0.0883\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0182 - val_mae: 0.0870\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0350 - val_loss: 0.0180 - val_mae: 0.0870\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0179 - val_mae: 0.0880\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.4255e-04 - mae: 0.0310 - val_loss: 0.0177 - val_mae: 0.0892\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0348 - val_loss: 0.0176 - val_mae: 0.0931\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - mae: 0.0413 - val_loss: 0.0178 - val_mae: 0.0898\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6514e-04 - mae: 0.0320 - val_loss: 0.0182 - val_mae: 0.0881\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.2206e-04 - mae: 0.0336 - val_loss: 0.0185 - val_mae: 0.0874\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3265e-04 - mae: 0.0331 - val_loss: 0.0182 - val_mae: 0.0872\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5237e-04 - mae: 0.0317 - val_loss: 0.0178 - val_mae: 0.0892\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0330 - val_loss: 0.0175 - val_mae: 0.0917\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0818e-04 - mae: 0.0311 - val_loss: 0.0174 - val_mae: 0.0917\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3649e-04 - mae: 0.0303 - val_loss: 0.0176 - val_mae: 0.0897\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.2284e-04 - mae: 0.0335 - val_loss: 0.0178 - val_mae: 0.0889\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.5895e-04 - mae: 0.0323 - val_loss: 0.0179 - val_mae: 0.0892\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.9586e-04 - mae: 0.0326 - val_loss: 0.0181 - val_mae: 0.0866\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7403e-04 - mae: 0.0320 - val_loss: 0.0182 - val_mae: 0.0862\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4925e-04 - mae: 0.0304 - val_loss: 0.0179 - val_mae: 0.0885\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.6209e-04 - mae: 0.0304 - val_loss: 0.0176 - val_mae: 0.0918\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.7342e-04 - mae: 0.0344 - val_loss: 0.0175 - val_mae: 0.0930\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4585e-04 - mae: 0.0333 - val_loss: 0.0176 - val_mae: 0.0907\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.6072e-04 - mae: 0.0326 - val_loss: 0.0177 - val_mae: 0.0903\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0318 - val_loss: 0.0177 - val_mae: 0.0895\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4325e-04 - mae: 0.0292 - val_loss: 0.0176 - val_mae: 0.0901\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0155e-04 - mae: 0.0293 - val_loss: 0.0178 - val_mae: 0.0894\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5229e-04 - mae: 0.0334 - val_loss: 0.0179 - val_mae: 0.0885\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.5709e-04 - mae: 0.0321 - val_loss: 0.0177 - val_mae: 0.0893\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5757e-04 - mae: 0.0260 - val_loss: 0.0178 - val_mae: 0.0885\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.5117e-04 - mae: 0.0292 - val_loss: 0.0179 - val_mae: 0.0890\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5069e-04 - mae: 0.0274 - val_loss: 0.0178 - val_mae: 0.0909\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.1842e-04 - mae: 0.0311 - val_loss: 0.0178 - val_mae: 0.0936\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9521e-04 - mae: 0.0330 - val_loss: 0.0180 - val_mae: 0.0919\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.2587e-04 - mae: 0.0273 - val_loss: 0.0184 - val_mae: 0.0895\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6659e-04 - mae: 0.0269 - val_loss: 0.0186 - val_mae: 0.0889\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0186 - val_mae: 0.0893\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.7166e-04 - mae: 0.0289 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6090e-04 - mae: 0.0309 - val_loss: 0.0182 - val_mae: 0.0945\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.5634e-04 - mae: 0.0317 - val_loss: 0.0181 - val_mae: 0.0920\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0350 - val_loss: 0.0180 - val_mae: 0.0877\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.3494e-04 - mae: 0.0298 - val_loss: 0.0181 - val_mae: 0.0865\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5743e-04 - mae: 0.0276 - val_loss: 0.0179 - val_mae: 0.0880\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4052e-04 - mae: 0.0307 - val_loss: 0.0177 - val_mae: 0.0917\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3336e-04 - mae: 0.0305 - val_loss: 0.0177 - val_mae: 0.0927\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.4259e-04 - mae: 0.0293 - val_loss: 0.0179 - val_mae: 0.0911\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0589e-04 - mae: 0.0310 - val_loss: 0.0180 - val_mae: 0.0919\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5868e-04 - mae: 0.0295 - val_loss: 0.0181 - val_mae: 0.0932\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1801e-04 - mae: 0.0306 - val_loss: 0.0182 - val_mae: 0.0928\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.4129e-04 - mae: 0.0252 - val_loss: 0.0183 - val_mae: 0.0907\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0011 - mae: 0.0342 - val_loss: 0.0182 - val_mae: 0.0896\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4324e-04 - mae: 0.0279 - val_loss: 0.0181 - val_mae: 0.0904\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6.9938e-04 - mae: 0.0287 - val_loss: 0.0181 - val_mae: 0.0914\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6230e-04 - mae: 0.0284 - val_loss: 0.0179 - val_mae: 0.0901\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3952e-04 - mae: 0.0331 - val_loss: 0.0178 - val_mae: 0.0890\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.4943e-04 - mae: 0.0287 - val_loss: 0.0179 - val_mae: 0.0880\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.3182e-04 - mae: 0.0272 - val_loss: 0.0179 - val_mae: 0.0877\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7247e-04 - mae: 0.0231 - val_loss: 0.0178 - val_mae: 0.0881\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6938e-04 - mae: 0.0253 - val_loss: 0.0178 - val_mae: 0.0891\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.0500e-04 - mae: 0.0289 - val_loss: 0.0177 - val_mae: 0.0886\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7080e-04 - mae: 0.0266 - val_loss: 0.0175 - val_mae: 0.0889\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.3600e-04 - mae: 0.0283 - val_loss: 0.0175 - val_mae: 0.0893\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.4201e-04 - mae: 0.0276 - val_loss: 0.0175 - val_mae: 0.0888\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.8399e-04 - mae: 0.0256 - val_loss: 0.0174 - val_mae: 0.0885\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.1426e-04 - mae: 0.0293 - val_loss: 0.0174 - val_mae: 0.0885\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7783e-04 - mae: 0.0283 - val_loss: 0.0174 - val_mae: 0.0880\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0400e-04 - mae: 0.0296 - val_loss: 0.0175 - val_mae: 0.0884\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.4103e-04 - mae: 0.0293 - val_loss: 0.0175 - val_mae: 0.0898\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.7029e-04 - mae: 0.0235 - val_loss: 0.0176 - val_mae: 0.0923\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.6262e-04 - mae: 0.0265 - val_loss: 0.0177 - val_mae: 0.0929\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0933e-04 - mae: 0.0273 - val_loss: 0.0179 - val_mae: 0.0916\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.9232e-04 - mae: 0.0266 - val_loss: 0.0180 - val_mae: 0.0888\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6305e-04 - mae: 0.0255 - val_loss: 0.0182 - val_mae: 0.0878\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6249e-04 - mae: 0.0228 - val_loss: 0.0182 - val_mae: 0.0872\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.1739e-04 - mae: 0.0261 - val_loss: 0.0181 - val_mae: 0.0874\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.8658e-04 - mae: 0.0257 - val_loss: 0.0180 - val_mae: 0.0888\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.9378e-04 - mae: 0.0259 - val_loss: 0.0179 - val_mae: 0.0906\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.3428e-04 - mae: 0.0251 - val_loss: 0.0179 - val_mae: 0.0923\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.5845e-04 - mae: 0.0236 - val_loss: 0.0178 - val_mae: 0.0920\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7257e-04 - mae: 0.0273 - val_loss: 0.0178 - val_mae: 0.0902\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.5919e-04 - mae: 0.0250 - val_loss: 0.0179 - val_mae: 0.0892\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.0618e-04 - mae: 0.0256 - val_loss: 0.0179 - val_mae: 0.0894\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.1752e-04 - mae: 0.0247 - val_loss: 0.0179 - val_mae: 0.0892\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.3209e-04 - mae: 0.0255 - val_loss: 0.0178 - val_mae: 0.0897\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5781e-04 - mae: 0.0256 - val_loss: 0.0177 - val_mae: 0.0901\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.2807e-04 - mae: 0.0220 - val_loss: 0.0176 - val_mae: 0.0913\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.6863e-04 - mae: 0.0260 - val_loss: 0.0176 - val_mae: 0.0912\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.8097e-04 - mae: 0.0271 - val_loss: 0.0179 - val_mae: 0.0918\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0015e-04 - mae: 0.0290 - val_loss: 0.0181 - val_mae: 0.0939\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.8230e-04 - mae: 0.0273 - val_loss: 0.0180 - val_mae: 0.0923\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.6383e-04 - mae: 0.0254 - val_loss: 0.0180 - val_mae: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:43,823] Trial 5 finished with value: 0.09158733487129211 and parameters: {'learning_rate': 0.0014619601850895823, 'weight_decay': 1.4691914863729165e-05}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0368 - mae: 0.2174 - val_loss: 0.0267 - val_mae: 0.1296\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1635 - val_loss: 0.0186 - val_mae: 0.0939\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - mae: 0.1335 - val_loss: 0.0161 - val_mae: 0.0924\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0145 - mae: 0.1322 - val_loss: 0.0164 - val_mae: 0.1015\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0134 - mae: 0.1322 - val_loss: 0.0169 - val_mae: 0.1057\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0135 - mae: 0.1298 - val_loss: 0.0172 - val_mae: 0.1048\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0117 - mae: 0.1224 - val_loss: 0.0172 - val_mae: 0.0991\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0971 - val_loss: 0.0173 - val_mae: 0.0925\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - mae: 0.0948 - val_loss: 0.0174 - val_mae: 0.0862\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0846 - val_loss: 0.0177 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - mae: 0.0866 - val_loss: 0.0179 - val_mae: 0.0810\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0833 - val_loss: 0.0181 - val_mae: 0.0796\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - mae: 0.0855 - val_loss: 0.0183 - val_mae: 0.0791\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0059 - mae: 0.0760 - val_loss: 0.0185 - val_mae: 0.0789\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0186 - val_mae: 0.0789\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0769 - val_loss: 0.0186 - val_mae: 0.0783\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0053 - mae: 0.0712 - val_loss: 0.0186 - val_mae: 0.0781\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0184 - val_mae: 0.0777\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0052 - mae: 0.0686 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0724 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0669 - val_loss: 0.0173 - val_mae: 0.0834\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0176 - val_mae: 0.0806\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0177 - val_mae: 0.0798\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0177 - val_mae: 0.0797\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0799\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0177 - val_mae: 0.0804\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0811\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0551 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0836\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0539 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0026 - mae: 0.0508 - val_loss: 0.0175 - val_mae: 0.0837\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0516 - val_loss: 0.0175 - val_mae: 0.0843\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0174 - val_mae: 0.0848\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0173 - val_mae: 0.0857\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0859\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0172 - val_mae: 0.0855\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0499 - val_loss: 0.0172 - val_mae: 0.0843\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0527 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0492 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0483 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0503 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0504 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0462 - val_loss: 0.0167 - val_mae: 0.0874\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0540 - val_loss: 0.0168 - val_mae: 0.0890\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0553 - val_loss: 0.0170 - val_mae: 0.0868\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0537 - val_loss: 0.0175 - val_mae: 0.0844\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0481 - val_loss: 0.0179 - val_mae: 0.0817\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0489 - val_loss: 0.0178 - val_mae: 0.0822\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0474 - val_loss: 0.0174 - val_mae: 0.0864\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0171 - val_mae: 0.0910\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0492 - val_loss: 0.0170 - val_mae: 0.0920\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0170 - val_mae: 0.0919\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0501 - val_loss: 0.0171 - val_mae: 0.0897\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0471 - val_loss: 0.0174 - val_mae: 0.0874\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0176 - val_mae: 0.0854\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0176 - val_mae: 0.0852\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0459 - val_loss: 0.0175 - val_mae: 0.0861\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0173 - val_mae: 0.0873\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0171 - val_mae: 0.0887\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0169 - val_mae: 0.0890\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0169 - val_mae: 0.0886\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0490 - val_loss: 0.0170 - val_mae: 0.0872\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0171 - val_mae: 0.0856\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0435 - val_loss: 0.0172 - val_mae: 0.0848\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0390 - val_loss: 0.0173 - val_mae: 0.0849\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0418 - val_loss: 0.0173 - val_mae: 0.0857\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0172 - val_mae: 0.0871\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0417 - val_loss: 0.0171 - val_mae: 0.0887\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0170 - val_mae: 0.0894\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0445 - val_loss: 0.0170 - val_mae: 0.0892\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0171 - val_mae: 0.0888\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0416 - val_loss: 0.0171 - val_mae: 0.0888\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0171 - val_mae: 0.0882\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 0.0172 - val_mae: 0.0879\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0368 - val_loss: 0.0172 - val_mae: 0.0874\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0172 - val_mae: 0.0880\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0172 - val_mae: 0.0888\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0172 - val_mae: 0.0895\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0171 - val_mae: 0.0896\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0171 - val_mae: 0.0889\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0171 - val_mae: 0.0893\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - mae: 0.0372 - val_loss: 0.0170 - val_mae: 0.0891\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0373 - val_loss: 0.0170 - val_mae: 0.0889\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.7101e-04 - mae: 0.0324 - val_loss: 0.0170 - val_mae: 0.0894\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0170 - val_mae: 0.0902\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0170 - val_mae: 0.0902\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0361 - val_loss: 0.0171 - val_mae: 0.0893\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.0173 - val_mae: 0.0895\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0173 - val_mae: 0.0905\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0173 - val_mae: 0.0914\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0172 - val_mae: 0.0917\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0172 - val_mae: 0.0917\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0401 - val_loss: 0.0173 - val_mae: 0.0912\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0174 - val_mae: 0.0915\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.9898e-04 - mae: 0.0352 - val_loss: 0.0174 - val_mae: 0.0923\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0174 - val_mae: 0.0927\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.4745e-04 - mae: 0.0344 - val_loss: 0.0174 - val_mae: 0.0929\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0370 - val_loss: 0.0173 - val_mae: 0.0931\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0173 - val_mae: 0.0922\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.0371e-04 - mae: 0.0315 - val_loss: 0.0174 - val_mae: 0.0916\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0174 - val_mae: 0.0919\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0174 - val_mae: 0.0924\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.0472e-04 - mae: 0.0322 - val_loss: 0.0175 - val_mae: 0.0928\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7.7722e-04 - mae: 0.0311 - val_loss: 0.0175 - val_mae: 0.0933\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 8.9451e-04 - mae: 0.0312 - val_loss: 0.0176 - val_mae: 0.0937\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0176 - val_mae: 0.0931\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0351 - val_loss: 0.0176 - val_mae: 0.0925\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0367 - val_loss: 0.0176 - val_mae: 0.0922\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8220e-04 - mae: 0.0332 - val_loss: 0.0175 - val_mae: 0.0929\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.9888e-04 - mae: 0.0292 - val_loss: 0.0175 - val_mae: 0.0926\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.2096e-04 - mae: 0.0331 - val_loss: 0.0175 - val_mae: 0.0927\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0175 - val_mae: 0.0922\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9310e-04 - mae: 0.0307 - val_loss: 0.0175 - val_mae: 0.0914\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.4525e-04 - mae: 0.0293 - val_loss: 0.0174 - val_mae: 0.0916\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.2119e-04 - mae: 0.0289 - val_loss: 0.0174 - val_mae: 0.0920\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.1757e-04 - mae: 0.0305 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.6584e-04 - mae: 0.0344 - val_loss: 0.0174 - val_mae: 0.0914\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.7823e-04 - mae: 0.0346 - val_loss: 0.0175 - val_mae: 0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:55:53,967] Trial 6 finished with value: 0.0917372852563858 and parameters: {'learning_rate': 0.0006198792357481174, 'weight_decay': 0.0001568973346722977}. Best is trial 0 with value: 0.08522693067789078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0279 - mae: 0.1907 - val_loss: 0.0319 - val_mae: 0.1528\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0240 - mae: 0.1721 - val_loss: 0.0313 - val_mae: 0.1497\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0227 - mae: 0.1719 - val_loss: 0.0306 - val_mae: 0.1465\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1647 - val_loss: 0.0300 - val_mae: 0.1434\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0270 - mae: 0.1832 - val_loss: 0.0295 - val_mae: 0.1403\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0250 - mae: 0.1703 - val_loss: 0.0289 - val_mae: 0.1372\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - mae: 0.1616 - val_loss: 0.0284 - val_mae: 0.1343\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0204 - mae: 0.1565 - val_loss: 0.0279 - val_mae: 0.1316\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0195 - mae: 0.1537 - val_loss: 0.0274 - val_mae: 0.1291\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0191 - mae: 0.1555 - val_loss: 0.0270 - val_mae: 0.1266\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0190 - mae: 0.1507 - val_loss: 0.0266 - val_mae: 0.1243\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0203 - mae: 0.1637 - val_loss: 0.0262 - val_mae: 0.1220\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - mae: 0.1564 - val_loss: 0.0258 - val_mae: 0.1197\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0183 - mae: 0.1556 - val_loss: 0.0254 - val_mae: 0.1176\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0166 - mae: 0.1383 - val_loss: 0.0251 - val_mae: 0.1156\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0177 - mae: 0.1473 - val_loss: 0.0248 - val_mae: 0.1136\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1527 - val_loss: 0.0245 - val_mae: 0.1117\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0136 - mae: 0.1274 - val_loss: 0.0242 - val_mae: 0.1100\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0149 - mae: 0.1363 - val_loss: 0.0239 - val_mae: 0.1083\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0147 - mae: 0.1330 - val_loss: 0.0236 - val_mae: 0.1066\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0146 - mae: 0.1295 - val_loss: 0.0234 - val_mae: 0.1051\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0131 - mae: 0.1287 - val_loss: 0.0231 - val_mae: 0.1036\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0159 - mae: 0.1415 - val_loss: 0.0229 - val_mae: 0.1022\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0170 - mae: 0.1475 - val_loss: 0.0227 - val_mae: 0.1008\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0153 - mae: 0.1383 - val_loss: 0.0225 - val_mae: 0.0994\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0164 - mae: 0.1423 - val_loss: 0.0223 - val_mae: 0.0981\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0127 - mae: 0.1270 - val_loss: 0.0221 - val_mae: 0.0968\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0132 - mae: 0.1256 - val_loss: 0.0219 - val_mae: 0.0956\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0139 - mae: 0.1300 - val_loss: 0.0217 - val_mae: 0.0944\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0124 - mae: 0.1254 - val_loss: 0.0216 - val_mae: 0.0934\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0118 - mae: 0.1215 - val_loss: 0.0214 - val_mae: 0.0924\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - mae: 0.1212 - val_loss: 0.0213 - val_mae: 0.0915\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0144 - mae: 0.1330 - val_loss: 0.0211 - val_mae: 0.0906\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0125 - mae: 0.1193 - val_loss: 0.0210 - val_mae: 0.0898\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0131 - mae: 0.1240 - val_loss: 0.0208 - val_mae: 0.0890\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0118 - mae: 0.1198 - val_loss: 0.0207 - val_mae: 0.0882\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1226 - val_loss: 0.0206 - val_mae: 0.0874\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0125 - mae: 0.1276 - val_loss: 0.0205 - val_mae: 0.0866\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0111 - mae: 0.1170 - val_loss: 0.0204 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1143 - val_loss: 0.0203 - val_mae: 0.0851\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0202 - val_mae: 0.0844\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1239 - val_loss: 0.0201 - val_mae: 0.0838\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0110 - mae: 0.1188 - val_loss: 0.0200 - val_mae: 0.0832\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1157 - val_loss: 0.0199 - val_mae: 0.0827\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0125 - mae: 0.1235 - val_loss: 0.0198 - val_mae: 0.0821\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0197 - val_mae: 0.0816\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0122 - mae: 0.1184 - val_loss: 0.0196 - val_mae: 0.0812\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1138 - val_loss: 0.0196 - val_mae: 0.0808\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0116 - mae: 0.1181 - val_loss: 0.0195 - val_mae: 0.0805\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0194 - val_mae: 0.0801\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0103 - mae: 0.1161 - val_loss: 0.0193 - val_mae: 0.0798\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1128 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0106 - mae: 0.1158 - val_loss: 0.0192 - val_mae: 0.0792\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0192 - val_mae: 0.0790\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0086 - mae: 0.1012 - val_loss: 0.0191 - val_mae: 0.0788\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0109 - mae: 0.1121 - val_loss: 0.0191 - val_mae: 0.0786\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0190 - val_mae: 0.0783\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0078 - mae: 0.0996 - val_loss: 0.0190 - val_mae: 0.0781\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0189 - val_mae: 0.0780\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0189 - val_mae: 0.0778\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0188 - val_mae: 0.0777\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0991 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1077 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0187 - val_mae: 0.0774\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - mae: 0.1046 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0096 - mae: 0.1096 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0071 - mae: 0.0929 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0077 - mae: 0.0933 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.0963 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.1003 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0090 - mae: 0.1051 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.1009 - val_loss: 0.0184 - val_mae: 0.0774\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0183 - val_mae: 0.0775\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - mae: 0.0990 - val_loss: 0.0183 - val_mae: 0.0776\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - mae: 0.0999 - val_loss: 0.0183 - val_mae: 0.0776\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0183 - val_mae: 0.0777\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0084 - mae: 0.1016 - val_loss: 0.0183 - val_mae: 0.0777\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0910 - val_loss: 0.0183 - val_mae: 0.0778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0085 - mae: 0.1002 - val_loss: 0.0183 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0989 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0929 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.1051 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.0956 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.1033 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0086 - mae: 0.1042 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0926 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0962 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0927 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0074 - mae: 0.0932 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0977 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0080 - mae: 0.0965 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0959 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0906 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0081 - mae: 0.0987 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0949 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0922 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0855 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - mae: 0.0891 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0996 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0911 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - mae: 0.0948 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0069 - mae: 0.0919 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0063 - mae: 0.0849 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0071 - mae: 0.0928 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0905 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0929 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0912 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0077 - mae: 0.0941 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0882 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - mae: 0.0856 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0949 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0904 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0855 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0886 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - mae: 0.0891 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0860 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0898 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - mae: 0.0860 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0891 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0882 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0928 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - mae: 0.0870 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0059 - mae: 0.0859 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0884 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0907 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0882 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - mae: 0.0847 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - mae: 0.0828 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0870 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - mae: 0.0867 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0796 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0858 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0806 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0925 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0871 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0825 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0828 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0882 - val_loss: 0.0179 - val_mae: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:04,219] Trial 7 finished with value: 0.07824554294347763 and parameters: {'learning_rate': 4.010875006693945e-05, 'weight_decay': 5.6544490579689775e-09}. Best is trial 7 with value: 0.07824554294347763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0220 - mae: 0.1672 - val_loss: 0.0264 - val_mae: 0.1418\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0195 - mae: 0.1557 - val_loss: 0.0263 - val_mae: 0.1417\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1482 - val_loss: 0.0263 - val_mae: 0.1415\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0175 - mae: 0.1521 - val_loss: 0.0263 - val_mae: 0.1414\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0204 - mae: 0.1641 - val_loss: 0.0263 - val_mae: 0.1413\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0203 - mae: 0.1625 - val_loss: 0.0263 - val_mae: 0.1411\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0198 - mae: 0.1557 - val_loss: 0.0262 - val_mae: 0.1410\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0176 - mae: 0.1490 - val_loss: 0.0262 - val_mae: 0.1408\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0217 - mae: 0.1629 - val_loss: 0.0262 - val_mae: 0.1407\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0222 - mae: 0.1666 - val_loss: 0.0262 - val_mae: 0.1405\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1491 - val_loss: 0.0261 - val_mae: 0.1404\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0200 - mae: 0.1596 - val_loss: 0.0261 - val_mae: 0.1402\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0223 - mae: 0.1703 - val_loss: 0.0261 - val_mae: 0.1401\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0188 - mae: 0.1560 - val_loss: 0.0260 - val_mae: 0.1399\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1556 - val_loss: 0.0260 - val_mae: 0.1398\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0179 - mae: 0.1546 - val_loss: 0.0260 - val_mae: 0.1396\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0222 - mae: 0.1662 - val_loss: 0.0260 - val_mae: 0.1395\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0187 - mae: 0.1537 - val_loss: 0.0259 - val_mae: 0.1393\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - mae: 0.1590 - val_loss: 0.0259 - val_mae: 0.1392\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0195 - mae: 0.1542 - val_loss: 0.0259 - val_mae: 0.1390\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0169 - mae: 0.1492 - val_loss: 0.0259 - val_mae: 0.1389\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0184 - mae: 0.1540 - val_loss: 0.0258 - val_mae: 0.1387\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0181 - mae: 0.1478 - val_loss: 0.0258 - val_mae: 0.1386\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0188 - mae: 0.1521 - val_loss: 0.0258 - val_mae: 0.1384\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0171 - mae: 0.1521 - val_loss: 0.0258 - val_mae: 0.1383\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0192 - mae: 0.1559 - val_loss: 0.0257 - val_mae: 0.1382\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1516 - val_loss: 0.0257 - val_mae: 0.1380\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0197 - mae: 0.1582 - val_loss: 0.0257 - val_mae: 0.1379\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0197 - mae: 0.1606 - val_loss: 0.0257 - val_mae: 0.1377\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1467 - val_loss: 0.0257 - val_mae: 0.1376\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0169 - mae: 0.1475 - val_loss: 0.0256 - val_mae: 0.1374\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0175 - mae: 0.1470 - val_loss: 0.0256 - val_mae: 0.1373\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0208 - mae: 0.1605 - val_loss: 0.0256 - val_mae: 0.1371\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0213 - mae: 0.1629 - val_loss: 0.0256 - val_mae: 0.1370\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0190 - mae: 0.1508 - val_loss: 0.0255 - val_mae: 0.1369\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0192 - mae: 0.1518 - val_loss: 0.0255 - val_mae: 0.1367\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0179 - mae: 0.1471 - val_loss: 0.0255 - val_mae: 0.1366\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0191 - mae: 0.1546 - val_loss: 0.0255 - val_mae: 0.1364\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0217 - mae: 0.1613 - val_loss: 0.0254 - val_mae: 0.1363\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0175 - mae: 0.1464 - val_loss: 0.0254 - val_mae: 0.1361\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0190 - mae: 0.1514 - val_loss: 0.0254 - val_mae: 0.1360\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0187 - mae: 0.1508 - val_loss: 0.0254 - val_mae: 0.1359\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0193 - mae: 0.1569 - val_loss: 0.0253 - val_mae: 0.1357\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0189 - mae: 0.1497 - val_loss: 0.0253 - val_mae: 0.1356\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0166 - mae: 0.1445 - val_loss: 0.0253 - val_mae: 0.1354\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0185 - mae: 0.1536 - val_loss: 0.0253 - val_mae: 0.1353\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0175 - mae: 0.1485 - val_loss: 0.0253 - val_mae: 0.1352\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0182 - mae: 0.1542 - val_loss: 0.0252 - val_mae: 0.1350\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - mae: 0.1598 - val_loss: 0.0252 - val_mae: 0.1349\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1460 - val_loss: 0.0252 - val_mae: 0.1347\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1506 - val_loss: 0.0252 - val_mae: 0.1346\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mae: 0.1464 - val_loss: 0.0251 - val_mae: 0.1345\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0175 - mae: 0.1406 - val_loss: 0.0251 - val_mae: 0.1343\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0187 - mae: 0.1508 - val_loss: 0.0251 - val_mae: 0.1342\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0180 - mae: 0.1520 - val_loss: 0.0251 - val_mae: 0.1340\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0173 - mae: 0.1435 - val_loss: 0.0250 - val_mae: 0.1339\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0195 - mae: 0.1545 - val_loss: 0.0250 - val_mae: 0.1338\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0220 - mae: 0.1647 - val_loss: 0.0250 - val_mae: 0.1336\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0193 - mae: 0.1586 - val_loss: 0.0250 - val_mae: 0.1335\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0189 - mae: 0.1487 - val_loss: 0.0250 - val_mae: 0.1333\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0181 - mae: 0.1530 - val_loss: 0.0249 - val_mae: 0.1332\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1548 - val_loss: 0.0249 - val_mae: 0.1330\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0172 - mae: 0.1487 - val_loss: 0.0249 - val_mae: 0.1329\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1522 - val_loss: 0.0249 - val_mae: 0.1328\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0179 - mae: 0.1543 - val_loss: 0.0248 - val_mae: 0.1326\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0171 - mae: 0.1438 - val_loss: 0.0248 - val_mae: 0.1325\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0183 - mae: 0.1526 - val_loss: 0.0248 - val_mae: 0.1323\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0179 - mae: 0.1482 - val_loss: 0.0248 - val_mae: 0.1322\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0180 - mae: 0.1475 - val_loss: 0.0247 - val_mae: 0.1321\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1536 - val_loss: 0.0247 - val_mae: 0.1319\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0205 - mae: 0.1519 - val_loss: 0.0247 - val_mae: 0.1318\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0197 - mae: 0.1557 - val_loss: 0.0247 - val_mae: 0.1316\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0184 - mae: 0.1475 - val_loss: 0.0247 - val_mae: 0.1315\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0179 - mae: 0.1489 - val_loss: 0.0246 - val_mae: 0.1314\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0196 - mae: 0.1519 - val_loss: 0.0246 - val_mae: 0.1312\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0172 - mae: 0.1491 - val_loss: 0.0246 - val_mae: 0.1311\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0188 - mae: 0.1570 - val_loss: 0.0246 - val_mae: 0.1310\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0169 - mae: 0.1422 - val_loss: 0.0245 - val_mae: 0.1308\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0177 - mae: 0.1487 - val_loss: 0.0245 - val_mae: 0.1307\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0158 - mae: 0.1411 - val_loss: 0.0245 - val_mae: 0.1306\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0180 - mae: 0.1509 - val_loss: 0.0245 - val_mae: 0.1304\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0195 - mae: 0.1523 - val_loss: 0.0245 - val_mae: 0.1303\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0171 - mae: 0.1441 - val_loss: 0.0244 - val_mae: 0.1302\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0182 - mae: 0.1496 - val_loss: 0.0244 - val_mae: 0.1300\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0167 - mae: 0.1437 - val_loss: 0.0244 - val_mae: 0.1299\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0174 - mae: 0.1510 - val_loss: 0.0244 - val_mae: 0.1298\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1476 - val_loss: 0.0244 - val_mae: 0.1296\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0187 - mae: 0.1523 - val_loss: 0.0243 - val_mae: 0.1295\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0172 - mae: 0.1477 - val_loss: 0.0243 - val_mae: 0.1294\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0177 - mae: 0.1518 - val_loss: 0.0243 - val_mae: 0.1292\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0152 - mae: 0.1377 - val_loss: 0.0243 - val_mae: 0.1291\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0162 - mae: 0.1420 - val_loss: 0.0243 - val_mae: 0.1290\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0188 - mae: 0.1540 - val_loss: 0.0242 - val_mae: 0.1288\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1497 - val_loss: 0.0242 - val_mae: 0.1287\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0154 - mae: 0.1394 - val_loss: 0.0242 - val_mae: 0.1286\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0175 - mae: 0.1472 - val_loss: 0.0242 - val_mae: 0.1285\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0195 - mae: 0.1586 - val_loss: 0.0242 - val_mae: 0.1283\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0159 - mae: 0.1441 - val_loss: 0.0241 - val_mae: 0.1282\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0159 - mae: 0.1421 - val_loss: 0.0241 - val_mae: 0.1281\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0147 - mae: 0.1342 - val_loss: 0.0241 - val_mae: 0.1279\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0175 - mae: 0.1489 - val_loss: 0.0241 - val_mae: 0.1278\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0171 - mae: 0.1452 - val_loss: 0.0241 - val_mae: 0.1277\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0175 - mae: 0.1484 - val_loss: 0.0240 - val_mae: 0.1276\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0172 - mae: 0.1470 - val_loss: 0.0240 - val_mae: 0.1274\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1348 - val_loss: 0.0240 - val_mae: 0.1273\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - mae: 0.1313 - val_loss: 0.0240 - val_mae: 0.1272\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0160 - mae: 0.1451 - val_loss: 0.0240 - val_mae: 0.1270\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1392 - val_loss: 0.0239 - val_mae: 0.1269\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0180 - mae: 0.1501 - val_loss: 0.0239 - val_mae: 0.1268\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0171 - mae: 0.1481 - val_loss: 0.0239 - val_mae: 0.1267\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0158 - mae: 0.1383 - val_loss: 0.0239 - val_mae: 0.1265\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - mae: 0.1588 - val_loss: 0.0239 - val_mae: 0.1264\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - mae: 0.1391 - val_loss: 0.0238 - val_mae: 0.1263\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1537 - val_loss: 0.0238 - val_mae: 0.1262\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0176 - mae: 0.1475 - val_loss: 0.0238 - val_mae: 0.1260\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0170 - mae: 0.1477 - val_loss: 0.0238 - val_mae: 0.1259\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0164 - mae: 0.1454 - val_loss: 0.0238 - val_mae: 0.1258\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0176 - mae: 0.1474 - val_loss: 0.0237 - val_mae: 0.1256\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0153 - mae: 0.1343 - val_loss: 0.0237 - val_mae: 0.1255\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0168 - mae: 0.1427 - val_loss: 0.0237 - val_mae: 0.1254\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0182 - mae: 0.1492 - val_loss: 0.0237 - val_mae: 0.1253\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1566 - val_loss: 0.0237 - val_mae: 0.1251\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0153 - mae: 0.1425 - val_loss: 0.0237 - val_mae: 0.1250\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0166 - mae: 0.1395 - val_loss: 0.0236 - val_mae: 0.1249\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0173 - mae: 0.1459 - val_loss: 0.0236 - val_mae: 0.1248\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0164 - mae: 0.1448 - val_loss: 0.0236 - val_mae: 0.1247\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0155 - mae: 0.1398 - val_loss: 0.0236 - val_mae: 0.1245\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0161 - mae: 0.1415 - val_loss: 0.0236 - val_mae: 0.1244\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0176 - mae: 0.1505 - val_loss: 0.0235 - val_mae: 0.1243\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0173 - mae: 0.1479 - val_loss: 0.0235 - val_mae: 0.1242\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0177 - mae: 0.1452 - val_loss: 0.0235 - val_mae: 0.1241\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0162 - mae: 0.1392 - val_loss: 0.0235 - val_mae: 0.1239\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0162 - mae: 0.1413 - val_loss: 0.0235 - val_mae: 0.1238\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0148 - mae: 0.1390 - val_loss: 0.0235 - val_mae: 0.1237\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0158 - mae: 0.1412 - val_loss: 0.0234 - val_mae: 0.1236\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0160 - mae: 0.1417 - val_loss: 0.0234 - val_mae: 0.1235\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0162 - mae: 0.1410 - val_loss: 0.0234 - val_mae: 0.1233\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0168 - mae: 0.1405 - val_loss: 0.0234 - val_mae: 0.1232\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - mae: 0.1520 - val_loss: 0.0234 - val_mae: 0.1231\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0159 - mae: 0.1386 - val_loss: 0.0234 - val_mae: 0.1230\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0154 - mae: 0.1422 - val_loss: 0.0233 - val_mae: 0.1229\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0151 - mae: 0.1395 - val_loss: 0.0233 - val_mae: 0.1227\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0172 - mae: 0.1442 - val_loss: 0.0233 - val_mae: 0.1226\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1436 - val_loss: 0.0233 - val_mae: 0.1225\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0149 - mae: 0.1371 - val_loss: 0.0233 - val_mae: 0.1224\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0164 - mae: 0.1494 - val_loss: 0.0232 - val_mae: 0.1223\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0166 - mae: 0.1401 - val_loss: 0.0232 - val_mae: 0.1221\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0143 - mae: 0.1355 - val_loss: 0.0232 - val_mae: 0.1220\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1553 - val_loss: 0.0232 - val_mae: 0.1219\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0174 - mae: 0.1459 - val_loss: 0.0232 - val_mae: 0.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:14,408] Trial 8 finished with value: 0.12178070843219757 and parameters: {'learning_rate': 1.9288162712327108e-06, 'weight_decay': 7.98241828617631e-05}. Best is trial 7 with value: 0.07824554294347763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - mae: 0.1561 - val_loss: 0.0288 - val_mae: 0.1503\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0194 - mae: 0.1599 - val_loss: 0.0288 - val_mae: 0.1502\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0213 - mae: 0.1643 - val_loss: 0.0288 - val_mae: 0.1501\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0212 - mae: 0.1650 - val_loss: 0.0287 - val_mae: 0.1500\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0234 - mae: 0.1771 - val_loss: 0.0287 - val_mae: 0.1498\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0198 - mae: 0.1659 - val_loss: 0.0287 - val_mae: 0.1497\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0203 - mae: 0.1567 - val_loss: 0.0287 - val_mae: 0.1496\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0178 - mae: 0.1487 - val_loss: 0.0286 - val_mae: 0.1494\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0220 - mae: 0.1654 - val_loss: 0.0286 - val_mae: 0.1493\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0195 - mae: 0.1577 - val_loss: 0.0286 - val_mae: 0.1492\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0192 - mae: 0.1580 - val_loss: 0.0286 - val_mae: 0.1490\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0202 - mae: 0.1598 - val_loss: 0.0286 - val_mae: 0.1489\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0174 - mae: 0.1467 - val_loss: 0.0285 - val_mae: 0.1488\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0202 - mae: 0.1610 - val_loss: 0.0285 - val_mae: 0.1486\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0174 - mae: 0.1471 - val_loss: 0.0285 - val_mae: 0.1485\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0201 - mae: 0.1632 - val_loss: 0.0285 - val_mae: 0.1484\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1695 - val_loss: 0.0285 - val_mae: 0.1483\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0193 - mae: 0.1574 - val_loss: 0.0284 - val_mae: 0.1481\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0196 - mae: 0.1562 - val_loss: 0.0284 - val_mae: 0.1480\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - mae: 0.1600 - val_loss: 0.0284 - val_mae: 0.1479\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0198 - mae: 0.1599 - val_loss: 0.0284 - val_mae: 0.1477\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0231 - mae: 0.1732 - val_loss: 0.0283 - val_mae: 0.1476\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0196 - mae: 0.1575 - val_loss: 0.0283 - val_mae: 0.1475\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0194 - mae: 0.1588 - val_loss: 0.0283 - val_mae: 0.1473\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0227 - mae: 0.1692 - val_loss: 0.0283 - val_mae: 0.1472\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0194 - mae: 0.1536 - val_loss: 0.0283 - val_mae: 0.1471\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0234 - mae: 0.1702 - val_loss: 0.0282 - val_mae: 0.1469\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0172 - mae: 0.1469 - val_loss: 0.0282 - val_mae: 0.1468\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0195 - mae: 0.1539 - val_loss: 0.0282 - val_mae: 0.1467\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0202 - mae: 0.1594 - val_loss: 0.0282 - val_mae: 0.1465\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - mae: 0.1555 - val_loss: 0.0281 - val_mae: 0.1464\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - mae: 0.1416 - val_loss: 0.0281 - val_mae: 0.1463\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0211 - mae: 0.1648 - val_loss: 0.0281 - val_mae: 0.1462\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0202 - mae: 0.1575 - val_loss: 0.0281 - val_mae: 0.1460\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1491 - val_loss: 0.0281 - val_mae: 0.1459\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0208 - mae: 0.1616 - val_loss: 0.0280 - val_mae: 0.1458\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0219 - mae: 0.1672 - val_loss: 0.0280 - val_mae: 0.1456\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1479 - val_loss: 0.0280 - val_mae: 0.1455\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0207 - mae: 0.1666 - val_loss: 0.0280 - val_mae: 0.1454\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1459 - val_loss: 0.0280 - val_mae: 0.1453\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0218 - mae: 0.1653 - val_loss: 0.0279 - val_mae: 0.1451\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0180 - mae: 0.1517 - val_loss: 0.0279 - val_mae: 0.1450\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0195 - mae: 0.1529 - val_loss: 0.0279 - val_mae: 0.1449\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0185 - mae: 0.1542 - val_loss: 0.0279 - val_mae: 0.1448\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0178 - mae: 0.1525 - val_loss: 0.0278 - val_mae: 0.1446\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0185 - mae: 0.1546 - val_loss: 0.0278 - val_mae: 0.1445\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0191 - mae: 0.1555 - val_loss: 0.0278 - val_mae: 0.1444\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0179 - mae: 0.1485 - val_loss: 0.0278 - val_mae: 0.1443\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0180 - mae: 0.1524 - val_loss: 0.0278 - val_mae: 0.1442\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0191 - mae: 0.1600 - val_loss: 0.0277 - val_mae: 0.1440\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - mae: 0.1513 - val_loss: 0.0277 - val_mae: 0.1439\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1566 - val_loss: 0.0277 - val_mae: 0.1438\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0197 - mae: 0.1619 - val_loss: 0.0277 - val_mae: 0.1437\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1509 - val_loss: 0.0277 - val_mae: 0.1435\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0192 - mae: 0.1566 - val_loss: 0.0276 - val_mae: 0.1434\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0189 - mae: 0.1541 - val_loss: 0.0276 - val_mae: 0.1433\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0185 - mae: 0.1538 - val_loss: 0.0276 - val_mae: 0.1432\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - mae: 0.1518 - val_loss: 0.0276 - val_mae: 0.1430\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1545 - val_loss: 0.0276 - val_mae: 0.1429\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0191 - mae: 0.1549 - val_loss: 0.0275 - val_mae: 0.1428\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0193 - mae: 0.1561 - val_loss: 0.0275 - val_mae: 0.1427\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0165 - mae: 0.1456 - val_loss: 0.0275 - val_mae: 0.1425\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0198 - mae: 0.1635 - val_loss: 0.0275 - val_mae: 0.1424\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0178 - mae: 0.1478 - val_loss: 0.0275 - val_mae: 0.1423\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mae: 0.1502 - val_loss: 0.0274 - val_mae: 0.1422\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0177 - mae: 0.1476 - val_loss: 0.0274 - val_mae: 0.1421\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0199 - mae: 0.1553 - val_loss: 0.0274 - val_mae: 0.1419\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0188 - mae: 0.1485 - val_loss: 0.0274 - val_mae: 0.1418\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mae: 0.1512 - val_loss: 0.0274 - val_mae: 0.1417\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0173 - mae: 0.1477 - val_loss: 0.0273 - val_mae: 0.1416\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0197 - mae: 0.1594 - val_loss: 0.0273 - val_mae: 0.1414\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0182 - mae: 0.1542 - val_loss: 0.0273 - val_mae: 0.1413\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0155 - mae: 0.1397 - val_loss: 0.0273 - val_mae: 0.1412\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0170 - mae: 0.1458 - val_loss: 0.0273 - val_mae: 0.1411\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0173 - mae: 0.1403 - val_loss: 0.0273 - val_mae: 0.1410\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0202 - mae: 0.1608 - val_loss: 0.0272 - val_mae: 0.1408\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0167 - mae: 0.1439 - val_loss: 0.0272 - val_mae: 0.1407\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0190 - mae: 0.1571 - val_loss: 0.0272 - val_mae: 0.1406\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1532 - val_loss: 0.0272 - val_mae: 0.1405\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0184 - mae: 0.1519 - val_loss: 0.0272 - val_mae: 0.1403\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0187 - mae: 0.1461 - val_loss: 0.0271 - val_mae: 0.1402\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - mae: 0.1514 - val_loss: 0.0271 - val_mae: 0.1401\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0165 - mae: 0.1448 - val_loss: 0.0271 - val_mae: 0.1400\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0172 - mae: 0.1418 - val_loss: 0.0271 - val_mae: 0.1399\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0203 - mae: 0.1581 - val_loss: 0.0271 - val_mae: 0.1397\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1551 - val_loss: 0.0271 - val_mae: 0.1396\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0175 - mae: 0.1467 - val_loss: 0.0270 - val_mae: 0.1395\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0186 - mae: 0.1460 - val_loss: 0.0270 - val_mae: 0.1394\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0192 - mae: 0.1528 - val_loss: 0.0270 - val_mae: 0.1393\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - mae: 0.1366 - val_loss: 0.0270 - val_mae: 0.1392\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0194 - mae: 0.1613 - val_loss: 0.0270 - val_mae: 0.1390\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0187 - mae: 0.1531 - val_loss: 0.0269 - val_mae: 0.1389\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0165 - mae: 0.1451 - val_loss: 0.0269 - val_mae: 0.1388\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0169 - mae: 0.1505 - val_loss: 0.0269 - val_mae: 0.1387\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0175 - mae: 0.1460 - val_loss: 0.0269 - val_mae: 0.1386\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - mae: 0.1394 - val_loss: 0.0269 - val_mae: 0.1385\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0196 - mae: 0.1600 - val_loss: 0.0268 - val_mae: 0.1383\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0213 - mae: 0.1625 - val_loss: 0.0268 - val_mae: 0.1382\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1540 - val_loss: 0.0268 - val_mae: 0.1381\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0180 - mae: 0.1511 - val_loss: 0.0268 - val_mae: 0.1380\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0186 - mae: 0.1554 - val_loss: 0.0268 - val_mae: 0.1379\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0179 - mae: 0.1454 - val_loss: 0.0268 - val_mae: 0.1378\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0186 - mae: 0.1533 - val_loss: 0.0267 - val_mae: 0.1376\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0182 - mae: 0.1569 - val_loss: 0.0267 - val_mae: 0.1375\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0211 - mae: 0.1620 - val_loss: 0.0267 - val_mae: 0.1374\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0171 - mae: 0.1470 - val_loss: 0.0267 - val_mae: 0.1373\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0190 - mae: 0.1585 - val_loss: 0.0267 - val_mae: 0.1372\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - mae: 0.1513 - val_loss: 0.0266 - val_mae: 0.1370\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0196 - mae: 0.1555 - val_loss: 0.0266 - val_mae: 0.1369\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0195 - mae: 0.1540 - val_loss: 0.0266 - val_mae: 0.1368\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0159 - mae: 0.1423 - val_loss: 0.0266 - val_mae: 0.1367\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1464 - val_loss: 0.0266 - val_mae: 0.1366\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0166 - mae: 0.1441 - val_loss: 0.0266 - val_mae: 0.1365\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0164 - mae: 0.1409 - val_loss: 0.0265 - val_mae: 0.1363\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0169 - mae: 0.1405 - val_loss: 0.0265 - val_mae: 0.1362\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0176 - mae: 0.1450 - val_loss: 0.0265 - val_mae: 0.1361\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0185 - mae: 0.1538 - val_loss: 0.0265 - val_mae: 0.1360\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0195 - mae: 0.1553 - val_loss: 0.0265 - val_mae: 0.1359\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1506 - val_loss: 0.0264 - val_mae: 0.1358\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0152 - mae: 0.1398 - val_loss: 0.0264 - val_mae: 0.1357\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0174 - mae: 0.1491 - val_loss: 0.0264 - val_mae: 0.1355\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0180 - mae: 0.1514 - val_loss: 0.0264 - val_mae: 0.1354\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0167 - mae: 0.1506 - val_loss: 0.0264 - val_mae: 0.1353\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0157 - mae: 0.1418 - val_loss: 0.0264 - val_mae: 0.1352\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - mae: 0.1416 - val_loss: 0.0263 - val_mae: 0.1351\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0172 - mae: 0.1474 - val_loss: 0.0263 - val_mae: 0.1350\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0175 - mae: 0.1470 - val_loss: 0.0263 - val_mae: 0.1349\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0174 - mae: 0.1461 - val_loss: 0.0263 - val_mae: 0.1348\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - mae: 0.1550 - val_loss: 0.0263 - val_mae: 0.1346\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0179 - mae: 0.1494 - val_loss: 0.0262 - val_mae: 0.1345\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0184 - mae: 0.1467 - val_loss: 0.0262 - val_mae: 0.1344\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0202 - mae: 0.1581 - val_loss: 0.0262 - val_mae: 0.1343\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0190 - mae: 0.1578 - val_loss: 0.0262 - val_mae: 0.1342\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0191 - mae: 0.1585 - val_loss: 0.0262 - val_mae: 0.1341\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0162 - mae: 0.1359 - val_loss: 0.0262 - val_mae: 0.1340\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0155 - mae: 0.1359 - val_loss: 0.0261 - val_mae: 0.1338\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0159 - mae: 0.1399 - val_loss: 0.0261 - val_mae: 0.1337\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0160 - mae: 0.1418 - val_loss: 0.0261 - val_mae: 0.1336\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0183 - mae: 0.1541 - val_loss: 0.0261 - val_mae: 0.1335\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0189 - mae: 0.1486 - val_loss: 0.0261 - val_mae: 0.1334\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0168 - mae: 0.1437 - val_loss: 0.0261 - val_mae: 0.1333\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1345 - val_loss: 0.0260 - val_mae: 0.1332\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1476 - val_loss: 0.0260 - val_mae: 0.1331\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0174 - mae: 0.1464 - val_loss: 0.0260 - val_mae: 0.1330\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0170 - mae: 0.1441 - val_loss: 0.0260 - val_mae: 0.1328\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0185 - mae: 0.1547 - val_loss: 0.0260 - val_mae: 0.1327\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0177 - mae: 0.1440 - val_loss: 0.0260 - val_mae: 0.1326\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0171 - mae: 0.1421 - val_loss: 0.0259 - val_mae: 0.1325\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0167 - mae: 0.1423 - val_loss: 0.0259 - val_mae: 0.1324\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0158 - mae: 0.1445 - val_loss: 0.0259 - val_mae: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:24,629] Trial 9 finished with value: 0.13230223953723907 and parameters: {'learning_rate': 1.6182561470878897e-06, 'weight_decay': 0.0033652273365982303}. Best is trial 7 with value: 0.07824554294347763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0179 - mae: 0.1504 - val_loss: 0.0232 - val_mae: 0.1243\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0154 - mae: 0.1360 - val_loss: 0.0230 - val_mae: 0.1230\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0145 - mae: 0.1327 - val_loss: 0.0228 - val_mae: 0.1216\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0164 - mae: 0.1435 - val_loss: 0.0226 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0179 - mae: 0.1492 - val_loss: 0.0224 - val_mae: 0.1188\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - mae: 0.1443 - val_loss: 0.0222 - val_mae: 0.1174\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1334 - val_loss: 0.0220 - val_mae: 0.1160\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0156 - mae: 0.1366 - val_loss: 0.0218 - val_mae: 0.1147\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0139 - mae: 0.1266 - val_loss: 0.0217 - val_mae: 0.1134\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0142 - mae: 0.1353 - val_loss: 0.0215 - val_mae: 0.1122\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0141 - mae: 0.1327 - val_loss: 0.0213 - val_mae: 0.1110\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0138 - mae: 0.1310 - val_loss: 0.0212 - val_mae: 0.1099\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0134 - mae: 0.1270 - val_loss: 0.0210 - val_mae: 0.1088\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0128 - mae: 0.1220 - val_loss: 0.0209 - val_mae: 0.1077\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0132 - mae: 0.1286 - val_loss: 0.0207 - val_mae: 0.1067\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0119 - mae: 0.1218 - val_loss: 0.0206 - val_mae: 0.1057\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0119 - mae: 0.1190 - val_loss: 0.0205 - val_mae: 0.1048\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0140 - mae: 0.1336 - val_loss: 0.0204 - val_mae: 0.1038\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0129 - mae: 0.1294 - val_loss: 0.0202 - val_mae: 0.1028\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0120 - mae: 0.1217 - val_loss: 0.0201 - val_mae: 0.1019\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0127 - mae: 0.1246 - val_loss: 0.0200 - val_mae: 0.1010\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - mae: 0.1254 - val_loss: 0.0199 - val_mae: 0.1002\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0136 - mae: 0.1282 - val_loss: 0.0198 - val_mae: 0.0994\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0124 - mae: 0.1218 - val_loss: 0.0197 - val_mae: 0.0986\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0119 - mae: 0.1218 - val_loss: 0.0196 - val_mae: 0.0979\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0122 - mae: 0.1216 - val_loss: 0.0195 - val_mae: 0.0971\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0195 - val_mae: 0.0965\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0194 - val_mae: 0.0958\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0193 - val_mae: 0.0951\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0192 - val_mae: 0.0945\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0191 - val_mae: 0.0939\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0191 - val_mae: 0.0933\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1098 - val_loss: 0.0190 - val_mae: 0.0927\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0190 - val_mae: 0.0922\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0093 - mae: 0.1017 - val_loss: 0.0189 - val_mae: 0.0916\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0102 - mae: 0.1081 - val_loss: 0.0189 - val_mae: 0.0911\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0188 - val_mae: 0.0906\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0188 - val_mae: 0.0901\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1037 - val_loss: 0.0187 - val_mae: 0.0897\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0187 - val_mae: 0.0892\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0107 - mae: 0.1136 - val_loss: 0.0186 - val_mae: 0.0887\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1124 - val_loss: 0.0186 - val_mae: 0.0883\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0107 - mae: 0.1101 - val_loss: 0.0186 - val_mae: 0.0878\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0185 - val_mae: 0.0874\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0185 - val_mae: 0.0870\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0185 - val_mae: 0.0866\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0184 - val_mae: 0.0862\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0184 - val_mae: 0.0859\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0091 - mae: 0.1055 - val_loss: 0.0184 - val_mae: 0.0856\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.1022 - val_loss: 0.0184 - val_mae: 0.0853\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0183 - val_mae: 0.0850\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.1014 - val_loss: 0.0183 - val_mae: 0.0848\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0183 - val_mae: 0.0845\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0183 - val_mae: 0.0843\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1092 - val_loss: 0.0183 - val_mae: 0.0841\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - mae: 0.0943 - val_loss: 0.0182 - val_mae: 0.0839\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0986 - val_loss: 0.0182 - val_mae: 0.0837\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0961 - val_loss: 0.0182 - val_mae: 0.0835\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.1008 - val_loss: 0.0182 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.1051 - val_loss: 0.0182 - val_mae: 0.0832\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0961 - val_loss: 0.0181 - val_mae: 0.0830\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0912 - val_loss: 0.0181 - val_mae: 0.0828\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0929 - val_loss: 0.0181 - val_mae: 0.0827\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0998 - val_loss: 0.0181 - val_mae: 0.0825\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1020 - val_loss: 0.0181 - val_mae: 0.0824\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0970 - val_loss: 0.0180 - val_mae: 0.0822\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0967 - val_loss: 0.0180 - val_mae: 0.0821\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0180 - val_mae: 0.0819\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0180 - val_mae: 0.0818\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0074 - mae: 0.0952 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0179 - val_mae: 0.0814\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0847 - val_loss: 0.0179 - val_mae: 0.0813\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0890 - val_loss: 0.0179 - val_mae: 0.0813\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0895 - val_loss: 0.0179 - val_mae: 0.0812\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0074 - mae: 0.0922 - val_loss: 0.0179 - val_mae: 0.0811\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0076 - mae: 0.0928 - val_loss: 0.0179 - val_mae: 0.0810\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0905 - val_loss: 0.0178 - val_mae: 0.0810\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0072 - mae: 0.0909 - val_loss: 0.0178 - val_mae: 0.0809\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0081 - mae: 0.0942 - val_loss: 0.0178 - val_mae: 0.0808\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0074 - mae: 0.0941 - val_loss: 0.0178 - val_mae: 0.0806\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0177 - val_mae: 0.0805\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0869 - val_loss: 0.0177 - val_mae: 0.0804\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0933 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0967 - val_loss: 0.0177 - val_mae: 0.0800\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0176 - val_mae: 0.0799\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0925 - val_loss: 0.0176 - val_mae: 0.0798\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0061 - mae: 0.0856 - val_loss: 0.0176 - val_mae: 0.0797\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0969 - val_loss: 0.0176 - val_mae: 0.0796\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0176 - val_mae: 0.0795\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - mae: 0.0928 - val_loss: 0.0176 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0875 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0904 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0881 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0074 - mae: 0.0944 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0850 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0819 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0061 - mae: 0.0800 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0856 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0062 - mae: 0.0817 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0066 - mae: 0.0902 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0928 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0068 - mae: 0.0872 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0065 - mae: 0.0870 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0861 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0944 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0909 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - mae: 0.0875 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0898 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0855 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - mae: 0.0949 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0071 - mae: 0.0908 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - mae: 0.0844 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0820 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - mae: 0.0882 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0063 - mae: 0.0856 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - mae: 0.0796 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0874 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0875 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0885 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0816 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0885 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0797 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0901 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0857 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - mae: 0.0873 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0065 - mae: 0.0859 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - mae: 0.0870 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - mae: 0.0832 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0773 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0060 - mae: 0.0821 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0056 - mae: 0.0797 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0817 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - mae: 0.0785 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0811 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0061 - mae: 0.0865 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0059 - mae: 0.0814 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0836 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0797 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0750 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - mae: 0.0800 - val_loss: 0.0172 - val_mae: 0.0780\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0821 - val_loss: 0.0172 - val_mae: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:34,934] Trial 10 finished with value: 0.07796110212802887 and parameters: {'learning_rate': 2.44251229921874e-05, 'weight_decay': 1.6081786471825142e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0234 - mae: 0.1685 - val_loss: 0.0296 - val_mae: 0.1551\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0211 - mae: 0.1647 - val_loss: 0.0294 - val_mae: 0.1541\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1686 - val_loss: 0.0292 - val_mae: 0.1530\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0223 - mae: 0.1665 - val_loss: 0.0290 - val_mae: 0.1519\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0199 - mae: 0.1638 - val_loss: 0.0287 - val_mae: 0.1508\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0213 - mae: 0.1619 - val_loss: 0.0285 - val_mae: 0.1496\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0168 - mae: 0.1418 - val_loss: 0.0283 - val_mae: 0.1485\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0210 - mae: 0.1608 - val_loss: 0.0281 - val_mae: 0.1474\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1661 - val_loss: 0.0279 - val_mae: 0.1463\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0170 - mae: 0.1458 - val_loss: 0.0277 - val_mae: 0.1452\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0197 - mae: 0.1552 - val_loss: 0.0275 - val_mae: 0.1442\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0178 - mae: 0.1470 - val_loss: 0.0273 - val_mae: 0.1431\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0207 - mae: 0.1582 - val_loss: 0.0271 - val_mae: 0.1421\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0202 - mae: 0.1583 - val_loss: 0.0269 - val_mae: 0.1410\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1498 - val_loss: 0.0267 - val_mae: 0.1400\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0200 - mae: 0.1614 - val_loss: 0.0265 - val_mae: 0.1390\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0218 - mae: 0.1642 - val_loss: 0.0263 - val_mae: 0.1379\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0201 - mae: 0.1543 - val_loss: 0.0261 - val_mae: 0.1369\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0167 - mae: 0.1496 - val_loss: 0.0260 - val_mae: 0.1359\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0150 - mae: 0.1358 - val_loss: 0.0258 - val_mae: 0.1349\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0183 - mae: 0.1469 - val_loss: 0.0256 - val_mae: 0.1339\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0189 - mae: 0.1550 - val_loss: 0.0254 - val_mae: 0.1329\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1464 - val_loss: 0.0253 - val_mae: 0.1319\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0162 - mae: 0.1385 - val_loss: 0.0251 - val_mae: 0.1309\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0177 - mae: 0.1460 - val_loss: 0.0250 - val_mae: 0.1300\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0161 - mae: 0.1392 - val_loss: 0.0248 - val_mae: 0.1291\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0153 - mae: 0.1371 - val_loss: 0.0247 - val_mae: 0.1282\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0177 - mae: 0.1479 - val_loss: 0.0245 - val_mae: 0.1273\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0168 - mae: 0.1449 - val_loss: 0.0244 - val_mae: 0.1264\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0171 - mae: 0.1432 - val_loss: 0.0242 - val_mae: 0.1255\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0156 - mae: 0.1418 - val_loss: 0.0241 - val_mae: 0.1246\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1404 - val_loss: 0.0239 - val_mae: 0.1238\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - mae: 0.1348 - val_loss: 0.0238 - val_mae: 0.1229\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0163 - mae: 0.1415 - val_loss: 0.0236 - val_mae: 0.1220\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0165 - mae: 0.1424 - val_loss: 0.0235 - val_mae: 0.1212\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0140 - mae: 0.1295 - val_loss: 0.0234 - val_mae: 0.1203\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0140 - mae: 0.1286 - val_loss: 0.0232 - val_mae: 0.1195\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1466 - val_loss: 0.0231 - val_mae: 0.1187\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0171 - mae: 0.1416 - val_loss: 0.0230 - val_mae: 0.1179\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0145 - mae: 0.1320 - val_loss: 0.0229 - val_mae: 0.1171\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0152 - mae: 0.1311 - val_loss: 0.0227 - val_mae: 0.1163\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0166 - mae: 0.1417 - val_loss: 0.0226 - val_mae: 0.1156\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0146 - mae: 0.1344 - val_loss: 0.0225 - val_mae: 0.1149\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0176 - mae: 0.1458 - val_loss: 0.0224 - val_mae: 0.1142\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1240 - val_loss: 0.0223 - val_mae: 0.1136\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0140 - mae: 0.1322 - val_loss: 0.0222 - val_mae: 0.1129\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0155 - mae: 0.1375 - val_loss: 0.0221 - val_mae: 0.1123\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0152 - mae: 0.1330 - val_loss: 0.0220 - val_mae: 0.1116\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0143 - mae: 0.1314 - val_loss: 0.0219 - val_mae: 0.1110\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0141 - mae: 0.1303 - val_loss: 0.0218 - val_mae: 0.1104\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0144 - mae: 0.1373 - val_loss: 0.0217 - val_mae: 0.1098\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0148 - mae: 0.1350 - val_loss: 0.0216 - val_mae: 0.1092\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0129 - mae: 0.1251 - val_loss: 0.0215 - val_mae: 0.1087\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - mae: 0.1304 - val_loss: 0.0214 - val_mae: 0.1081\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0128 - mae: 0.1241 - val_loss: 0.0213 - val_mae: 0.1075\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1167 - val_loss: 0.0212 - val_mae: 0.1070\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0131 - mae: 0.1238 - val_loss: 0.0211 - val_mae: 0.1064\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - mae: 0.1225 - val_loss: 0.0211 - val_mae: 0.1059\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0113 - mae: 0.1164 - val_loss: 0.0210 - val_mae: 0.1054\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0116 - mae: 0.1198 - val_loss: 0.0209 - val_mae: 0.1049\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1159 - val_loss: 0.0208 - val_mae: 0.1044\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - mae: 0.1197 - val_loss: 0.0208 - val_mae: 0.1039\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0125 - mae: 0.1225 - val_loss: 0.0207 - val_mae: 0.1035\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0109 - mae: 0.1134 - val_loss: 0.0206 - val_mae: 0.1030\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0206 - val_mae: 0.1025\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1160 - val_loss: 0.0205 - val_mae: 0.1021\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0103 - mae: 0.1112 - val_loss: 0.0204 - val_mae: 0.1017\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1065 - val_loss: 0.0204 - val_mae: 0.1013\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0106 - mae: 0.1108 - val_loss: 0.0203 - val_mae: 0.1008\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0114 - mae: 0.1202 - val_loss: 0.0202 - val_mae: 0.1004\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0126 - mae: 0.1274 - val_loss: 0.0202 - val_mae: 0.1000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0118 - mae: 0.1247 - val_loss: 0.0201 - val_mae: 0.0995\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0120 - mae: 0.1224 - val_loss: 0.0200 - val_mae: 0.0991\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0200 - val_mae: 0.0987\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0199 - val_mae: 0.0983\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1166 - val_loss: 0.0199 - val_mae: 0.0979\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0111 - mae: 0.1164 - val_loss: 0.0198 - val_mae: 0.0975\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0117 - mae: 0.1201 - val_loss: 0.0197 - val_mae: 0.0972\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0109 - mae: 0.1143 - val_loss: 0.0197 - val_mae: 0.0968\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.1048 - val_loss: 0.0196 - val_mae: 0.0965\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0103 - mae: 0.1112 - val_loss: 0.0196 - val_mae: 0.0962\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0195 - val_mae: 0.0959\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0115 - mae: 0.1164 - val_loss: 0.0195 - val_mae: 0.0956\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0110 - mae: 0.1160 - val_loss: 0.0194 - val_mae: 0.0952\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0194 - val_mae: 0.0949\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0194 - val_mae: 0.0946\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0193 - val_mae: 0.0943\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1162 - val_loss: 0.0193 - val_mae: 0.0940\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0116 - mae: 0.1150 - val_loss: 0.0192 - val_mae: 0.0937\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1066 - val_loss: 0.0192 - val_mae: 0.0934\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1075 - val_loss: 0.0192 - val_mae: 0.0931\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - mae: 0.1071 - val_loss: 0.0191 - val_mae: 0.0928\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0191 - val_mae: 0.0926\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0191 - val_mae: 0.0923\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0190 - val_mae: 0.0921\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0190 - val_mae: 0.0918\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0190 - val_mae: 0.0915\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0189 - val_mae: 0.0910\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0189 - val_mae: 0.0907\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0100 - mae: 0.1094 - val_loss: 0.0189 - val_mae: 0.0905\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0188 - val_mae: 0.0903\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0110 - mae: 0.1163 - val_loss: 0.0188 - val_mae: 0.0900\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0090 - mae: 0.1070 - val_loss: 0.0188 - val_mae: 0.0898\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1001 - val_loss: 0.0187 - val_mae: 0.0894\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0187 - val_mae: 0.0891\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - mae: 0.1116 - val_loss: 0.0187 - val_mae: 0.0889\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0186 - val_mae: 0.0887\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0186 - val_mae: 0.0884\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.0998 - val_loss: 0.0186 - val_mae: 0.0882\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0186 - val_mae: 0.0880\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0185 - val_mae: 0.0878\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1096 - val_loss: 0.0185 - val_mae: 0.0876\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0103 - mae: 0.1136 - val_loss: 0.0185 - val_mae: 0.0874\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0109 - mae: 0.1136 - val_loss: 0.0185 - val_mae: 0.0872\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0184 - val_mae: 0.0870\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0079 - mae: 0.0943 - val_loss: 0.0184 - val_mae: 0.0868\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0184 - val_mae: 0.0866\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0184 - val_mae: 0.0864\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0184 - val_mae: 0.0863\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0923 - val_loss: 0.0183 - val_mae: 0.0861\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0183 - val_mae: 0.0859\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0183 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0079 - mae: 0.0970 - val_loss: 0.0183 - val_mae: 0.0855\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0079 - mae: 0.0978 - val_loss: 0.0183 - val_mae: 0.0853\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0096 - mae: 0.1040 - val_loss: 0.0183 - val_mae: 0.0851\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0183 - val_mae: 0.0849\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0928 - val_loss: 0.0182 - val_mae: 0.0847\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0182 - val_mae: 0.0846\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - mae: 0.1112 - val_loss: 0.0182 - val_mae: 0.0845\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.0984 - val_loss: 0.0182 - val_mae: 0.0843\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0182 - val_mae: 0.0843\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0102 - mae: 0.1118 - val_loss: 0.0182 - val_mae: 0.0842\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0182 - val_mae: 0.0841\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0080 - mae: 0.0991 - val_loss: 0.0181 - val_mae: 0.0840\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0181 - val_mae: 0.0839\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0911 - val_loss: 0.0181 - val_mae: 0.0839\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0181 - val_mae: 0.0838\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.0982 - val_loss: 0.0181 - val_mae: 0.0837\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0181 - val_mae: 0.0837\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0934 - val_loss: 0.0181 - val_mae: 0.0836\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0945 - val_loss: 0.0181 - val_mae: 0.0835\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0088 - mae: 0.1034 - val_loss: 0.0180 - val_mae: 0.0835\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0967 - val_loss: 0.0180 - val_mae: 0.0834\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0992 - val_loss: 0.0180 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0994 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0091 - mae: 0.1064 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.0975 - val_loss: 0.0180 - val_mae: 0.0832\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.1011 - val_loss: 0.0180 - val_mae: 0.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:45,155] Trial 11 finished with value: 0.08319808542728424 and parameters: {'learning_rate': 1.4443159922897843e-05, 'weight_decay': 2.4575634127371804e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0228 - mae: 0.1767 - val_loss: 0.0323 - val_mae: 0.1639\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0232 - mae: 0.1738 - val_loss: 0.0312 - val_mae: 0.1587\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0204 - mae: 0.1598 - val_loss: 0.0302 - val_mae: 0.1536\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0201 - mae: 0.1623 - val_loss: 0.0292 - val_mae: 0.1484\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0207 - mae: 0.1571 - val_loss: 0.0282 - val_mae: 0.1433\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1534 - val_loss: 0.0273 - val_mae: 0.1382\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0187 - mae: 0.1565 - val_loss: 0.0264 - val_mae: 0.1332\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0183 - mae: 0.1536 - val_loss: 0.0256 - val_mae: 0.1284\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0154 - mae: 0.1359 - val_loss: 0.0249 - val_mae: 0.1237\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0146 - mae: 0.1350 - val_loss: 0.0242 - val_mae: 0.1192\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0162 - mae: 0.1399 - val_loss: 0.0235 - val_mae: 0.1150\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0157 - mae: 0.1393 - val_loss: 0.0229 - val_mae: 0.1111\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0136 - mae: 0.1264 - val_loss: 0.0224 - val_mae: 0.1077\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0128 - mae: 0.1245 - val_loss: 0.0219 - val_mae: 0.1044\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0125 - mae: 0.1252 - val_loss: 0.0214 - val_mae: 0.1013\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0136 - mae: 0.1302 - val_loss: 0.0209 - val_mae: 0.0983\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0138 - mae: 0.1333 - val_loss: 0.0205 - val_mae: 0.0958\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0101 - mae: 0.1137 - val_loss: 0.0202 - val_mae: 0.0937\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0117 - mae: 0.1191 - val_loss: 0.0198 - val_mae: 0.0917\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0114 - mae: 0.1155 - val_loss: 0.0195 - val_mae: 0.0897\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0112 - mae: 0.1174 - val_loss: 0.0192 - val_mae: 0.0879\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0120 - mae: 0.1174 - val_loss: 0.0190 - val_mae: 0.0866\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0187 - val_mae: 0.0854\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0106 - mae: 0.1123 - val_loss: 0.0185 - val_mae: 0.0843\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0183 - val_mae: 0.0834\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.0990 - val_loss: 0.0181 - val_mae: 0.0826\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0106 - mae: 0.1158 - val_loss: 0.0180 - val_mae: 0.0818\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0178 - val_mae: 0.0811\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0996 - val_loss: 0.0177 - val_mae: 0.0805\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1095 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0087 - mae: 0.1035 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0086 - mae: 0.1010 - val_loss: 0.0173 - val_mae: 0.0789\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.1033 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0969 - val_loss: 0.0171 - val_mae: 0.0783\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0966 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.1032 - val_loss: 0.0170 - val_mae: 0.0781\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.1000 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0081 - mae: 0.0995 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0953 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0892 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - mae: 0.0996 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.0998 - val_loss: 0.0170 - val_mae: 0.0781\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - mae: 0.0978 - val_loss: 0.0170 - val_mae: 0.0781\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0923 - val_loss: 0.0170 - val_mae: 0.0782\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0882 - val_loss: 0.0170 - val_mae: 0.0783\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0171 - val_mae: 0.0783\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0878 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0975 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0919 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0072 - mae: 0.0910 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0887 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - mae: 0.0926 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0936 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0977 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0917 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0864 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0059 - mae: 0.0840 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0876 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0861 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0867 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0817 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0866 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0803 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0849 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0871 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0865 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0055 - mae: 0.0789 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0889 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0810 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0052 - mae: 0.0774 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0911 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0860 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0049 - mae: 0.0769 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0886 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0829 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0847 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0807 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0805 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0806 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - mae: 0.0826 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0760 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0052 - mae: 0.0756 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0058 - mae: 0.0823 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0171 - val_mae: 0.0790\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0769 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - mae: 0.0727 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0052 - mae: 0.0777 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0780 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0739 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - mae: 0.0744 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - mae: 0.0769 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0053 - mae: 0.0755 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0780 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0787 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0779 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0769 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0799 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0762 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0056 - mae: 0.0800 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0751 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0755 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0802 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0737 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0741 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0708 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0059 - mae: 0.0796 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0732 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - mae: 0.0772 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0727 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0683 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0764 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0762 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0694 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0709 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0729 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0045 - mae: 0.0717 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0741 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0724 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0743 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0686 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0730 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0050 - mae: 0.0749 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0694 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0708 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0680 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0754 - val_loss: 0.0170 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0691 - val_loss: 0.0170 - val_mae: 0.0799\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mae: 0.0687 - val_loss: 0.0170 - val_mae: 0.0800\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0800\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0725 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0047 - mae: 0.0703 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0722 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0721 - val_loss: 0.0170 - val_mae: 0.0803\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0803\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0043 - mae: 0.0691 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0684 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0723 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0678 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - mae: 0.0721 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0708 - val_loss: 0.0169 - val_mae: 0.0805\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0714 - val_loss: 0.0169 - val_mae: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:56:55,879] Trial 12 finished with value: 0.08053125441074371 and parameters: {'learning_rate': 6.025500785009225e-05, 'weight_decay': 9.556986823563704e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0425 - mae: 0.2274 - val_loss: 0.0426 - val_mae: 0.2046\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0444 - mae: 0.2331 - val_loss: 0.0425 - val_mae: 0.2044\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0397 - mae: 0.2234 - val_loss: 0.0425 - val_mae: 0.2042\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0389 - mae: 0.2214 - val_loss: 0.0424 - val_mae: 0.2040\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0396 - mae: 0.2204 - val_loss: 0.0423 - val_mae: 0.2038\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0392 - mae: 0.2241 - val_loss: 0.0423 - val_mae: 0.2035\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0364 - mae: 0.2089 - val_loss: 0.0422 - val_mae: 0.2033\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0426 - mae: 0.2305 - val_loss: 0.0421 - val_mae: 0.2031\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0401 - mae: 0.2251 - val_loss: 0.0421 - val_mae: 0.2029\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0406 - mae: 0.2251 - val_loss: 0.0420 - val_mae: 0.2026\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0373 - mae: 0.2193 - val_loss: 0.0419 - val_mae: 0.2024\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0428 - mae: 0.2358 - val_loss: 0.0419 - val_mae: 0.2022\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0447 - mae: 0.2357 - val_loss: 0.0418 - val_mae: 0.2019\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0403 - mae: 0.2237 - val_loss: 0.0417 - val_mae: 0.2017\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0368 - mae: 0.2136 - val_loss: 0.0417 - val_mae: 0.2015\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0406 - mae: 0.2262 - val_loss: 0.0416 - val_mae: 0.2012\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0404 - mae: 0.2260 - val_loss: 0.0416 - val_mae: 0.2010\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0361 - mae: 0.2153 - val_loss: 0.0415 - val_mae: 0.2008\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0440 - mae: 0.2342 - val_loss: 0.0414 - val_mae: 0.2006\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0415 - mae: 0.2214 - val_loss: 0.0414 - val_mae: 0.2003\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0422 - mae: 0.2302 - val_loss: 0.0413 - val_mae: 0.2001\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0381 - mae: 0.2168 - val_loss: 0.0412 - val_mae: 0.1999\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0483 - mae: 0.2428 - val_loss: 0.0412 - val_mae: 0.1996\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0412 - mae: 0.2245 - val_loss: 0.0411 - val_mae: 0.1994\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0385 - mae: 0.2210 - val_loss: 0.0410 - val_mae: 0.1991\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0374 - mae: 0.2195 - val_loss: 0.0410 - val_mae: 0.1989\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0448 - mae: 0.2379 - val_loss: 0.0409 - val_mae: 0.1987\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0373 - mae: 0.2153 - val_loss: 0.0408 - val_mae: 0.1985\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0439 - mae: 0.2321 - val_loss: 0.0408 - val_mae: 0.1982\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0416 - mae: 0.2249 - val_loss: 0.0407 - val_mae: 0.1980\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0416 - mae: 0.2270 - val_loss: 0.0407 - val_mae: 0.1978\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0371 - mae: 0.2156 - val_loss: 0.0406 - val_mae: 0.1976\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0432 - mae: 0.2347 - val_loss: 0.0405 - val_mae: 0.1973\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0404 - mae: 0.2245 - val_loss: 0.0405 - val_mae: 0.1971\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0385 - mae: 0.2251 - val_loss: 0.0404 - val_mae: 0.1969\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0355 - mae: 0.2056 - val_loss: 0.0403 - val_mae: 0.1967\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0376 - mae: 0.2113 - val_loss: 0.0403 - val_mae: 0.1964\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0396 - mae: 0.2193 - val_loss: 0.0402 - val_mae: 0.1962\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0367 - mae: 0.2171 - val_loss: 0.0402 - val_mae: 0.1960\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0465 - mae: 0.2398 - val_loss: 0.0401 - val_mae: 0.1958\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0354 - mae: 0.2061 - val_loss: 0.0400 - val_mae: 0.1956\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0434 - mae: 0.2308 - val_loss: 0.0400 - val_mae: 0.1954\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0402 - mae: 0.2232 - val_loss: 0.0399 - val_mae: 0.1952\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0398 - mae: 0.2187 - val_loss: 0.0398 - val_mae: 0.1949\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0358 - mae: 0.2122 - val_loss: 0.0398 - val_mae: 0.1947\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0370 - mae: 0.2154 - val_loss: 0.0397 - val_mae: 0.1945\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0406 - mae: 0.2266 - val_loss: 0.0397 - val_mae: 0.1943\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0374 - mae: 0.2199 - val_loss: 0.0396 - val_mae: 0.1941\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0387 - mae: 0.2172 - val_loss: 0.0395 - val_mae: 0.1939\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0424 - mae: 0.2244 - val_loss: 0.0395 - val_mae: 0.1937\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0386 - mae: 0.2178 - val_loss: 0.0394 - val_mae: 0.1935\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0389 - mae: 0.2221 - val_loss: 0.0394 - val_mae: 0.1933\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0387 - mae: 0.2231 - val_loss: 0.0393 - val_mae: 0.1930\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0380 - mae: 0.2252 - val_loss: 0.0392 - val_mae: 0.1928\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0411 - mae: 0.2274 - val_loss: 0.0392 - val_mae: 0.1926\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0378 - mae: 0.2247 - val_loss: 0.0391 - val_mae: 0.1924\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0430 - mae: 0.2323 - val_loss: 0.0391 - val_mae: 0.1922\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0403 - mae: 0.2206 - val_loss: 0.0390 - val_mae: 0.1920\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0319 - mae: 0.1985 - val_loss: 0.0389 - val_mae: 0.1918\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0420 - mae: 0.2373 - val_loss: 0.0389 - val_mae: 0.1916\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0397 - mae: 0.2208 - val_loss: 0.0388 - val_mae: 0.1914\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0368 - mae: 0.2073 - val_loss: 0.0388 - val_mae: 0.1912\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0386 - mae: 0.2241 - val_loss: 0.0387 - val_mae: 0.1909\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0401 - mae: 0.2322 - val_loss: 0.0387 - val_mae: 0.1907\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0435 - mae: 0.2319 - val_loss: 0.0386 - val_mae: 0.1905\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0331 - mae: 0.2015 - val_loss: 0.0385 - val_mae: 0.1903\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0373 - mae: 0.2195 - val_loss: 0.0385 - val_mae: 0.1901\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0373 - mae: 0.2190 - val_loss: 0.0384 - val_mae: 0.1899\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0315 - mae: 0.1993 - val_loss: 0.0384 - val_mae: 0.1897\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0401 - mae: 0.2260 - val_loss: 0.0383 - val_mae: 0.1895\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0402 - mae: 0.2244 - val_loss: 0.0383 - val_mae: 0.1893\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0372 - mae: 0.2184 - val_loss: 0.0382 - val_mae: 0.1891\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0370 - mae: 0.2134 - val_loss: 0.0381 - val_mae: 0.1889\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0380 - mae: 0.2208 - val_loss: 0.0381 - val_mae: 0.1887\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0382 - mae: 0.2189 - val_loss: 0.0380 - val_mae: 0.1885\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0413 - mae: 0.2257 - val_loss: 0.0380 - val_mae: 0.1883\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0399 - mae: 0.2257 - val_loss: 0.0379 - val_mae: 0.1881\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0338 - mae: 0.2025 - val_loss: 0.0379 - val_mae: 0.1879\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0363 - mae: 0.2153 - val_loss: 0.0378 - val_mae: 0.1876\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0344 - mae: 0.2043 - val_loss: 0.0378 - val_mae: 0.1874\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0382 - mae: 0.2199 - val_loss: 0.0377 - val_mae: 0.1872\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - mae: 0.2118 - val_loss: 0.0376 - val_mae: 0.1870\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0395 - mae: 0.2239 - val_loss: 0.0376 - val_mae: 0.1868\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0384 - mae: 0.2179 - val_loss: 0.0375 - val_mae: 0.1866\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0419 - mae: 0.2255 - val_loss: 0.0375 - val_mae: 0.1864\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0371 - mae: 0.2137 - val_loss: 0.0374 - val_mae: 0.1862\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0362 - mae: 0.2162 - val_loss: 0.0374 - val_mae: 0.1860\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0362 - mae: 0.2146 - val_loss: 0.0373 - val_mae: 0.1858\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0419 - mae: 0.2302 - val_loss: 0.0373 - val_mae: 0.1856\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0343 - mae: 0.2125 - val_loss: 0.0372 - val_mae: 0.1854\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0380 - mae: 0.2238 - val_loss: 0.0371 - val_mae: 0.1852\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0353 - mae: 0.2089 - val_loss: 0.0371 - val_mae: 0.1850\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0374 - mae: 0.2192 - val_loss: 0.0370 - val_mae: 0.1848\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0382 - mae: 0.2172 - val_loss: 0.0370 - val_mae: 0.1846\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0384 - mae: 0.2220 - val_loss: 0.0369 - val_mae: 0.1844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0359 - mae: 0.2127 - val_loss: 0.0369 - val_mae: 0.1842\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0317 - mae: 0.1975 - val_loss: 0.0368 - val_mae: 0.1840\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0328 - mae: 0.2021 - val_loss: 0.0368 - val_mae: 0.1838\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0356 - mae: 0.2084 - val_loss: 0.0367 - val_mae: 0.1836\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0361 - mae: 0.2146 - val_loss: 0.0367 - val_mae: 0.1834\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0332 - mae: 0.1937 - val_loss: 0.0366 - val_mae: 0.1832\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0349 - mae: 0.2114 - val_loss: 0.0366 - val_mae: 0.1830\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0341 - mae: 0.2065 - val_loss: 0.0365 - val_mae: 0.1828\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0366 - mae: 0.2173 - val_loss: 0.0365 - val_mae: 0.1826\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0283 - mae: 0.1878 - val_loss: 0.0364 - val_mae: 0.1824\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0341 - mae: 0.2105 - val_loss: 0.0364 - val_mae: 0.1822\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0350 - mae: 0.2057 - val_loss: 0.0363 - val_mae: 0.1820\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0357 - mae: 0.2158 - val_loss: 0.0363 - val_mae: 0.1818\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0347 - mae: 0.2121 - val_loss: 0.0362 - val_mae: 0.1816\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0331 - mae: 0.2007 - val_loss: 0.0362 - val_mae: 0.1814\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0342 - mae: 0.2037 - val_loss: 0.0361 - val_mae: 0.1812\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0332 - mae: 0.2085 - val_loss: 0.0361 - val_mae: 0.1811\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0362 - mae: 0.2061 - val_loss: 0.0360 - val_mae: 0.1809\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0430 - mae: 0.2400 - val_loss: 0.0360 - val_mae: 0.1807\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0381 - mae: 0.2141 - val_loss: 0.0359 - val_mae: 0.1805\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0356 - mae: 0.2101 - val_loss: 0.0359 - val_mae: 0.1803\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0401 - mae: 0.2233 - val_loss: 0.0358 - val_mae: 0.1801\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0374 - mae: 0.2156 - val_loss: 0.0358 - val_mae: 0.1799\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0349 - mae: 0.2117 - val_loss: 0.0357 - val_mae: 0.1797\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0325 - mae: 0.2024 - val_loss: 0.0357 - val_mae: 0.1795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0321 - mae: 0.1995 - val_loss: 0.0356 - val_mae: 0.1793\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0336 - mae: 0.2063 - val_loss: 0.0356 - val_mae: 0.1791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0401 - mae: 0.2262 - val_loss: 0.0355 - val_mae: 0.1789\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0325 - mae: 0.2059 - val_loss: 0.0355 - val_mae: 0.1787\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0353 - mae: 0.2181 - val_loss: 0.0354 - val_mae: 0.1785\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0324 - mae: 0.2006 - val_loss: 0.0354 - val_mae: 0.1783\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0281 - mae: 0.1875 - val_loss: 0.0353 - val_mae: 0.1781\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0317 - mae: 0.2021 - val_loss: 0.0353 - val_mae: 0.1779\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0332 - mae: 0.2038 - val_loss: 0.0352 - val_mae: 0.1777\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0333 - mae: 0.2044 - val_loss: 0.0352 - val_mae: 0.1776\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0315 - mae: 0.1982 - val_loss: 0.0351 - val_mae: 0.1774\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0332 - mae: 0.2060 - val_loss: 0.0351 - val_mae: 0.1772\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0336 - mae: 0.2077 - val_loss: 0.0351 - val_mae: 0.1770\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0376 - mae: 0.2174 - val_loss: 0.0350 - val_mae: 0.1768\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0365 - mae: 0.2155 - val_loss: 0.0350 - val_mae: 0.1766\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0314 - mae: 0.2019 - val_loss: 0.0349 - val_mae: 0.1764\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0322 - mae: 0.1994 - val_loss: 0.0349 - val_mae: 0.1762\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0334 - mae: 0.2059 - val_loss: 0.0348 - val_mae: 0.1760\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0300 - mae: 0.1891 - val_loss: 0.0348 - val_mae: 0.1758\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0358 - mae: 0.2146 - val_loss: 0.0347 - val_mae: 0.1757\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0314 - mae: 0.1937 - val_loss: 0.0347 - val_mae: 0.1755\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0358 - mae: 0.2168 - val_loss: 0.0346 - val_mae: 0.1753\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0334 - mae: 0.2054 - val_loss: 0.0346 - val_mae: 0.1751\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0405 - mae: 0.2223 - val_loss: 0.0345 - val_mae: 0.1749\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0305 - mae: 0.1972 - val_loss: 0.0345 - val_mae: 0.1747\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0335 - mae: 0.2038 - val_loss: 0.0345 - val_mae: 0.1745\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0309 - mae: 0.1952 - val_loss: 0.0344 - val_mae: 0.1743\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0323 - mae: 0.2001 - val_loss: 0.0344 - val_mae: 0.1742\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0366 - mae: 0.2087 - val_loss: 0.0343 - val_mae: 0.1740\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0304 - mae: 0.1964 - val_loss: 0.0343 - val_mae: 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:06,172] Trial 13 finished with value: 0.1738041639328003 and parameters: {'learning_rate': 1.891350397944202e-06, 'weight_decay': 7.52298211964175e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0231 - mae: 0.1659 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0193 - mae: 0.1521 - val_loss: 0.0227 - val_mae: 0.1082\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0134 - mae: 0.1267 - val_loss: 0.0211 - val_mae: 0.0970\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0137 - mae: 0.1305 - val_loss: 0.0200 - val_mae: 0.0959\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0119 - mae: 0.1238 - val_loss: 0.0192 - val_mae: 0.0958\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0119 - mae: 0.1232 - val_loss: 0.0186 - val_mae: 0.0954\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0105 - mae: 0.1105 - val_loss: 0.0183 - val_mae: 0.0966\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0092 - mae: 0.1094 - val_loss: 0.0180 - val_mae: 0.0967\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0178 - val_mae: 0.0962\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0098 - mae: 0.1130 - val_loss: 0.0176 - val_mae: 0.0948\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0081 - mae: 0.1030 - val_loss: 0.0175 - val_mae: 0.0931\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0095 - mae: 0.1115 - val_loss: 0.0175 - val_mae: 0.0913\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0969 - val_loss: 0.0174 - val_mae: 0.0895\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0938 - val_loss: 0.0174 - val_mae: 0.0877\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0884 - val_loss: 0.0174 - val_mae: 0.0862\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0073 - mae: 0.0911 - val_loss: 0.0174 - val_mae: 0.0847\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0877 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0805 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - mae: 0.0861 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0056 - mae: 0.0798 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0834 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0803 - val_loss: 0.0176 - val_mae: 0.0784\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0767 - val_loss: 0.0176 - val_mae: 0.0781\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0176 - val_mae: 0.0779\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - mae: 0.0798 - val_loss: 0.0176 - val_mae: 0.0778\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0710 - val_loss: 0.0176 - val_mae: 0.0781\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0176 - val_mae: 0.0786\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0735 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0689 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0046 - mae: 0.0704 - val_loss: 0.0175 - val_mae: 0.0804\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0706 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0175 - val_mae: 0.0810\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0666 - val_loss: 0.0175 - val_mae: 0.0813\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0742 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - mae: 0.0709 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0740 - val_loss: 0.0176 - val_mae: 0.0818\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0044 - mae: 0.0707 - val_loss: 0.0176 - val_mae: 0.0818\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0821\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0674 - val_loss: 0.0176 - val_mae: 0.0823\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0823\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0671 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0659 - val_loss: 0.0176 - val_mae: 0.0809\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0175 - val_mae: 0.0806\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0175 - val_mae: 0.0804\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0175 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0599 - val_loss: 0.0175 - val_mae: 0.0802\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0543 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0174 - val_mae: 0.0805\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0530 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0845\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0172 - val_mae: 0.0833\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0504 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0507 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0172 - val_mae: 0.0835\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0518 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0520 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0500 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0475 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0511 - val_loss: 0.0173 - val_mae: 0.0840\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0172 - val_mae: 0.0843\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0466 - val_loss: 0.0172 - val_mae: 0.0848\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0497 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0172 - val_mae: 0.0857\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0473 - val_loss: 0.0171 - val_mae: 0.0857\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0495 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0460 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0453 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0448 - val_loss: 0.0171 - val_mae: 0.0844\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0422 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0168 - val_mae: 0.0868\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - mae: 0.0413 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0172 - val_mae: 0.0839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:16,386] Trial 14 finished with value: 0.08389332890510559 and parameters: {'learning_rate': 0.0002553989648807396, 'weight_decay': 2.526792420145048e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0222 - mae: 0.1680 - val_loss: 0.0316 - val_mae: 0.1658\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0255 - mae: 0.1816 - val_loss: 0.0312 - val_mae: 0.1638\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0209 - mae: 0.1590 - val_loss: 0.0307 - val_mae: 0.1617\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0215 - mae: 0.1650 - val_loss: 0.0303 - val_mae: 0.1596\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0228 - mae: 0.1683 - val_loss: 0.0299 - val_mae: 0.1575\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0241 - mae: 0.1760 - val_loss: 0.0294 - val_mae: 0.1554\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0220 - mae: 0.1625 - val_loss: 0.0290 - val_mae: 0.1533\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0186 - mae: 0.1526 - val_loss: 0.0286 - val_mae: 0.1512\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0204 - mae: 0.1588 - val_loss: 0.0282 - val_mae: 0.1491\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0200 - mae: 0.1584 - val_loss: 0.0278 - val_mae: 0.1470\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0184 - mae: 0.1525 - val_loss: 0.0275 - val_mae: 0.1449\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0200 - mae: 0.1593 - val_loss: 0.0271 - val_mae: 0.1429\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0173 - mae: 0.1457 - val_loss: 0.0268 - val_mae: 0.1409\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0168 - mae: 0.1452 - val_loss: 0.0264 - val_mae: 0.1390\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0195 - mae: 0.1484 - val_loss: 0.0261 - val_mae: 0.1371\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1539 - val_loss: 0.0258 - val_mae: 0.1352\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1476 - val_loss: 0.0255 - val_mae: 0.1334\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0173 - mae: 0.1489 - val_loss: 0.0252 - val_mae: 0.1315\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0183 - mae: 0.1490 - val_loss: 0.0249 - val_mae: 0.1297\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0158 - mae: 0.1378 - val_loss: 0.0247 - val_mae: 0.1279\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0161 - mae: 0.1384 - val_loss: 0.0244 - val_mae: 0.1261\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - mae: 0.1345 - val_loss: 0.0241 - val_mae: 0.1243\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0156 - mae: 0.1372 - val_loss: 0.0239 - val_mae: 0.1226\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0142 - mae: 0.1300 - val_loss: 0.0237 - val_mae: 0.1210\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0131 - mae: 0.1286 - val_loss: 0.0235 - val_mae: 0.1194\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0126 - mae: 0.1267 - val_loss: 0.0232 - val_mae: 0.1179\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - mae: 0.1177 - val_loss: 0.0230 - val_mae: 0.1164\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0116 - mae: 0.1202 - val_loss: 0.0228 - val_mae: 0.1150\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0129 - mae: 0.1280 - val_loss: 0.0227 - val_mae: 0.1136\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0126 - mae: 0.1207 - val_loss: 0.0225 - val_mae: 0.1122\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0140 - mae: 0.1332 - val_loss: 0.0223 - val_mae: 0.1109\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0125 - mae: 0.1272 - val_loss: 0.0221 - val_mae: 0.1096\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0123 - mae: 0.1223 - val_loss: 0.0219 - val_mae: 0.1083\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0142 - mae: 0.1266 - val_loss: 0.0218 - val_mae: 0.1070\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0141 - mae: 0.1285 - val_loss: 0.0216 - val_mae: 0.1057\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0125 - mae: 0.1231 - val_loss: 0.0215 - val_mae: 0.1045\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0137 - mae: 0.1238 - val_loss: 0.0213 - val_mae: 0.1033\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0120 - mae: 0.1212 - val_loss: 0.0212 - val_mae: 0.1021\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0117 - mae: 0.1199 - val_loss: 0.0211 - val_mae: 0.1010\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0117 - mae: 0.1181 - val_loss: 0.0209 - val_mae: 0.0999\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - mae: 0.1143 - val_loss: 0.0208 - val_mae: 0.0988\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0109 - mae: 0.1156 - val_loss: 0.0207 - val_mae: 0.0978\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1140 - val_loss: 0.0205 - val_mae: 0.0968\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1138 - val_loss: 0.0204 - val_mae: 0.0959\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0203 - val_mae: 0.0950\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - mae: 0.1088 - val_loss: 0.0202 - val_mae: 0.0942\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1099 - val_loss: 0.0201 - val_mae: 0.0934\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0109 - mae: 0.1178 - val_loss: 0.0200 - val_mae: 0.0927\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0092 - mae: 0.1080 - val_loss: 0.0199 - val_mae: 0.0919\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mae: 0.1132 - val_loss: 0.0199 - val_mae: 0.0912\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0099 - mae: 0.1099 - val_loss: 0.0198 - val_mae: 0.0906\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - mae: 0.1113 - val_loss: 0.0197 - val_mae: 0.0900\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0196 - val_mae: 0.0895\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.1030 - val_loss: 0.0196 - val_mae: 0.0890\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0195 - val_mae: 0.0885\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0094 - mae: 0.1027 - val_loss: 0.0194 - val_mae: 0.0881\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0114 - mae: 0.1144 - val_loss: 0.0194 - val_mae: 0.0876\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0193 - val_mae: 0.0872\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0101 - mae: 0.1082 - val_loss: 0.0192 - val_mae: 0.0867\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0091 - mae: 0.1055 - val_loss: 0.0192 - val_mae: 0.0863\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0094 - mae: 0.1091 - val_loss: 0.0191 - val_mae: 0.0860\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0106 - mae: 0.1134 - val_loss: 0.0191 - val_mae: 0.0856\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0102 - mae: 0.1088 - val_loss: 0.0190 - val_mae: 0.0852\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0190 - val_mae: 0.0849\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0972 - val_loss: 0.0190 - val_mae: 0.0846\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0085 - mae: 0.1011 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1008 - val_loss: 0.0189 - val_mae: 0.0839\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0188 - val_mae: 0.0836\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0083 - mae: 0.0947 - val_loss: 0.0188 - val_mae: 0.0834\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1001 - val_loss: 0.0188 - val_mae: 0.0831\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0080 - mae: 0.1003 - val_loss: 0.0187 - val_mae: 0.0828\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0898 - val_loss: 0.0187 - val_mae: 0.0826\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - mae: 0.1068 - val_loss: 0.0187 - val_mae: 0.0824\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - mae: 0.0942 - val_loss: 0.0186 - val_mae: 0.0822\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0084 - mae: 0.0997 - val_loss: 0.0186 - val_mae: 0.0820\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - mae: 0.0961 - val_loss: 0.0186 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0956 - val_loss: 0.0186 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0083 - mae: 0.1030 - val_loss: 0.0185 - val_mae: 0.0816\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0085 - mae: 0.1014 - val_loss: 0.0185 - val_mae: 0.0815\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0185 - val_mae: 0.0813\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0184 - val_mae: 0.0811\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0071 - mae: 0.0924 - val_loss: 0.0184 - val_mae: 0.0809\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0184 - val_mae: 0.0808\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0076 - mae: 0.0920 - val_loss: 0.0184 - val_mae: 0.0806\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0183 - val_mae: 0.0805\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0869 - val_loss: 0.0183 - val_mae: 0.0803\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - mae: 0.0905 - val_loss: 0.0183 - val_mae: 0.0802\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0940 - val_loss: 0.0183 - val_mae: 0.0801\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0183 - val_mae: 0.0800\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0977 - val_loss: 0.0182 - val_mae: 0.0799\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0085 - mae: 0.1006 - val_loss: 0.0182 - val_mae: 0.0799\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0894 - val_loss: 0.0182 - val_mae: 0.0798\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0088 - mae: 0.1068 - val_loss: 0.0182 - val_mae: 0.0798\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.1005 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0868 - val_loss: 0.0181 - val_mae: 0.0797\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.0980 - val_loss: 0.0181 - val_mae: 0.0797\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0909 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0897 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0898 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0076 - mae: 0.0941 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0977 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - mae: 0.0905 - val_loss: 0.0180 - val_mae: 0.0800\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0078 - mae: 0.0982 - val_loss: 0.0180 - val_mae: 0.0800\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.1021 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0908 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0865 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0848 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - mae: 0.0859 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0076 - mae: 0.0946 - val_loss: 0.0179 - val_mae: 0.0801\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0884 - val_loss: 0.0178 - val_mae: 0.0801\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0178 - val_mae: 0.0801\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - mae: 0.0896 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0885 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0067 - mae: 0.0916 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0843 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0834 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0073 - mae: 0.0910 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0060 - mae: 0.0863 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0922 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0078 - mae: 0.0986 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0879 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - mae: 0.0919 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - mae: 0.0902 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - mae: 0.0867 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0072 - mae: 0.0899 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0055 - mae: 0.0826 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0913 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0076 - mae: 0.0953 - val_loss: 0.0176 - val_mae: 0.0800\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0868 - val_loss: 0.0176 - val_mae: 0.0800\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - mae: 0.0864 - val_loss: 0.0176 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0900 - val_loss: 0.0176 - val_mae: 0.0798\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0815 - val_loss: 0.0176 - val_mae: 0.0798\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0062 - mae: 0.0877 - val_loss: 0.0176 - val_mae: 0.0797\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0797\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0176 - val_mae: 0.0796\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0920 - val_loss: 0.0176 - val_mae: 0.0795\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0864 - val_loss: 0.0176 - val_mae: 0.0794\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0869 - val_loss: 0.0176 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mae: 0.0876 - val_loss: 0.0176 - val_mae: 0.0794\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0062 - mae: 0.0838 - val_loss: 0.0176 - val_mae: 0.0793\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0846 - val_loss: 0.0176 - val_mae: 0.0793\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0887 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0916 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0058 - mae: 0.0842 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0069 - mae: 0.0928 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0791 - val_loss: 0.0176 - val_mae: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:26,553] Trial 15 finished with value: 0.07914000749588013 and parameters: {'learning_rate': 3.0426207670632304e-05, 'weight_decay': 9.639861519297356e-08}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0575 - mae: 0.2688 - val_loss: 0.0520 - val_mae: 0.2237\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0555 - mae: 0.2589 - val_loss: 0.0517 - val_mae: 0.2229\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0548 - mae: 0.2549 - val_loss: 0.0514 - val_mae: 0.2221\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0554 - mae: 0.2496 - val_loss: 0.0510 - val_mae: 0.2212\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0543 - mae: 0.2541 - val_loss: 0.0507 - val_mae: 0.2203\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0569 - mae: 0.2607 - val_loss: 0.0504 - val_mae: 0.2194\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0533 - mae: 0.2558 - val_loss: 0.0501 - val_mae: 0.2185\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0435 - mae: 0.2289 - val_loss: 0.0497 - val_mae: 0.2177\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0432 - mae: 0.2309 - val_loss: 0.0494 - val_mae: 0.2168\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0508 - mae: 0.2438 - val_loss: 0.0491 - val_mae: 0.2159\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0547 - mae: 0.2608 - val_loss: 0.0488 - val_mae: 0.2150\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0462 - mae: 0.2396 - val_loss: 0.0484 - val_mae: 0.2141\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0451 - mae: 0.2382 - val_loss: 0.0481 - val_mae: 0.2133\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0476 - mae: 0.2447 - val_loss: 0.0478 - val_mae: 0.2124\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0493 - mae: 0.2486 - val_loss: 0.0475 - val_mae: 0.2115\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0606 - mae: 0.2783 - val_loss: 0.0472 - val_mae: 0.2106\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0451 - mae: 0.2334 - val_loss: 0.0469 - val_mae: 0.2097\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0492 - mae: 0.2391 - val_loss: 0.0465 - val_mae: 0.2088\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0578 - mae: 0.2689 - val_loss: 0.0462 - val_mae: 0.2079\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0487 - mae: 0.2419 - val_loss: 0.0459 - val_mae: 0.2070\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0449 - mae: 0.2450 - val_loss: 0.0456 - val_mae: 0.2061\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0526 - mae: 0.2610 - val_loss: 0.0453 - val_mae: 0.2052\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0498 - mae: 0.2519 - val_loss: 0.0450 - val_mae: 0.2043\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0418 - mae: 0.2179 - val_loss: 0.0447 - val_mae: 0.2035\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0406 - mae: 0.2311 - val_loss: 0.0445 - val_mae: 0.2026\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0455 - mae: 0.2420 - val_loss: 0.0442 - val_mae: 0.2017\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0479 - mae: 0.2393 - val_loss: 0.0439 - val_mae: 0.2009\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0426 - mae: 0.2317 - val_loss: 0.0436 - val_mae: 0.2000\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0467 - mae: 0.2493 - val_loss: 0.0433 - val_mae: 0.1992\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0394 - mae: 0.2202 - val_loss: 0.0431 - val_mae: 0.1983\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0469 - mae: 0.2459 - val_loss: 0.0428 - val_mae: 0.1974\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0460 - mae: 0.2424 - val_loss: 0.0425 - val_mae: 0.1966\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0404 - mae: 0.2225 - val_loss: 0.0423 - val_mae: 0.1957\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0463 - mae: 0.2329 - val_loss: 0.0420 - val_mae: 0.1949\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0427 - mae: 0.2261 - val_loss: 0.0417 - val_mae: 0.1940\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0458 - mae: 0.2510 - val_loss: 0.0415 - val_mae: 0.1932\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0452 - mae: 0.2406 - val_loss: 0.0412 - val_mae: 0.1924\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0408 - mae: 0.2250 - val_loss: 0.0410 - val_mae: 0.1916\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0382 - mae: 0.2195 - val_loss: 0.0407 - val_mae: 0.1908\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0419 - mae: 0.2279 - val_loss: 0.0405 - val_mae: 0.1900\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0420 - mae: 0.2288 - val_loss: 0.0402 - val_mae: 0.1893\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0421 - mae: 0.2302 - val_loss: 0.0400 - val_mae: 0.1885\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0328 - mae: 0.2030 - val_loss: 0.0398 - val_mae: 0.1877\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0369 - mae: 0.2137 - val_loss: 0.0396 - val_mae: 0.1870\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0375 - mae: 0.2094 - val_loss: 0.0393 - val_mae: 0.1863\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0341 - mae: 0.2018 - val_loss: 0.0391 - val_mae: 0.1855\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0441 - mae: 0.2287 - val_loss: 0.0389 - val_mae: 0.1848\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0397 - mae: 0.2197 - val_loss: 0.0387 - val_mae: 0.1841\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0371 - mae: 0.2116 - val_loss: 0.0385 - val_mae: 0.1833\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0355 - mae: 0.2072 - val_loss: 0.0382 - val_mae: 0.1826\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0357 - mae: 0.2114 - val_loss: 0.0380 - val_mae: 0.1819\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0385 - mae: 0.2208 - val_loss: 0.0378 - val_mae: 0.1812\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0348 - mae: 0.2134 - val_loss: 0.0376 - val_mae: 0.1805\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0380 - mae: 0.2127 - val_loss: 0.0374 - val_mae: 0.1798\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0387 - mae: 0.2219 - val_loss: 0.0372 - val_mae: 0.1790\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0375 - mae: 0.2126 - val_loss: 0.0370 - val_mae: 0.1783\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0394 - mae: 0.2257 - val_loss: 0.0368 - val_mae: 0.1776\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0375 - mae: 0.2108 - val_loss: 0.0366 - val_mae: 0.1769\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0357 - mae: 0.2050 - val_loss: 0.0364 - val_mae: 0.1762\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0347 - mae: 0.2108 - val_loss: 0.0362 - val_mae: 0.1755\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0363 - mae: 0.2091 - val_loss: 0.0360 - val_mae: 0.1748\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0357 - mae: 0.2035 - val_loss: 0.0358 - val_mae: 0.1741\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0415 - mae: 0.2261 - val_loss: 0.0356 - val_mae: 0.1735\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0344 - mae: 0.2065 - val_loss: 0.0354 - val_mae: 0.1728\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0346 - mae: 0.2042 - val_loss: 0.0352 - val_mae: 0.1722\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0324 - mae: 0.2007 - val_loss: 0.0350 - val_mae: 0.1715\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0310 - mae: 0.1991 - val_loss: 0.0349 - val_mae: 0.1709\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - mae: 0.2051 - val_loss: 0.0347 - val_mae: 0.1702\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0330 - mae: 0.2064 - val_loss: 0.0345 - val_mae: 0.1696\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0330 - mae: 0.2044 - val_loss: 0.0343 - val_mae: 0.1690\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0377 - mae: 0.2128 - val_loss: 0.0341 - val_mae: 0.1683\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0318 - mae: 0.2026 - val_loss: 0.0340 - val_mae: 0.1677\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0319 - mae: 0.1974 - val_loss: 0.0338 - val_mae: 0.1671\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0326 - mae: 0.2064 - val_loss: 0.0336 - val_mae: 0.1664\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0338 - mae: 0.2044 - val_loss: 0.0335 - val_mae: 0.1658\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0328 - mae: 0.2026 - val_loss: 0.0333 - val_mae: 0.1652\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0323 - mae: 0.2004 - val_loss: 0.0331 - val_mae: 0.1646\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0330 - mae: 0.1969 - val_loss: 0.0330 - val_mae: 0.1640\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0329 - mae: 0.1939 - val_loss: 0.0328 - val_mae: 0.1634\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0272 - mae: 0.1857 - val_loss: 0.0327 - val_mae: 0.1628\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0303 - mae: 0.1892 - val_loss: 0.0325 - val_mae: 0.1622\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0329 - mae: 0.2056 - val_loss: 0.0324 - val_mae: 0.1616\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - mae: 0.2070 - val_loss: 0.0322 - val_mae: 0.1610\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0325 - mae: 0.1907 - val_loss: 0.0321 - val_mae: 0.1604\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0363 - mae: 0.2159 - val_loss: 0.0319 - val_mae: 0.1598\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0316 - mae: 0.1996 - val_loss: 0.0318 - val_mae: 0.1592\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0298 - mae: 0.1923 - val_loss: 0.0316 - val_mae: 0.1586\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0283 - mae: 0.1904 - val_loss: 0.0315 - val_mae: 0.1580\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0335 - mae: 0.2061 - val_loss: 0.0314 - val_mae: 0.1574\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0302 - mae: 0.1934 - val_loss: 0.0312 - val_mae: 0.1568\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0308 - mae: 0.1936 - val_loss: 0.0311 - val_mae: 0.1563\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0357 - mae: 0.2081 - val_loss: 0.0309 - val_mae: 0.1557\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.2054 - val_loss: 0.0308 - val_mae: 0.1551\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0291 - mae: 0.1908 - val_loss: 0.0307 - val_mae: 0.1546\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0283 - mae: 0.1867 - val_loss: 0.0305 - val_mae: 0.1540\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0292 - mae: 0.1882 - val_loss: 0.0304 - val_mae: 0.1534\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0292 - mae: 0.1908 - val_loss: 0.0303 - val_mae: 0.1529\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0290 - mae: 0.1829 - val_loss: 0.0302 - val_mae: 0.1523\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0286 - mae: 0.1893 - val_loss: 0.0300 - val_mae: 0.1518\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0289 - mae: 0.1903 - val_loss: 0.0299 - val_mae: 0.1512\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0282 - mae: 0.1880 - val_loss: 0.0298 - val_mae: 0.1507\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0299 - mae: 0.1908 - val_loss: 0.0297 - val_mae: 0.1502\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0273 - mae: 0.1841 - val_loss: 0.0296 - val_mae: 0.1496\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - mae: 0.1874 - val_loss: 0.0294 - val_mae: 0.1491\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0261 - mae: 0.1843 - val_loss: 0.0293 - val_mae: 0.1486\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0277 - mae: 0.1846 - val_loss: 0.0292 - val_mae: 0.1481\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0265 - mae: 0.1846 - val_loss: 0.0291 - val_mae: 0.1476\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0299 - mae: 0.1893 - val_loss: 0.0290 - val_mae: 0.1471\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0268 - mae: 0.1797 - val_loss: 0.0289 - val_mae: 0.1466\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0261 - mae: 0.1733 - val_loss: 0.0288 - val_mae: 0.1461\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0346 - mae: 0.2004 - val_loss: 0.0287 - val_mae: 0.1456\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0243 - mae: 0.1724 - val_loss: 0.0286 - val_mae: 0.1451\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0257 - mae: 0.1740 - val_loss: 0.0285 - val_mae: 0.1446\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0271 - mae: 0.1812 - val_loss: 0.0284 - val_mae: 0.1441\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - mae: 0.1925 - val_loss: 0.0283 - val_mae: 0.1437\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0271 - mae: 0.1831 - val_loss: 0.0282 - val_mae: 0.1432\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0272 - mae: 0.1863 - val_loss: 0.0281 - val_mae: 0.1427\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0301 - mae: 0.1914 - val_loss: 0.0280 - val_mae: 0.1422\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0252 - mae: 0.1778 - val_loss: 0.0279 - val_mae: 0.1417\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0274 - mae: 0.1859 - val_loss: 0.0278 - val_mae: 0.1413\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0263 - mae: 0.1798 - val_loss: 0.0277 - val_mae: 0.1408\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0242 - mae: 0.1776 - val_loss: 0.0276 - val_mae: 0.1404\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0261 - mae: 0.1802 - val_loss: 0.0275 - val_mae: 0.1399\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0263 - mae: 0.1845 - val_loss: 0.0274 - val_mae: 0.1395\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - mae: 0.2103 - val_loss: 0.0273 - val_mae: 0.1390\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0257 - mae: 0.1816 - val_loss: 0.0272 - val_mae: 0.1386\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0263 - mae: 0.1804 - val_loss: 0.0271 - val_mae: 0.1381\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0229 - mae: 0.1714 - val_loss: 0.0270 - val_mae: 0.1377\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0237 - mae: 0.1771 - val_loss: 0.0269 - val_mae: 0.1372\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0266 - mae: 0.1845 - val_loss: 0.0268 - val_mae: 0.1368\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0251 - mae: 0.1759 - val_loss: 0.0267 - val_mae: 0.1363\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0260 - mae: 0.1839 - val_loss: 0.0266 - val_mae: 0.1359\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0292 - mae: 0.1879 - val_loss: 0.0265 - val_mae: 0.1354\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0280 - mae: 0.1901 - val_loss: 0.0264 - val_mae: 0.1349\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0232 - mae: 0.1727 - val_loss: 0.0263 - val_mae: 0.1345\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0220 - mae: 0.1621 - val_loss: 0.0262 - val_mae: 0.1340\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0218 - mae: 0.1712 - val_loss: 0.0262 - val_mae: 0.1336\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0238 - mae: 0.1762 - val_loss: 0.0261 - val_mae: 0.1331\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - mae: 0.1721 - val_loss: 0.0260 - val_mae: 0.1327\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0243 - mae: 0.1720 - val_loss: 0.0259 - val_mae: 0.1322\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0205 - mae: 0.1594 - val_loss: 0.0258 - val_mae: 0.1318\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0265 - mae: 0.1802 - val_loss: 0.0257 - val_mae: 0.1313\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0278 - mae: 0.1788 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0209 - mae: 0.1632 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0241 - mae: 0.1753 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0249 - mae: 0.1753 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0229 - mae: 0.1682 - val_loss: 0.0253 - val_mae: 0.1292\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0226 - mae: 0.1668 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0252 - mae: 0.1791 - val_loss: 0.0252 - val_mae: 0.1284\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0263 - mae: 0.1812 - val_loss: 0.0251 - val_mae: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:36,890] Trial 16 finished with value: 0.1279830038547516 and parameters: {'learning_rate': 6.477316583022758e-06, 'weight_decay': 1.322813744917166e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0522 - mae: 0.2558 - val_loss: 0.0402 - val_mae: 0.2001\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0496 - mae: 0.2546 - val_loss: 0.0400 - val_mae: 0.1994\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0452 - mae: 0.2356 - val_loss: 0.0398 - val_mae: 0.1987\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0479 - mae: 0.2395 - val_loss: 0.0396 - val_mae: 0.1979\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0447 - mae: 0.2374 - val_loss: 0.0394 - val_mae: 0.1971\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0379 - mae: 0.2212 - val_loss: 0.0392 - val_mae: 0.1964\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0374 - mae: 0.2110 - val_loss: 0.0390 - val_mae: 0.1956\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0400 - mae: 0.2239 - val_loss: 0.0388 - val_mae: 0.1949\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0436 - mae: 0.2308 - val_loss: 0.0385 - val_mae: 0.1941\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0425 - mae: 0.2296 - val_loss: 0.0383 - val_mae: 0.1933\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0357 - mae: 0.2103 - val_loss: 0.0381 - val_mae: 0.1926\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0432 - mae: 0.2192 - val_loss: 0.0380 - val_mae: 0.1918\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0573 - mae: 0.2684 - val_loss: 0.0378 - val_mae: 0.1910\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0404 - mae: 0.2234 - val_loss: 0.0376 - val_mae: 0.1903\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0324 - mae: 0.1936 - val_loss: 0.0374 - val_mae: 0.1895\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0424 - mae: 0.2291 - val_loss: 0.0372 - val_mae: 0.1887\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0408 - mae: 0.2202 - val_loss: 0.0370 - val_mae: 0.1879\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0464 - mae: 0.2422 - val_loss: 0.0368 - val_mae: 0.1872\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0415 - mae: 0.2209 - val_loss: 0.0366 - val_mae: 0.1864\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0419 - mae: 0.2268 - val_loss: 0.0364 - val_mae: 0.1856\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0411 - mae: 0.2260 - val_loss: 0.0362 - val_mae: 0.1849\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0341 - mae: 0.2035 - val_loss: 0.0360 - val_mae: 0.1841\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0427 - mae: 0.2321 - val_loss: 0.0359 - val_mae: 0.1834\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0440 - mae: 0.2384 - val_loss: 0.0357 - val_mae: 0.1826\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0418 - mae: 0.2206 - val_loss: 0.0355 - val_mae: 0.1819\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0439 - mae: 0.2315 - val_loss: 0.0353 - val_mae: 0.1812\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0343 - mae: 0.2035 - val_loss: 0.0352 - val_mae: 0.1805\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0397 - mae: 0.2267 - val_loss: 0.0350 - val_mae: 0.1798\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0357 - mae: 0.2127 - val_loss: 0.0348 - val_mae: 0.1791\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0386 - mae: 0.2213 - val_loss: 0.0347 - val_mae: 0.1785\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0394 - mae: 0.2217 - val_loss: 0.0345 - val_mae: 0.1778\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0412 - mae: 0.2228 - val_loss: 0.0343 - val_mae: 0.1771\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0380 - mae: 0.2189 - val_loss: 0.0342 - val_mae: 0.1765\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0333 - mae: 0.2113 - val_loss: 0.0340 - val_mae: 0.1758\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0388 - mae: 0.2183 - val_loss: 0.0338 - val_mae: 0.1751\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0355 - mae: 0.2181 - val_loss: 0.0337 - val_mae: 0.1745\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0371 - mae: 0.2075 - val_loss: 0.0335 - val_mae: 0.1738\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0349 - mae: 0.2103 - val_loss: 0.0334 - val_mae: 0.1732\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0379 - mae: 0.2156 - val_loss: 0.0332 - val_mae: 0.1726\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0344 - mae: 0.2061 - val_loss: 0.0331 - val_mae: 0.1720\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0394 - mae: 0.2181 - val_loss: 0.0329 - val_mae: 0.1713\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0384 - mae: 0.2206 - val_loss: 0.0328 - val_mae: 0.1707\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0339 - mae: 0.2087 - val_loss: 0.0326 - val_mae: 0.1701\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0351 - mae: 0.2118 - val_loss: 0.0325 - val_mae: 0.1695\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0380 - mae: 0.2193 - val_loss: 0.0323 - val_mae: 0.1689\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0339 - mae: 0.2060 - val_loss: 0.0322 - val_mae: 0.1683\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0334 - mae: 0.2016 - val_loss: 0.0320 - val_mae: 0.1677\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0350 - mae: 0.2080 - val_loss: 0.0319 - val_mae: 0.1671\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0335 - mae: 0.2050 - val_loss: 0.0317 - val_mae: 0.1664\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0327 - mae: 0.2010 - val_loss: 0.0316 - val_mae: 0.1658\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0344 - mae: 0.2049 - val_loss: 0.0315 - val_mae: 0.1652\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0389 - mae: 0.2260 - val_loss: 0.0313 - val_mae: 0.1646\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0333 - mae: 0.2021 - val_loss: 0.0312 - val_mae: 0.1641\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0409 - mae: 0.2268 - val_loss: 0.0310 - val_mae: 0.1634\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0303 - mae: 0.1877 - val_loss: 0.0309 - val_mae: 0.1629\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0331 - mae: 0.2070 - val_loss: 0.0308 - val_mae: 0.1623\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0372 - mae: 0.2118 - val_loss: 0.0307 - val_mae: 0.1617\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0313 - mae: 0.1990 - val_loss: 0.0305 - val_mae: 0.1611\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0329 - mae: 0.2049 - val_loss: 0.0304 - val_mae: 0.1605\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0332 - mae: 0.2040 - val_loss: 0.0303 - val_mae: 0.1599\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0316 - mae: 0.1984 - val_loss: 0.0302 - val_mae: 0.1594\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0292 - mae: 0.1927 - val_loss: 0.0300 - val_mae: 0.1588\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0359 - mae: 0.2132 - val_loss: 0.0299 - val_mae: 0.1582\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0350 - mae: 0.2047 - val_loss: 0.0298 - val_mae: 0.1577\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0358 - mae: 0.2075 - val_loss: 0.0297 - val_mae: 0.1572\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0271 - mae: 0.1838 - val_loss: 0.0296 - val_mae: 0.1566\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0354 - mae: 0.2121 - val_loss: 0.0295 - val_mae: 0.1561\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0308 - mae: 0.1970 - val_loss: 0.0294 - val_mae: 0.1556\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0318 - mae: 0.2029 - val_loss: 0.0292 - val_mae: 0.1551\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0317 - mae: 0.2055 - val_loss: 0.0291 - val_mae: 0.1545\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0282 - mae: 0.1867 - val_loss: 0.0290 - val_mae: 0.1540\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0334 - mae: 0.2093 - val_loss: 0.0289 - val_mae: 0.1534\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0336 - mae: 0.2014 - val_loss: 0.0288 - val_mae: 0.1529\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0309 - mae: 0.2004 - val_loss: 0.0287 - val_mae: 0.1524\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0321 - mae: 0.1935 - val_loss: 0.0286 - val_mae: 0.1518\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0315 - mae: 0.1956 - val_loss: 0.0285 - val_mae: 0.1513\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0255 - mae: 0.1769 - val_loss: 0.0284 - val_mae: 0.1508\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0285 - mae: 0.1844 - val_loss: 0.0283 - val_mae: 0.1502\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0285 - mae: 0.1895 - val_loss: 0.0282 - val_mae: 0.1497\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0269 - mae: 0.1881 - val_loss: 0.0281 - val_mae: 0.1492\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0312 - mae: 0.2053 - val_loss: 0.0280 - val_mae: 0.1487\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0274 - mae: 0.1853 - val_loss: 0.0279 - val_mae: 0.1482\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0293 - mae: 0.1931 - val_loss: 0.0278 - val_mae: 0.1477\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0328 - mae: 0.2026 - val_loss: 0.0277 - val_mae: 0.1471\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0316 - mae: 0.2010 - val_loss: 0.0276 - val_mae: 0.1466\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - mae: 0.1867 - val_loss: 0.0275 - val_mae: 0.1461\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0316 - mae: 0.1961 - val_loss: 0.0274 - val_mae: 0.1456\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0308 - mae: 0.1980 - val_loss: 0.0273 - val_mae: 0.1451\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0292 - mae: 0.1812 - val_loss: 0.0272 - val_mae: 0.1446\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0304 - mae: 0.1925 - val_loss: 0.0271 - val_mae: 0.1442\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0257 - mae: 0.1794 - val_loss: 0.0271 - val_mae: 0.1437\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0271 - mae: 0.1828 - val_loss: 0.0270 - val_mae: 0.1433\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0281 - mae: 0.1897 - val_loss: 0.0269 - val_mae: 0.1428\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0276 - mae: 0.1862 - val_loss: 0.0268 - val_mae: 0.1424\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0361 - mae: 0.2085 - val_loss: 0.0267 - val_mae: 0.1419\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0265 - mae: 0.1856 - val_loss: 0.0267 - val_mae: 0.1415\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0320 - mae: 0.2005 - val_loss: 0.0266 - val_mae: 0.1410\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0265 - mae: 0.1753 - val_loss: 0.0265 - val_mae: 0.1405\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0279 - mae: 0.1897 - val_loss: 0.0264 - val_mae: 0.1400\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0218 - mae: 0.1649 - val_loss: 0.0263 - val_mae: 0.1396\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0248 - mae: 0.1799 - val_loss: 0.0262 - val_mae: 0.1391\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0297 - mae: 0.1925 - val_loss: 0.0262 - val_mae: 0.1386\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0265 - mae: 0.1840 - val_loss: 0.0261 - val_mae: 0.1382\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0295 - mae: 0.1933 - val_loss: 0.0260 - val_mae: 0.1377\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0299 - mae: 0.1892 - val_loss: 0.0259 - val_mae: 0.1372\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0267 - mae: 0.1793 - val_loss: 0.0259 - val_mae: 0.1368\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0236 - mae: 0.1665 - val_loss: 0.0258 - val_mae: 0.1363\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0236 - mae: 0.1745 - val_loss: 0.0257 - val_mae: 0.1359\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0301 - mae: 0.1936 - val_loss: 0.0256 - val_mae: 0.1354\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0295 - mae: 0.1941 - val_loss: 0.0256 - val_mae: 0.1349\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0248 - mae: 0.1772 - val_loss: 0.0255 - val_mae: 0.1345\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0232 - mae: 0.1691 - val_loss: 0.0254 - val_mae: 0.1340\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0239 - mae: 0.1685 - val_loss: 0.0254 - val_mae: 0.1336\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0267 - mae: 0.1828 - val_loss: 0.0253 - val_mae: 0.1332\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0246 - mae: 0.1811 - val_loss: 0.0252 - val_mae: 0.1328\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0228 - mae: 0.1694 - val_loss: 0.0252 - val_mae: 0.1324\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0252 - mae: 0.1758 - val_loss: 0.0251 - val_mae: 0.1319\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0220 - mae: 0.1676 - val_loss: 0.0250 - val_mae: 0.1315\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0233 - mae: 0.1677 - val_loss: 0.0250 - val_mae: 0.1311\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0230 - mae: 0.1701 - val_loss: 0.0249 - val_mae: 0.1307\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0233 - mae: 0.1729 - val_loss: 0.0248 - val_mae: 0.1303\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0252 - mae: 0.1736 - val_loss: 0.0248 - val_mae: 0.1299\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0242 - mae: 0.1822 - val_loss: 0.0247 - val_mae: 0.1295\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0290 - mae: 0.1902 - val_loss: 0.0246 - val_mae: 0.1291\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0250 - mae: 0.1768 - val_loss: 0.0246 - val_mae: 0.1286\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1651 - val_loss: 0.0245 - val_mae: 0.1282\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0237 - mae: 0.1700 - val_loss: 0.0244 - val_mae: 0.1278\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0228 - mae: 0.1627 - val_loss: 0.0244 - val_mae: 0.1274\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0302 - mae: 0.1978 - val_loss: 0.0243 - val_mae: 0.1270\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0256 - mae: 0.1757 - val_loss: 0.0242 - val_mae: 0.1267\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0286 - mae: 0.1879 - val_loss: 0.0242 - val_mae: 0.1263\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0250 - mae: 0.1792 - val_loss: 0.0241 - val_mae: 0.1259\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0258 - mae: 0.1787 - val_loss: 0.0241 - val_mae: 0.1255\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0270 - mae: 0.1831 - val_loss: 0.0240 - val_mae: 0.1252\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0236 - mae: 0.1742 - val_loss: 0.0240 - val_mae: 0.1248\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0210 - mae: 0.1691 - val_loss: 0.0239 - val_mae: 0.1245\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0259 - mae: 0.1769 - val_loss: 0.0239 - val_mae: 0.1241\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0235 - mae: 0.1710 - val_loss: 0.0238 - val_mae: 0.1238\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0266 - mae: 0.1783 - val_loss: 0.0238 - val_mae: 0.1235\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0283 - mae: 0.1850 - val_loss: 0.0237 - val_mae: 0.1231\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0271 - mae: 0.1866 - val_loss: 0.0236 - val_mae: 0.1228\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0237 - mae: 0.1696 - val_loss: 0.0236 - val_mae: 0.1224\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0199 - mae: 0.1608 - val_loss: 0.0235 - val_mae: 0.1221\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0222 - mae: 0.1664 - val_loss: 0.0235 - val_mae: 0.1218\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0228 - mae: 0.1714 - val_loss: 0.0234 - val_mae: 0.1214\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0202 - mae: 0.1586 - val_loss: 0.0234 - val_mae: 0.1211\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0269 - mae: 0.1838 - val_loss: 0.0233 - val_mae: 0.1208\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0210 - mae: 0.1576 - val_loss: 0.0233 - val_mae: 0.1205\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0204 - mae: 0.1579 - val_loss: 0.0232 - val_mae: 0.1201\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0238 - mae: 0.1684 - val_loss: 0.0232 - val_mae: 0.1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:47,122] Trial 17 finished with value: 0.11979298293590546 and parameters: {'learning_rate': 5.780841992837617e-06, 'weight_decay': 7.923238676419618e-07}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0263 - mae: 0.1792 - val_loss: 0.1291 - val_mae: 0.4246\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1329 - mae: 0.4258 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0080 - mae: 0.0926 - val_loss: 0.0184 - val_mae: 0.1007\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0076 - mae: 0.0934 - val_loss: 0.0176 - val_mae: 0.0837\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0692 - val_loss: 0.0177 - val_mae: 0.0938\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0781 - val_loss: 0.0239 - val_mae: 0.1578\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0129 - mae: 0.1306 - val_loss: 0.0221 - val_mae: 0.1021\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0067 - mae: 0.0848 - val_loss: 0.0220 - val_mae: 0.1065\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0192 - val_mae: 0.0906\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - mae: 0.0760 - val_loss: 0.0166 - val_mae: 0.0959\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0792 - val_loss: 0.0163 - val_mae: 0.0982\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0063 - mae: 0.0905 - val_loss: 0.0173 - val_mae: 0.0834\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0184 - val_mae: 0.0887\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0713 - val_loss: 0.0183 - val_mae: 0.0890\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0051 - mae: 0.0740 - val_loss: 0.0178 - val_mae: 0.0861\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - mae: 0.0709 - val_loss: 0.0173 - val_mae: 0.0832\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0637 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0686 - val_loss: 0.0168 - val_mae: 0.0890\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0171 - val_mae: 0.0931\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0707 - val_loss: 0.0173 - val_mae: 0.0956\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0176 - val_mae: 0.0970\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0690 - val_loss: 0.0176 - val_mae: 0.0964\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0707 - val_loss: 0.0175 - val_mae: 0.0943\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0173 - val_mae: 0.0899\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0879\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0172 - val_mae: 0.0864\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0811\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0164 - val_mae: 0.0813\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0165 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0166 - val_mae: 0.0832\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0862\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0868\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0872\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0872\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0869\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0865\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0861\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0830\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0825\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0824\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0861\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0858\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0859\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0850\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0869\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0868\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0861\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0852\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0863\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:57:57,939] Trial 18 finished with value: 0.08474120497703552 and parameters: {'learning_rate': 0.014670261712091306, 'weight_decay': 1.4968715084083847e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - mae: 0.1492 - val_loss: 0.0317 - val_mae: 0.1559\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1583 - val_loss: 0.0317 - val_mae: 0.1558\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0207 - mae: 0.1587 - val_loss: 0.0317 - val_mae: 0.1558\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0246 - mae: 0.1687 - val_loss: 0.0317 - val_mae: 0.1558\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0240 - mae: 0.1680 - val_loss: 0.0317 - val_mae: 0.1557\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0239 - mae: 0.1628 - val_loss: 0.0317 - val_mae: 0.1557\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0228 - mae: 0.1611 - val_loss: 0.0317 - val_mae: 0.1557\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0240 - mae: 0.1712 - val_loss: 0.0317 - val_mae: 0.1556\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0234 - mae: 0.1588 - val_loss: 0.0317 - val_mae: 0.1556\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0227 - mae: 0.1649 - val_loss: 0.0317 - val_mae: 0.1555\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0244 - mae: 0.1678 - val_loss: 0.0316 - val_mae: 0.1555\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0212 - mae: 0.1611 - val_loss: 0.0316 - val_mae: 0.1555\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0233 - mae: 0.1666 - val_loss: 0.0316 - val_mae: 0.1554\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0227 - mae: 0.1654 - val_loss: 0.0316 - val_mae: 0.1554\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0230 - mae: 0.1582 - val_loss: 0.0316 - val_mae: 0.1554\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0223 - mae: 0.1621 - val_loss: 0.0316 - val_mae: 0.1553\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0237 - mae: 0.1643 - val_loss: 0.0316 - val_mae: 0.1553\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0268 - mae: 0.1835 - val_loss: 0.0316 - val_mae: 0.1552\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0255 - mae: 0.1760 - val_loss: 0.0316 - val_mae: 0.1552\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0260 - mae: 0.1761 - val_loss: 0.0316 - val_mae: 0.1552\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0228 - mae: 0.1628 - val_loss: 0.0316 - val_mae: 0.1551\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0240 - mae: 0.1617 - val_loss: 0.0315 - val_mae: 0.1551\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0228 - mae: 0.1664 - val_loss: 0.0315 - val_mae: 0.1551\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0215 - mae: 0.1575 - val_loss: 0.0315 - val_mae: 0.1550\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0210 - mae: 0.1588 - val_loss: 0.0315 - val_mae: 0.1550\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0253 - mae: 0.1716 - val_loss: 0.0315 - val_mae: 0.1550\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0209 - mae: 0.1612 - val_loss: 0.0315 - val_mae: 0.1549\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0222 - mae: 0.1597 - val_loss: 0.0315 - val_mae: 0.1549\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0228 - mae: 0.1646 - val_loss: 0.0315 - val_mae: 0.1548\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0229 - mae: 0.1627 - val_loss: 0.0315 - val_mae: 0.1548\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - mae: 0.1641 - val_loss: 0.0315 - val_mae: 0.1548\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0235 - mae: 0.1648 - val_loss: 0.0315 - val_mae: 0.1547\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - mae: 0.1641 - val_loss: 0.0315 - val_mae: 0.1547\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0278 - mae: 0.1771 - val_loss: 0.0314 - val_mae: 0.1547\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0221 - mae: 0.1583 - val_loss: 0.0314 - val_mae: 0.1546\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0227 - mae: 0.1628 - val_loss: 0.0314 - val_mae: 0.1546\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0237 - mae: 0.1707 - val_loss: 0.0314 - val_mae: 0.1546\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0223 - mae: 0.1654 - val_loss: 0.0314 - val_mae: 0.1545\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0232 - mae: 0.1629 - val_loss: 0.0314 - val_mae: 0.1545\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0246 - mae: 0.1718 - val_loss: 0.0314 - val_mae: 0.1544\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0224 - mae: 0.1594 - val_loss: 0.0314 - val_mae: 0.1544\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0242 - mae: 0.1686 - val_loss: 0.0314 - val_mae: 0.1544\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0207 - mae: 0.1534 - val_loss: 0.0314 - val_mae: 0.1543\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0231 - mae: 0.1683 - val_loss: 0.0314 - val_mae: 0.1543\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0210 - mae: 0.1569 - val_loss: 0.0313 - val_mae: 0.1543\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0239 - mae: 0.1674 - val_loss: 0.0313 - val_mae: 0.1542\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0220 - mae: 0.1590 - val_loss: 0.0313 - val_mae: 0.1542\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0230 - mae: 0.1603 - val_loss: 0.0313 - val_mae: 0.1542\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0239 - mae: 0.1676 - val_loss: 0.0313 - val_mae: 0.1541\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0205 - mae: 0.1541 - val_loss: 0.0313 - val_mae: 0.1541\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0232 - mae: 0.1604 - val_loss: 0.0313 - val_mae: 0.1540\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0212 - mae: 0.1544 - val_loss: 0.0313 - val_mae: 0.1540\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - mae: 0.1691 - val_loss: 0.0313 - val_mae: 0.1540\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0214 - mae: 0.1577 - val_loss: 0.0313 - val_mae: 0.1539\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0222 - mae: 0.1640 - val_loss: 0.0313 - val_mae: 0.1539\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0225 - mae: 0.1653 - val_loss: 0.0313 - val_mae: 0.1539\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0209 - mae: 0.1559 - val_loss: 0.0312 - val_mae: 0.1538\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1671 - val_loss: 0.0312 - val_mae: 0.1538\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0203 - mae: 0.1574 - val_loss: 0.0312 - val_mae: 0.1538\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0246 - mae: 0.1642 - val_loss: 0.0312 - val_mae: 0.1537\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0229 - mae: 0.1661 - val_loss: 0.0312 - val_mae: 0.1537\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0248 - mae: 0.1670 - val_loss: 0.0312 - val_mae: 0.1536\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0238 - mae: 0.1684 - val_loss: 0.0312 - val_mae: 0.1536\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0239 - mae: 0.1692 - val_loss: 0.0312 - val_mae: 0.1536\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0198 - mae: 0.1538 - val_loss: 0.0312 - val_mae: 0.1535\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0248 - mae: 0.1694 - val_loss: 0.0312 - val_mae: 0.1535\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0197 - mae: 0.1518 - val_loss: 0.0312 - val_mae: 0.1535\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0217 - mae: 0.1581 - val_loss: 0.0312 - val_mae: 0.1534\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0240 - mae: 0.1656 - val_loss: 0.0311 - val_mae: 0.1534\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0227 - mae: 0.1644 - val_loss: 0.0311 - val_mae: 0.1534\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0273 - mae: 0.1783 - val_loss: 0.0311 - val_mae: 0.1533\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0212 - mae: 0.1562 - val_loss: 0.0311 - val_mae: 0.1533\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0243 - mae: 0.1626 - val_loss: 0.0311 - val_mae: 0.1533\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0234 - mae: 0.1666 - val_loss: 0.0311 - val_mae: 0.1532\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0216 - mae: 0.1589 - val_loss: 0.0311 - val_mae: 0.1532\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0205 - mae: 0.1551 - val_loss: 0.0311 - val_mae: 0.1531\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0213 - mae: 0.1598 - val_loss: 0.0311 - val_mae: 0.1531\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0228 - mae: 0.1603 - val_loss: 0.0311 - val_mae: 0.1531\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0236 - mae: 0.1672 - val_loss: 0.0311 - val_mae: 0.1530\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0246 - mae: 0.1670 - val_loss: 0.0311 - val_mae: 0.1530\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0207 - mae: 0.1550 - val_loss: 0.0310 - val_mae: 0.1530\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0210 - mae: 0.1577 - val_loss: 0.0310 - val_mae: 0.1529\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1614 - val_loss: 0.0310 - val_mae: 0.1529\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0225 - mae: 0.1660 - val_loss: 0.0310 - val_mae: 0.1529\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0224 - mae: 0.1609 - val_loss: 0.0310 - val_mae: 0.1528\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0243 - mae: 0.1689 - val_loss: 0.0310 - val_mae: 0.1528\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0192 - mae: 0.1508 - val_loss: 0.0310 - val_mae: 0.1527\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0204 - mae: 0.1531 - val_loss: 0.0310 - val_mae: 0.1527\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0226 - mae: 0.1653 - val_loss: 0.0310 - val_mae: 0.1527\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0211 - mae: 0.1549 - val_loss: 0.0310 - val_mae: 0.1526\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0208 - mae: 0.1598 - val_loss: 0.0310 - val_mae: 0.1526\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0239 - mae: 0.1661 - val_loss: 0.0310 - val_mae: 0.1526\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0211 - mae: 0.1590 - val_loss: 0.0309 - val_mae: 0.1525\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0217 - mae: 0.1581 - val_loss: 0.0309 - val_mae: 0.1525\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0231 - mae: 0.1626 - val_loss: 0.0309 - val_mae: 0.1525\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0227 - mae: 0.1620 - val_loss: 0.0309 - val_mae: 0.1524\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0217 - mae: 0.1598 - val_loss: 0.0309 - val_mae: 0.1524\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0197 - mae: 0.1551 - val_loss: 0.0309 - val_mae: 0.1524\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0227 - mae: 0.1560 - val_loss: 0.0309 - val_mae: 0.1523\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0234 - mae: 0.1605 - val_loss: 0.0309 - val_mae: 0.1523\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0230 - mae: 0.1663 - val_loss: 0.0309 - val_mae: 0.1522\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0230 - mae: 0.1604 - val_loss: 0.0309 - val_mae: 0.1522\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0228 - mae: 0.1605 - val_loss: 0.0309 - val_mae: 0.1522\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0223 - mae: 0.1552 - val_loss: 0.0309 - val_mae: 0.1521\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0202 - mae: 0.1522 - val_loss: 0.0308 - val_mae: 0.1521\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0249 - mae: 0.1669 - val_loss: 0.0308 - val_mae: 0.1521\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1587 - val_loss: 0.0308 - val_mae: 0.1520\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0220 - mae: 0.1612 - val_loss: 0.0308 - val_mae: 0.1520\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0248 - mae: 0.1754 - val_loss: 0.0308 - val_mae: 0.1520\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0213 - mae: 0.1540 - val_loss: 0.0308 - val_mae: 0.1519\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0228 - mae: 0.1648 - val_loss: 0.0308 - val_mae: 0.1519\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - mae: 0.1712 - val_loss: 0.0308 - val_mae: 0.1519\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0215 - mae: 0.1627 - val_loss: 0.0308 - val_mae: 0.1518\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0220 - mae: 0.1577 - val_loss: 0.0308 - val_mae: 0.1518\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0247 - mae: 0.1660 - val_loss: 0.0308 - val_mae: 0.1518\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0227 - mae: 0.1633 - val_loss: 0.0308 - val_mae: 0.1517\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0219 - mae: 0.1604 - val_loss: 0.0307 - val_mae: 0.1517\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0228 - mae: 0.1663 - val_loss: 0.0307 - val_mae: 0.1517\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0215 - mae: 0.1553 - val_loss: 0.0307 - val_mae: 0.1516\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0204 - mae: 0.1549 - val_loss: 0.0307 - val_mae: 0.1516\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0201 - mae: 0.1572 - val_loss: 0.0307 - val_mae: 0.1516\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0249 - mae: 0.1705 - val_loss: 0.0307 - val_mae: 0.1515\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0220 - mae: 0.1602 - val_loss: 0.0307 - val_mae: 0.1515\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0208 - mae: 0.1600 - val_loss: 0.0307 - val_mae: 0.1514\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1642 - val_loss: 0.0307 - val_mae: 0.1514\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1568 - val_loss: 0.0307 - val_mae: 0.1514\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0205 - mae: 0.1544 - val_loss: 0.0307 - val_mae: 0.1513\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0236 - mae: 0.1625 - val_loss: 0.0307 - val_mae: 0.1513\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0186 - mae: 0.1512 - val_loss: 0.0306 - val_mae: 0.1513\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1603 - val_loss: 0.0306 - val_mae: 0.1512\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0229 - mae: 0.1644 - val_loss: 0.0306 - val_mae: 0.1512\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0229 - mae: 0.1563 - val_loss: 0.0306 - val_mae: 0.1512\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0202 - mae: 0.1542 - val_loss: 0.0306 - val_mae: 0.1511\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0215 - mae: 0.1557 - val_loss: 0.0306 - val_mae: 0.1511\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0229 - mae: 0.1658 - val_loss: 0.0306 - val_mae: 0.1511\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0206 - mae: 0.1573 - val_loss: 0.0306 - val_mae: 0.1510\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0198 - mae: 0.1466 - val_loss: 0.0306 - val_mae: 0.1510\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0195 - mae: 0.1524 - val_loss: 0.0306 - val_mae: 0.1510\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0234 - mae: 0.1618 - val_loss: 0.0306 - val_mae: 0.1509\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0203 - mae: 0.1563 - val_loss: 0.0306 - val_mae: 0.1509\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0250 - mae: 0.1688 - val_loss: 0.0306 - val_mae: 0.1509\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0196 - mae: 0.1525 - val_loss: 0.0305 - val_mae: 0.1508\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0186 - mae: 0.1509 - val_loss: 0.0305 - val_mae: 0.1508\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0217 - mae: 0.1540 - val_loss: 0.0305 - val_mae: 0.1508\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0215 - mae: 0.1562 - val_loss: 0.0305 - val_mae: 0.1507\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1613 - val_loss: 0.0305 - val_mae: 0.1507\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0219 - mae: 0.1628 - val_loss: 0.0305 - val_mae: 0.1507\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1602 - val_loss: 0.0305 - val_mae: 0.1506\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0224 - mae: 0.1582 - val_loss: 0.0305 - val_mae: 0.1506\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1610 - val_loss: 0.0305 - val_mae: 0.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:58:07,996] Trial 19 finished with value: 0.15055134892463684 and parameters: {'learning_rate': 5.450697670694043e-07, 'weight_decay': 6.473007270396716e-08}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0182 - mae: 0.1500 - val_loss: 0.0197 - val_mae: 0.0882\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0143 - mae: 0.1327 - val_loss: 0.0181 - val_mae: 0.0900\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0105 - mae: 0.1120 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0977 - val_loss: 0.0177 - val_mae: 0.0956\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0986 - val_loss: 0.0179 - val_mae: 0.0924\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0893 - val_loss: 0.0182 - val_mae: 0.0884\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0838 - val_loss: 0.0185 - val_mae: 0.0846\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0800 - val_loss: 0.0187 - val_mae: 0.0816\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0767 - val_loss: 0.0188 - val_mae: 0.0801\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0711 - val_loss: 0.0185 - val_mae: 0.0791\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0183 - val_mae: 0.0786\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0784\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0177 - val_mae: 0.0787\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0672 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0636 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0577 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0173 - val_mae: 0.0811\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0173 - val_mae: 0.0809\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0544 - val_loss: 0.0172 - val_mae: 0.0850\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0168 - val_mae: 0.0824\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0511 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0170 - val_mae: 0.0815\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0488 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0517 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0168 - val_mae: 0.0816\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0167 - val_mae: 0.0825\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0449 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0502 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0507 - val_loss: 0.0168 - val_mae: 0.0822\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0426 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - mae: 0.0429 - val_loss: 0.0167 - val_mae: 0.0864\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0458 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0410 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0167 - val_mae: 0.0826\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0827\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0417 - val_loss: 0.0165 - val_mae: 0.0849\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0403 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0429 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0400 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0408 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0416 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0401 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0167 - val_mae: 0.0876\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0398 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - mae: 0.0395 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0367 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9051e-04 - mae: 0.0330 - val_loss: 0.0169 - val_mae: 0.0878\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0168 - val_mae: 0.0892\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0378 - val_loss: 0.0169 - val_mae: 0.0878\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0359 - val_loss: 0.0170 - val_mae: 0.0865\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.2418e-04 - mae: 0.0327 - val_loss: 0.0171 - val_mae: 0.0851\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0170 - val_mae: 0.0859\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.9160e-04 - mae: 0.0320 - val_loss: 0.0169 - val_mae: 0.0879\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.4953e-04 - mae: 0.0331 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0169 - val_mae: 0.0876\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6851e-04 - mae: 0.0323 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.3140e-04 - mae: 0.0321 - val_loss: 0.0170 - val_mae: 0.0862\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.9263e-04 - mae: 0.0313 - val_loss: 0.0170 - val_mae: 0.0866\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3885e-04 - mae: 0.0290 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.7665e-04 - mae: 0.0273 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.4959e-04 - mae: 0.0300 - val_loss: 0.0171 - val_mae: 0.0882\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 9.9268e-04 - mae: 0.0329 - val_loss: 0.0171 - val_mae: 0.0884\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0366 - val_loss: 0.0170 - val_mae: 0.0881\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.0742e-04 - mae: 0.0302 - val_loss: 0.0170 - val_mae: 0.0887\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.1885e-04 - mae: 0.0321 - val_loss: 0.0169 - val_mae: 0.0881\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.2177e-04 - mae: 0.0300 - val_loss: 0.0169 - val_mae: 0.0889\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.9039e-04 - mae: 0.0278 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.5811e-04 - mae: 0.0275 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.3654e-04 - mae: 0.0278 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.9826e-04 - mae: 0.0270 - val_loss: 0.0170 - val_mae: 0.0860\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.0920e-04 - mae: 0.0295 - val_loss: 0.0169 - val_mae: 0.0886\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.4446e-04 - mae: 0.0287 - val_loss: 0.0170 - val_mae: 0.0907\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.2897e-04 - mae: 0.0306 - val_loss: 0.0171 - val_mae: 0.0909\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0171 - val_mae: 0.0896\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.3246e-04 - mae: 0.0267 - val_loss: 0.0172 - val_mae: 0.0889\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4878e-04 - mae: 0.0277 - val_loss: 0.0172 - val_mae: 0.0887\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.5401e-04 - mae: 0.0309 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0690e-04 - mae: 0.0315 - val_loss: 0.0170 - val_mae: 0.0884\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.0150e-04 - mae: 0.0264 - val_loss: 0.0169 - val_mae: 0.0883\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.9354e-04 - mae: 0.0274 - val_loss: 0.0169 - val_mae: 0.0875\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2198e-04 - mae: 0.0269 - val_loss: 0.0168 - val_mae: 0.0874\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.4570e-04 - mae: 0.0254 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9219e-04 - mae: 0.0298 - val_loss: 0.0167 - val_mae: 0.0872\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.5231e-04 - mae: 0.0294 - val_loss: 0.0167 - val_mae: 0.0874\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.9264e-04 - mae: 0.0313 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.6001e-04 - mae: 0.0291 - val_loss: 0.0168 - val_mae: 0.0900\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.1683e-04 - mae: 0.0266 - val_loss: 0.0168 - val_mae: 0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:58:18,122] Trial 20 finished with value: 0.08944808691740036 and parameters: {'learning_rate': 0.0007636934765620424, 'weight_decay': 1.4922868649815158e-09}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0353 - mae: 0.2072 - val_loss: 0.0429 - val_mae: 0.1848\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0353 - mae: 0.2108 - val_loss: 0.0423 - val_mae: 0.1827\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0299 - mae: 0.1988 - val_loss: 0.0417 - val_mae: 0.1806\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0324 - mae: 0.2041 - val_loss: 0.0411 - val_mae: 0.1785\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0281 - mae: 0.1897 - val_loss: 0.0404 - val_mae: 0.1763\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0306 - mae: 0.1905 - val_loss: 0.0398 - val_mae: 0.1742\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0280 - mae: 0.1828 - val_loss: 0.0392 - val_mae: 0.1721\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0323 - mae: 0.1970 - val_loss: 0.0386 - val_mae: 0.1700\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0262 - mae: 0.1754 - val_loss: 0.0381 - val_mae: 0.1679\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0265 - mae: 0.1764 - val_loss: 0.0375 - val_mae: 0.1659\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0227 - mae: 0.1666 - val_loss: 0.0369 - val_mae: 0.1639\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0228 - mae: 0.1680 - val_loss: 0.0364 - val_mae: 0.1619\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0240 - mae: 0.1658 - val_loss: 0.0359 - val_mae: 0.1600\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0233 - mae: 0.1732 - val_loss: 0.0353 - val_mae: 0.1580\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0284 - mae: 0.1873 - val_loss: 0.0348 - val_mae: 0.1561\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0225 - mae: 0.1642 - val_loss: 0.0344 - val_mae: 0.1543\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0232 - mae: 0.1741 - val_loss: 0.0339 - val_mae: 0.1525\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0230 - mae: 0.1646 - val_loss: 0.0334 - val_mae: 0.1507\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0223 - mae: 0.1707 - val_loss: 0.0329 - val_mae: 0.1489\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0207 - mae: 0.1527 - val_loss: 0.0325 - val_mae: 0.1472\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0231 - mae: 0.1598 - val_loss: 0.0321 - val_mae: 0.1455\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0220 - mae: 0.1591 - val_loss: 0.0317 - val_mae: 0.1438\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1599 - val_loss: 0.0313 - val_mae: 0.1421\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0201 - mae: 0.1578 - val_loss: 0.0309 - val_mae: 0.1405\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - mae: 0.1513 - val_loss: 0.0305 - val_mae: 0.1389\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0225 - mae: 0.1704 - val_loss: 0.0301 - val_mae: 0.1373\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0206 - mae: 0.1592 - val_loss: 0.0298 - val_mae: 0.1357\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0187 - mae: 0.1512 - val_loss: 0.0294 - val_mae: 0.1342\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0204 - mae: 0.1538 - val_loss: 0.0291 - val_mae: 0.1327\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0176 - mae: 0.1432 - val_loss: 0.0287 - val_mae: 0.1313\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0181 - mae: 0.1499 - val_loss: 0.0284 - val_mae: 0.1298\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1487 - val_loss: 0.0281 - val_mae: 0.1285\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0182 - mae: 0.1493 - val_loss: 0.0278 - val_mae: 0.1271\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0183 - mae: 0.1495 - val_loss: 0.0275 - val_mae: 0.1258\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0149 - mae: 0.1341 - val_loss: 0.0273 - val_mae: 0.1245\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0172 - mae: 0.1433 - val_loss: 0.0270 - val_mae: 0.1233\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0174 - mae: 0.1422 - val_loss: 0.0267 - val_mae: 0.1221\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0150 - mae: 0.1366 - val_loss: 0.0265 - val_mae: 0.1210\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0153 - mae: 0.1350 - val_loss: 0.0263 - val_mae: 0.1199\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0164 - mae: 0.1391 - val_loss: 0.0260 - val_mae: 0.1189\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0176 - mae: 0.1453 - val_loss: 0.0258 - val_mae: 0.1178\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0166 - mae: 0.1389 - val_loss: 0.0256 - val_mae: 0.1168\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0145 - mae: 0.1325 - val_loss: 0.0254 - val_mae: 0.1158\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0159 - mae: 0.1393 - val_loss: 0.0252 - val_mae: 0.1148\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0131 - mae: 0.1254 - val_loss: 0.0250 - val_mae: 0.1138\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141 - mae: 0.1312 - val_loss: 0.0248 - val_mae: 0.1128\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0113 - mae: 0.1164 - val_loss: 0.0246 - val_mae: 0.1118\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141 - mae: 0.1277 - val_loss: 0.0245 - val_mae: 0.1109\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0143 - mae: 0.1380 - val_loss: 0.0243 - val_mae: 0.1100\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0130 - mae: 0.1214 - val_loss: 0.0241 - val_mae: 0.1092\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0147 - mae: 0.1290 - val_loss: 0.0239 - val_mae: 0.1084\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0155 - mae: 0.1363 - val_loss: 0.0238 - val_mae: 0.1077\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141 - mae: 0.1313 - val_loss: 0.0236 - val_mae: 0.1070\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0138 - mae: 0.1308 - val_loss: 0.0234 - val_mae: 0.1062\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0143 - mae: 0.1307 - val_loss: 0.0233 - val_mae: 0.1056\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0140 - mae: 0.1269 - val_loss: 0.0231 - val_mae: 0.1049\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1171 - val_loss: 0.0230 - val_mae: 0.1042\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0123 - mae: 0.1211 - val_loss: 0.0229 - val_mae: 0.1036\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0129 - mae: 0.1255 - val_loss: 0.0227 - val_mae: 0.1030\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0136 - mae: 0.1238 - val_loss: 0.0226 - val_mae: 0.1024\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1247 - val_loss: 0.0225 - val_mae: 0.1019\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0140 - mae: 0.1305 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0134 - mae: 0.1231 - val_loss: 0.0222 - val_mae: 0.1008\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0144 - mae: 0.1301 - val_loss: 0.0221 - val_mae: 0.1003\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0114 - mae: 0.1182 - val_loss: 0.0220 - val_mae: 0.0997\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0145 - mae: 0.1309 - val_loss: 0.0218 - val_mae: 0.0992\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mae: 0.1144 - val_loss: 0.0217 - val_mae: 0.0986\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0137 - mae: 0.1266 - val_loss: 0.0216 - val_mae: 0.0981\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0117 - mae: 0.1156 - val_loss: 0.0215 - val_mae: 0.0976\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0133 - mae: 0.1254 - val_loss: 0.0214 - val_mae: 0.0971\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0109 - mae: 0.1141 - val_loss: 0.0213 - val_mae: 0.0966\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0116 - mae: 0.1189 - val_loss: 0.0212 - val_mae: 0.0961\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0211 - val_mae: 0.0957\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0122 - mae: 0.1243 - val_loss: 0.0210 - val_mae: 0.0952\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1135 - val_loss: 0.0209 - val_mae: 0.0948\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - mae: 0.1161 - val_loss: 0.0208 - val_mae: 0.0943\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1165 - val_loss: 0.0208 - val_mae: 0.0940\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1134 - val_loss: 0.0207 - val_mae: 0.0936\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0105 - mae: 0.1109 - val_loss: 0.0206 - val_mae: 0.0932\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0106 - mae: 0.1153 - val_loss: 0.0205 - val_mae: 0.0929\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1156 - val_loss: 0.0205 - val_mae: 0.0925\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1136 - val_loss: 0.0204 - val_mae: 0.0921\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0109 - mae: 0.1120 - val_loss: 0.0203 - val_mae: 0.0918\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0202 - val_mae: 0.0915\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0108 - mae: 0.1152 - val_loss: 0.0202 - val_mae: 0.0911\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0116 - mae: 0.1173 - val_loss: 0.0201 - val_mae: 0.0908\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0110 - mae: 0.1116 - val_loss: 0.0200 - val_mae: 0.0905\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1155 - val_loss: 0.0200 - val_mae: 0.0902\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1139 - val_loss: 0.0199 - val_mae: 0.0899\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0198 - val_mae: 0.0896\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0112 - mae: 0.1182 - val_loss: 0.0198 - val_mae: 0.0893\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0197 - val_mae: 0.0890\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mae: 0.1138 - val_loss: 0.0197 - val_mae: 0.0887\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.1019 - val_loss: 0.0196 - val_mae: 0.0884\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.0195 - val_mae: 0.0882\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1095 - val_loss: 0.0195 - val_mae: 0.0879\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1118 - val_loss: 0.0194 - val_mae: 0.0876\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0194 - val_mae: 0.0873\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0099 - mae: 0.1095 - val_loss: 0.0193 - val_mae: 0.0870\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0193 - val_mae: 0.0868\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0192 - val_mae: 0.0866\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1079 - val_loss: 0.0192 - val_mae: 0.0864\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1068 - val_loss: 0.0191 - val_mae: 0.0862\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0191 - val_mae: 0.0860\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0190 - val_mae: 0.0858\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0097 - mae: 0.1110 - val_loss: 0.0190 - val_mae: 0.0857\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0096 - mae: 0.1056 - val_loss: 0.0189 - val_mae: 0.0855\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0189 - val_mae: 0.0853\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.1037 - val_loss: 0.0189 - val_mae: 0.0851\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0089 - mae: 0.1041 - val_loss: 0.0188 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1105 - val_loss: 0.0188 - val_mae: 0.0848\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - mae: 0.1070 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0187 - val_mae: 0.0845\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0187 - val_mae: 0.0844\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0187 - val_mae: 0.0842\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.0996 - val_loss: 0.0186 - val_mae: 0.0841\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0108 - mae: 0.1179 - val_loss: 0.0186 - val_mae: 0.0839\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0186 - val_mae: 0.0838\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0085 - mae: 0.1026 - val_loss: 0.0185 - val_mae: 0.0836\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0087 - mae: 0.1051 - val_loss: 0.0185 - val_mae: 0.0835\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0185 - val_mae: 0.0833\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0184 - val_mae: 0.0832\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1047 - val_loss: 0.0184 - val_mae: 0.0831\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1032 - val_loss: 0.0184 - val_mae: 0.0830\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0995 - val_loss: 0.0184 - val_mae: 0.0829\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0975 - val_loss: 0.0183 - val_mae: 0.0828\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0183 - val_mae: 0.0827\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1055 - val_loss: 0.0183 - val_mae: 0.0827\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0183 - val_mae: 0.0826\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0081 - mae: 0.0964 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0969 - val_loss: 0.0182 - val_mae: 0.0825\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0088 - mae: 0.1042 - val_loss: 0.0182 - val_mae: 0.0824\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - mae: 0.1042 - val_loss: 0.0182 - val_mae: 0.0823\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0085 - mae: 0.1005 - val_loss: 0.0182 - val_mae: 0.0822\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.0990 - val_loss: 0.0182 - val_mae: 0.0822\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0181 - val_mae: 0.0821\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0088 - mae: 0.1043 - val_loss: 0.0181 - val_mae: 0.0820\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0094 - mae: 0.1017 - val_loss: 0.0181 - val_mae: 0.0818\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0181 - val_mae: 0.0818\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0075 - mae: 0.0955 - val_loss: 0.0181 - val_mae: 0.0817\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0851 - val_loss: 0.0181 - val_mae: 0.0817\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.1000 - val_loss: 0.0181 - val_mae: 0.0817\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0939 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0079 - mae: 0.0967 - val_loss: 0.0180 - val_mae: 0.0817\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0180 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.1000 - val_loss: 0.0180 - val_mae: 0.0816\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0180 - val_mae: 0.0816\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0180 - val_mae: 0.0815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:58:28,519] Trial 21 finished with value: 0.08151700347661972 and parameters: {'learning_rate': 2.4941221483762378e-05, 'weight_decay': 5.004433034225862e-07}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0310 - mae: 0.1992 - val_loss: 0.0365 - val_mae: 0.1890\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0307 - mae: 0.2037 - val_loss: 0.0351 - val_mae: 0.1838\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0269 - mae: 0.1829 - val_loss: 0.0338 - val_mae: 0.1783\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0314 - mae: 0.1981 - val_loss: 0.0325 - val_mae: 0.1727\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0273 - mae: 0.1912 - val_loss: 0.0313 - val_mae: 0.1670\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0265 - mae: 0.1846 - val_loss: 0.0301 - val_mae: 0.1613\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0231 - mae: 0.1774 - val_loss: 0.0290 - val_mae: 0.1556\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0220 - mae: 0.1650 - val_loss: 0.0279 - val_mae: 0.1501\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0230 - mae: 0.1676 - val_loss: 0.0270 - val_mae: 0.1446\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0213 - mae: 0.1642 - val_loss: 0.0260 - val_mae: 0.1395\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0237 - mae: 0.1737 - val_loss: 0.0252 - val_mae: 0.1346\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0218 - mae: 0.1680 - val_loss: 0.0244 - val_mae: 0.1298\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0205 - mae: 0.1657 - val_loss: 0.0237 - val_mae: 0.1251\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0168 - mae: 0.1442 - val_loss: 0.0230 - val_mae: 0.1205\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0184 - mae: 0.1539 - val_loss: 0.0224 - val_mae: 0.1161\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0178 - mae: 0.1502 - val_loss: 0.0218 - val_mae: 0.1120\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - mae: 0.1437 - val_loss: 0.0213 - val_mae: 0.1084\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0146 - mae: 0.1317 - val_loss: 0.0208 - val_mae: 0.1055\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0158 - mae: 0.1416 - val_loss: 0.0204 - val_mae: 0.1028\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0154 - mae: 0.1327 - val_loss: 0.0200 - val_mae: 0.1006\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0145 - mae: 0.1385 - val_loss: 0.0197 - val_mae: 0.0984\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0129 - mae: 0.1285 - val_loss: 0.0194 - val_mae: 0.0963\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0133 - mae: 0.1312 - val_loss: 0.0191 - val_mae: 0.0945\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0126 - mae: 0.1240 - val_loss: 0.0189 - val_mae: 0.0927\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0141 - mae: 0.1310 - val_loss: 0.0187 - val_mae: 0.0911\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0119 - mae: 0.1192 - val_loss: 0.0185 - val_mae: 0.0898\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0129 - mae: 0.1260 - val_loss: 0.0183 - val_mae: 0.0886\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - mae: 0.1233 - val_loss: 0.0182 - val_mae: 0.0876\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0128 - mae: 0.1229 - val_loss: 0.0181 - val_mae: 0.0867\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0117 - mae: 0.1219 - val_loss: 0.0180 - val_mae: 0.0861\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0121 - mae: 0.1201 - val_loss: 0.0179 - val_mae: 0.0856\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0126 - mae: 0.1227 - val_loss: 0.0178 - val_mae: 0.0853\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0110 - mae: 0.1193 - val_loss: 0.0178 - val_mae: 0.0850\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0126 - mae: 0.1275 - val_loss: 0.0177 - val_mae: 0.0848\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0112 - mae: 0.1195 - val_loss: 0.0177 - val_mae: 0.0847\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0128 - mae: 0.1243 - val_loss: 0.0176 - val_mae: 0.0846\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0125 - mae: 0.1250 - val_loss: 0.0176 - val_mae: 0.0845\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0110 - mae: 0.1185 - val_loss: 0.0176 - val_mae: 0.0844\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0102 - mae: 0.1107 - val_loss: 0.0176 - val_mae: 0.0843\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0125 - mae: 0.1244 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0100 - mae: 0.1095 - val_loss: 0.0175 - val_mae: 0.0838\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0110 - mae: 0.1165 - val_loss: 0.0175 - val_mae: 0.0836\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0116 - mae: 0.1201 - val_loss: 0.0175 - val_mae: 0.0833\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0106 - mae: 0.1134 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0175 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0108 - mae: 0.1103 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0103 - mae: 0.1081 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0107 - mae: 0.1096 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0082 - mae: 0.1005 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0110 - mae: 0.1166 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1137 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1108 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1084 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0110 - mae: 0.1149 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0078 - mae: 0.0969 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1091 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0082 - mae: 0.0972 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0083 - mae: 0.1006 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0094 - mae: 0.1066 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.1054 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0088 - mae: 0.1052 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - mae: 0.1043 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0081 - mae: 0.0990 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0085 - mae: 0.0995 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0088 - mae: 0.1008 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0994 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0977 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0998 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0957 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0091 - mae: 0.1054 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - mae: 0.1068 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0086 - mae: 0.1019 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0074 - mae: 0.0962 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0075 - mae: 0.0979 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0080 - mae: 0.1001 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0978 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0070 - mae: 0.0918 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0993 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0079 - mae: 0.0974 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0080 - mae: 0.0986 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0082 - mae: 0.1009 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.0990 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.1039 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0954 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0069 - mae: 0.0934 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.1011 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0954 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0082 - mae: 0.0986 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0954 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0068 - mae: 0.0923 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0945 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0865 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0904 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0989 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0080 - mae: 0.1003 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0905 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0967 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0078 - mae: 0.0977 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0964 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0947 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0074 - mae: 0.0919 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0062 - mae: 0.0847 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.1008 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0901 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0071 - mae: 0.0924 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0070 - mae: 0.0904 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0066 - mae: 0.0890 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0069 - mae: 0.0940 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0071 - mae: 0.0922 - val_loss: 0.0175 - val_mae: 0.0823\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0064 - mae: 0.0897 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0916 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0063 - mae: 0.0854 - val_loss: 0.0175 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0054 - mae: 0.0823 - val_loss: 0.0175 - val_mae: 0.0821\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0883 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0897 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mae: 0.0952 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - mae: 0.0889 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0864 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0852 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0075 - mae: 0.0950 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0065 - mae: 0.0860 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0061 - mae: 0.0851 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0867 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0068 - mae: 0.0899 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0878 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0071 - mae: 0.0871 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0849 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0817 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - mae: 0.0857 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0887 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0061 - mae: 0.0843 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0058 - mae: 0.0865 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0065 - mae: 0.0854 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0058 - mae: 0.0826 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0893 - val_loss: 0.0175 - val_mae: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:58:41,229] Trial 22 finished with value: 0.08213689178228378 and parameters: {'learning_rate': 4.851867543535114e-05, 'weight_decay': 1.3759276663228347e-07}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0196 - mae: 0.1602 - val_loss: 0.0268 - val_mae: 0.1341\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0198 - mae: 0.1554 - val_loss: 0.0265 - val_mae: 0.1321\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0172 - mae: 0.1475 - val_loss: 0.0261 - val_mae: 0.1299\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0168 - mae: 0.1482 - val_loss: 0.0257 - val_mae: 0.1277\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0173 - mae: 0.1440 - val_loss: 0.0253 - val_mae: 0.1255\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0162 - mae: 0.1415 - val_loss: 0.0249 - val_mae: 0.1232\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0162 - mae: 0.1436 - val_loss: 0.0245 - val_mae: 0.1210\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0154 - mae: 0.1423 - val_loss: 0.0242 - val_mae: 0.1187\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0154 - mae: 0.1353 - val_loss: 0.0238 - val_mae: 0.1166\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0154 - mae: 0.1433 - val_loss: 0.0235 - val_mae: 0.1144\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0142 - mae: 0.1316 - val_loss: 0.0232 - val_mae: 0.1124\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0165 - mae: 0.1420 - val_loss: 0.0229 - val_mae: 0.1104\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0134 - mae: 0.1271 - val_loss: 0.0226 - val_mae: 0.1083\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0157 - mae: 0.1384 - val_loss: 0.0223 - val_mae: 0.1064\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0145 - mae: 0.1327 - val_loss: 0.0221 - val_mae: 0.1045\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0138 - mae: 0.1290 - val_loss: 0.0218 - val_mae: 0.1027\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0134 - mae: 0.1312 - val_loss: 0.0216 - val_mae: 0.1010\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0115 - mae: 0.1157 - val_loss: 0.0214 - val_mae: 0.0995\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0123 - mae: 0.1200 - val_loss: 0.0212 - val_mae: 0.0981\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0128 - mae: 0.1259 - val_loss: 0.0210 - val_mae: 0.0967\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0113 - mae: 0.1111 - val_loss: 0.0208 - val_mae: 0.0954\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0136 - mae: 0.1308 - val_loss: 0.0207 - val_mae: 0.0942\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0205 - val_mae: 0.0930\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0115 - mae: 0.1175 - val_loss: 0.0203 - val_mae: 0.0919\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0117 - mae: 0.1162 - val_loss: 0.0202 - val_mae: 0.0910\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0130 - mae: 0.1249 - val_loss: 0.0201 - val_mae: 0.0902\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0109 - mae: 0.1139 - val_loss: 0.0199 - val_mae: 0.0894\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0107 - mae: 0.1125 - val_loss: 0.0198 - val_mae: 0.0887\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0114 - mae: 0.1196 - val_loss: 0.0197 - val_mae: 0.0881\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0196 - val_mae: 0.0874\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0121 - mae: 0.1191 - val_loss: 0.0195 - val_mae: 0.0868\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0194 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0097 - mae: 0.1116 - val_loss: 0.0193 - val_mae: 0.0858\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0100 - mae: 0.1079 - val_loss: 0.0192 - val_mae: 0.0854\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0191 - val_mae: 0.0851\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0190 - val_mae: 0.0847\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0188 - val_mae: 0.0840\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0093 - mae: 0.1017 - val_loss: 0.0187 - val_mae: 0.0837\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0186 - val_mae: 0.0833\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0092 - mae: 0.1012 - val_loss: 0.0186 - val_mae: 0.0831\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1073 - val_loss: 0.0185 - val_mae: 0.0830\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0184 - val_mae: 0.0828\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0951 - val_loss: 0.0184 - val_mae: 0.0827\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1047 - val_loss: 0.0183 - val_mae: 0.0827\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0082 - mae: 0.0996 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0091 - mae: 0.1069 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0086 - mae: 0.1049 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0181 - val_mae: 0.0826\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0181 - val_mae: 0.0826\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.0988 - val_loss: 0.0181 - val_mae: 0.0826\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0180 - val_mae: 0.0826\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0915 - val_loss: 0.0180 - val_mae: 0.0826\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0180 - val_mae: 0.0826\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0179 - val_mae: 0.0827\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0076 - mae: 0.0973 - val_loss: 0.0179 - val_mae: 0.0827\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0083 - mae: 0.0984 - val_loss: 0.0179 - val_mae: 0.0827\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.0987 - val_loss: 0.0178 - val_mae: 0.0827\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0178 - val_mae: 0.0827\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0079 - mae: 0.1002 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0079 - mae: 0.0971 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0967 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.1023 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mae: 0.0906 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0085 - mae: 0.1013 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0969 - val_loss: 0.0177 - val_mae: 0.0822\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0902 - val_loss: 0.0177 - val_mae: 0.0821\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - mae: 0.1001 - val_loss: 0.0177 - val_mae: 0.0821\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0942 - val_loss: 0.0177 - val_mae: 0.0820\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0890 - val_loss: 0.0177 - val_mae: 0.0820\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0075 - mae: 0.0970 - val_loss: 0.0177 - val_mae: 0.0818\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0079 - mae: 0.0963 - val_loss: 0.0177 - val_mae: 0.0818\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0067 - mae: 0.0885 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - mae: 0.0979 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0072 - mae: 0.0901 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0921 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0068 - mae: 0.0920 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0082 - mae: 0.0975 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0851 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0071 - mae: 0.0922 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0839 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0889 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0074 - mae: 0.0959 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0078 - mae: 0.0945 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0069 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0074 - mae: 0.0960 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0931 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0899 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0900 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0071 - mae: 0.0926 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0064 - mae: 0.0849 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0067 - mae: 0.0885 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0871 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0888 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0834 - val_loss: 0.0176 - val_mae: 0.0813\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0932 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0820 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0846 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0786 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - mae: 0.0896 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0058 - mae: 0.0842 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0940 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0913 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0862 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0062 - mae: 0.0857 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0061 - mae: 0.0853 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0066 - mae: 0.0908 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0054 - mae: 0.0769 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0843 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0835 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0058 - mae: 0.0820 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0067 - mae: 0.0876 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0058 - mae: 0.0812 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0848 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0064 - mae: 0.0859 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0059 - mae: 0.0843 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0784 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0055 - mae: 0.0806 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0057 - mae: 0.0792 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0063 - mae: 0.0829 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0056 - mae: 0.0807 - val_loss: 0.0176 - val_mae: 0.0818\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0053 - mae: 0.0768 - val_loss: 0.0176 - val_mae: 0.0818\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0060 - mae: 0.0843 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0066 - mae: 0.0835 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0057 - mae: 0.0806 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0776 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0816 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0065 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0892 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0778 - val_loss: 0.0176 - val_mae: 0.0815\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0067 - mae: 0.0877 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0055 - mae: 0.0757 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0755 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0062 - mae: 0.0805 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0061 - mae: 0.0815 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0059 - mae: 0.0828 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0062 - mae: 0.0827 - val_loss: 0.0175 - val_mae: 0.0815\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0823 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0055 - mae: 0.0818 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0062 - mae: 0.0813 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0065 - mae: 0.0869 - val_loss: 0.0175 - val_mae: 0.0816\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0743 - val_loss: 0.0175 - val_mae: 0.0816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:58:55,330] Trial 23 finished with value: 0.08164747059345245 and parameters: {'learning_rate': 3.3372188144642476e-05, 'weight_decay': 4.967444016485161e-08}. Best is trial 10 with value: 0.07796110212802887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - mae: 0.1757 - val_loss: 0.0247 - val_mae: 0.1359\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0187 - mae: 0.1507 - val_loss: 0.0235 - val_mae: 0.1282\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0183 - mae: 0.1479 - val_loss: 0.0224 - val_mae: 0.1211\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0193 - mae: 0.1558 - val_loss: 0.0215 - val_mae: 0.1146\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0135 - mae: 0.1318 - val_loss: 0.0208 - val_mae: 0.1089\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0161 - mae: 0.1433 - val_loss: 0.0203 - val_mae: 0.1034\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0157 - mae: 0.1385 - val_loss: 0.0198 - val_mae: 0.0983\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0130 - mae: 0.1227 - val_loss: 0.0194 - val_mae: 0.0940\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0127 - mae: 0.1238 - val_loss: 0.0191 - val_mae: 0.0910\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - mae: 0.1164 - val_loss: 0.0189 - val_mae: 0.0886\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0187 - val_mae: 0.0871\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0106 - mae: 0.1129 - val_loss: 0.0186 - val_mae: 0.0863\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0114 - mae: 0.1189 - val_loss: 0.0185 - val_mae: 0.0860\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.1049 - val_loss: 0.0183 - val_mae: 0.0859\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0112 - mae: 0.1127 - val_loss: 0.0182 - val_mae: 0.0857\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1092 - val_loss: 0.0180 - val_mae: 0.0855\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0179 - val_mae: 0.0855\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0091 - mae: 0.1076 - val_loss: 0.0179 - val_mae: 0.0856\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0085 - mae: 0.1041 - val_loss: 0.0178 - val_mae: 0.0855\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0177 - val_mae: 0.0852\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0084 - mae: 0.0976 - val_loss: 0.0176 - val_mae: 0.0850\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0091 - mae: 0.1097 - val_loss: 0.0175 - val_mae: 0.0846\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - mae: 0.1003 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0084 - mae: 0.1015 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0987 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0093 - mae: 0.1072 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0907 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0076 - mae: 0.0970 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0077 - mae: 0.0973 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0073 - mae: 0.0934 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0957 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0074 - mae: 0.0949 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0062 - mae: 0.0826 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0924 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0924 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0850 - val_loss: 0.0170 - val_mae: 0.0801\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0821 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0062 - mae: 0.0835 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0862 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0171 - val_mae: 0.0805\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0063 - mae: 0.0890 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0069 - mae: 0.0894 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0847 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0054 - mae: 0.0813 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - mae: 0.0855 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0062 - mae: 0.0847 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - mae: 0.0811 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - mae: 0.0820 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0054 - mae: 0.0775 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0824 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - mae: 0.0747 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0797 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0805 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - mae: 0.0785 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mae: 0.0752 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0050 - mae: 0.0765 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0754 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0754 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0740 - val_loss: 0.0174 - val_mae: 0.0805\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0779 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0752 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0049 - mae: 0.0741 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0721 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - mae: 0.0768 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - mae: 0.0759 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0056 - mae: 0.0819 - val_loss: 0.0175 - val_mae: 0.0810\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0749 - val_loss: 0.0175 - val_mae: 0.0810\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0757 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0709 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0778 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0051 - mae: 0.0755 - val_loss: 0.0176 - val_mae: 0.0811\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0051 - mae: 0.0748 - val_loss: 0.0176 - val_mae: 0.0811\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0051 - mae: 0.0757 - val_loss: 0.0176 - val_mae: 0.0810\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0054 - mae: 0.0780 - val_loss: 0.0176 - val_mae: 0.0808\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0807\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0051 - mae: 0.0757 - val_loss: 0.0175 - val_mae: 0.0805\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0676 - val_loss: 0.0175 - val_mae: 0.0804\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0691 - val_loss: 0.0175 - val_mae: 0.0804\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0046 - mae: 0.0710 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mae: 0.0720 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0701 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0728 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0704 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0671 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0690 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0676 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0671 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0042 - mae: 0.0696 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0679 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0723 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - mae: 0.0713 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0045 - mae: 0.0692 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0698 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0717 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0045 - mae: 0.0685 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0666 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0648 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0684 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0696 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0682 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0811\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0540 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:59:07,244] Trial 24 finished with value: 0.08203449845314026 and parameters: {'learning_rate': 0.00011117500611526397, 'weight_decay': 1.5572036455719538e-06}. Best is trial 10 with value: 0.07796110212802887.\n",
      "[I 2023-12-05 13:59:07,282] A new study created in RDB with name: no-name-b84c726f-9fd3-4067-b901-7986a62a7ac0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1207\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1207\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1206\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1206\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0091 - mae: 0.1055 - val_loss: 0.0243 - val_mae: 0.1205\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1204\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0243 - val_mae: 0.1204\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1203\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0243 - val_mae: 0.1202\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0243 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1079 - val_loss: 0.0243 - val_mae: 0.1201\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0243 - val_mae: 0.1201\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1200\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0243 - val_mae: 0.1199\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0243 - val_mae: 0.1199\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0243 - val_mae: 0.1198\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0242 - val_mae: 0.1197\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0242 - val_mae: 0.1196\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0242 - val_mae: 0.1196\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0242 - val_mae: 0.1195\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1078 - val_loss: 0.0242 - val_mae: 0.1194\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0242 - val_mae: 0.1194\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1193\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1193\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0242 - val_mae: 0.1192\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0095 - mae: 0.1048 - val_loss: 0.0242 - val_mae: 0.1191\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1191\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.1190\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0242 - val_mae: 0.1190\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0242 - val_mae: 0.1189\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1030 - val_loss: 0.0241 - val_mae: 0.1188\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1188\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1187\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1186\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1186\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0241 - val_mae: 0.1185\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1185\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0241 - val_mae: 0.1183\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0241 - val_mae: 0.1183\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0241 - val_mae: 0.1182\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1181\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0090 - mae: 0.1018 - val_loss: 0.0241 - val_mae: 0.1181\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0240 - val_mae: 0.1180\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1180\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1179\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0240 - val_mae: 0.1178\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1178\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0240 - val_mae: 0.1177\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1175\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0240 - val_mae: 0.1175\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0091 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1173\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0240 - val_mae: 0.1173\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1172\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0239 - val_mae: 0.1171\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1171\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0239 - val_mae: 0.1170\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1169\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1169\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0239 - val_mae: 0.1168\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1018 - val_loss: 0.0239 - val_mae: 0.1167\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1167\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1166\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1166\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1165\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1012 - val_loss: 0.0239 - val_mae: 0.1164\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0090 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1164\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0238 - val_mae: 0.1163\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0238 - val_mae: 0.1162\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1162\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1160\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0238 - val_mae: 0.1159\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0238 - val_mae: 0.1159\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0238 - val_mae: 0.1158\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1155\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1154\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0087 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1153\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0237 - val_mae: 0.1153\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0237 - val_mae: 0.1152\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1150\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0086 - mae: 0.1009 - val_loss: 0.0236 - val_mae: 0.1146\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1146\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1145\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0236 - val_mae: 0.1143\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1142\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0236 - val_mae: 0.1142\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0236 - val_mae: 0.1141\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1139\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0087 - mae: 0.0990 - val_loss: 0.0236 - val_mae: 0.1138\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0236 - val_mae: 0.1138\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1137\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0235 - val_mae: 0.1136\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0235 - val_mae: 0.1136\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0235 - val_mae: 0.1135\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1134\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0086 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1134\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1133\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0235 - val_mae: 0.1133\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0235 - val_mae: 0.1132\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0235 - val_mae: 0.1131\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1131\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.0997 - val_loss: 0.0235 - val_mae: 0.1130\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1011 - val_loss: 0.0235 - val_mae: 0.1129\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0234 - val_mae: 0.1129\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0234 - val_mae: 0.1128\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0234 - val_mae: 0.1127\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0234 - val_mae: 0.1127\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1126\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0234 - val_mae: 0.1126\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0234 - val_mae: 0.1124\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1124\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0234 - val_mae: 0.1123\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0234 - val_mae: 0.1122\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0234 - val_mae: 0.1122\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0087 - mae: 0.0997 - val_loss: 0.0234 - val_mae: 0.1121\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1120\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0086 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1120\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0233 - val_mae: 0.1119\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0233 - val_mae: 0.1118\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0233 - val_mae: 0.1118\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0233 - val_mae: 0.1117\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0233 - val_mae: 0.1116\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0233 - val_mae: 0.1116\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0233 - val_mae: 0.1115\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0081 - mae: 0.0946 - val_loss: 0.0233 - val_mae: 0.1114\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0233 - val_mae: 0.1114\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0233 - val_mae: 0.1113\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0233 - val_mae: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:59:29,063] Trial 0 finished with value: 0.11123034358024597 and parameters: {'learning_rate': 7.550324147331352e-06, 'weight_decay': 3.900244774254743e-09}. Best is trial 0 with value: 0.11123034358024597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0209 - val_mae: 0.1360\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0122 - mae: 0.1291 - val_loss: 0.0207 - val_mae: 0.0898\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0060 - mae: 0.0721 - val_loss: 0.0194 - val_mae: 0.0851\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0049 - mae: 0.0669 - val_loss: 0.0179 - val_mae: 0.0890\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0044 - mae: 0.0693 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0806\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0165 - val_mae: 0.0824\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0163 - val_mae: 0.0861\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0164 - val_mae: 0.0895\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0036 - mae: 0.0645 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0035 - mae: 0.0644 - val_loss: 0.0165 - val_mae: 0.0866\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0035 - mae: 0.0653 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0856\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0868\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0165 - val_mae: 0.0866\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0165 - val_mae: 0.0862\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0165 - val_mae: 0.0858\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0863\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0863\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0872\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0875\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0872\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0864\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0864\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 13:59:50,659] Trial 1 finished with value: 0.085108183324337 and parameters: {'learning_rate': 0.02487409409109935, 'weight_decay': 1.3012051749220018e-05}. Best is trial 1 with value: 0.085108183324337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0251 - val_mae: 0.1243\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0251 - val_mae: 0.1242\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0099 - mae: 0.1113 - val_loss: 0.0251 - val_mae: 0.1241\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0251 - val_mae: 0.1241\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0099 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1240\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0250 - val_mae: 0.1240\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - mae: 0.1110 - val_loss: 0.0250 - val_mae: 0.1239\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0097 - mae: 0.1095 - val_loss: 0.0250 - val_mae: 0.1238\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0250 - val_mae: 0.1238\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0250 - val_mae: 0.1237\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0250 - val_mae: 0.1236\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1102 - val_loss: 0.0250 - val_mae: 0.1236\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0250 - val_mae: 0.1235\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0250 - val_mae: 0.1234\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0250 - val_mae: 0.1234\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0250 - val_mae: 0.1233\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0249 - val_mae: 0.1232\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0249 - val_mae: 0.1232\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1231\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0249 - val_mae: 0.1230\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1230\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0249 - val_mae: 0.1229\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1229\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0249 - val_mae: 0.1228\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1227\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0249 - val_mae: 0.1227\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1226\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0249 - val_mae: 0.1225\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0095 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1225\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0248 - val_mae: 0.1224\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1223\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1223\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1222\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0248 - val_mae: 0.1221\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1079 - val_loss: 0.0248 - val_mae: 0.1221\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1220\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0248 - val_mae: 0.1220\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1219\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0248 - val_mae: 0.1218\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1218\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0248 - val_mae: 0.1217\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0248 - val_mae: 0.1216\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1216\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0247 - val_mae: 0.1215\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1215\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1214\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1213\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1213\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1212\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0247 - val_mae: 0.1212\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1211\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0247 - val_mae: 0.1210\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1210\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1209\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1209\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1208\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0094 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1207\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1207\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1206\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1206\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1205\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1204\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0246 - val_mae: 0.1204\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1203\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0246 - val_mae: 0.1203\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1052 - val_loss: 0.0246 - val_mae: 0.1200\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0246 - val_mae: 0.1200\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1199\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1199\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1197\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1196\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0245 - val_mae: 0.1196\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1194\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1194\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1193\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1192\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1192\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0245 - val_mae: 0.1191\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1191\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0244 - val_mae: 0.1190\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1190\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1189\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0244 - val_mae: 0.1188\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0244 - val_mae: 0.1188\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1186\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1186\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1185\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0244 - val_mae: 0.1184\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0244 - val_mae: 0.1184\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0244 - val_mae: 0.1183\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0244 - val_mae: 0.1183\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0243 - val_mae: 0.1182\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0243 - val_mae: 0.1182\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0243 - val_mae: 0.1177\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0243 - val_mae: 0.1177\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0243 - val_mae: 0.1174\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0242 - val_mae: 0.1170\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0242 - val_mae: 0.1170\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1162\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1162\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1161\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1161\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:00:10,991] Trial 2 finished with value: 0.1156509667634964 and parameters: {'learning_rate': 1.329107332661616e-05, 'weight_decay': 2.623490255020606e-06}. Best is trial 1 with value: 0.085108183324337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0097 - mae: 0.1096 - val_loss: 0.0252 - val_mae: 0.1218\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0252 - val_mae: 0.1217\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0252 - val_mae: 0.1217\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0252 - val_mae: 0.1217\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1216\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0252 - val_mae: 0.1216\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0252 - val_mae: 0.1216\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0252 - val_mae: 0.1215\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0252 - val_mae: 0.1215\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1084 - val_loss: 0.0252 - val_mae: 0.1214\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0252 - val_mae: 0.1214\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1095 - val_loss: 0.0252 - val_mae: 0.1214\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0252 - val_mae: 0.1213\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0252 - val_mae: 0.1213\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0251 - val_mae: 0.1212\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0251 - val_mae: 0.1212\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1063 - val_loss: 0.0251 - val_mae: 0.1212\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0251 - val_mae: 0.1211\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0251 - val_mae: 0.1211\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1093 - val_loss: 0.0251 - val_mae: 0.1211\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0251 - val_mae: 0.1210\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1210\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0251 - val_mae: 0.1209\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1209\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0251 - val_mae: 0.1209\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0251 - val_mae: 0.1208\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0251 - val_mae: 0.1208\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0251 - val_mae: 0.1207\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0251 - val_mae: 0.1207\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0251 - val_mae: 0.1207\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0098 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1206\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1206\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0251 - val_mae: 0.1205\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0251 - val_mae: 0.1205\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0250 - val_mae: 0.1205\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1204\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1080 - val_loss: 0.0250 - val_mae: 0.1204\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1204\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0250 - val_mae: 0.1203\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0250 - val_mae: 0.1203\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0250 - val_mae: 0.1202\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0250 - val_mae: 0.1202\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0250 - val_mae: 0.1202\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0250 - val_mae: 0.1201\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0250 - val_mae: 0.1201\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0250 - val_mae: 0.1200\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0250 - val_mae: 0.1200\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0250 - val_mae: 0.1200\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0250 - val_mae: 0.1199\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0250 - val_mae: 0.1199\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0250 - val_mae: 0.1199\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0250 - val_mae: 0.1198\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0250 - val_mae: 0.1198\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0250 - val_mae: 0.1197\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1197\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0249 - val_mae: 0.1197\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0249 - val_mae: 0.1195\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1195\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1052 - val_loss: 0.0249 - val_mae: 0.1194\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0249 - val_mae: 0.1194\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0249 - val_mae: 0.1194\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0094 - mae: 0.1064 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0249 - val_mae: 0.1192\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0249 - val_mae: 0.1192\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0249 - val_mae: 0.1192\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0249 - val_mae: 0.1191\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0249 - val_mae: 0.1191\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0249 - val_mae: 0.1190\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0249 - val_mae: 0.1190\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0249 - val_mae: 0.1190\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0249 - val_mae: 0.1189\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1189\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0248 - val_mae: 0.1189\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1187\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1187\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1187\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1186\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1186\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1186\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1185\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1185\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0248 - val_mae: 0.1185\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0248 - val_mae: 0.1184\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1184\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0248 - val_mae: 0.1183\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1183\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0248 - val_mae: 0.1183\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0248 - val_mae: 0.1182\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0248 - val_mae: 0.1182\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1182\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1180\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1180\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1180\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1179\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1179\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1178\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1178\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1178\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1176\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0247 - val_mae: 0.1176\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1176\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0247 - val_mae: 0.1175\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1175\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0247 - val_mae: 0.1175\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1173\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1173\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1173\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1172\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1172\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1172\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1171\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1171\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1171\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1170\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1170\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1170\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0246 - val_mae: 0.1169\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0246 - val_mae: 0.1169\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1169\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1168\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1168\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1168\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1167\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1167\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1167\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1166\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1166\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1166\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1165\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1165\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1165\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1164\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0245 - val_mae: 0.1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:00:31,012] Trial 3 finished with value: 0.11640835553407669 and parameters: {'learning_rate': 6.472062872221373e-06, 'weight_decay': 1.3649685535101645e-08}. Best is trial 1 with value: 0.085108183324337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0090 - mae: 0.1046 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0092 - mae: 0.1059 - val_loss: 0.0246 - val_mae: 0.1199\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1044 - val_loss: 0.0246 - val_mae: 0.1198\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1196\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1193\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0245 - val_mae: 0.1192\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1190\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1185\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0244 - val_mae: 0.1184\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0243 - val_mae: 0.1177\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0243 - val_mae: 0.1174\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1170\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1003 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1162\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1158\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0240 - val_mae: 0.1156\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0998 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0239 - val_mae: 0.1150\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0989 - val_loss: 0.0239 - val_mae: 0.1148\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1146\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0994 - val_loss: 0.0238 - val_mae: 0.1141\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0238 - val_mae: 0.1139\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0238 - val_mae: 0.1138\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0238 - val_mae: 0.1136\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1134\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1132\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1131\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0237 - val_mae: 0.1129\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1127\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0979 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0236 - val_mae: 0.1122\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0082 - mae: 0.0973 - val_loss: 0.0236 - val_mae: 0.1119\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1116\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0235 - val_mae: 0.1112\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0234 - val_mae: 0.1111\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0234 - val_mae: 0.1107\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0234 - val_mae: 0.1105\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0946 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1102\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1100\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0233 - val_mae: 0.1098\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0079 - mae: 0.0941 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1086\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0231 - val_mae: 0.1084\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0230 - val_mae: 0.1078\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0933 - val_loss: 0.0230 - val_mae: 0.1076\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0078 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1070\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1060\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0228 - val_mae: 0.1056\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0908 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0227 - val_mae: 0.1053\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0227 - val_mae: 0.1049\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0076 - mae: 0.0902 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0226 - val_mae: 0.1039\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0908 - val_loss: 0.0225 - val_mae: 0.1033\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0224 - val_mae: 0.1023\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0887 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0224 - val_mae: 0.1019\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0223 - val_mae: 0.1017\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0223 - val_mae: 0.1015\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.1013\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0222 - val_mae: 0.1009\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0222 - val_mae: 0.1005\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.1003\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0221 - val_mae: 0.0999\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0221 - val_mae: 0.0997\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0221 - val_mae: 0.0995\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0067 - mae: 0.0829 - val_loss: 0.0221 - val_mae: 0.0993\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0838 - val_loss: 0.0220 - val_mae: 0.0991\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0843 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0220 - val_mae: 0.0987\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0220 - val_mae: 0.0985\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0219 - val_mae: 0.0978\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0860 - val_loss: 0.0219 - val_mae: 0.0976\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0218 - val_mae: 0.0974\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0825 - val_loss: 0.0218 - val_mae: 0.0970\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0803 - val_loss: 0.0218 - val_mae: 0.0968\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0217 - val_mae: 0.0966\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0810 - val_loss: 0.0217 - val_mae: 0.0963\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0804 - val_loss: 0.0217 - val_mae: 0.0961\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0834 - val_loss: 0.0217 - val_mae: 0.0959\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0809 - val_loss: 0.0216 - val_mae: 0.0955\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0216 - val_mae: 0.0952\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0216 - val_mae: 0.0950\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0067 - mae: 0.0819 - val_loss: 0.0215 - val_mae: 0.0948\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0065 - mae: 0.0793 - val_loss: 0.0215 - val_mae: 0.0946\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0817 - val_loss: 0.0215 - val_mae: 0.0943\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0804 - val_loss: 0.0215 - val_mae: 0.0941\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0813 - val_loss: 0.0214 - val_mae: 0.0939\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0829 - val_loss: 0.0214 - val_mae: 0.0936\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0214 - val_mae: 0.0934\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0214 - val_mae: 0.0932\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0213 - val_mae: 0.0930\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0066 - mae: 0.0808 - val_loss: 0.0213 - val_mae: 0.0927\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0213 - val_mae: 0.0925\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0213 - val_mae: 0.0923\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0760 - val_loss: 0.0212 - val_mae: 0.0921\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0809 - val_loss: 0.0212 - val_mae: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:00:50,102] Trial 4 finished with value: 0.09185388684272766 and parameters: {'learning_rate': 3.3707840237371834e-05, 'weight_decay': 1.1798896599520189e-09}. Best is trial 1 with value: 0.085108183324337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1124 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0102 - mae: 0.1119 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0104 - mae: 0.1137 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0103 - mae: 0.1124 - val_loss: 0.0253 - val_mae: 0.1249\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0104 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1124 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0102 - mae: 0.1128 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0102 - mae: 0.1118 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1104 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0105 - mae: 0.1136 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0253 - val_mae: 0.1248\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0105 - mae: 0.1135 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1102 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1093 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1104 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0100 - mae: 0.1091 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0095 - mae: 0.1081 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0103 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1096 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1093 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0103 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0253 - val_mae: 0.1247\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0104 - mae: 0.1124 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1108 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0101 - mae: 0.1118 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0104 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - mae: 0.1143 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0102 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0103 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0102 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1246\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1115 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1113 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0102 - mae: 0.1119 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1107 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1123 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1123 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1119 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1140 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1124 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0106 - mae: 0.1157 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1118 - val_loss: 0.0252 - val_mae: 0.1245\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0252 - val_mae: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:01:09,125] Trial 5 finished with value: 0.12446046620607376 and parameters: {'learning_rate': 4.421929608108059e-07, 'weight_decay': 0.0004412766794898174}. Best is trial 1 with value: 0.085108183324337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0176 - val_mae: 0.0894\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0056 - mae: 0.0786 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0047 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0886\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0677 - val_loss: 0.0172 - val_mae: 0.0888\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0037 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0873\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0868\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0873\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0879\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0884\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0167 - val_mae: 0.0893\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0626 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0622 - val_loss: 0.0166 - val_mae: 0.0876\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0827\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0873\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0875\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0862\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0862\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0868\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0871\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0865\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0871\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0874\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0874\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0872\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:01:28,368] Trial 6 finished with value: 0.0843486413359642 and parameters: {'learning_rate': 0.012979954082694355, 'weight_decay': 0.003628337880532606}. Best is trial 6 with value: 0.0843486413359642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1053 - val_loss: 0.0223 - val_mae: 0.1017\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0207 - val_mae: 0.0866\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0060 - mae: 0.0739 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0046 - mae: 0.0664 - val_loss: 0.0177 - val_mae: 0.0883\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0046 - mae: 0.0737 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0734 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0805\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0876\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0882\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0875\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0829\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0829\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0868\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0869\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0170 - val_mae: 0.0815\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0825\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0813\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0868\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0876\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0879\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0877\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0554 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0870\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0868\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:01:47,155] Trial 7 finished with value: 0.08570673316717148 and parameters: {'learning_rate': 0.005734673381477518, 'weight_decay': 5.0293109817637345e-09}. Best is trial 6 with value: 0.0843486413359642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0248 - val_mae: 0.1180\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0246 - val_mae: 0.1170\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0246 - val_mae: 0.1167\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0246 - val_mae: 0.1163\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0245 - val_mae: 0.1160\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0245 - val_mae: 0.1157\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0244 - val_mae: 0.1153\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0244 - val_mae: 0.1150\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0243 - val_mae: 0.1146\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.0995 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0089 - mae: 0.1002 - val_loss: 0.0242 - val_mae: 0.1140\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0242 - val_mae: 0.1136\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1002 - val_loss: 0.0241 - val_mae: 0.1133\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0241 - val_mae: 0.1130\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0989 - val_loss: 0.0241 - val_mae: 0.1126\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1123\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0240 - val_mae: 0.1120\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0239 - val_mae: 0.1117\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0239 - val_mae: 0.1114\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0239 - val_mae: 0.1110\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0238 - val_mae: 0.1107\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0082 - mae: 0.0948 - val_loss: 0.0238 - val_mae: 0.1104\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0237 - val_mae: 0.1101\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0237 - val_mae: 0.1098\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1094\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0948 - val_loss: 0.0236 - val_mae: 0.1091\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0236 - val_mae: 0.1088\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0235 - val_mae: 0.1084\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0235 - val_mae: 0.1081\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0234 - val_mae: 0.1078\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0925 - val_loss: 0.0234 - val_mae: 0.1074\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0919 - val_loss: 0.0234 - val_mae: 0.1071\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0948 - val_loss: 0.0233 - val_mae: 0.1068\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0233 - val_mae: 0.1064\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0232 - val_mae: 0.1061\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0232 - val_mae: 0.1058\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0934 - val_loss: 0.0232 - val_mae: 0.1054\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0231 - val_mae: 0.1051\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0231 - val_mae: 0.1047\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0909 - val_loss: 0.0230 - val_mae: 0.1043\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0078 - mae: 0.0909 - val_loss: 0.0230 - val_mae: 0.1040\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0229 - val_mae: 0.1036\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0229 - val_mae: 0.1032\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0228 - val_mae: 0.1029\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.1021\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0227 - val_mae: 0.1017\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0227 - val_mae: 0.1013\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0226 - val_mae: 0.1010\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0226 - val_mae: 0.1006\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0225 - val_mae: 0.1002\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.0994\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0224 - val_mae: 0.0991\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0069 - mae: 0.0846 - val_loss: 0.0223 - val_mae: 0.0987\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0891 - val_loss: 0.0223 - val_mae: 0.0983\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0222 - val_mae: 0.0979\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0849 - val_loss: 0.0222 - val_mae: 0.0975\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0838 - val_loss: 0.0221 - val_mae: 0.0972\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0221 - val_mae: 0.0968\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0221 - val_mae: 0.0964\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0220 - val_mae: 0.0960\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0832 - val_loss: 0.0220 - val_mae: 0.0956\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0219 - val_mae: 0.0953\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0829 - val_loss: 0.0219 - val_mae: 0.0949\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0218 - val_mae: 0.0945\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0218 - val_mae: 0.0941\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0217 - val_mae: 0.0937\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0217 - val_mae: 0.0934\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0803 - val_loss: 0.0216 - val_mae: 0.0930\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0216 - val_mae: 0.0926\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0798 - val_loss: 0.0215 - val_mae: 0.0923\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0214 - val_mae: 0.0919\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0214 - val_mae: 0.0915\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0747 - val_loss: 0.0213 - val_mae: 0.0912\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0213 - val_mae: 0.0909\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0769 - val_loss: 0.0212 - val_mae: 0.0906\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0062 - mae: 0.0743 - val_loss: 0.0212 - val_mae: 0.0903\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0772 - val_loss: 0.0211 - val_mae: 0.0900\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0823 - val_loss: 0.0211 - val_mae: 0.0898\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0210 - val_mae: 0.0896\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0210 - val_mae: 0.0894\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0209 - val_mae: 0.0891\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0785 - val_loss: 0.0209 - val_mae: 0.0889\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0062 - mae: 0.0765 - val_loss: 0.0208 - val_mae: 0.0887\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0746 - val_loss: 0.0208 - val_mae: 0.0885\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0759 - val_loss: 0.0207 - val_mae: 0.0883\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0207 - val_mae: 0.0881\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0756 - val_loss: 0.0206 - val_mae: 0.0880\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0757 - val_loss: 0.0206 - val_mae: 0.0878\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0725 - val_loss: 0.0205 - val_mae: 0.0876\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0205 - val_mae: 0.0874\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0732 - val_loss: 0.0204 - val_mae: 0.0872\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0752 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0203 - val_mae: 0.0868\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0056 - mae: 0.0720 - val_loss: 0.0203 - val_mae: 0.0866\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0692 - val_loss: 0.0202 - val_mae: 0.0864\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0774 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0201 - val_mae: 0.0860\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0201 - val_mae: 0.0858\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0050 - mae: 0.0685 - val_loss: 0.0200 - val_mae: 0.0856\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0200 - val_mae: 0.0854\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0056 - mae: 0.0713 - val_loss: 0.0199 - val_mae: 0.0852\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0729 - val_loss: 0.0199 - val_mae: 0.0851\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0053 - mae: 0.0705 - val_loss: 0.0198 - val_mae: 0.0849\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0703 - val_loss: 0.0198 - val_mae: 0.0847\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0689 - val_loss: 0.0197 - val_mae: 0.0845\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0728 - val_loss: 0.0197 - val_mae: 0.0844\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - mae: 0.0697 - val_loss: 0.0196 - val_mae: 0.0842\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0055 - mae: 0.0745 - val_loss: 0.0196 - val_mae: 0.0840\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0705 - val_loss: 0.0196 - val_mae: 0.0838\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0195 - val_mae: 0.0837\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0195 - val_mae: 0.0835\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0194 - val_mae: 0.0833\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0714 - val_loss: 0.0194 - val_mae: 0.0831\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0193 - val_mae: 0.0830\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0193 - val_mae: 0.0828\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0193 - val_mae: 0.0827\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0695 - val_loss: 0.0192 - val_mae: 0.0825\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0703 - val_loss: 0.0192 - val_mae: 0.0823\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0680 - val_loss: 0.0191 - val_mae: 0.0822\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0672 - val_loss: 0.0191 - val_mae: 0.0820\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0682 - val_loss: 0.0191 - val_mae: 0.0819\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0709 - val_loss: 0.0190 - val_mae: 0.0818\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0190 - val_mae: 0.0816\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0190 - val_mae: 0.0815\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0189 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - mae: 0.0658 - val_loss: 0.0189 - val_mae: 0.0813\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0189 - val_mae: 0.0812\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0707 - val_loss: 0.0188 - val_mae: 0.0811\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0052 - mae: 0.0734 - val_loss: 0.0188 - val_mae: 0.0810\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0188 - val_mae: 0.0809\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0188 - val_mae: 0.0808\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0187 - val_mae: 0.0807\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0187 - val_mae: 0.0806\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0187 - val_mae: 0.0805\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0187 - val_mae: 0.0805\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0186 - val_mae: 0.0804\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0186 - val_mae: 0.0804\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0186 - val_mae: 0.0803\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0186 - val_mae: 0.0803\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0658 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0051 - mae: 0.0657 - val_loss: 0.0185 - val_mae: 0.0802\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0185 - val_mae: 0.0801\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0801\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0184 - val_mae: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:02:05,845] Trial 8 finished with value: 0.08014242351055145 and parameters: {'learning_rate': 7.937796360865135e-05, 'weight_decay': 0.00016363889931851811}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1123\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1087\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0947 - val_loss: 0.0231 - val_mae: 0.1051\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1016\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0224 - val_mae: 0.0980\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.0942\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0065 - mae: 0.0816 - val_loss: 0.0216 - val_mae: 0.0906\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0786 - val_loss: 0.0211 - val_mae: 0.0877\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0058 - mae: 0.0737 - val_loss: 0.0207 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0055 - mae: 0.0726 - val_loss: 0.0202 - val_mae: 0.0831\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0695 - val_loss: 0.0198 - val_mae: 0.0818\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0194 - val_mae: 0.0818\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0191 - val_mae: 0.0822\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0051 - mae: 0.0690 - val_loss: 0.0188 - val_mae: 0.0826\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0185 - val_mae: 0.0834\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0671 - val_loss: 0.0183 - val_mae: 0.0840\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0715 - val_loss: 0.0181 - val_mae: 0.0845\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0689 - val_loss: 0.0180 - val_mae: 0.0845\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0726 - val_loss: 0.0178 - val_mae: 0.0840\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0177 - val_mae: 0.0833\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0042 - mae: 0.0669 - val_loss: 0.0176 - val_mae: 0.0812\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0785\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0780\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0176 - val_mae: 0.0776\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0774\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0598 - val_loss: 0.0176 - val_mae: 0.0775\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0610 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0641 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0039 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0029 - mae: 0.0517 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0171 - val_mae: 0.0836\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0832\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0524 - val_loss: 0.0176 - val_mae: 0.0816\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0533 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0175 - val_mae: 0.0823\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0176 - val_mae: 0.0821\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0177 - val_mae: 0.0820\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0831\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0177 - val_mae: 0.0831\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0550 - val_loss: 0.0178 - val_mae: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:02:25,326] Trial 9 finished with value: 0.08314559608697891 and parameters: {'learning_rate': 0.0008513535436440991, 'weight_decay': 3.935926574096522e-05}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0241 - val_mae: 0.1182\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0241 - val_mae: 0.1180\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1177\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1172\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1166\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0239 - val_mae: 0.1163\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0238 - val_mae: 0.1160\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1154\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0236 - val_mae: 0.1142\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0236 - val_mae: 0.1139\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0236 - val_mae: 0.1136\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0235 - val_mae: 0.1133\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0979 - val_loss: 0.0235 - val_mae: 0.1130\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1127\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1124\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1121\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0961 - val_loss: 0.0233 - val_mae: 0.1116\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0966 - val_loss: 0.0233 - val_mae: 0.1113\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0233 - val_mae: 0.1110\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0965 - val_loss: 0.0232 - val_mae: 0.1107\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0973 - val_loss: 0.0231 - val_mae: 0.1101\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1097\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0231 - val_mae: 0.1094\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0230 - val_mae: 0.1091\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0923 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0928 - val_loss: 0.0230 - val_mae: 0.1085\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1081\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1078\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0944 - val_loss: 0.0228 - val_mae: 0.1075\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0944 - val_loss: 0.0228 - val_mae: 0.1072\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0228 - val_mae: 0.1069\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0077 - mae: 0.0921 - val_loss: 0.0227 - val_mae: 0.1065\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1062\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0226 - val_mae: 0.1055\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0938 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0226 - val_mae: 0.1049\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0225 - val_mae: 0.1046\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0902 - val_loss: 0.0225 - val_mae: 0.1043\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0913 - val_loss: 0.0224 - val_mae: 0.1040\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0884 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0224 - val_mae: 0.1033\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0223 - val_mae: 0.1030\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0905 - val_loss: 0.0223 - val_mae: 0.1027\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0873 - val_loss: 0.0222 - val_mae: 0.1021\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0911 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0221 - val_mae: 0.1014\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0070 - mae: 0.0873 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0221 - val_mae: 0.1008\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0899 - val_loss: 0.0220 - val_mae: 0.1005\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0896 - val_loss: 0.0220 - val_mae: 0.1001\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0219 - val_mae: 0.0999\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0867 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0851 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0838 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0987\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0878 - val_loss: 0.0217 - val_mae: 0.0984\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0823 - val_loss: 0.0217 - val_mae: 0.0978\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0862 - val_loss: 0.0216 - val_mae: 0.0976\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0849 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0852 - val_loss: 0.0215 - val_mae: 0.0971\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0846 - val_loss: 0.0215 - val_mae: 0.0968\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0215 - val_mae: 0.0966\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0827 - val_loss: 0.0214 - val_mae: 0.0963\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0064 - mae: 0.0819 - val_loss: 0.0214 - val_mae: 0.0961\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0213 - val_mae: 0.0958\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0213 - val_mae: 0.0956\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065 - mae: 0.0834 - val_loss: 0.0213 - val_mae: 0.0953\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0065 - mae: 0.0835 - val_loss: 0.0212 - val_mae: 0.0951\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0212 - val_mae: 0.0949\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0947\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0834 - val_loss: 0.0211 - val_mae: 0.0945\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0800 - val_loss: 0.0211 - val_mae: 0.0943\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064 - mae: 0.0806 - val_loss: 0.0210 - val_mae: 0.0941\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0210 - val_mae: 0.0939\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0777 - val_loss: 0.0210 - val_mae: 0.0936\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0814 - val_loss: 0.0209 - val_mae: 0.0934\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0064 - mae: 0.0801 - val_loss: 0.0209 - val_mae: 0.0932\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0796 - val_loss: 0.0208 - val_mae: 0.0930\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0777 - val_loss: 0.0208 - val_mae: 0.0928\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0804 - val_loss: 0.0208 - val_mae: 0.0926\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0207 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0774 - val_loss: 0.0207 - val_mae: 0.0922\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0778 - val_loss: 0.0207 - val_mae: 0.0920\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0778 - val_loss: 0.0206 - val_mae: 0.0918\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0777 - val_loss: 0.0206 - val_mae: 0.0916\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0801 - val_loss: 0.0205 - val_mae: 0.0914\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.0912\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0058 - mae: 0.0758 - val_loss: 0.0205 - val_mae: 0.0910\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0793 - val_loss: 0.0204 - val_mae: 0.0908\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0060 - mae: 0.0790 - val_loss: 0.0204 - val_mae: 0.0905\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0767 - val_loss: 0.0204 - val_mae: 0.0903\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0061 - mae: 0.0784 - val_loss: 0.0203 - val_mae: 0.0901\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0203 - val_mae: 0.0899\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0784 - val_loss: 0.0203 - val_mae: 0.0897\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0059 - mae: 0.0786 - val_loss: 0.0202 - val_mae: 0.0895\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0058 - mae: 0.0754 - val_loss: 0.0202 - val_mae: 0.0893\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0202 - val_mae: 0.0891\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0767 - val_loss: 0.0201 - val_mae: 0.0889\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0759 - val_loss: 0.0201 - val_mae: 0.0887\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0201 - val_mae: 0.0885\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0200 - val_mae: 0.0883\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0756 - val_loss: 0.0200 - val_mae: 0.0881\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0879\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0794 - val_loss: 0.0199 - val_mae: 0.0877\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0745 - val_loss: 0.0199 - val_mae: 0.0876\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0056 - mae: 0.0759 - val_loss: 0.0199 - val_mae: 0.0874\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0198 - val_mae: 0.0872\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0198 - val_mae: 0.0870\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0739 - val_loss: 0.0198 - val_mae: 0.0869\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0197 - val_mae: 0.0867\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0058 - mae: 0.0761 - val_loss: 0.0197 - val_mae: 0.0866\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0755 - val_loss: 0.0197 - val_mae: 0.0864\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0753 - val_loss: 0.0196 - val_mae: 0.0862\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0196 - val_mae: 0.0861\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0196 - val_mae: 0.0859\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.0858\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0195 - val_mae: 0.0856\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0195 - val_mae: 0.0854\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0763 - val_loss: 0.0195 - val_mae: 0.0853\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0194 - val_mae: 0.0851\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0740 - val_loss: 0.0194 - val_mae: 0.0850\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0734 - val_loss: 0.0194 - val_mae: 0.0848\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0055 - mae: 0.0747 - val_loss: 0.0193 - val_mae: 0.0847\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0193 - val_mae: 0.0845\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0193 - val_mae: 0.0844\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0192 - val_mae: 0.0842\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0725 - val_loss: 0.0192 - val_mae: 0.0841\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0839\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0192 - val_mae: 0.0837\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0754 - val_loss: 0.0191 - val_mae: 0.0836\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0775 - val_loss: 0.0191 - val_mae: 0.0834\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0677 - val_loss: 0.0191 - val_mae: 0.0833\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0745 - val_loss: 0.0191 - val_mae: 0.0831\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0747 - val_loss: 0.0190 - val_mae: 0.0829\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0190 - val_mae: 0.0828\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0051 - mae: 0.0737 - val_loss: 0.0190 - val_mae: 0.0826\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0190 - val_mae: 0.0825\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0720 - val_loss: 0.0189 - val_mae: 0.0823\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0721 - val_loss: 0.0189 - val_mae: 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:02:44,192] Trial 10 finished with value: 0.08221465349197388 and parameters: {'learning_rate': 5.1602332025791137e-05, 'weight_decay': 0.0020825415459014133}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0250 - val_mae: 0.1225\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1222\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0249 - val_mae: 0.1220\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1218\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1215\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1213\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1210\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1094 - val_loss: 0.0247 - val_mae: 0.1208\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1205\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0246 - val_mae: 0.1200\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0246 - val_mae: 0.1197\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1192\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1190\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1185\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1162\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1160\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0240 - val_mae: 0.1158\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1151\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1149\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0239 - val_mae: 0.1146\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0091 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1144\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0238 - val_mae: 0.1142\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0238 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1133\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1131\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0236 - val_mae: 0.1129\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1127\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1122\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1120\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.0988 - val_loss: 0.0235 - val_mae: 0.1118\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0235 - val_mae: 0.1116\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1112\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0234 - val_mae: 0.1110\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1108\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1106\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0233 - val_mae: 0.1103\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0232 - val_mae: 0.1097\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0232 - val_mae: 0.1095\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0231 - val_mae: 0.1089\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1087\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0231 - val_mae: 0.1085\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0230 - val_mae: 0.1083\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0230 - val_mae: 0.1081\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0230 - val_mae: 0.1079\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0937 - val_loss: 0.0230 - val_mae: 0.1077\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0229 - val_mae: 0.1075\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1073\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0229 - val_mae: 0.1071\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1069\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0081 - mae: 0.0936 - val_loss: 0.0228 - val_mae: 0.1067\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0228 - val_mae: 0.1063\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0227 - val_mae: 0.1057\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0227 - val_mae: 0.1055\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1053\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0078 - mae: 0.0915 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0913 - val_loss: 0.0226 - val_mae: 0.1049\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.1045\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0225 - val_mae: 0.1043\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0224 - val_mae: 0.1034\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0223 - val_mae: 0.1026\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0867 - val_loss: 0.0222 - val_mae: 0.1016\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0222 - val_mae: 0.1013\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0222 - val_mae: 0.1011\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0221 - val_mae: 0.1009\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0864 - val_loss: 0.0221 - val_mae: 0.1005\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0855 - val_loss: 0.0221 - val_mae: 0.1003\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0220 - val_mae: 0.1001\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0220 - val_mae: 0.0999\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0220 - val_mae: 0.0996\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0220 - val_mae: 0.0994\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0219 - val_mae: 0.0990\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0073 - mae: 0.0853 - val_loss: 0.0219 - val_mae: 0.0987\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0219 - val_mae: 0.0985\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0218 - val_mae: 0.0983\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0845 - val_loss: 0.0218 - val_mae: 0.0980\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0218 - val_mae: 0.0978\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0831 - val_loss: 0.0218 - val_mae: 0.0976\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - mae: 0.0834 - val_loss: 0.0217 - val_mae: 0.0973\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0068 - mae: 0.0831 - val_loss: 0.0217 - val_mae: 0.0971\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0070 - mae: 0.0823 - val_loss: 0.0217 - val_mae: 0.0968\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0216 - val_mae: 0.0966\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0068 - mae: 0.0830 - val_loss: 0.0216 - val_mae: 0.0963\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - mae: 0.0825 - val_loss: 0.0216 - val_mae: 0.0961\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0825 - val_loss: 0.0216 - val_mae: 0.0958\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0822 - val_loss: 0.0215 - val_mae: 0.0956\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0215 - val_mae: 0.0953\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0215 - val_mae: 0.0951\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0215 - val_mae: 0.0948\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0214 - val_mae: 0.0945\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0817 - val_loss: 0.0214 - val_mae: 0.0943\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0214 - val_mae: 0.0940\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0213 - val_mae: 0.0938\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0805 - val_loss: 0.0213 - val_mae: 0.0935\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0790 - val_loss: 0.0213 - val_mae: 0.0930\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0065 - mae: 0.0793 - val_loss: 0.0212 - val_mae: 0.0928\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0066 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0925\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0815 - val_loss: 0.0212 - val_mae: 0.0923\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0788 - val_loss: 0.0211 - val_mae: 0.0920\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0065 - mae: 0.0785 - val_loss: 0.0211 - val_mae: 0.0918\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0211 - val_mae: 0.0916\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0210 - val_mae: 0.0913\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0210 - val_mae: 0.0911\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0804 - val_loss: 0.0210 - val_mae: 0.0909\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0210 - val_mae: 0.0906\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0062 - mae: 0.0764 - val_loss: 0.0209 - val_mae: 0.0904\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0794 - val_loss: 0.0209 - val_mae: 0.0901\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0209 - val_mae: 0.0899\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0768 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0062 - mae: 0.0766 - val_loss: 0.0208 - val_mae: 0.0894\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0788 - val_loss: 0.0208 - val_mae: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:03:03,117] Trial 11 finished with value: 0.08923231810331345 and parameters: {'learning_rate': 5.442934525835481e-05, 'weight_decay': 0.0030965598051397127}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1177\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1175\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0241 - val_mae: 0.1173\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1172\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1171\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1168\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1165\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1164\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1163\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0989 - val_loss: 0.0239 - val_mae: 0.1160\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0239 - val_mae: 0.1158\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0239 - val_mae: 0.1157\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0239 - val_mae: 0.1156\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0239 - val_mae: 0.1154\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0239 - val_mae: 0.1153\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1150\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0238 - val_mae: 0.1148\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.0994 - val_loss: 0.0238 - val_mae: 0.1147\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0238 - val_mae: 0.1145\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1144\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0992 - val_loss: 0.0238 - val_mae: 0.1142\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1141\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0984 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0237 - val_mae: 0.1138\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1001 - val_loss: 0.0237 - val_mae: 0.1136\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1133\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1132\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0236 - val_mae: 0.1130\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0990 - val_loss: 0.0236 - val_mae: 0.1129\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0236 - val_mae: 0.1127\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0086 - mae: 0.0978 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0236 - val_mae: 0.1123\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0088 - mae: 0.1008 - val_loss: 0.0235 - val_mae: 0.1122\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0235 - val_mae: 0.1120\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0235 - val_mae: 0.1119\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1116\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0234 - val_mae: 0.1113\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1111\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0961 - val_loss: 0.0234 - val_mae: 0.1110\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0234 - val_mae: 0.1108\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1107\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1105\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084 - mae: 0.0950 - val_loss: 0.0233 - val_mae: 0.1102\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0983 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.0984 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0233 - val_mae: 0.1098\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0963 - val_loss: 0.0233 - val_mae: 0.1094\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0232 - val_mae: 0.1092\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0946 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1084\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0941 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0948 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0231 - val_mae: 0.1075\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0081 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0943 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0908 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0915 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0908 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0228 - val_mae: 0.1054\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0899 - val_loss: 0.0228 - val_mae: 0.1052\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0228 - val_mae: 0.1051\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0228 - val_mae: 0.1049\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1048\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0911 - val_loss: 0.0227 - val_mae: 0.1042\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0905 - val_loss: 0.0227 - val_mae: 0.1039\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0894 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0226 - val_mae: 0.1035\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0909 - val_loss: 0.0226 - val_mae: 0.1034\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0226 - val_mae: 0.1032\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0225 - val_mae: 0.1028\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0225 - val_mae: 0.1026\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0225 - val_mae: 0.1025\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0225 - val_mae: 0.1024\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0225 - val_mae: 0.1022\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0883 - val_loss: 0.0224 - val_mae: 0.1019\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0224 - val_mae: 0.1018\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0224 - val_mae: 0.1017\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0224 - val_mae: 0.1015\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0875 - val_loss: 0.0224 - val_mae: 0.1014\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0884 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0223 - val_mae: 0.1010\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0854 - val_loss: 0.0223 - val_mae: 0.1008\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0223 - val_mae: 0.1007\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0223 - val_mae: 0.1005\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0884 - val_loss: 0.0222 - val_mae: 0.1002\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0222 - val_mae: 0.1001\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0860 - val_loss: 0.0222 - val_mae: 0.1000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0865 - val_loss: 0.0222 - val_mae: 0.0998\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0222 - val_mae: 0.0997\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0221 - val_mae: 0.0995\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0221 - val_mae: 0.0994\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0077 - mae: 0.0885 - val_loss: 0.0221 - val_mae: 0.0993\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0878 - val_loss: 0.0221 - val_mae: 0.0991\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0221 - val_mae: 0.0990\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.0988\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0837 - val_loss: 0.0220 - val_mae: 0.0987\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0864 - val_loss: 0.0220 - val_mae: 0.0985\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0849 - val_loss: 0.0220 - val_mae: 0.0984\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0878 - val_loss: 0.0220 - val_mae: 0.0983\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0220 - val_mae: 0.0981\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0071 - mae: 0.0834 - val_loss: 0.0219 - val_mae: 0.0978\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0073 - mae: 0.0841 - val_loss: 0.0219 - val_mae: 0.0977\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0975\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0219 - val_mae: 0.0974\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0219 - val_mae: 0.0972\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0971\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0070 - mae: 0.0823 - val_loss: 0.0218 - val_mae: 0.0970\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0844 - val_loss: 0.0218 - val_mae: 0.0968\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.0967\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0965\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0836 - val_loss: 0.0218 - val_mae: 0.0964\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0862 - val_loss: 0.0217 - val_mae: 0.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:03:21,947] Trial 12 finished with value: 0.09626232087612152 and parameters: {'learning_rate': 2.5007661823321552e-05, 'weight_decay': 0.00019901512254179377}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1029 - val_loss: 0.0249 - val_mae: 0.1164\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1030 - val_loss: 0.0247 - val_mae: 0.1149\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1027 - val_loss: 0.0244 - val_mae: 0.1135\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.0990 - val_loss: 0.0242 - val_mae: 0.1120\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1106\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0238 - val_mae: 0.1093\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0931 - val_loss: 0.0236 - val_mae: 0.1079\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0234 - val_mae: 0.1066\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0081 - mae: 0.0915 - val_loss: 0.0233 - val_mae: 0.1053\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0231 - val_mae: 0.1039\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0229 - val_mae: 0.1026\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0883 - val_loss: 0.0228 - val_mae: 0.1013\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0072 - mae: 0.0834 - val_loss: 0.0226 - val_mae: 0.0999\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0224 - val_mae: 0.0985\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0857 - val_loss: 0.0223 - val_mae: 0.0972\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0870 - val_loss: 0.0221 - val_mae: 0.0958\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0220 - val_mae: 0.0943\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0072 - mae: 0.0814 - val_loss: 0.0218 - val_mae: 0.0930\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0216 - val_mae: 0.0916\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - mae: 0.0786 - val_loss: 0.0215 - val_mae: 0.0902\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0066 - mae: 0.0779 - val_loss: 0.0213 - val_mae: 0.0889\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0065 - mae: 0.0777 - val_loss: 0.0211 - val_mae: 0.0876\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0064 - mae: 0.0766 - val_loss: 0.0210 - val_mae: 0.0864\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - mae: 0.0749 - val_loss: 0.0208 - val_mae: 0.0852\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0733 - val_loss: 0.0206 - val_mae: 0.0840\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0752 - val_loss: 0.0204 - val_mae: 0.0831\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0203 - val_mae: 0.0823\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0060 - mae: 0.0731 - val_loss: 0.0201 - val_mae: 0.0818\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0747 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0712 - val_loss: 0.0198 - val_mae: 0.0812\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0744 - val_loss: 0.0196 - val_mae: 0.0810\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0723 - val_loss: 0.0195 - val_mae: 0.0810\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0732 - val_loss: 0.0194 - val_mae: 0.0808\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0683 - val_loss: 0.0193 - val_mae: 0.0806\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0665 - val_loss: 0.0192 - val_mae: 0.0805\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0690 - val_loss: 0.0190 - val_mae: 0.0803\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0190 - val_mae: 0.0800\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0189 - val_mae: 0.0797\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0684 - val_loss: 0.0188 - val_mae: 0.0794\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0668 - val_loss: 0.0187 - val_mae: 0.0788\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0186 - val_mae: 0.0786\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0185 - val_mae: 0.0785\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0050 - mae: 0.0684 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0049 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0783\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0662 - val_loss: 0.0184 - val_mae: 0.0783\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0046 - mae: 0.0667 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0042 - mae: 0.0615 - val_loss: 0.0183 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0676 - val_loss: 0.0183 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0655 - val_loss: 0.0182 - val_mae: 0.0780\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0648 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0614 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0644 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049 - mae: 0.0659 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0638 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0614 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0044 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0178 - val_mae: 0.0789\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0178 - val_mae: 0.0790\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0653 - val_loss: 0.0177 - val_mae: 0.0790\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0177 - val_mae: 0.0790\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0609 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0040 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0536 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0579 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0043 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0651 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0636 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0798\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0562 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0590 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:03:40,860] Trial 13 finished with value: 0.08081777393817902 and parameters: {'learning_rate': 0.00035808221190662074, 'weight_decay': 0.002723522458391234}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0242 - val_mae: 0.1156\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0237 - val_mae: 0.1121\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0233 - val_mae: 0.1088\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0913 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0217 - val_mae: 0.0962\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0211 - val_mae: 0.0922\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0889\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0199 - val_mae: 0.0861\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0060 - mae: 0.0741 - val_loss: 0.0194 - val_mae: 0.0843\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0058 - mae: 0.0735 - val_loss: 0.0189 - val_mae: 0.0833\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0826\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0047 - mae: 0.0698 - val_loss: 0.0182 - val_mae: 0.0820\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0734 - val_loss: 0.0180 - val_mae: 0.0811\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0179 - val_mae: 0.0810\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0682 - val_loss: 0.0178 - val_mae: 0.0809\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0177 - val_mae: 0.0808\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0177 - val_mae: 0.0804\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0601 - val_loss: 0.0177 - val_mae: 0.0805\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0177 - val_mae: 0.0807\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0177 - val_mae: 0.0807\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0658 - val_loss: 0.0177 - val_mae: 0.0808\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0659 - val_loss: 0.0177 - val_mae: 0.0809\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0177 - val_mae: 0.0810\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0177 - val_mae: 0.0808\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0177 - val_mae: 0.0806\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0176 - val_mae: 0.0804\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0650 - val_loss: 0.0176 - val_mae: 0.0803\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0816\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0813\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0580 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0814\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0546 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0832\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0175 - val_mae: 0.0833\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0175 - val_mae: 0.0830\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0176 - val_mae: 0.0820\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0833\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0177 - val_mae: 0.0845\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0178 - val_mae: 0.0840\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0545 - val_loss: 0.0178 - val_mae: 0.0834\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0178 - val_mae: 0.0833\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0178 - val_mae: 0.0836\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0178 - val_mae: 0.0838\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0178 - val_mae: 0.0838\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0178 - val_mae: 0.0841\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0178 - val_mae: 0.0841\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0179 - val_mae: 0.0830\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0180 - val_mae: 0.0818\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0180 - val_mae: 0.0827\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0179 - val_mae: 0.0842\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0178 - val_mae: 0.0843\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0552 - val_loss: 0.0179 - val_mae: 0.0835\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0180 - val_mae: 0.0823\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0180 - val_mae: 0.0826\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0523 - val_loss: 0.0179 - val_mae: 0.0839\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0178 - val_mae: 0.0846\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0178 - val_mae: 0.0850\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0180 - val_mae: 0.0844\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0182 - val_mae: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:03:59,750] Trial 14 finished with value: 0.08330176770687103 and parameters: {'learning_rate': 0.0008542651977675683, 'weight_decay': 0.005172854912275656}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1182\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1169\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0239 - val_mae: 0.1157\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0238 - val_mae: 0.1145\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0236 - val_mae: 0.1133\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0966 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1109\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0232 - val_mae: 0.1097\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0231 - val_mae: 0.1085\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0229 - val_mae: 0.1073\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0224 - val_mae: 0.1022\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0075 - mae: 0.0887 - val_loss: 0.0222 - val_mae: 0.1009\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0836 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0827 - val_loss: 0.0218 - val_mae: 0.0969\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0828 - val_loss: 0.0216 - val_mae: 0.0956\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0215 - val_mae: 0.0943\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0213 - val_mae: 0.0931\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0795 - val_loss: 0.0212 - val_mae: 0.0918\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0761 - val_loss: 0.0210 - val_mae: 0.0907\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0754 - val_loss: 0.0209 - val_mae: 0.0895\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0207 - val_mae: 0.0884\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0727 - val_loss: 0.0205 - val_mae: 0.0874\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0752 - val_loss: 0.0204 - val_mae: 0.0865\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0061 - mae: 0.0747 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0058 - mae: 0.0721 - val_loss: 0.0201 - val_mae: 0.0849\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0199 - val_mae: 0.0842\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0709 - val_loss: 0.0198 - val_mae: 0.0835\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0696 - val_loss: 0.0197 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0680 - val_loss: 0.0195 - val_mae: 0.0825\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0675 - val_loss: 0.0194 - val_mae: 0.0821\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0686 - val_loss: 0.0192 - val_mae: 0.0818\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0191 - val_mae: 0.0815\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0680 - val_loss: 0.0189 - val_mae: 0.0812\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0188 - val_mae: 0.0810\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0691 - val_loss: 0.0187 - val_mae: 0.0809\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0049 - mae: 0.0652 - val_loss: 0.0185 - val_mae: 0.0809\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0184 - val_mae: 0.0809\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0183 - val_mae: 0.0810\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0045 - mae: 0.0649 - val_loss: 0.0182 - val_mae: 0.0811\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0181 - val_mae: 0.0812\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0179 - val_mae: 0.0813\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0049 - mae: 0.0712 - val_loss: 0.0179 - val_mae: 0.0812\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0178 - val_mae: 0.0811\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - mae: 0.0690 - val_loss: 0.0178 - val_mae: 0.0808\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0642 - val_loss: 0.0178 - val_mae: 0.0806\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0803\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0042 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0801\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0799\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0797\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0042 - mae: 0.0629 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0177 - val_mae: 0.0790\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0047 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0177 - val_mae: 0.0788\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0177 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0177 - val_mae: 0.0785\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0177 - val_mae: 0.0784\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0177 - val_mae: 0.0783\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0599 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0177 - val_mae: 0.0781\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0642 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0654 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0641 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0619 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0605 - val_loss: 0.0176 - val_mae: 0.0779\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0176 - val_mae: 0.0780\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0786\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0648 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0571 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0584 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0607 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0630 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0176 - val_mae: 0.0784\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0785\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0176 - val_mae: 0.0784\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0176 - val_mae: 0.0784\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0038 - mae: 0.0581 - val_loss: 0.0176 - val_mae: 0.0784\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0176 - val_mae: 0.0785\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0785\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0612 - val_loss: 0.0175 - val_mae: 0.0786\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0609 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0175 - val_mae: 0.0795\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0571 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:04:18,523] Trial 15 finished with value: 0.08062633872032166 and parameters: {'learning_rate': 0.0002270383335376269, 'weight_decay': 4.614516898313907e-05}. Best is trial 8 with value: 0.08014242351055145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0233 - val_mae: 0.1107\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0966 - val_loss: 0.0231 - val_mae: 0.1094\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1081\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0228 - val_mae: 0.1066\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0224 - val_mae: 0.1038\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0222 - val_mae: 0.1024\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0892 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0218 - val_mae: 0.0985\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0865 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0857 - val_loss: 0.0214 - val_mae: 0.0961\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0213 - val_mae: 0.0949\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0843 - val_loss: 0.0211 - val_mae: 0.0936\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0824 - val_loss: 0.0210 - val_mae: 0.0923\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0208 - val_mae: 0.0912\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0834 - val_loss: 0.0207 - val_mae: 0.0901\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0205 - val_mae: 0.0891\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0064 - mae: 0.0798 - val_loss: 0.0204 - val_mae: 0.0881\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0767 - val_loss: 0.0202 - val_mae: 0.0871\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0741 - val_loss: 0.0201 - val_mae: 0.0861\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0785 - val_loss: 0.0199 - val_mae: 0.0852\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0198 - val_mae: 0.0843\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0197 - val_mae: 0.0835\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0759 - val_loss: 0.0195 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0194 - val_mae: 0.0819\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - mae: 0.0751 - val_loss: 0.0193 - val_mae: 0.0812\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0058 - mae: 0.0773 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0705 - val_loss: 0.0190 - val_mae: 0.0800\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0720 - val_loss: 0.0189 - val_mae: 0.0796\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0746 - val_loss: 0.0188 - val_mae: 0.0793\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0809 - val_loss: 0.0187 - val_mae: 0.0790\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0724 - val_loss: 0.0187 - val_mae: 0.0789\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0705 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0185 - val_mae: 0.0786\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0689 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0655 - val_loss: 0.0184 - val_mae: 0.0783\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0184 - val_mae: 0.0782\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0700 - val_loss: 0.0183 - val_mae: 0.0781\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0183 - val_mae: 0.0780\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0182 - val_mae: 0.0778\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0720 - val_loss: 0.0182 - val_mae: 0.0776\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0181 - val_mae: 0.0774\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0774\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0683 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0180 - val_mae: 0.0770\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0681 - val_loss: 0.0180 - val_mae: 0.0770\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0674 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0634 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0704 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0650 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0650 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0684 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0654 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0673 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0659 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0663 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0640 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0774\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0775\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0686 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0640 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0039 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0789\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0630 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0582 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0791\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0565 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0040 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:04:38,303] Trial 16 finished with value: 0.07986561208963394 and parameters: {'learning_rate': 0.00020808621663340377, 'weight_decay': 2.238406804947867e-05}. Best is trial 16 with value: 0.07986561208963394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0254 - val_mae: 0.1229\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0250 - val_mae: 0.1200\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1172\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.1001 - val_loss: 0.0238 - val_mae: 0.1125\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0084 - mae: 0.0984 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0232 - val_mae: 0.1081\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0937 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1037\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0892 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0222 - val_mae: 0.0994\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.0970\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0217 - val_mae: 0.0945\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0215 - val_mae: 0.0921\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0212 - val_mae: 0.0899\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0209 - val_mae: 0.0878\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0728 - val_loss: 0.0207 - val_mae: 0.0858\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0058 - mae: 0.0737 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0056 - mae: 0.0722 - val_loss: 0.0201 - val_mae: 0.0824\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0678 - val_loss: 0.0198 - val_mae: 0.0814\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0687 - val_loss: 0.0196 - val_mae: 0.0807\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0191 - val_mae: 0.0810\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0188 - val_mae: 0.0813\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0673 - val_loss: 0.0186 - val_mae: 0.0817\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0045 - mae: 0.0678 - val_loss: 0.0184 - val_mae: 0.0821\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0183 - val_mae: 0.0823\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0182 - val_mae: 0.0827\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0180 - val_mae: 0.0830\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0660 - val_loss: 0.0179 - val_mae: 0.0832\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0038 - mae: 0.0641 - val_loss: 0.0178 - val_mae: 0.0830\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0040 - mae: 0.0651 - val_loss: 0.0177 - val_mae: 0.0829\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0828\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0646 - val_loss: 0.0176 - val_mae: 0.0820\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0174 - val_mae: 0.0816\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0810\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0809\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0036 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0845\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0841\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0836\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0835\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:04:57,772] Trial 17 finished with value: 0.08398880064487457 and parameters: {'learning_rate': 0.0007571966980866759, 'weight_decay': 6.585185807527975e-07}. Best is trial 16 with value: 0.07986561208963394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0256 - val_mae: 0.1256\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0255 - val_mae: 0.1253\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0255 - val_mae: 0.1250\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0099 - mae: 0.1120 - val_loss: 0.0254 - val_mae: 0.1246\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0254 - val_mae: 0.1243\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0253 - val_mae: 0.1240\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1236\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1233\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0100 - mae: 0.1115 - val_loss: 0.0252 - val_mae: 0.1229\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0097 - mae: 0.1093 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1102 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0246 - val_mae: 0.1189\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0092 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1177\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1168\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0243 - val_mae: 0.1165\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0242 - val_mae: 0.1163\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0242 - val_mae: 0.1160\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0242 - val_mae: 0.1157\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0241 - val_mae: 0.1154\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0241 - val_mae: 0.1151\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0241 - val_mae: 0.1149\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0091 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1146\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0088 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1143\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1141\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0239 - val_mae: 0.1136\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0239 - val_mae: 0.1133\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1131\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0238 - val_mae: 0.1128\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0238 - val_mae: 0.1126\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0084 - mae: 0.0984 - val_loss: 0.0238 - val_mae: 0.1124\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1121\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0237 - val_mae: 0.1116\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1114\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0236 - val_mae: 0.1112\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0236 - val_mae: 0.1109\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0236 - val_mae: 0.1104\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0235 - val_mae: 0.1097\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0084 - mae: 0.0966 - val_loss: 0.0235 - val_mae: 0.1095\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0234 - val_mae: 0.1093\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1090\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1088\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0233 - val_mae: 0.1085\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0233 - val_mae: 0.1083\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0233 - val_mae: 0.1080\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0233 - val_mae: 0.1078\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0232 - val_mae: 0.1076\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0232 - val_mae: 0.1073\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0232 - val_mae: 0.1071\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0232 - val_mae: 0.1069\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1066\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0231 - val_mae: 0.1064\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0934 - val_loss: 0.0231 - val_mae: 0.1062\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0231 - val_mae: 0.1060\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0230 - val_mae: 0.1058\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0230 - val_mae: 0.1055\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0230 - val_mae: 0.1053\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0080 - mae: 0.0930 - val_loss: 0.0230 - val_mae: 0.1051\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0230 - val_mae: 0.1049\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0077 - mae: 0.0913 - val_loss: 0.0229 - val_mae: 0.1047\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0229 - val_mae: 0.1044\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0229 - val_mae: 0.1042\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0229 - val_mae: 0.1040\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0228 - val_mae: 0.1038\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0228 - val_mae: 0.1035\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1033\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1031\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0227 - val_mae: 0.1029\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0227 - val_mae: 0.1026\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0227 - val_mae: 0.1024\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0883 - val_loss: 0.0227 - val_mae: 0.1022\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0227 - val_mae: 0.1020\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0226 - val_mae: 0.1017\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0226 - val_mae: 0.1015\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0226 - val_mae: 0.1013\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0073 - mae: 0.0874 - val_loss: 0.0226 - val_mae: 0.1011\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0225 - val_mae: 0.1008\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0073 - mae: 0.0855 - val_loss: 0.0225 - val_mae: 0.1006\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0076 - mae: 0.0884 - val_loss: 0.0225 - val_mae: 0.1004\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0225 - val_mae: 0.1002\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0224 - val_mae: 0.0999\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0224 - val_mae: 0.0997\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0072 - mae: 0.0859 - val_loss: 0.0224 - val_mae: 0.0995\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0223 - val_mae: 0.0992\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0854 - val_loss: 0.0223 - val_mae: 0.0990\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0068 - mae: 0.0828 - val_loss: 0.0223 - val_mae: 0.0987\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0074 - mae: 0.0855 - val_loss: 0.0223 - val_mae: 0.0985\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0222 - val_mae: 0.0983\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0222 - val_mae: 0.0980\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0222 - val_mae: 0.0978\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.0975\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0069 - mae: 0.0834 - val_loss: 0.0221 - val_mae: 0.0973\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0221 - val_mae: 0.0971\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0071 - mae: 0.0839 - val_loss: 0.0221 - val_mae: 0.0968\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0069 - mae: 0.0824 - val_loss: 0.0221 - val_mae: 0.0966\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0220 - val_mae: 0.0964\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0836 - val_loss: 0.0220 - val_mae: 0.0961\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0071 - mae: 0.0839 - val_loss: 0.0220 - val_mae: 0.0959\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0812 - val_loss: 0.0220 - val_mae: 0.0957\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0219 - val_mae: 0.0954\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0071 - mae: 0.0851 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0069 - mae: 0.0828 - val_loss: 0.0219 - val_mae: 0.0950\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0792 - val_loss: 0.0218 - val_mae: 0.0947\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0065 - mae: 0.0793 - val_loss: 0.0218 - val_mae: 0.0945\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0218 - val_mae: 0.0942\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0069 - mae: 0.0820 - val_loss: 0.0218 - val_mae: 0.0940\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0217 - val_mae: 0.0937\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0068 - mae: 0.0800 - val_loss: 0.0217 - val_mae: 0.0935\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0217 - val_mae: 0.0932\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0068 - mae: 0.0818 - val_loss: 0.0217 - val_mae: 0.0930\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0066 - mae: 0.0802 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0069 - mae: 0.0824 - val_loss: 0.0216 - val_mae: 0.0925\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0068 - mae: 0.0801 - val_loss: 0.0216 - val_mae: 0.0922\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0215 - val_mae: 0.0920\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0061 - mae: 0.0767 - val_loss: 0.0215 - val_mae: 0.0917\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0069 - mae: 0.0811 - val_loss: 0.0215 - val_mae: 0.0915\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0779 - val_loss: 0.0215 - val_mae: 0.0913\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0064 - mae: 0.0794 - val_loss: 0.0214 - val_mae: 0.0910\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0780 - val_loss: 0.0214 - val_mae: 0.0908\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0214 - val_mae: 0.0905\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0214 - val_mae: 0.0903\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0213 - val_mae: 0.0900\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0213 - val_mae: 0.0898\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0213 - val_mae: 0.0896\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0212 - val_mae: 0.0893\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0212 - val_mae: 0.0891\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - mae: 0.0748 - val_loss: 0.0212 - val_mae: 0.0889\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0212 - val_mae: 0.0887\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0065 - mae: 0.0785 - val_loss: 0.0211 - val_mae: 0.0885\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0211 - val_mae: 0.0883\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0060 - mae: 0.0749 - val_loss: 0.0211 - val_mae: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:05:15,632] Trial 18 finished with value: 0.08804995566606522 and parameters: {'learning_rate': 5.578642810937984e-05, 'weight_decay': 2.305696609808373e-06}. Best is trial 16 with value: 0.07986561208963394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1111 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0102 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0102 - mae: 0.1124 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0248 - val_mae: 0.1245\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0101 - mae: 0.1111 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0101 - mae: 0.1092 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.0248 - val_mae: 0.1244\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0102 - mae: 0.1114 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0101 - mae: 0.1118 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0105 - mae: 0.1134 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1119 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0248 - val_mae: 0.1241\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0248 - val_mae: 0.1241\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0248 - val_mae: 0.1241\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0102 - mae: 0.1101 - val_loss: 0.0248 - val_mae: 0.1241\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0247 - val_mae: 0.1241\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0247 - val_mae: 0.1241\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0247 - val_mae: 0.1241\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0099 - mae: 0.1110 - val_loss: 0.0247 - val_mae: 0.1241\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0102 - mae: 0.1108 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1240\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1093 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1107 - val_loss: 0.0247 - val_mae: 0.1239\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1107 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0104 - mae: 0.1137 - val_loss: 0.0247 - val_mae: 0.1238\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0247 - val_mae: 0.1237\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1107 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0102 - mae: 0.1114 - val_loss: 0.0247 - val_mae: 0.1236\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1235\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1124 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0101 - mae: 0.1106 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0247 - val_mae: 0.1234\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1106 - val_loss: 0.0247 - val_mae: 0.1233\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1233\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0104 - mae: 0.1127 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0246 - val_mae: 0.1233\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1068 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1232\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0246 - val_mae: 0.1231\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0103 - mae: 0.1117 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1112 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1112 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1229\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0093 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1228\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1111 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0246 - val_mae: 0.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:05:34,829] Trial 19 finished with value: 0.122691810131073 and parameters: {'learning_rate': 2.2360082240786293e-06, 'weight_decay': 6.778116752590876e-06}. Best is trial 16 with value: 0.07986561208963394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1010 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0085 - mae: 0.1001 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1167\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0086 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1012 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0087 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:05:53,813] Trial 20 finished with value: 0.11656072735786438 and parameters: {'learning_rate': 3.0963176170041566e-07, 'weight_decay': 1.2616643549088736e-06}. Best is trial 16 with value: 0.07986561208963394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0245 - val_mae: 0.1193\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0245 - val_mae: 0.1190\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1187\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0244 - val_mae: 0.1183\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1159\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1151\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1146\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0238 - val_mae: 0.1142\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1138\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0237 - val_mae: 0.1134\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0087 - mae: 0.0979 - val_loss: 0.0236 - val_mae: 0.1130\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0082 - mae: 0.0972 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0971 - val_loss: 0.0234 - val_mae: 0.1113\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0234 - val_mae: 0.1108\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0233 - val_mae: 0.1104\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0232 - val_mae: 0.1094\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0231 - val_mae: 0.1085\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0230 - val_mae: 0.1080\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0229 - val_mae: 0.1070\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0228 - val_mae: 0.1056\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0909 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0226 - val_mae: 0.1035\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0225 - val_mae: 0.1030\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0224 - val_mae: 0.1020\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0891 - val_loss: 0.0223 - val_mae: 0.1009\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0074 - mae: 0.0863 - val_loss: 0.0222 - val_mae: 0.1003\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0221 - val_mae: 0.0992\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0220 - val_mae: 0.0987\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0073 - mae: 0.0865 - val_loss: 0.0220 - val_mae: 0.0982\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0219 - val_mae: 0.0976\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0218 - val_mae: 0.0971\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0069 - mae: 0.0824 - val_loss: 0.0218 - val_mae: 0.0965\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0071 - mae: 0.0851 - val_loss: 0.0217 - val_mae: 0.0959\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0071 - mae: 0.0833 - val_loss: 0.0216 - val_mae: 0.0954\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0071 - mae: 0.0862 - val_loss: 0.0216 - val_mae: 0.0949\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0215 - val_mae: 0.0944\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0830 - val_loss: 0.0214 - val_mae: 0.0939\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0841 - val_loss: 0.0214 - val_mae: 0.0935\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0213 - val_mae: 0.0930\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0070 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0925\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0212 - val_mae: 0.0921\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0067 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0917\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0064 - mae: 0.0782 - val_loss: 0.0211 - val_mae: 0.0913\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0773 - val_loss: 0.0210 - val_mae: 0.0908\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0904\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0209 - val_mae: 0.0900\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0069 - mae: 0.0807 - val_loss: 0.0208 - val_mae: 0.0896\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0065 - mae: 0.0785 - val_loss: 0.0207 - val_mae: 0.0893\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0066 - mae: 0.0792 - val_loss: 0.0207 - val_mae: 0.0889\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0206 - val_mae: 0.0885\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0061 - mae: 0.0757 - val_loss: 0.0205 - val_mae: 0.0881\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0061 - mae: 0.0750 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0754 - val_loss: 0.0204 - val_mae: 0.0873\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0203 - val_mae: 0.0870\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0060 - mae: 0.0758 - val_loss: 0.0203 - val_mae: 0.0868\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0202 - val_mae: 0.0865\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0058 - mae: 0.0746 - val_loss: 0.0201 - val_mae: 0.0863\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0056 - mae: 0.0723 - val_loss: 0.0201 - val_mae: 0.0861\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0200 - val_mae: 0.0859\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0200 - val_mae: 0.0857\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0199 - val_mae: 0.0855\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0059 - mae: 0.0741 - val_loss: 0.0198 - val_mae: 0.0853\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0198 - val_mae: 0.0850\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0055 - mae: 0.0717 - val_loss: 0.0197 - val_mae: 0.0848\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0197 - val_mae: 0.0845\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0058 - mae: 0.0754 - val_loss: 0.0196 - val_mae: 0.0843\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0059 - mae: 0.0741 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0056 - mae: 0.0735 - val_loss: 0.0195 - val_mae: 0.0839\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0053 - mae: 0.0692 - val_loss: 0.0195 - val_mae: 0.0837\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0194 - val_mae: 0.0835\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0052 - mae: 0.0690 - val_loss: 0.0194 - val_mae: 0.0833\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0058 - mae: 0.0764 - val_loss: 0.0193 - val_mae: 0.0831\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - mae: 0.0693 - val_loss: 0.0193 - val_mae: 0.0829\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0055 - mae: 0.0697 - val_loss: 0.0192 - val_mae: 0.0827\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0825\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0720 - val_loss: 0.0191 - val_mae: 0.0823\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0191 - val_mae: 0.0820\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0190 - val_mae: 0.0818\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - mae: 0.0698 - val_loss: 0.0190 - val_mae: 0.0816\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0190 - val_mae: 0.0814\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0189 - val_mae: 0.0812\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0189 - val_mae: 0.0810\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0189 - val_mae: 0.0808\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0696 - val_loss: 0.0188 - val_mae: 0.0806\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0678 - val_loss: 0.0188 - val_mae: 0.0805\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0188 - val_mae: 0.0803\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0051 - mae: 0.0703 - val_loss: 0.0188 - val_mae: 0.0802\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0187 - val_mae: 0.0800\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0187 - val_mae: 0.0798\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0053 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0797\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0052 - mae: 0.0696 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0046 - mae: 0.0681 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0186 - val_mae: 0.0794\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0049 - mae: 0.0699 - val_loss: 0.0186 - val_mae: 0.0793\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0628 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0679 - val_loss: 0.0184 - val_mae: 0.0793\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0184 - val_mae: 0.0793\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0184 - val_mae: 0.0792\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0184 - val_mae: 0.0791\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0047 - mae: 0.0646 - val_loss: 0.0183 - val_mae: 0.0791\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0183 - val_mae: 0.0790\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0183 - val_mae: 0.0790\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0183 - val_mae: 0.0791\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - mae: 0.0662 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0048 - mae: 0.0673 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - mae: 0.0641 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0180 - val_mae: 0.0791\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0180 - val_mae: 0.0789\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0180 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0046 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0787\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0046 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0785\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0180 - val_mae: 0.0784\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - mae: 0.0638 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0045 - mae: 0.0645 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0045 - mae: 0.0635 - val_loss: 0.0180 - val_mae: 0.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:06:11,230] Trial 21 finished with value: 0.07773890346288681 and parameters: {'learning_rate': 0.00011314299896892114, 'weight_decay': 4.3201239196814674e-05}. Best is trial 21 with value: 0.07773890346288681.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1106 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1095 - val_loss: 0.0248 - val_mae: 0.1236\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0248 - val_mae: 0.1233\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1230\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0247 - val_mae: 0.1227\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1224\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0247 - val_mae: 0.1221\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1218\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1215\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0246 - val_mae: 0.1212\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0245 - val_mae: 0.1209\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0245 - val_mae: 0.1203\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1194\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0243 - val_mae: 0.1189\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0243 - val_mae: 0.1186\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0242 - val_mae: 0.1178\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0242 - val_mae: 0.1175\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0242 - val_mae: 0.1170\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0093 - mae: 0.1037 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1158\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0240 - val_mae: 0.1150\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1148\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0238 - val_mae: 0.1138\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0085 - mae: 0.0995 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0087 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1128\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0237 - val_mae: 0.1125\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0084 - mae: 0.0973 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0081 - mae: 0.0961 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1104\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0235 - val_mae: 0.1101\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0953 - val_loss: 0.0234 - val_mae: 0.1096\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0084 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1094\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0081 - mae: 0.0953 - val_loss: 0.0234 - val_mae: 0.1091\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1089\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0234 - val_mae: 0.1087\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1084\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0233 - val_mae: 0.1080\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0233 - val_mae: 0.1077\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0082 - mae: 0.0946 - val_loss: 0.0232 - val_mae: 0.1075\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0919 - val_loss: 0.0232 - val_mae: 0.1072\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0232 - val_mae: 0.1070\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0232 - val_mae: 0.1067\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0232 - val_mae: 0.1065\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0079 - mae: 0.0948 - val_loss: 0.0231 - val_mae: 0.1062\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0918 - val_loss: 0.0231 - val_mae: 0.1060\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0231 - val_mae: 0.1057\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0231 - val_mae: 0.1055\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0230 - val_mae: 0.1052\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0075 - mae: 0.0903 - val_loss: 0.0230 - val_mae: 0.1050\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0230 - val_mae: 0.1047\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0230 - val_mae: 0.1044\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0229 - val_mae: 0.1042\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0229 - val_mae: 0.1039\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0229 - val_mae: 0.1036\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0229 - val_mae: 0.1033\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1031\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0228 - val_mae: 0.1028\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0228 - val_mae: 0.1023\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0227 - val_mae: 0.1020\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0227 - val_mae: 0.1017\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0227 - val_mae: 0.1015\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0227 - val_mae: 0.1012\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0226 - val_mae: 0.1009\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0887 - val_loss: 0.0226 - val_mae: 0.1006\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0226 - val_mae: 0.1004\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0072 - mae: 0.0873 - val_loss: 0.0226 - val_mae: 0.1001\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0225 - val_mae: 0.0996\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0069 - mae: 0.0834 - val_loss: 0.0225 - val_mae: 0.0993\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0071 - mae: 0.0861 - val_loss: 0.0225 - val_mae: 0.0990\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0224 - val_mae: 0.0988\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0224 - val_mae: 0.0985\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0224 - val_mae: 0.0982\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.0979\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0223 - val_mae: 0.0977\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0223 - val_mae: 0.0974\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0223 - val_mae: 0.0971\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0222 - val_mae: 0.0969\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0838 - val_loss: 0.0222 - val_mae: 0.0966\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0222 - val_mae: 0.0963\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0070 - mae: 0.0830 - val_loss: 0.0222 - val_mae: 0.0961\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0069 - mae: 0.0829 - val_loss: 0.0221 - val_mae: 0.0958\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0066 - mae: 0.0792 - val_loss: 0.0221 - val_mae: 0.0955\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0221 - val_mae: 0.0953\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0220 - val_mae: 0.0950\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0220 - val_mae: 0.0947\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0220 - val_mae: 0.0944\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0220 - val_mae: 0.0942\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0068 - mae: 0.0822 - val_loss: 0.0219 - val_mae: 0.0939\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0219 - val_mae: 0.0937\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0219 - val_mae: 0.0934\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0817 - val_loss: 0.0218 - val_mae: 0.0932\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0218 - val_mae: 0.0929\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0218 - val_mae: 0.0927\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0778 - val_loss: 0.0218 - val_mae: 0.0924\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0217 - val_mae: 0.0921\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0067 - mae: 0.0804 - val_loss: 0.0217 - val_mae: 0.0919\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0068 - mae: 0.0833 - val_loss: 0.0217 - val_mae: 0.0916\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0787 - val_loss: 0.0216 - val_mae: 0.0914\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0216 - val_mae: 0.0911\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0216 - val_mae: 0.0909\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0062 - mae: 0.0768 - val_loss: 0.0215 - val_mae: 0.0906\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0215 - val_mae: 0.0904\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0215 - val_mae: 0.0901\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0062 - mae: 0.0783 - val_loss: 0.0215 - val_mae: 0.0898\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0063 - mae: 0.0774 - val_loss: 0.0214 - val_mae: 0.0896\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0214 - val_mae: 0.0893\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0060 - mae: 0.0759 - val_loss: 0.0214 - val_mae: 0.0891\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0213 - val_mae: 0.0888\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0068 - mae: 0.0808 - val_loss: 0.0213 - val_mae: 0.0885\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0213 - val_mae: 0.0883\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0212 - val_mae: 0.0880\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0212 - val_mae: 0.0878\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0212 - val_mae: 0.0875\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0059 - mae: 0.0754 - val_loss: 0.0211 - val_mae: 0.0872\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0211 - val_mae: 0.0870\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0061 - mae: 0.0769 - val_loss: 0.0211 - val_mae: 0.0867\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0211 - val_mae: 0.0865\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0210 - val_mae: 0.0863\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0761 - val_loss: 0.0210 - val_mae: 0.0861\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0060 - mae: 0.0758 - val_loss: 0.0210 - val_mae: 0.0859\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0209 - val_mae: 0.0857\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0061 - mae: 0.0743 - val_loss: 0.0209 - val_mae: 0.0855\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0209 - val_mae: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:06:28,692] Trial 22 finished with value: 0.08534863591194153 and parameters: {'learning_rate': 5.9180127328726826e-05, 'weight_decay': 6.7727469075796056e-06}. Best is trial 21 with value: 0.07773890346288681.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0091 - mae: 0.1027 - val_loss: 0.0243 - val_mae: 0.1164\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0242 - val_mae: 0.1158\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0241 - val_mae: 0.1152\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1146\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0240 - val_mae: 0.1140\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0239 - val_mae: 0.1134\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1127\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0237 - val_mae: 0.1121\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0236 - val_mae: 0.1114\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1101\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0234 - val_mae: 0.1095\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1088\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0232 - val_mae: 0.1081\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0230 - val_mae: 0.1060\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1053\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0078 - mae: 0.0892 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0227 - val_mae: 0.1038\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0077 - mae: 0.0908 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0225 - val_mae: 0.1024\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0078 - mae: 0.0894 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.1009\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0223 - val_mae: 0.1001\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0077 - mae: 0.0865 - val_loss: 0.0222 - val_mae: 0.0994\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0075 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.0986\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0220 - val_mae: 0.0978\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0219 - val_mae: 0.0963\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0072 - mae: 0.0834 - val_loss: 0.0217 - val_mae: 0.0947\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0216 - val_mae: 0.0940\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0069 - mae: 0.0815 - val_loss: 0.0215 - val_mae: 0.0933\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0214 - val_mae: 0.0926\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0783 - val_loss: 0.0213 - val_mae: 0.0919\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0067 - mae: 0.0805 - val_loss: 0.0213 - val_mae: 0.0912\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0212 - val_mae: 0.0905\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0070 - mae: 0.0822 - val_loss: 0.0211 - val_mae: 0.0898\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0063 - mae: 0.0758 - val_loss: 0.0210 - val_mae: 0.0891\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0209 - val_mae: 0.0885\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0208 - val_mae: 0.0879\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0059 - mae: 0.0755 - val_loss: 0.0207 - val_mae: 0.0873\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0752 - val_loss: 0.0206 - val_mae: 0.0867\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0060 - mae: 0.0735 - val_loss: 0.0205 - val_mae: 0.0861\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0060 - mae: 0.0743 - val_loss: 0.0204 - val_mae: 0.0856\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0061 - mae: 0.0742 - val_loss: 0.0203 - val_mae: 0.0851\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0058 - mae: 0.0723 - val_loss: 0.0202 - val_mae: 0.0847\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0061 - mae: 0.0753 - val_loss: 0.0201 - val_mae: 0.0843\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0057 - mae: 0.0722 - val_loss: 0.0200 - val_mae: 0.0840\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0058 - mae: 0.0719 - val_loss: 0.0199 - val_mae: 0.0836\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0058 - mae: 0.0719 - val_loss: 0.0198 - val_mae: 0.0833\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0057 - mae: 0.0739 - val_loss: 0.0197 - val_mae: 0.0831\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - mae: 0.0720 - val_loss: 0.0196 - val_mae: 0.0827\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0704 - val_loss: 0.0195 - val_mae: 0.0825\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0823\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0059 - mae: 0.0721 - val_loss: 0.0193 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0700 - val_loss: 0.0192 - val_mae: 0.0820\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0059 - mae: 0.0746 - val_loss: 0.0191 - val_mae: 0.0819\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0059 - mae: 0.0735 - val_loss: 0.0191 - val_mae: 0.0818\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0713 - val_loss: 0.0190 - val_mae: 0.0817\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0049 - mae: 0.0659 - val_loss: 0.0189 - val_mae: 0.0816\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0051 - mae: 0.0663 - val_loss: 0.0188 - val_mae: 0.0816\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0052 - mae: 0.0700 - val_loss: 0.0188 - val_mae: 0.0815\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0058 - mae: 0.0771 - val_loss: 0.0187 - val_mae: 0.0814\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0053 - mae: 0.0678 - val_loss: 0.0187 - val_mae: 0.0813\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - mae: 0.0654 - val_loss: 0.0186 - val_mae: 0.0812\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0049 - mae: 0.0667 - val_loss: 0.0185 - val_mae: 0.0811\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0185 - val_mae: 0.0810\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0184 - val_mae: 0.0808\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0048 - mae: 0.0667 - val_loss: 0.0184 - val_mae: 0.0807\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0048 - mae: 0.0669 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0727 - val_loss: 0.0183 - val_mae: 0.0804\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0050 - mae: 0.0666 - val_loss: 0.0182 - val_mae: 0.0803\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0047 - mae: 0.0663 - val_loss: 0.0182 - val_mae: 0.0801\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0049 - mae: 0.0706 - val_loss: 0.0182 - val_mae: 0.0799\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0181 - val_mae: 0.0797\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0181 - val_mae: 0.0796\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0640 - val_loss: 0.0181 - val_mae: 0.0794\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0047 - mae: 0.0668 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0043 - mae: 0.0633 - val_loss: 0.0180 - val_mae: 0.0789\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - mae: 0.0632 - val_loss: 0.0180 - val_mae: 0.0787\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0048 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0786\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - mae: 0.0634 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0779\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - mae: 0.0641 - val_loss: 0.0178 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0046 - mae: 0.0659 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0048 - mae: 0.0660 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0042 - mae: 0.0605 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0631 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0042 - mae: 0.0611 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0176 - val_mae: 0.0772\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - mae: 0.0588 - val_loss: 0.0176 - val_mae: 0.0773\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0773\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0176 - val_mae: 0.0774\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0176 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0774\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0175 - val_mae: 0.0774\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0041 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0048 - mae: 0.0710 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - mae: 0.0575 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0041 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0562 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0175 - val_mae: 0.0781\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0174 - val_mae: 0.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:06:45,767] Trial 23 finished with value: 0.07876582443714142 and parameters: {'learning_rate': 0.00014674929486484578, 'weight_decay': 5.257344318523965e-05}. Best is trial 21 with value: 0.07773890346288681.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0235 - val_mae: 0.1138\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0231 - val_mae: 0.1096\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0226 - val_mae: 0.1057\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0221 - val_mae: 0.1021\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0217 - val_mae: 0.0985\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0826 - val_loss: 0.0212 - val_mae: 0.0951\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0064 - mae: 0.0775 - val_loss: 0.0208 - val_mae: 0.0922\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0898\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0059 - mae: 0.0759 - val_loss: 0.0198 - val_mae: 0.0878\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0057 - mae: 0.0727 - val_loss: 0.0194 - val_mae: 0.0865\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0057 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0857\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0052 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0852\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0051 - mae: 0.0706 - val_loss: 0.0185 - val_mae: 0.0845\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0048 - mae: 0.0667 - val_loss: 0.0183 - val_mae: 0.0839\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0181 - val_mae: 0.0832\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0179 - val_mae: 0.0825\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0043 - mae: 0.0678 - val_loss: 0.0178 - val_mae: 0.0815\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0178 - val_mae: 0.0806\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0801\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0177 - val_mae: 0.0796\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0041 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0792\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0176 - val_mae: 0.0793\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - mae: 0.0592 - val_loss: 0.0176 - val_mae: 0.0796\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.0805\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0173 - val_mae: 0.0808\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0171 - val_mae: 0.0813\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0042 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0812\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0813\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0656 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0172 - val_mae: 0.0836\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0835\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0173 - val_mae: 0.0832\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0173 - val_mae: 0.0836\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0844\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0842\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0173 - val_mae: 0.0843\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0174 - val_mae: 0.0840\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0174 - val_mae: 0.0833\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0175 - val_mae: 0.0809\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0175 - val_mae: 0.0813\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0602 - val_loss: 0.0176 - val_mae: 0.0849\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0178 - val_mae: 0.0817\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0522 - val_loss: 0.0178 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0177 - val_mae: 0.0848\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - mae: 0.0541 - val_loss: 0.0175 - val_mae: 0.0862\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0030 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0860\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0176 - val_mae: 0.0848\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0178 - val_mae: 0.0831\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0178 - val_mae: 0.0808\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0178 - val_mae: 0.0810\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0177 - val_mae: 0.0829\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0175 - val_mae: 0.0844\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0851\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0173 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0842\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0176 - val_mae: 0.0829\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0177 - val_mae: 0.0805\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0547 - val_loss: 0.0177 - val_mae: 0.0807\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0542 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0173 - val_mae: 0.0860\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0176 - val_mae: 0.0837\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0028 - mae: 0.0494 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0178 - val_mae: 0.0830\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0027 - mae: 0.0505 - val_loss: 0.0177 - val_mae: 0.0843\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0177 - val_mae: 0.0856\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0177 - val_mae: 0.0860\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0178 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0028 - mae: 0.0521 - val_loss: 0.0178 - val_mae: 0.0853\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0178 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0178 - val_mae: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:07:03,800] Trial 24 finished with value: 0.08696676045656204 and parameters: {'learning_rate': 0.0010927775102100331, 'weight_decay': 1.4955627152065494e-05}. Best is trial 21 with value: 0.07773890346288681.\n",
      "[I 2023-12-05 14:07:03,845] A new study created in RDB with name: no-name-51a5076e-6497-4800-874b-07644128e645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0246 - val_mae: 0.1201\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0245 - val_mae: 0.1193\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0240 - val_mae: 0.1163\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1153\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0238 - val_mae: 0.1143\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0236 - val_mae: 0.1133\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0235 - val_mae: 0.1123\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0234 - val_mae: 0.1113\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1104\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0232 - val_mae: 0.1094\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0231 - val_mae: 0.1085\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - mae: 0.0933 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1056\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0901 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0222 - val_mae: 0.1008\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0219 - val_mae: 0.0978\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0069 - mae: 0.0842 - val_loss: 0.0218 - val_mae: 0.0968\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0071 - mae: 0.0845 - val_loss: 0.0215 - val_mae: 0.0947\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0071 - mae: 0.0837 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0831 - val_loss: 0.0213 - val_mae: 0.0926\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0212 - val_mae: 0.0916\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0828 - val_loss: 0.0211 - val_mae: 0.0905\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0792 - val_loss: 0.0209 - val_mae: 0.0895\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0208 - val_mae: 0.0885\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0063 - mae: 0.0766 - val_loss: 0.0207 - val_mae: 0.0874\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0070 - mae: 0.0835 - val_loss: 0.0206 - val_mae: 0.0865\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0205 - val_mae: 0.0855\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0204 - val_mae: 0.0847\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0064 - mae: 0.0769 - val_loss: 0.0202 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0058 - mae: 0.0722 - val_loss: 0.0201 - val_mae: 0.0830\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0822\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0198 - val_mae: 0.0807\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0758 - val_loss: 0.0197 - val_mae: 0.0801\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0053 - mae: 0.0711 - val_loss: 0.0196 - val_mae: 0.0794\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0054 - mae: 0.0719 - val_loss: 0.0195 - val_mae: 0.0788\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0055 - mae: 0.0729 - val_loss: 0.0194 - val_mae: 0.0782\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0059 - mae: 0.0739 - val_loss: 0.0193 - val_mae: 0.0776\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0055 - mae: 0.0746 - val_loss: 0.0192 - val_mae: 0.0772\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0049 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0768\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0764\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0058 - mae: 0.0744 - val_loss: 0.0189 - val_mae: 0.0761\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0188 - val_mae: 0.0758\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0187 - val_mae: 0.0756\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - mae: 0.0681 - val_loss: 0.0187 - val_mae: 0.0755\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0052 - mae: 0.0726 - val_loss: 0.0186 - val_mae: 0.0753\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0185 - val_mae: 0.0752\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0184 - val_mae: 0.0751\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0184 - val_mae: 0.0750\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0183 - val_mae: 0.0750\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0685 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0182 - val_mae: 0.0749\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0661 - val_loss: 0.0181 - val_mae: 0.0750\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0685 - val_loss: 0.0181 - val_mae: 0.0750\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0181 - val_mae: 0.0751\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0622 - val_loss: 0.0180 - val_mae: 0.0751\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0665 - val_loss: 0.0180 - val_mae: 0.0752\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0753\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0179 - val_mae: 0.0754\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0178 - val_mae: 0.0755\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0651 - val_loss: 0.0178 - val_mae: 0.0756\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0687 - val_loss: 0.0178 - val_mae: 0.0757\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0177 - val_mae: 0.0757\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - mae: 0.0653 - val_loss: 0.0177 - val_mae: 0.0758\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0177 - val_mae: 0.0759\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0760\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0176 - val_mae: 0.0760\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0176 - val_mae: 0.0761\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0761\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0176 - val_mae: 0.0761\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0176 - val_mae: 0.0760\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0176 - val_mae: 0.0761\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0688 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0761\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0175 - val_mae: 0.0762\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0175 - val_mae: 0.0763\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0614 - val_loss: 0.0175 - val_mae: 0.0767\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0175 - val_mae: 0.0768\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0614 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0696 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0697 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0719 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0635 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0040 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0607 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0045 - mae: 0.0646 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0782\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0614 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0789\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0789\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0043 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:07:17,908] Trial 0 finished with value: 0.07924208045005798 and parameters: {'learning_rate': 0.00012345404993175738, 'weight_decay': 0.005466152059368209}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0254 - val_mae: 0.1267\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0102 - mae: 0.1128 - val_loss: 0.0254 - val_mae: 0.1267\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0101 - mae: 0.1117 - val_loss: 0.0254 - val_mae: 0.1267\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0254 - val_mae: 0.1267\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0101 - mae: 0.1129 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1124 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1136 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1137 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1105 - val_loss: 0.0254 - val_mae: 0.1266\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0254 - val_mae: 0.1265\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0254 - val_mae: 0.1265\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1114 - val_loss: 0.0254 - val_mae: 0.1265\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1127 - val_loss: 0.0254 - val_mae: 0.1265\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1129 - val_loss: 0.0254 - val_mae: 0.1265\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0102 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1134 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1265\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1138 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1138 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1132 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0099 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1099 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1133 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0101 - mae: 0.1127 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1134 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0253 - val_mae: 0.1263\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1118 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1125 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0253 - val_mae: 0.1262\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1137 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1117 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - mae: 0.1102 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1107 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1116 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1116 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0104 - mae: 0.1126 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0102 - mae: 0.1128 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0098 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1261\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1138 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0100 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1130 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0102 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1123 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1129 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1260\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0101 - mae: 0.1126 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0099 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1259\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1114 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1099 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1134 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1106 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0098 - mae: 0.1105 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0100 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1258\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0252 - val_mae: 0.1258\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0252 - val_mae: 0.1258\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0097 - mae: 0.1101 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0101 - mae: 0.1126 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0252 - val_mae: 0.1257\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1121 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1118 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1109 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0252 - val_mae: 0.1256\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0100 - mae: 0.1123 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0098 - mae: 0.1111 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1110 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0252 - val_mae: 0.1255\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1111 - val_loss: 0.0252 - val_mae: 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:07:32,865] Trial 1 finished with value: 0.12545287609100342 and parameters: {'learning_rate': 7.685274887511721e-07, 'weight_decay': 4.7458429650196885e-08}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0115 - mae: 0.1217 - val_loss: 0.0260 - val_mae: 0.1311\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1184 - val_loss: 0.0255 - val_mae: 0.1278\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1247\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0248 - val_mae: 0.1219\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0242 - val_mae: 0.1170\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0239 - val_mae: 0.1149\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1130\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0233 - val_mae: 0.1093\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0906 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0226 - val_mae: 0.1026\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.1012\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0866 - val_loss: 0.0222 - val_mae: 0.0997\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.0982\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0219 - val_mae: 0.0967\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0069 - mae: 0.0829 - val_loss: 0.0217 - val_mae: 0.0951\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0805 - val_loss: 0.0215 - val_mae: 0.0937\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0781 - val_loss: 0.0213 - val_mae: 0.0922\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0908\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0209 - val_mae: 0.0898\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0207 - val_mae: 0.0889\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0746 - val_loss: 0.0205 - val_mae: 0.0881\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0722 - val_loss: 0.0203 - val_mae: 0.0873\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0741 - val_loss: 0.0201 - val_mae: 0.0866\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0688 - val_loss: 0.0199 - val_mae: 0.0858\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0056 - mae: 0.0724 - val_loss: 0.0197 - val_mae: 0.0851\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0685 - val_loss: 0.0195 - val_mae: 0.0844\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0053 - mae: 0.0701 - val_loss: 0.0193 - val_mae: 0.0837\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0191 - val_mae: 0.0831\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0700 - val_loss: 0.0189 - val_mae: 0.0827\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0639 - val_loss: 0.0187 - val_mae: 0.0824\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0707 - val_loss: 0.0186 - val_mae: 0.0824\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0824\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0642 - val_loss: 0.0182 - val_mae: 0.0825\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0695 - val_loss: 0.0181 - val_mae: 0.0823\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0820\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0179 - val_mae: 0.0811\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0178 - val_mae: 0.0807\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0177 - val_mae: 0.0799\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0630 - val_loss: 0.0176 - val_mae: 0.0792\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0599 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0789\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0791\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0640 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0542 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0821\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:07:47,739] Trial 2 finished with value: 0.08382976055145264 and parameters: {'learning_rate': 0.00031629296854895206, 'weight_decay': 0.0013799383545765652}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1032 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1046 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0088 - mae: 0.1030 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0092 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1051 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1176\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0085 - mae: 0.1004 - val_loss: 0.0244 - val_mae: 0.1174\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0244 - val_mae: 0.1171\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1003 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0244 - val_mae: 0.1170\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1169\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1169\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0244 - val_mae: 0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:08:02,842] Trial 3 finished with value: 0.11692335456609726 and parameters: {'learning_rate': 1.3588002207300666e-06, 'weight_decay': 1.7062989500766725e-09}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0230 - val_mae: 0.1106\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0218 - val_mae: 0.1025\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0206 - val_mae: 0.0939\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0193 - val_mae: 0.0862\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0181 - val_mae: 0.0830\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0718 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0051 - mae: 0.0730 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0706 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0737 - val_loss: 0.0167 - val_mae: 0.0813\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0724 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0173 - val_mae: 0.0789\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0785\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0179 - val_mae: 0.0798\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0566 - val_loss: 0.0178 - val_mae: 0.0810\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0177 - val_mae: 0.0825\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0175 - val_mae: 0.0841\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0853\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0859\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0856\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0030 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0630 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0848\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0853\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0172 - val_mae: 0.0819\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0870\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0849\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0861\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0176 - val_mae: 0.0819\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0175 - val_mae: 0.0867\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0175 - val_mae: 0.0869\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0175 - val_mae: 0.0861\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0524 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0541 - val_loss: 0.0174 - val_mae: 0.0869\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0174 - val_mae: 0.0848\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0518 - val_loss: 0.0173 - val_mae: 0.0845\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0173 - val_mae: 0.0870\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0897\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - mae: 0.0545 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0172 - val_mae: 0.0859\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0864\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0850\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0841\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0173 - val_mae: 0.0852\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0539 - val_loss: 0.0174 - val_mae: 0.0874\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0174 - val_mae: 0.0860\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0855\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0175 - val_mae: 0.0845\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0553 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0841\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0175 - val_mae: 0.0873\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0175 - val_mae: 0.0916\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0871\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:08:17,703] Trial 4 finished with value: 0.09570694714784622 and parameters: {'learning_rate': 0.0013275915691619402, 'weight_decay': 0.001350070836148524}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0091 - mae: 0.1050 - val_loss: 0.0215 - val_mae: 0.0961\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0188 - val_mae: 0.0798\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0053 - mae: 0.0721 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0048 - mae: 0.0746 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0684 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0842\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0174 - val_mae: 0.0862\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0889\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0677 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0681 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0877\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0885\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0884\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0643 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0627 - val_loss: 0.0166 - val_mae: 0.0868\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0644 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0820\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0636 - val_loss: 0.0168 - val_mae: 0.0864\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0644 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0874\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0036 - mae: 0.0643 - val_loss: 0.0166 - val_mae: 0.0875\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0166 - val_mae: 0.0868\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:08:33,744] Trial 5 finished with value: 0.08537499606609344 and parameters: {'learning_rate': 0.00439758409693151, 'weight_decay': 9.247419144821622e-05}. Best is trial 0 with value: 0.07924208045005798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1168\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0243 - val_mae: 0.1165\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0243 - val_mae: 0.1161\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0242 - val_mae: 0.1157\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0242 - val_mae: 0.1153\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0241 - val_mae: 0.1149\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0241 - val_mae: 0.1145\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1141\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0240 - val_mae: 0.1137\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0240 - val_mae: 0.1133\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1129\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0239 - val_mae: 0.1125\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0238 - val_mae: 0.1121\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0238 - val_mae: 0.1117\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0237 - val_mae: 0.1113\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0237 - val_mae: 0.1109\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0237 - val_mae: 0.1105\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0236 - val_mae: 0.1101\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0236 - val_mae: 0.1096\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0235 - val_mae: 0.1092\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0235 - val_mae: 0.1087\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1083\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0234 - val_mae: 0.1078\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0930 - val_loss: 0.0233 - val_mae: 0.1074\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0233 - val_mae: 0.1069\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0080 - mae: 0.0926 - val_loss: 0.0232 - val_mae: 0.1064\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0926 - val_loss: 0.0232 - val_mae: 0.1059\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0231 - val_mae: 0.1054\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0231 - val_mae: 0.1049\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0230 - val_mae: 0.1044\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0230 - val_mae: 0.1039\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0229 - val_mae: 0.1034\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0229 - val_mae: 0.1028\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0228 - val_mae: 0.1022\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0075 - mae: 0.0896 - val_loss: 0.0228 - val_mae: 0.1016\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0227 - val_mae: 0.1011\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0887 - val_loss: 0.0227 - val_mae: 0.1005\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0226 - val_mae: 0.1000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0226 - val_mae: 0.0995\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0225 - val_mae: 0.0989\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0225 - val_mae: 0.0984\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0858 - val_loss: 0.0224 - val_mae: 0.0979\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0072 - mae: 0.0868 - val_loss: 0.0224 - val_mae: 0.0974\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - mae: 0.0840 - val_loss: 0.0223 - val_mae: 0.0968\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0222 - val_mae: 0.0963\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0070 - mae: 0.0838 - val_loss: 0.0222 - val_mae: 0.0958\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0221 - val_mae: 0.0952\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0221 - val_mae: 0.0947\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0069 - mae: 0.0818 - val_loss: 0.0220 - val_mae: 0.0942\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0069 - mae: 0.0823 - val_loss: 0.0219 - val_mae: 0.0937\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0219 - val_mae: 0.0933\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0218 - val_mae: 0.0928\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0218 - val_mae: 0.0923\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0068 - mae: 0.0810 - val_loss: 0.0217 - val_mae: 0.0918\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0216 - val_mae: 0.0913\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0216 - val_mae: 0.0909\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0063 - mae: 0.0767 - val_loss: 0.0215 - val_mae: 0.0904\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0214 - val_mae: 0.0900\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0792 - val_loss: 0.0214 - val_mae: 0.0895\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0064 - mae: 0.0789 - val_loss: 0.0213 - val_mae: 0.0890\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - mae: 0.0734 - val_loss: 0.0212 - val_mae: 0.0885\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0212 - val_mae: 0.0880\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0764 - val_loss: 0.0211 - val_mae: 0.0875\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0756 - val_loss: 0.0210 - val_mae: 0.0870\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0771 - val_loss: 0.0210 - val_mae: 0.0865\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0209 - val_mae: 0.0860\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0208 - val_mae: 0.0856\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0734 - val_loss: 0.0208 - val_mae: 0.0851\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0061 - mae: 0.0752 - val_loss: 0.0207 - val_mae: 0.0848\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0059 - mae: 0.0761 - val_loss: 0.0206 - val_mae: 0.0844\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0765 - val_loss: 0.0206 - val_mae: 0.0841\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0058 - mae: 0.0722 - val_loss: 0.0205 - val_mae: 0.0838\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0057 - mae: 0.0711 - val_loss: 0.0204 - val_mae: 0.0835\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0204 - val_mae: 0.0832\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0766 - val_loss: 0.0203 - val_mae: 0.0830\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0717 - val_loss: 0.0202 - val_mae: 0.0827\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0057 - mae: 0.0763 - val_loss: 0.0202 - val_mae: 0.0824\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0058 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0822\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0200 - val_mae: 0.0819\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0735 - val_loss: 0.0200 - val_mae: 0.0816\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0736 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0057 - mae: 0.0718 - val_loss: 0.0199 - val_mae: 0.0811\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0049 - mae: 0.0671 - val_loss: 0.0198 - val_mae: 0.0809\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0054 - mae: 0.0714 - val_loss: 0.0197 - val_mae: 0.0807\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0197 - val_mae: 0.0805\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0731 - val_loss: 0.0196 - val_mae: 0.0802\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0714 - val_loss: 0.0196 - val_mae: 0.0801\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0195 - val_mae: 0.0799\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0053 - mae: 0.0726 - val_loss: 0.0194 - val_mae: 0.0797\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0194 - val_mae: 0.0796\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0193 - val_mae: 0.0796\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0719 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0192 - val_mae: 0.0793\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0191 - val_mae: 0.0792\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0046 - mae: 0.0652 - val_loss: 0.0191 - val_mae: 0.0791\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0789\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0190 - val_mae: 0.0788\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0651 - val_loss: 0.0189 - val_mae: 0.0788\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0053 - mae: 0.0703 - val_loss: 0.0189 - val_mae: 0.0787\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0049 - mae: 0.0666 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0050 - mae: 0.0673 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0667 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0640 - val_loss: 0.0187 - val_mae: 0.0786\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0681 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0185 - val_mae: 0.0789\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0185 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0791\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0051 - mae: 0.0744 - val_loss: 0.0184 - val_mae: 0.0791\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0655 - val_loss: 0.0184 - val_mae: 0.0790\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0183 - val_mae: 0.0790\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0692 - val_loss: 0.0183 - val_mae: 0.0790\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0050 - mae: 0.0680 - val_loss: 0.0182 - val_mae: 0.0790\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0181 - val_mae: 0.0789\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0181 - val_mae: 0.0788\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0181 - val_mae: 0.0787\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0787\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0671 - val_loss: 0.0180 - val_mae: 0.0787\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0180 - val_mae: 0.0787\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0647 - val_loss: 0.0180 - val_mae: 0.0786\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0180 - val_mae: 0.0785\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0047 - mae: 0.0684 - val_loss: 0.0180 - val_mae: 0.0785\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0784\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0784\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0676 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0179 - val_mae: 0.0783\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - mae: 0.0661 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0179 - val_mae: 0.0781\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - mae: 0.0613 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0044 - mae: 0.0657 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0045 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:08:48,726] Trial 6 finished with value: 0.07804609090089798 and parameters: {'learning_rate': 7.949489667457115e-05, 'weight_decay': 5.04527771850937e-06}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0239 - val_mae: 0.1150\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1021 - val_loss: 0.0237 - val_mae: 0.1137\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1124\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1112\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1099\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1085\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1071\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0227 - val_mae: 0.1057\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0077 - mae: 0.0895 - val_loss: 0.0225 - val_mae: 0.1042\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1026\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.1009\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0979\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - mae: 0.0859 - val_loss: 0.0216 - val_mae: 0.0966\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0214 - val_mae: 0.0954\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0212 - val_mae: 0.0942\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0066 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0930\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0069 - mae: 0.0845 - val_loss: 0.0209 - val_mae: 0.0920\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0770 - val_loss: 0.0207 - val_mae: 0.0909\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0822 - val_loss: 0.0205 - val_mae: 0.0898\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0066 - mae: 0.0783 - val_loss: 0.0203 - val_mae: 0.0889\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0773 - val_loss: 0.0202 - val_mae: 0.0879\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0200 - val_mae: 0.0869\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0761 - val_loss: 0.0198 - val_mae: 0.0861\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0742 - val_loss: 0.0196 - val_mae: 0.0854\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0194 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0756 - val_loss: 0.0193 - val_mae: 0.0840\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0191 - val_mae: 0.0833\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0055 - mae: 0.0737 - val_loss: 0.0190 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0188 - val_mae: 0.0822\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0704 - val_loss: 0.0187 - val_mae: 0.0819\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0719 - val_loss: 0.0186 - val_mae: 0.0815\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0048 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0708 - val_loss: 0.0183 - val_mae: 0.0810\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0742 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0733 - val_loss: 0.0181 - val_mae: 0.0807\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0181 - val_mae: 0.0806\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - mae: 0.0752 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0045 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0795\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0733 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0688 - val_loss: 0.0179 - val_mae: 0.0790\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0179 - val_mae: 0.0786\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0691 - val_loss: 0.0179 - val_mae: 0.0782\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0662 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0179 - val_mae: 0.0777\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0658 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0651 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0645 - val_loss: 0.0177 - val_mae: 0.0781\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0649 - val_loss: 0.0177 - val_mae: 0.0784\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0176 - val_mae: 0.0786\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0043 - mae: 0.0634 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0176 - val_mae: 0.0790\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0176 - val_mae: 0.0790\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0682 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0586 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0042 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0609 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0612 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0612 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0805\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0041 - mae: 0.0650 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0042 - mae: 0.0618 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - mae: 0.0595 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0175 - val_mae: 0.0792\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0175 - val_mae: 0.0796\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - mae: 0.0609 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0803\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0812\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0816\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0040 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - mae: 0.0594 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0171 - val_mae: 0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:09:05,661] Trial 7 finished with value: 0.08105161786079407 and parameters: {'learning_rate': 0.0001833476100448001, 'weight_decay': 1.6186175169138845e-05}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1190\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0089 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1182\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1182\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0244 - val_mae: 0.1181\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0091 - mae: 0.1050 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1179\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:09:21,666] Trial 8 finished with value: 0.11793720722198486 and parameters: {'learning_rate': 9.462129826178972e-07, 'weight_decay': 7.309859763848851e-05}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0214 - val_mae: 0.0959\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0067 - mae: 0.0805 - val_loss: 0.0188 - val_mae: 0.0830\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0050 - mae: 0.0750 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0045 - mae: 0.0698 - val_loss: 0.0175 - val_mae: 0.0836\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0165 - val_mae: 0.0878\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0635 - val_loss: 0.0165 - val_mae: 0.0876\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0648 - val_loss: 0.0166 - val_mae: 0.0868\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0627 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0842\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0859\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0868\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0872\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0167 - val_mae: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:09:36,586] Trial 9 finished with value: 0.08409398049116135 and parameters: {'learning_rate': 0.0034518329213833842, 'weight_decay': 9.876560883133907e-06}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0235 - val_mae: 0.1108\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1104\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0951 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1099\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0234 - val_mae: 0.1097\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0973 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0233 - val_mae: 0.1090\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0081 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0232 - val_mae: 0.1083\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0232 - val_mae: 0.1081\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1074\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0931 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0226 - val_mae: 0.1039\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0920 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0224 - val_mae: 0.1024\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0902 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0223 - val_mae: 0.1019\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1016\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0071 - mae: 0.0865 - val_loss: 0.0222 - val_mae: 0.1011\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0222 - val_mae: 0.1009\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0222 - val_mae: 0.1006\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0221 - val_mae: 0.1004\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0220 - val_mae: 0.0993\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0220 - val_mae: 0.0991\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0069 - mae: 0.0834 - val_loss: 0.0219 - val_mae: 0.0986\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0219 - val_mae: 0.0983\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0077 - mae: 0.0881 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0073 - mae: 0.0854 - val_loss: 0.0218 - val_mae: 0.0978\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0218 - val_mae: 0.0975\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0218 - val_mae: 0.0973\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0217 - val_mae: 0.0970\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0068 - mae: 0.0848 - val_loss: 0.0217 - val_mae: 0.0967\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0217 - val_mae: 0.0965\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0216 - val_mae: 0.0962\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0069 - mae: 0.0850 - val_loss: 0.0216 - val_mae: 0.0960\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0072 - mae: 0.0842 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0067 - mae: 0.0823 - val_loss: 0.0215 - val_mae: 0.0954\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0064 - mae: 0.0815 - val_loss: 0.0215 - val_mae: 0.0951\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0215 - val_mae: 0.0949\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0214 - val_mae: 0.0946\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0214 - val_mae: 0.0943\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0214 - val_mae: 0.0941\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0069 - mae: 0.0817 - val_loss: 0.0213 - val_mae: 0.0938\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0793 - val_loss: 0.0213 - val_mae: 0.0935\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0073 - mae: 0.0855 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0065 - mae: 0.0806 - val_loss: 0.0212 - val_mae: 0.0930\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0831 - val_loss: 0.0212 - val_mae: 0.0927\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0212 - val_mae: 0.0925\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0801 - val_loss: 0.0211 - val_mae: 0.0922\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0071 - mae: 0.0844 - val_loss: 0.0211 - val_mae: 0.0920\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0211 - val_mae: 0.0917\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0071 - mae: 0.0858 - val_loss: 0.0210 - val_mae: 0.0915\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0067 - mae: 0.0782 - val_loss: 0.0210 - val_mae: 0.0913\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0062 - mae: 0.0782 - val_loss: 0.0210 - val_mae: 0.0910\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0209 - val_mae: 0.0908\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0064 - mae: 0.0810 - val_loss: 0.0209 - val_mae: 0.0906\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0806 - val_loss: 0.0209 - val_mae: 0.0904\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0069 - mae: 0.0850 - val_loss: 0.0208 - val_mae: 0.0902\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0065 - mae: 0.0793 - val_loss: 0.0208 - val_mae: 0.0899\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0066 - mae: 0.0806 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0064 - mae: 0.0794 - val_loss: 0.0208 - val_mae: 0.0895\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0207 - val_mae: 0.0893\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0064 - mae: 0.0793 - val_loss: 0.0207 - val_mae: 0.0892\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0067 - mae: 0.0794 - val_loss: 0.0207 - val_mae: 0.0890\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0839 - val_loss: 0.0206 - val_mae: 0.0888\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0064 - mae: 0.0798 - val_loss: 0.0206 - val_mae: 0.0886\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0062 - mae: 0.0779 - val_loss: 0.0206 - val_mae: 0.0884\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0792 - val_loss: 0.0206 - val_mae: 0.0882\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0817 - val_loss: 0.0205 - val_mae: 0.0881\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0062 - mae: 0.0781 - val_loss: 0.0205 - val_mae: 0.0879\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0772 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0736 - val_loss: 0.0205 - val_mae: 0.0875\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0065 - mae: 0.0810 - val_loss: 0.0204 - val_mae: 0.0874\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0204 - val_mae: 0.0872\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0772 - val_loss: 0.0204 - val_mae: 0.0869\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0815 - val_loss: 0.0203 - val_mae: 0.0865\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0059 - mae: 0.0781 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0772 - val_loss: 0.0203 - val_mae: 0.0862\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0743 - val_loss: 0.0202 - val_mae: 0.0860\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0728 - val_loss: 0.0202 - val_mae: 0.0859\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0796 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0202 - val_mae: 0.0855\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0058 - mae: 0.0758 - val_loss: 0.0201 - val_mae: 0.0854\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - mae: 0.0741 - val_loss: 0.0201 - val_mae: 0.0852\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0850\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0753 - val_loss: 0.0201 - val_mae: 0.0849\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0200 - val_mae: 0.0847\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0200 - val_mae: 0.0846\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0722 - val_loss: 0.0200 - val_mae: 0.0844\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0200 - val_mae: 0.0843\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0199 - val_mae: 0.0841\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0755 - val_loss: 0.0199 - val_mae: 0.0840\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0199 - val_mae: 0.0839\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0056 - mae: 0.0722 - val_loss: 0.0198 - val_mae: 0.0837\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0715 - val_loss: 0.0198 - val_mae: 0.0836\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0721 - val_loss: 0.0198 - val_mae: 0.0835\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0198 - val_mae: 0.0833\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0197 - val_mae: 0.0832\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0052 - mae: 0.0706 - val_loss: 0.0197 - val_mae: 0.0831\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060 - mae: 0.0746 - val_loss: 0.0197 - val_mae: 0.0829\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0197 - val_mae: 0.0828\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0196 - val_mae: 0.0827\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.0826\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0785 - val_loss: 0.0196 - val_mae: 0.0824\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - mae: 0.0745 - val_loss: 0.0196 - val_mae: 0.0823\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0196 - val_mae: 0.0822\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0722 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0729 - val_loss: 0.0195 - val_mae: 0.0820\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0698 - val_loss: 0.0195 - val_mae: 0.0819\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0195 - val_mae: 0.0818\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0737 - val_loss: 0.0195 - val_mae: 0.0817\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0194 - val_mae: 0.0816\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0194 - val_mae: 0.0815\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0056 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0814\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0194 - val_mae: 0.0813\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0812\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0769 - val_loss: 0.0193 - val_mae: 0.0811\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - mae: 0.0750 - val_loss: 0.0193 - val_mae: 0.0810\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0060 - mae: 0.0775 - val_loss: 0.0193 - val_mae: 0.0809\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0193 - val_mae: 0.0808\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0762 - val_loss: 0.0193 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:09:51,093] Trial 10 finished with value: 0.0807504653930664 and parameters: {'learning_rate': 2.9473385156150887e-05, 'weight_decay': 4.4509713519593616e-07}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0088 - mae: 0.1029 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0243 - val_mae: 0.1182\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0243 - val_mae: 0.1176\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1010 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0089 - mae: 0.1027 - val_loss: 0.0241 - val_mae: 0.1162\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1156\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1154\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0240 - val_mae: 0.1148\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0239 - val_mae: 0.1146\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0989 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1139\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0238 - val_mae: 0.1136\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1134\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0084 - mae: 0.0990 - val_loss: 0.0238 - val_mae: 0.1131\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0237 - val_mae: 0.1128\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1125\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0984 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0975 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1112\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0236 - val_mae: 0.1110\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1109\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0235 - val_mae: 0.1108\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0080 - mae: 0.0949 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0235 - val_mae: 0.1105\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1099\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1097\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1096\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1095\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1093\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1092\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1090\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0947 - val_loss: 0.0233 - val_mae: 0.1089\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0233 - val_mae: 0.1087\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0233 - val_mae: 0.1084\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0233 - val_mae: 0.1083\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0233 - val_mae: 0.1081\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0232 - val_mae: 0.1080\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0077 - mae: 0.0929 - val_loss: 0.0232 - val_mae: 0.1078\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0232 - val_mae: 0.1077\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0232 - val_mae: 0.1075\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0232 - val_mae: 0.1074\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0232 - val_mae: 0.1072\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1071\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0231 - val_mae: 0.1069\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0231 - val_mae: 0.1068\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0231 - val_mae: 0.1066\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0231 - val_mae: 0.1065\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1063\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1062\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1060\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0230 - val_mae: 0.1059\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0230 - val_mae: 0.1057\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0910 - val_loss: 0.0230 - val_mae: 0.1056\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0230 - val_mae: 0.1054\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0230 - val_mae: 0.1053\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0919 - val_loss: 0.0229 - val_mae: 0.1051\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0229 - val_mae: 0.1050\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0919 - val_loss: 0.0229 - val_mae: 0.1048\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0229 - val_mae: 0.1047\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0229 - val_mae: 0.1045\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0229 - val_mae: 0.1043\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0922 - val_loss: 0.0229 - val_mae: 0.1042\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0228 - val_mae: 0.1040\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0075 - mae: 0.0885 - val_loss: 0.0228 - val_mae: 0.1039\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0228 - val_mae: 0.1037\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0228 - val_mae: 0.1036\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0895 - val_loss: 0.0228 - val_mae: 0.1034\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.1033\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0227 - val_mae: 0.1031\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0901 - val_loss: 0.0227 - val_mae: 0.1029\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0889 - val_loss: 0.0227 - val_mae: 0.1028\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0227 - val_mae: 0.1026\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0227 - val_mae: 0.1025\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0227 - val_mae: 0.1023\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0226 - val_mae: 0.1021\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0226 - val_mae: 0.1020\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0226 - val_mae: 0.1018\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0226 - val_mae: 0.1016\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0226 - val_mae: 0.1015\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0225 - val_mae: 0.1013\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1012\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - mae: 0.0874 - val_loss: 0.0225 - val_mae: 0.1010\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0887 - val_loss: 0.0225 - val_mae: 0.1008\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0860 - val_loss: 0.0225 - val_mae: 0.1007\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0225 - val_mae: 0.1005\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0224 - val_mae: 0.1003\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0855 - val_loss: 0.0224 - val_mae: 0.1002\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0224 - val_mae: 0.1000\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0224 - val_mae: 0.0998\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0224 - val_mae: 0.0996\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0071 - mae: 0.0832 - val_loss: 0.0224 - val_mae: 0.0995\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0223 - val_mae: 0.0993\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0223 - val_mae: 0.0991\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0842 - val_loss: 0.0223 - val_mae: 0.0990\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0074 - mae: 0.0861 - val_loss: 0.0223 - val_mae: 0.0988\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0880 - val_loss: 0.0223 - val_mae: 0.0986\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0835 - val_loss: 0.0223 - val_mae: 0.0984\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0222 - val_mae: 0.0982\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0222 - val_mae: 0.0981\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0844 - val_loss: 0.0222 - val_mae: 0.0979\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0222 - val_mae: 0.0977\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0222 - val_mae: 0.0975\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0221 - val_mae: 0.0973\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0221 - val_mae: 0.0972\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0221 - val_mae: 0.0970\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0221 - val_mae: 0.0968\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0813 - val_loss: 0.0221 - val_mae: 0.0966\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0221 - val_mae: 0.0964\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0837 - val_loss: 0.0220 - val_mae: 0.0962\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0220 - val_mae: 0.0960\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0220 - val_mae: 0.0958\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0220 - val_mae: 0.0956\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0843 - val_loss: 0.0220 - val_mae: 0.0954\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0070 - mae: 0.0822 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0219 - val_mae: 0.0951\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0219 - val_mae: 0.0949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:10:13,882] Trial 11 finished with value: 0.0948602706193924 and parameters: {'learning_rate': 1.621860022947736e-05, 'weight_decay': 0.006411041331123748}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0250 - val_mae: 0.1243\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1241\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0249 - val_mae: 0.1238\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1236\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1103 - val_loss: 0.0248 - val_mae: 0.1233\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0096 - mae: 0.1091 - val_loss: 0.0248 - val_mae: 0.1230\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1228\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1225\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0246 - val_mae: 0.1223\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0246 - val_mae: 0.1220\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1217\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0245 - val_mae: 0.1215\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1212\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1210\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1207\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0244 - val_mae: 0.1205\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0243 - val_mae: 0.1202\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0243 - val_mae: 0.1200\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0242 - val_mae: 0.1195\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0242 - val_mae: 0.1192\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0242 - val_mae: 0.1190\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0241 - val_mae: 0.1188\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1185\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0241 - val_mae: 0.1183\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1181\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0240 - val_mae: 0.1179\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1174\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1172\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0239 - val_mae: 0.1170\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1032 - val_loss: 0.0238 - val_mae: 0.1168\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1165\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0238 - val_mae: 0.1163\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0237 - val_mae: 0.1161\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1159\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0237 - val_mae: 0.1157\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1155\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0236 - val_mae: 0.1153\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0236 - val_mae: 0.1151\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0236 - val_mae: 0.1148\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0083 - mae: 0.0985 - val_loss: 0.0235 - val_mae: 0.1146\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0235 - val_mae: 0.1144\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1142\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0235 - val_mae: 0.1140\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0234 - val_mae: 0.1138\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0234 - val_mae: 0.1136\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0234 - val_mae: 0.1133\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0995 - val_loss: 0.0233 - val_mae: 0.1131\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0989 - val_loss: 0.0233 - val_mae: 0.1129\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0986 - val_loss: 0.0233 - val_mae: 0.1127\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0233 - val_mae: 0.1125\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0232 - val_mae: 0.1123\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1120\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0232 - val_mae: 0.1118\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0231 - val_mae: 0.1116\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0231 - val_mae: 0.1114\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0082 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1112\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0085 - mae: 0.0973 - val_loss: 0.0231 - val_mae: 0.1109\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0080 - mae: 0.0947 - val_loss: 0.0230 - val_mae: 0.1107\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0084 - mae: 0.0974 - val_loss: 0.0230 - val_mae: 0.1105\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1102\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0229 - val_mae: 0.1100\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0229 - val_mae: 0.1097\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0229 - val_mae: 0.1094\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0079 - mae: 0.0952 - val_loss: 0.0228 - val_mae: 0.1092\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0228 - val_mae: 0.1089\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0228 - val_mae: 0.1086\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0227 - val_mae: 0.1083\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0227 - val_mae: 0.1080\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1077\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0226 - val_mae: 0.1074\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0942 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0225 - val_mae: 0.1068\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0225 - val_mae: 0.1065\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0077 - mae: 0.0929 - val_loss: 0.0225 - val_mae: 0.1062\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0224 - val_mae: 0.1059\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0079 - mae: 0.0935 - val_loss: 0.0224 - val_mae: 0.1055\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0077 - mae: 0.0923 - val_loss: 0.0224 - val_mae: 0.1052\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0223 - val_mae: 0.1049\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0223 - val_mae: 0.1046\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0079 - mae: 0.0910 - val_loss: 0.0223 - val_mae: 0.1043\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - mae: 0.0914 - val_loss: 0.0222 - val_mae: 0.1040\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0222 - val_mae: 0.1037\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1033\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0221 - val_mae: 0.1030\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0075 - mae: 0.0891 - val_loss: 0.0221 - val_mae: 0.1027\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0220 - val_mae: 0.1024\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0075 - mae: 0.0887 - val_loss: 0.0220 - val_mae: 0.1021\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0891 - val_loss: 0.0220 - val_mae: 0.1018\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0219 - val_mae: 0.1014\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0219 - val_mae: 0.1011\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0219 - val_mae: 0.1008\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0884 - val_loss: 0.0218 - val_mae: 0.1005\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0884 - val_loss: 0.0218 - val_mae: 0.1002\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0218 - val_mae: 0.0999\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0217 - val_mae: 0.0996\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0875 - val_loss: 0.0217 - val_mae: 0.0994\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0217 - val_mae: 0.0991\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0216 - val_mae: 0.0988\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0216 - val_mae: 0.0985\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0216 - val_mae: 0.0982\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0215 - val_mae: 0.0979\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0873 - val_loss: 0.0215 - val_mae: 0.0977\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0215 - val_mae: 0.0974\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0214 - val_mae: 0.0971\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0071 - mae: 0.0850 - val_loss: 0.0214 - val_mae: 0.0968\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0073 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0966\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0213 - val_mae: 0.0963\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0213 - val_mae: 0.0961\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0072 - mae: 0.0861 - val_loss: 0.0213 - val_mae: 0.0958\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0070 - mae: 0.0824 - val_loss: 0.0212 - val_mae: 0.0956\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0068 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0953\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0212 - val_mae: 0.0950\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0068 - mae: 0.0838 - val_loss: 0.0211 - val_mae: 0.0948\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0066 - mae: 0.0823 - val_loss: 0.0211 - val_mae: 0.0945\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0211 - val_mae: 0.0942\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0210 - val_mae: 0.0940\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0069 - mae: 0.0820 - val_loss: 0.0210 - val_mae: 0.0937\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0822 - val_loss: 0.0210 - val_mae: 0.0935\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0071 - mae: 0.0834 - val_loss: 0.0209 - val_mae: 0.0932\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0209 - val_mae: 0.0929\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0209 - val_mae: 0.0927\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0208 - val_mae: 0.0925\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0208 - val_mae: 0.0922\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - mae: 0.0823 - val_loss: 0.0208 - val_mae: 0.0920\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0067 - mae: 0.0824 - val_loss: 0.0207 - val_mae: 0.0918\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0071 - mae: 0.0818 - val_loss: 0.0207 - val_mae: 0.0916\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0207 - val_mae: 0.0913\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0206 - val_mae: 0.0911\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0206 - val_mae: 0.0909\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0206 - val_mae: 0.0907\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0904\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0205 - val_mae: 0.0902\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0063 - mae: 0.0795 - val_loss: 0.0205 - val_mae: 0.0900\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0064 - mae: 0.0803 - val_loss: 0.0205 - val_mae: 0.0898\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0204 - val_mae: 0.0896\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0062 - mae: 0.0799 - val_loss: 0.0204 - val_mae: 0.0894\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0063 - mae: 0.0800 - val_loss: 0.0204 - val_mae: 0.0891\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0203 - val_mae: 0.0889\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0203 - val_mae: 0.0887\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0062 - mae: 0.0754 - val_loss: 0.0203 - val_mae: 0.0885\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0202 - val_mae: 0.0883\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0066 - mae: 0.0805 - val_loss: 0.0202 - val_mae: 0.0880\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0062 - mae: 0.0782 - val_loss: 0.0202 - val_mae: 0.0878\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0821 - val_loss: 0.0201 - val_mae: 0.0876\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0201 - val_mae: 0.0874\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0201 - val_mae: 0.0872\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0759 - val_loss: 0.0201 - val_mae: 0.0870\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0064 - mae: 0.0782 - val_loss: 0.0200 - val_mae: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:10:38,268] Trial 12 finished with value: 0.08680359274148941 and parameters: {'learning_rate': 2.8173693672959767e-05, 'weight_decay': 9.181183305676816e-05}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0089 - mae: 0.0993 - val_loss: 0.0223 - val_mae: 0.1001\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0205 - val_mae: 0.0883\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0059 - mae: 0.0751 - val_loss: 0.0191 - val_mae: 0.0852\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0055 - mae: 0.0728 - val_loss: 0.0186 - val_mae: 0.0851\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0713 - val_loss: 0.0184 - val_mae: 0.0835\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0044 - mae: 0.0679 - val_loss: 0.0182 - val_mae: 0.0814\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0650 - val_loss: 0.0181 - val_mae: 0.0806\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0177 - val_mae: 0.0820\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0171 - val_mae: 0.0849\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0168 - val_mae: 0.0873\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - mae: 0.0640 - val_loss: 0.0166 - val_mae: 0.0893\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - mae: 0.0667 - val_loss: 0.0166 - val_mae: 0.0883\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0039 - mae: 0.0698 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0802\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - mae: 0.0613 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0032 - mae: 0.0552 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0872\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0863\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0033 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0829\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0870\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0814\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0862\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0868\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0870\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0853\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0883\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0869\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0032 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0836\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0172 - val_mae: 0.0865\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0840\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0173 - val_mae: 0.0887\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0875\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0170 - val_mae: 0.0811\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0864\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0880\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0546 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - mae: 0.0526 - val_loss: 0.0173 - val_mae: 0.0835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:10:57,177] Trial 13 finished with value: 0.08345282822847366 and parameters: {'learning_rate': 0.0022929618531471806, 'weight_decay': 8.187141590130105e-08}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0094 - mae: 0.1072 - val_loss: 0.0245 - val_mae: 0.1197\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0091 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1186\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0234 - val_mae: 0.1092\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0946 - val_loss: 0.0233 - val_mae: 0.1083\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0078 - mae: 0.0921 - val_loss: 0.0232 - val_mae: 0.1074\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0231 - val_mae: 0.1064\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0922 - val_loss: 0.0231 - val_mae: 0.1054\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0230 - val_mae: 0.1045\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0229 - val_mae: 0.1035\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0228 - val_mae: 0.1026\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0227 - val_mae: 0.1016\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0226 - val_mae: 0.1007\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0224 - val_mae: 0.0989\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0223 - val_mae: 0.0980\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0071 - mae: 0.0844 - val_loss: 0.0222 - val_mae: 0.0972\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0859 - val_loss: 0.0220 - val_mae: 0.0963\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - mae: 0.0854 - val_loss: 0.0219 - val_mae: 0.0954\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - mae: 0.0834 - val_loss: 0.0218 - val_mae: 0.0945\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0065 - mae: 0.0818 - val_loss: 0.0217 - val_mae: 0.0936\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0067 - mae: 0.0825 - val_loss: 0.0215 - val_mae: 0.0918\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0066 - mae: 0.0809 - val_loss: 0.0214 - val_mae: 0.0911\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0213 - val_mae: 0.0903\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0896\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0210 - val_mae: 0.0890\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0785 - val_loss: 0.0209 - val_mae: 0.0884\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0778 - val_loss: 0.0208 - val_mae: 0.0878\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0207 - val_mae: 0.0874\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0064 - mae: 0.0793 - val_loss: 0.0206 - val_mae: 0.0869\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0750 - val_loss: 0.0205 - val_mae: 0.0864\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0203 - val_mae: 0.0860\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0055 - mae: 0.0753 - val_loss: 0.0202 - val_mae: 0.0856\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0851\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0200 - val_mae: 0.0847\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0737 - val_loss: 0.0199 - val_mae: 0.0842\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0051 - mae: 0.0702 - val_loss: 0.0198 - val_mae: 0.0839\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0197 - val_mae: 0.0835\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0058 - mae: 0.0767 - val_loss: 0.0196 - val_mae: 0.0831\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0053 - mae: 0.0700 - val_loss: 0.0195 - val_mae: 0.0828\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0052 - mae: 0.0712 - val_loss: 0.0194 - val_mae: 0.0825\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0193 - val_mae: 0.0822\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0709 - val_loss: 0.0193 - val_mae: 0.0819\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0192 - val_mae: 0.0816\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0720 - val_loss: 0.0191 - val_mae: 0.0814\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0190 - val_mae: 0.0811\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0189 - val_mae: 0.0808\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0046 - mae: 0.0709 - val_loss: 0.0189 - val_mae: 0.0805\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0052 - mae: 0.0735 - val_loss: 0.0188 - val_mae: 0.0803\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0052 - mae: 0.0699 - val_loss: 0.0187 - val_mae: 0.0800\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0187 - val_mae: 0.0797\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0789\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0184 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0184 - val_mae: 0.0784\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0184 - val_mae: 0.0782\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0780\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0689 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0693 - val_loss: 0.0182 - val_mae: 0.0777\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0182 - val_mae: 0.0776\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0181 - val_mae: 0.0775\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0181 - val_mae: 0.0774\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0046 - mae: 0.0646 - val_loss: 0.0181 - val_mae: 0.0773\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0773\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - mae: 0.0650 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0044 - mae: 0.0638 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0582 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0685 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0655 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0776\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0044 - mae: 0.0693 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0047 - mae: 0.0695 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0047 - mae: 0.0691 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0175 - val_mae: 0.0776\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0042 - mae: 0.0672 - val_loss: 0.0175 - val_mae: 0.0774\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0636 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0651 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0770\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0039 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0174 - val_mae: 0.0788\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0174 - val_mae: 0.0786\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - mae: 0.0640 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0783\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0044 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0175 - val_mae: 0.0779\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0175 - val_mae: 0.0778\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0781\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0043 - mae: 0.0676 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0040 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0787\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0789\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:11:14,482] Trial 14 finished with value: 0.07892321050167084 and parameters: {'learning_rate': 0.00013189588878328854, 'weight_decay': 5.707777345338188e-08}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0242 - val_mae: 0.1189\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0241 - val_mae: 0.1179\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0239 - val_mae: 0.1168\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1157\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1147\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0236 - val_mae: 0.1138\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0986 - val_loss: 0.0235 - val_mae: 0.1129\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0234 - val_mae: 0.1119\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0233 - val_mae: 0.1110\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0082 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1101\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1091\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0229 - val_mae: 0.1081\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0079 - mae: 0.0941 - val_loss: 0.0228 - val_mae: 0.1072\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1062\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0913 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0224 - val_mae: 0.1031\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0221 - val_mae: 0.1010\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0070 - mae: 0.0852 - val_loss: 0.0217 - val_mae: 0.0980\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0216 - val_mae: 0.0970\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0214 - val_mae: 0.0959\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0834 - val_loss: 0.0212 - val_mae: 0.0948\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0937\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0068 - mae: 0.0818 - val_loss: 0.0209 - val_mae: 0.0926\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0208 - val_mae: 0.0915\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0206 - val_mae: 0.0903\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0204 - val_mae: 0.0892\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0203 - val_mae: 0.0882\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0782 - val_loss: 0.0201 - val_mae: 0.0872\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0199 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0057 - mae: 0.0734 - val_loss: 0.0198 - val_mae: 0.0856\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0196 - val_mae: 0.0849\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0195 - val_mae: 0.0843\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0766 - val_loss: 0.0193 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0191 - val_mae: 0.0833\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0190 - val_mae: 0.0829\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0709 - val_loss: 0.0188 - val_mae: 0.0826\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0051 - mae: 0.0754 - val_loss: 0.0187 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0186 - val_mae: 0.0819\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0054 - mae: 0.0737 - val_loss: 0.0185 - val_mae: 0.0815\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0746 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0720 - val_loss: 0.0183 - val_mae: 0.0808\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0053 - mae: 0.0727 - val_loss: 0.0182 - val_mae: 0.0804\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0182 - val_mae: 0.0800\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0050 - mae: 0.0723 - val_loss: 0.0181 - val_mae: 0.0797\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0702 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0044 - mae: 0.0678 - val_loss: 0.0181 - val_mae: 0.0792\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0693 - val_loss: 0.0180 - val_mae: 0.0791\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0180 - val_mae: 0.0790\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0049 - mae: 0.0712 - val_loss: 0.0180 - val_mae: 0.0789\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0051 - mae: 0.0720 - val_loss: 0.0179 - val_mae: 0.0788\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0043 - mae: 0.0676 - val_loss: 0.0179 - val_mae: 0.0786\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0669 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0693 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0178 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0667 - val_loss: 0.0178 - val_mae: 0.0788\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0176 - val_mae: 0.0795\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0176 - val_mae: 0.0796\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0798\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0041 - mae: 0.0628 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0049 - mae: 0.0707 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0174 - val_mae: 0.0805\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - mae: 0.0654 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0041 - mae: 0.0645 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0174 - val_mae: 0.0795\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0174 - val_mae: 0.0793\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - mae: 0.0588 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0172 - val_mae: 0.0803\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0801\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - mae: 0.0607 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0172 - val_mae: 0.0813\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0814\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0813\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0035 - mae: 0.0629 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0172 - val_mae: 0.0802\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0592 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0798\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0800\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0035 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0802\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0805\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:11:32,046] Trial 15 finished with value: 0.08083589375019073 and parameters: {'learning_rate': 0.00017062768580519808, 'weight_decay': 1.9437367158480386e-08}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0246 - val_mae: 0.1210\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0092 - mae: 0.1061 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0092 - mae: 0.1062 - val_loss: 0.0245 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0092 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0244 - val_mae: 0.1193\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1189\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0242 - val_mae: 0.1184\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0090 - mae: 0.1039 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0240 - val_mae: 0.1167\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0240 - val_mae: 0.1163\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0239 - val_mae: 0.1159\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0239 - val_mae: 0.1154\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0086 - mae: 0.1010 - val_loss: 0.0238 - val_mae: 0.1151\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0238 - val_mae: 0.1147\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0998 - val_loss: 0.0238 - val_mae: 0.1143\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0237 - val_mae: 0.1136\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0085 - mae: 0.0990 - val_loss: 0.0236 - val_mae: 0.1132\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1128\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0082 - mae: 0.0966 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0084 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0082 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1117\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1113\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1105\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0080 - mae: 0.0951 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0942 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0079 - mae: 0.0934 - val_loss: 0.0229 - val_mae: 0.1062\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1058\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1053\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0075 - mae: 0.0907 - val_loss: 0.0228 - val_mae: 0.1049\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0076 - mae: 0.0906 - val_loss: 0.0228 - val_mae: 0.1044\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0227 - val_mae: 0.1039\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0227 - val_mae: 0.1034\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0226 - val_mae: 0.1025\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0883 - val_loss: 0.0225 - val_mae: 0.1020\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0883 - val_loss: 0.0225 - val_mae: 0.1015\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0224 - val_mae: 0.1011\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0073 - mae: 0.0884 - val_loss: 0.0224 - val_mae: 0.1006\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.1001\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0071 - mae: 0.0863 - val_loss: 0.0223 - val_mae: 0.0996\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0070 - mae: 0.0853 - val_loss: 0.0223 - val_mae: 0.0991\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0222 - val_mae: 0.0986\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0222 - val_mae: 0.0981\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0221 - val_mae: 0.0976\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0221 - val_mae: 0.0972\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0072 - mae: 0.0860 - val_loss: 0.0220 - val_mae: 0.0967\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0220 - val_mae: 0.0962\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0071 - mae: 0.0845 - val_loss: 0.0219 - val_mae: 0.0957\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - mae: 0.0830 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0218 - val_mae: 0.0947\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0218 - val_mae: 0.0942\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0938\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - mae: 0.0813 - val_loss: 0.0217 - val_mae: 0.0933\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0792 - val_loss: 0.0216 - val_mae: 0.0928\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0216 - val_mae: 0.0924\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0812 - val_loss: 0.0215 - val_mae: 0.0919\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0065 - mae: 0.0806 - val_loss: 0.0215 - val_mae: 0.0915\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0214 - val_mae: 0.0910\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0214 - val_mae: 0.0906\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0067 - mae: 0.0816 - val_loss: 0.0213 - val_mae: 0.0901\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0065 - mae: 0.0785 - val_loss: 0.0213 - val_mae: 0.0897\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0212 - val_mae: 0.0892\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0066 - mae: 0.0790 - val_loss: 0.0212 - val_mae: 0.0888\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0066 - mae: 0.0816 - val_loss: 0.0211 - val_mae: 0.0884\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0066 - mae: 0.0793 - val_loss: 0.0211 - val_mae: 0.0881\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0211 - val_mae: 0.0877\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0210 - val_mae: 0.0873\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0062 - mae: 0.0783 - val_loss: 0.0210 - val_mae: 0.0870\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0066 - mae: 0.0803 - val_loss: 0.0209 - val_mae: 0.0867\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0063 - mae: 0.0769 - val_loss: 0.0209 - val_mae: 0.0864\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0208 - val_mae: 0.0860\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0208 - val_mae: 0.0857\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0207 - val_mae: 0.0854\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0061 - mae: 0.0759 - val_loss: 0.0207 - val_mae: 0.0852\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0059 - mae: 0.0736 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0055 - mae: 0.0714 - val_loss: 0.0206 - val_mae: 0.0846\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0205 - val_mae: 0.0844\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0057 - mae: 0.0735 - val_loss: 0.0205 - val_mae: 0.0841\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0057 - mae: 0.0724 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0058 - mae: 0.0744 - val_loss: 0.0204 - val_mae: 0.0837\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0056 - mae: 0.0710 - val_loss: 0.0203 - val_mae: 0.0835\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0058 - mae: 0.0738 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0724 - val_loss: 0.0202 - val_mae: 0.0831\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0057 - mae: 0.0700 - val_loss: 0.0202 - val_mae: 0.0829\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - mae: 0.0732 - val_loss: 0.0201 - val_mae: 0.0828\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - mae: 0.0739 - val_loss: 0.0201 - val_mae: 0.0827\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0056 - mae: 0.0716 - val_loss: 0.0200 - val_mae: 0.0825\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0701 - val_loss: 0.0200 - val_mae: 0.0824\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0199 - val_mae: 0.0823\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0060 - mae: 0.0745 - val_loss: 0.0199 - val_mae: 0.0822\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0772 - val_loss: 0.0198 - val_mae: 0.0821\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0057 - mae: 0.0739 - val_loss: 0.0198 - val_mae: 0.0820\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0064 - mae: 0.0778 - val_loss: 0.0198 - val_mae: 0.0819\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0056 - mae: 0.0735 - val_loss: 0.0197 - val_mae: 0.0818\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0055 - mae: 0.0721 - val_loss: 0.0197 - val_mae: 0.0818\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0716 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0059 - mae: 0.0731 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0053 - mae: 0.0700 - val_loss: 0.0196 - val_mae: 0.0816\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0056 - mae: 0.0728 - val_loss: 0.0195 - val_mae: 0.0815\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0058 - mae: 0.0729 - val_loss: 0.0195 - val_mae: 0.0814\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0195 - val_mae: 0.0814\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0194 - val_mae: 0.0813\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0050 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0812\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0723 - val_loss: 0.0194 - val_mae: 0.0811\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0714 - val_loss: 0.0193 - val_mae: 0.0810\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0193 - val_mae: 0.0810\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0193 - val_mae: 0.0809\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0057 - mae: 0.0730 - val_loss: 0.0193 - val_mae: 0.0809\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0192 - val_mae: 0.0808\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0055 - mae: 0.0727 - val_loss: 0.0192 - val_mae: 0.0807\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0054 - mae: 0.0725 - val_loss: 0.0192 - val_mae: 0.0807\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0049 - mae: 0.0667 - val_loss: 0.0191 - val_mae: 0.0806\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0050 - mae: 0.0727 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0049 - mae: 0.0672 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0191 - val_mae: 0.0805\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0053 - mae: 0.0727 - val_loss: 0.0190 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0050 - mae: 0.0685 - val_loss: 0.0190 - val_mae: 0.0804\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0050 - mae: 0.0722 - val_loss: 0.0190 - val_mae: 0.0804\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0190 - val_mae: 0.0803\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0189 - val_mae: 0.0803\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0189 - val_mae: 0.0803\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - mae: 0.0698 - val_loss: 0.0189 - val_mae: 0.0802\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - mae: 0.0696 - val_loss: 0.0189 - val_mae: 0.0802\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0189 - val_mae: 0.0801\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0051 - mae: 0.0716 - val_loss: 0.0188 - val_mae: 0.0800\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0188 - val_mae: 0.0800\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - mae: 0.0716 - val_loss: 0.0188 - val_mae: 0.0799\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0719 - val_loss: 0.0188 - val_mae: 0.0798\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0798\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0718 - val_loss: 0.0187 - val_mae: 0.0797\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0187 - val_mae: 0.0797\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0051 - mae: 0.0722 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0673 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0050 - mae: 0.0681 - val_loss: 0.0186 - val_mae: 0.0794\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0186 - val_mae: 0.0793\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0055 - mae: 0.0726 - val_loss: 0.0186 - val_mae: 0.0792\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0186 - val_mae: 0.0792\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0186 - val_mae: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:11:49,431] Trial 16 finished with value: 0.07910710573196411 and parameters: {'learning_rate': 3.94380758316214e-05, 'weight_decay': 5.515320087899345e-08}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0099 - mae: 0.1040 - val_loss: 0.0227 - val_mae: 0.1091\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0220 - val_mae: 0.1031\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0213 - val_mae: 0.0964\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0204 - val_mae: 0.0891\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0060 - mae: 0.0737 - val_loss: 0.0193 - val_mae: 0.0820\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0057 - mae: 0.0718 - val_loss: 0.0183 - val_mae: 0.0788\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0724 - val_loss: 0.0175 - val_mae: 0.0790\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0754 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0046 - mae: 0.0702 - val_loss: 0.0169 - val_mae: 0.0819\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0046 - mae: 0.0714 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0042 - mae: 0.0671 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - mae: 0.0680 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0040 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0041 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0862\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0169 - val_mae: 0.0829\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0843\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0829\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0842\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - mae: 0.0540 - val_loss: 0.0171 - val_mae: 0.0818\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0817\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0031 - mae: 0.0541 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0172 - val_mae: 0.0826\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0851\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0847\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0815\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0842\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0173 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0845\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0173 - val_mae: 0.0834\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0863\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0858\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0796\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0173 - val_mae: 0.0809\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0553 - val_loss: 0.0173 - val_mae: 0.0851\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0173 - val_mae: 0.0807\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0814\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0830\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0173 - val_mae: 0.0831\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0175 - val_mae: 0.0833\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0835\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - mae: 0.0526 - val_loss: 0.0174 - val_mae: 0.0835\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0174 - val_mae: 0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:12:09,312] Trial 17 finished with value: 0.0794084370136261 and parameters: {'learning_rate': 0.001143651420316701, 'weight_decay': 5.76450894873858e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1092 - val_loss: 0.0250 - val_mae: 0.1234\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0250 - val_mae: 0.1230\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1226\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1223\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0248 - val_mae: 0.1219\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0095 - mae: 0.1068 - val_loss: 0.0248 - val_mae: 0.1215\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1212\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1208\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0246 - val_mae: 0.1205\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0246 - val_mae: 0.1198\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1192\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1189\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1186\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0244 - val_mae: 0.1183\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0243 - val_mae: 0.1177\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0241 - val_mae: 0.1166\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1161\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0088 - mae: 0.1004 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0240 - val_mae: 0.1150\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0239 - val_mae: 0.1148\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0089 - mae: 0.1012 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0088 - mae: 0.1008 - val_loss: 0.0238 - val_mae: 0.1140\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0979 - val_loss: 0.0237 - val_mae: 0.1132\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0237 - val_mae: 0.1130\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0237 - val_mae: 0.1127\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1124\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1122\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0084 - mae: 0.0976 - val_loss: 0.0236 - val_mae: 0.1119\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0235 - val_mae: 0.1116\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0235 - val_mae: 0.1114\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1109\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0234 - val_mae: 0.1106\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0080 - mae: 0.0951 - val_loss: 0.0233 - val_mae: 0.1099\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0079 - mae: 0.0934 - val_loss: 0.0232 - val_mae: 0.1094\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0939 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0231 - val_mae: 0.1084\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1076\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0079 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0228 - val_mae: 0.1060\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0077 - mae: 0.0913 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0227 - val_mae: 0.1052\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0227 - val_mae: 0.1049\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0077 - mae: 0.0899 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0226 - val_mae: 0.1044\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1032\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0225 - val_mae: 0.1030\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0224 - val_mae: 0.1024\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0072 - mae: 0.0860 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0073 - mae: 0.0874 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0222 - val_mae: 0.1008\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0071 - mae: 0.0845 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0221 - val_mae: 0.0997\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.0994\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0220 - val_mae: 0.0990\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0220 - val_mae: 0.0986\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0219 - val_mae: 0.0983\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0809 - val_loss: 0.0219 - val_mae: 0.0979\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0218 - val_mae: 0.0976\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0071 - mae: 0.0837 - val_loss: 0.0218 - val_mae: 0.0969\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0217 - val_mae: 0.0966\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0811 - val_loss: 0.0217 - val_mae: 0.0962\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0069 - mae: 0.0809 - val_loss: 0.0216 - val_mae: 0.0958\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0216 - val_mae: 0.0955\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0069 - mae: 0.0817 - val_loss: 0.0215 - val_mae: 0.0951\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0215 - val_mae: 0.0948\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0066 - mae: 0.0787 - val_loss: 0.0214 - val_mae: 0.0944\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0069 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0941\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0064 - mae: 0.0787 - val_loss: 0.0213 - val_mae: 0.0934\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0068 - mae: 0.0811 - val_loss: 0.0213 - val_mae: 0.0930\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0789 - val_loss: 0.0212 - val_mae: 0.0927\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0212 - val_mae: 0.0923\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0802 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066 - mae: 0.0780 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0770 - val_loss: 0.0210 - val_mae: 0.0911\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0770 - val_loss: 0.0210 - val_mae: 0.0908\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0209 - val_mae: 0.0904\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0781 - val_loss: 0.0209 - val_mae: 0.0900\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0066 - mae: 0.0782 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0743 - val_loss: 0.0208 - val_mae: 0.0894\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0059 - mae: 0.0751 - val_loss: 0.0207 - val_mae: 0.0890\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0063 - mae: 0.0771 - val_loss: 0.0207 - val_mae: 0.0887\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0731 - val_loss: 0.0206 - val_mae: 0.0883\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0061 - mae: 0.0738 - val_loss: 0.0206 - val_mae: 0.0880\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0055 - mae: 0.0710 - val_loss: 0.0205 - val_mae: 0.0876\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0061 - mae: 0.0716 - val_loss: 0.0205 - val_mae: 0.0873\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0063 - mae: 0.0748 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0062 - mae: 0.0760 - val_loss: 0.0204 - val_mae: 0.0866\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0063 - mae: 0.0768 - val_loss: 0.0203 - val_mae: 0.0863\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0064 - mae: 0.0762 - val_loss: 0.0203 - val_mae: 0.0860\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0724 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0202 - val_mae: 0.0854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0061 - mae: 0.0740 - val_loss: 0.0201 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0059 - mae: 0.0731 - val_loss: 0.0201 - val_mae: 0.0848\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0057 - mae: 0.0721 - val_loss: 0.0200 - val_mae: 0.0845\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0715 - val_loss: 0.0200 - val_mae: 0.0842\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0055 - mae: 0.0702 - val_loss: 0.0199 - val_mae: 0.0839\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0058 - mae: 0.0736 - val_loss: 0.0199 - val_mae: 0.0837\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0058 - mae: 0.0725 - val_loss: 0.0198 - val_mae: 0.0834\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0055 - mae: 0.0707 - val_loss: 0.0198 - val_mae: 0.0832\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0056 - mae: 0.0718 - val_loss: 0.0197 - val_mae: 0.0830\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0058 - mae: 0.0743 - val_loss: 0.0197 - val_mae: 0.0828\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0056 - mae: 0.0707 - val_loss: 0.0196 - val_mae: 0.0826\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0196 - val_mae: 0.0824\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - mae: 0.0698 - val_loss: 0.0195 - val_mae: 0.0823\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0052 - mae: 0.0708 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0194 - val_mae: 0.0819\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0052 - mae: 0.0679 - val_loss: 0.0194 - val_mae: 0.0817\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0705 - val_loss: 0.0193 - val_mae: 0.0815\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0053 - mae: 0.0684 - val_loss: 0.0193 - val_mae: 0.0814\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0050 - mae: 0.0672 - val_loss: 0.0192 - val_mae: 0.0812\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0192 - val_mae: 0.0810\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0718 - val_loss: 0.0191 - val_mae: 0.0808\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0053 - mae: 0.0711 - val_loss: 0.0191 - val_mae: 0.0806\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0053 - mae: 0.0712 - val_loss: 0.0190 - val_mae: 0.0804\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0048 - mae: 0.0674 - val_loss: 0.0190 - val_mae: 0.0802\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0052 - mae: 0.0698 - val_loss: 0.0189 - val_mae: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:12:28,556] Trial 18 finished with value: 0.0799897089600563 and parameters: {'learning_rate': 4.4605199483418835e-05, 'weight_decay': 1.7038140372476742e-06}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0094 - mae: 0.1078 - val_loss: 0.0248 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1202\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0091 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1197\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0245 - val_mae: 0.1191\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0244 - val_mae: 0.1185\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0243 - val_mae: 0.1174\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1155\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0239 - val_mae: 0.1150\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0086 - mae: 0.1006 - val_loss: 0.0238 - val_mae: 0.1140\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1131\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1116\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0082 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1106\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0081 - mae: 0.0951 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0080 - mae: 0.0948 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0079 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0078 - mae: 0.0928 - val_loss: 0.0228 - val_mae: 0.1059\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0225 - val_mae: 0.1030\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0224 - val_mae: 0.1024\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.1018\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0222 - val_mae: 0.1005\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0222 - val_mae: 0.0999\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0221 - val_mae: 0.0992\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.0985\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0076 - mae: 0.0888 - val_loss: 0.0219 - val_mae: 0.0979\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0219 - val_mae: 0.0972\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0218 - val_mae: 0.0966\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0067 - mae: 0.0834 - val_loss: 0.0217 - val_mae: 0.0959\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0216 - val_mae: 0.0952\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0216 - val_mae: 0.0945\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - mae: 0.0825 - val_loss: 0.0215 - val_mae: 0.0938\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0214 - val_mae: 0.0931\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0213 - val_mae: 0.0923\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - mae: 0.0831 - val_loss: 0.0213 - val_mae: 0.0916\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0063 - mae: 0.0799 - val_loss: 0.0212 - val_mae: 0.0909\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0067 - mae: 0.0830 - val_loss: 0.0211 - val_mae: 0.0902\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0210 - val_mae: 0.0895\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0889\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0062 - mae: 0.0799 - val_loss: 0.0208 - val_mae: 0.0883\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0207 - val_mae: 0.0877\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0064 - mae: 0.0793 - val_loss: 0.0206 - val_mae: 0.0871\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0062 - mae: 0.0774 - val_loss: 0.0206 - val_mae: 0.0865\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0205 - val_mae: 0.0860\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0062 - mae: 0.0781 - val_loss: 0.0204 - val_mae: 0.0854\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - mae: 0.0777 - val_loss: 0.0203 - val_mae: 0.0848\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0059 - mae: 0.0768 - val_loss: 0.0202 - val_mae: 0.0843\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0059 - mae: 0.0739 - val_loss: 0.0201 - val_mae: 0.0838\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0058 - mae: 0.0729 - val_loss: 0.0200 - val_mae: 0.0834\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0199 - val_mae: 0.0830\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0059 - mae: 0.0747 - val_loss: 0.0198 - val_mae: 0.0827\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0057 - mae: 0.0710 - val_loss: 0.0198 - val_mae: 0.0824\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0197 - val_mae: 0.0820\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0052 - mae: 0.0731 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0055 - mae: 0.0724 - val_loss: 0.0195 - val_mae: 0.0815\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0059 - mae: 0.0761 - val_loss: 0.0194 - val_mae: 0.0812\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0193 - val_mae: 0.0810\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0056 - mae: 0.0706 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0056 - mae: 0.0737 - val_loss: 0.0192 - val_mae: 0.0805\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0191 - val_mae: 0.0803\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0055 - mae: 0.0717 - val_loss: 0.0190 - val_mae: 0.0802\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0190 - val_mae: 0.0800\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0051 - mae: 0.0700 - val_loss: 0.0189 - val_mae: 0.0799\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0049 - mae: 0.0700 - val_loss: 0.0188 - val_mae: 0.0798\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0188 - val_mae: 0.0796\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0187 - val_mae: 0.0795\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0186 - val_mae: 0.0794\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0052 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0794\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0184 - val_mae: 0.0793\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0184 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0056 - mae: 0.0776 - val_loss: 0.0183 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0183 - val_mae: 0.0792\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0047 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0050 - mae: 0.0711 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0181 - val_mae: 0.0791\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0181 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0050 - mae: 0.0704 - val_loss: 0.0181 - val_mae: 0.0790\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0047 - mae: 0.0720 - val_loss: 0.0181 - val_mae: 0.0789\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0180 - val_mae: 0.0788\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0050 - mae: 0.0706 - val_loss: 0.0180 - val_mae: 0.0787\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0786\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0180 - val_mae: 0.0784\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0180 - val_mae: 0.0783\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0046 - mae: 0.0654 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0179 - val_mae: 0.0778\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0179 - val_mae: 0.0777\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0179 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0050 - mae: 0.0712 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0051 - mae: 0.0726 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0044 - mae: 0.0633 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0046 - mae: 0.0688 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0043 - mae: 0.0615 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0178 - val_mae: 0.0774\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0046 - mae: 0.0689 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0046 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0774\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0045 - mae: 0.0658 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0045 - mae: 0.0641 - val_loss: 0.0176 - val_mae: 0.0776\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0176 - val_mae: 0.0777\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0176 - val_mae: 0.0778\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0176 - val_mae: 0.0779\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0175 - val_mae: 0.0780\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0175 - val_mae: 0.0781\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0175 - val_mae: 0.0781\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0042 - mae: 0.0631 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0175 - val_mae: 0.0783\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0042 - mae: 0.0628 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0046 - mae: 0.0695 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0042 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0785\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0047 - mae: 0.0690 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0047 - mae: 0.0700 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0042 - mae: 0.0648 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0045 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:12:54,286] Trial 19 finished with value: 0.07834775745868683 and parameters: {'learning_rate': 7.794394864270648e-05, 'weight_decay': 1.1602399496769476e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1213\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1211\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1209\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0246 - val_mae: 0.1207\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0246 - val_mae: 0.1204\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1202\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0096 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1197\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0245 - val_mae: 0.1195\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1026 - val_loss: 0.0244 - val_mae: 0.1193\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1190\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1188\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0243 - val_mae: 0.1185\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1176\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1170\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0241 - val_mae: 0.1168\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0240 - val_mae: 0.1163\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0240 - val_mae: 0.1161\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1159\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1157\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0239 - val_mae: 0.1155\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0239 - val_mae: 0.1153\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1007 - val_loss: 0.0239 - val_mae: 0.1151\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0239 - val_mae: 0.1149\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0238 - val_mae: 0.1147\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1145\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0238 - val_mae: 0.1143\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0238 - val_mae: 0.1141\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1139\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0237 - val_mae: 0.1137\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0088 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1135\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0237 - val_mae: 0.1133\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0236 - val_mae: 0.1131\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.0998 - val_loss: 0.0236 - val_mae: 0.1130\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0236 - val_mae: 0.1128\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0092 - mae: 0.1015 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1124\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0235 - val_mae: 0.1122\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1120\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0235 - val_mae: 0.1118\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0234 - val_mae: 0.1116\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0234 - val_mae: 0.1114\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0234 - val_mae: 0.1112\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0234 - val_mae: 0.1110\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0233 - val_mae: 0.1108\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0992 - val_loss: 0.0233 - val_mae: 0.1107\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1105\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0973 - val_loss: 0.0233 - val_mae: 0.1103\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0082 - mae: 0.0967 - val_loss: 0.0233 - val_mae: 0.1101\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0232 - val_mae: 0.1099\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0086 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1097\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1095\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1093\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0231 - val_mae: 0.1091\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0081 - mae: 0.0930 - val_loss: 0.0231 - val_mae: 0.1090\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1088\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0081 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1086\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0087 - mae: 0.0961 - val_loss: 0.0230 - val_mae: 0.1084\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0230 - val_mae: 0.1082\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1080\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0230 - val_mae: 0.1078\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0230 - val_mae: 0.1076\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0229 - val_mae: 0.1074\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0083 - mae: 0.0921 - val_loss: 0.0229 - val_mae: 0.1072\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0229 - val_mae: 0.1070\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1066\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0081 - mae: 0.0928 - val_loss: 0.0228 - val_mae: 0.1063\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0082 - mae: 0.0931 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0227 - val_mae: 0.1057\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0080 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1055\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0227 - val_mae: 0.1053\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0226 - val_mae: 0.1049\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.1045\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0074 - mae: 0.0895 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - mae: 0.0886 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0079 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0075 - mae: 0.0875 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0077 - mae: 0.0874 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0222 - val_mae: 0.1016\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0079 - mae: 0.0889 - val_loss: 0.0222 - val_mae: 0.1014\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0074 - mae: 0.0894 - val_loss: 0.0222 - val_mae: 0.1012\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.1005\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0070 - mae: 0.0855 - val_loss: 0.0221 - val_mae: 0.1003\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0221 - val_mae: 0.0999\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.0997\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0073 - mae: 0.0867 - val_loss: 0.0220 - val_mae: 0.0995\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0847 - val_loss: 0.0220 - val_mae: 0.0993\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0220 - val_mae: 0.0991\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0076 - mae: 0.0874 - val_loss: 0.0219 - val_mae: 0.0988\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0219 - val_mae: 0.0986\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0219 - val_mae: 0.0984\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0069 - mae: 0.0826 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0075 - mae: 0.0865 - val_loss: 0.0218 - val_mae: 0.0980\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0072 - mae: 0.0845 - val_loss: 0.0218 - val_mae: 0.0978\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0976\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0841 - val_loss: 0.0218 - val_mae: 0.0974\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0072 - mae: 0.0858 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0075 - mae: 0.0868 - val_loss: 0.0217 - val_mae: 0.0970\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0074 - mae: 0.0855 - val_loss: 0.0217 - val_mae: 0.0968\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0217 - val_mae: 0.0966\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0216 - val_mae: 0.0965\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0216 - val_mae: 0.0963\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0068 - mae: 0.0811 - val_loss: 0.0216 - val_mae: 0.0961\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0072 - mae: 0.0847 - val_loss: 0.0216 - val_mae: 0.0959\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0215 - val_mae: 0.0957\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0816 - val_loss: 0.0215 - val_mae: 0.0955\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0073 - mae: 0.0850 - val_loss: 0.0215 - val_mae: 0.0953\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0827 - val_loss: 0.0215 - val_mae: 0.0951\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0215 - val_mae: 0.0949\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0214 - val_mae: 0.0947\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0070 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0945\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0214 - val_mae: 0.0944\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0068 - mae: 0.0831 - val_loss: 0.0214 - val_mae: 0.0942\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0067 - mae: 0.0824 - val_loss: 0.0213 - val_mae: 0.0940\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0213 - val_mae: 0.0938\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0066 - mae: 0.0821 - val_loss: 0.0213 - val_mae: 0.0936\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0070 - mae: 0.0829 - val_loss: 0.0213 - val_mae: 0.0934\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0075 - mae: 0.0861 - val_loss: 0.0212 - val_mae: 0.0932\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0212 - val_mae: 0.0931\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0212 - val_mae: 0.0929\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0212 - val_mae: 0.0927\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0211 - val_mae: 0.0926\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - mae: 0.0803 - val_loss: 0.0211 - val_mae: 0.0924\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0211 - val_mae: 0.0922\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0211 - val_mae: 0.0920\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0068 - mae: 0.0811 - val_loss: 0.0210 - val_mae: 0.0919\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0063 - mae: 0.0788 - val_loss: 0.0210 - val_mae: 0.0917\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0064 - mae: 0.0801 - val_loss: 0.0210 - val_mae: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:13:19,964] Trial 20 finished with value: 0.09155241400003433 and parameters: {'learning_rate': 1.886770087692023e-05, 'weight_decay': 8.799872567276707e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0243 - val_mae: 0.1175\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0085 - mae: 0.0998 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0086 - mae: 0.1005 - val_loss: 0.0238 - val_mae: 0.1142\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1134\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0083 - mae: 0.0985 - val_loss: 0.0236 - val_mae: 0.1126\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0083 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1118\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0081 - mae: 0.0961 - val_loss: 0.0234 - val_mae: 0.1111\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0233 - val_mae: 0.1103\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0232 - val_mae: 0.1095\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0231 - val_mae: 0.1088\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0081 - mae: 0.0947 - val_loss: 0.0230 - val_mae: 0.1080\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0229 - val_mae: 0.1072\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0078 - mae: 0.0915 - val_loss: 0.0228 - val_mae: 0.1064\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0081 - mae: 0.0950 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0225 - val_mae: 0.1030\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0074 - mae: 0.0902 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0223 - val_mae: 0.1013\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0222 - val_mae: 0.1005\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0221 - val_mae: 0.0997\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0073 - mae: 0.0850 - val_loss: 0.0220 - val_mae: 0.0981\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0817 - val_loss: 0.0219 - val_mae: 0.0973\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0072 - mae: 0.0888 - val_loss: 0.0218 - val_mae: 0.0964\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0217 - val_mae: 0.0957\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0804 - val_loss: 0.0216 - val_mae: 0.0949\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0816 - val_loss: 0.0215 - val_mae: 0.0940\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0848 - val_loss: 0.0214 - val_mae: 0.0932\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0213 - val_mae: 0.0925\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0212 - val_mae: 0.0919\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0062 - mae: 0.0764 - val_loss: 0.0211 - val_mae: 0.0912\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0064 - mae: 0.0803 - val_loss: 0.0210 - val_mae: 0.0905\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0209 - val_mae: 0.0899\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0064 - mae: 0.0797 - val_loss: 0.0208 - val_mae: 0.0893\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0062 - mae: 0.0787 - val_loss: 0.0207 - val_mae: 0.0887\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0206 - val_mae: 0.0882\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0205 - val_mae: 0.0876\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0059 - mae: 0.0765 - val_loss: 0.0204 - val_mae: 0.0872\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0058 - mae: 0.0743 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0201 - val_mae: 0.0853\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - mae: 0.0773 - val_loss: 0.0200 - val_mae: 0.0849\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0765 - val_loss: 0.0199 - val_mae: 0.0844\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0198 - val_mae: 0.0840\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - mae: 0.0708 - val_loss: 0.0197 - val_mae: 0.0837\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0053 - mae: 0.0705 - val_loss: 0.0196 - val_mae: 0.0833\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0053 - mae: 0.0695 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0195 - val_mae: 0.0826\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0055 - mae: 0.0726 - val_loss: 0.0194 - val_mae: 0.0822\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0193 - val_mae: 0.0819\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0053 - mae: 0.0711 - val_loss: 0.0193 - val_mae: 0.0816\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0192 - val_mae: 0.0813\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0191 - val_mae: 0.0811\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0060 - mae: 0.0765 - val_loss: 0.0191 - val_mae: 0.0808\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0190 - val_mae: 0.0805\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - mae: 0.0732 - val_loss: 0.0190 - val_mae: 0.0803\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0770 - val_loss: 0.0189 - val_mae: 0.0801\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0050 - mae: 0.0718 - val_loss: 0.0189 - val_mae: 0.0800\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0744 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0048 - mae: 0.0669 - val_loss: 0.0188 - val_mae: 0.0796\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0051 - mae: 0.0682 - val_loss: 0.0188 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0188 - val_mae: 0.0794\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0791\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0660 - val_loss: 0.0186 - val_mae: 0.0790\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0186 - val_mae: 0.0789\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0186 - val_mae: 0.0788\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0050 - mae: 0.0686 - val_loss: 0.0186 - val_mae: 0.0787\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0050 - mae: 0.0715 - val_loss: 0.0185 - val_mae: 0.0786\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0185 - val_mae: 0.0785\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0047 - mae: 0.0711 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0185 - val_mae: 0.0783\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0056 - mae: 0.0761 - val_loss: 0.0184 - val_mae: 0.0781\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0184 - val_mae: 0.0780\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0045 - mae: 0.0703 - val_loss: 0.0184 - val_mae: 0.0779\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0045 - mae: 0.0645 - val_loss: 0.0184 - val_mae: 0.0779\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0048 - mae: 0.0661 - val_loss: 0.0183 - val_mae: 0.0778\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0047 - mae: 0.0684 - val_loss: 0.0183 - val_mae: 0.0778\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0183 - val_mae: 0.0779\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0182 - val_mae: 0.0779\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0181 - val_mae: 0.0778\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0181 - val_mae: 0.0777\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0607 - val_loss: 0.0181 - val_mae: 0.0776\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0047 - mae: 0.0651 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0649 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0775\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0180 - val_mae: 0.0775\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0048 - mae: 0.0669 - val_loss: 0.0180 - val_mae: 0.0774\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0180 - val_mae: 0.0774\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0048 - mae: 0.0685 - val_loss: 0.0180 - val_mae: 0.0773\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0180 - val_mae: 0.0773\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0180 - val_mae: 0.0773\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0047 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0047 - mae: 0.0643 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0180 - val_mae: 0.0772\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0627 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0643 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0651 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0178 - val_mae: 0.0777\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0633 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0651 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0639 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0658 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0776\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0688 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - mae: 0.0607 - val_loss: 0.0177 - val_mae: 0.0780\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - mae: 0.0602 - val_loss: 0.0177 - val_mae: 0.0781\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0641 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0176 - val_mae: 0.0783\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0176 - val_mae: 0.0783\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0046 - mae: 0.0701 - val_loss: 0.0176 - val_mae: 0.0783\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0177 - val_mae: 0.0783\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:13:38,945] Trial 21 finished with value: 0.07831612229347229 and parameters: {'learning_rate': 8.496727816904508e-05, 'weight_decay': 1.2556481202136442e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1184\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1181\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0090 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0087 - mae: 0.1022 - val_loss: 0.0240 - val_mae: 0.1175\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0240 - val_mae: 0.1171\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0239 - val_mae: 0.1168\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0239 - val_mae: 0.1165\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1158\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1155\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1148\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0085 - mae: 0.1003 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0236 - val_mae: 0.1141\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1138\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0235 - val_mae: 0.1134\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0234 - val_mae: 0.1131\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0087 - mae: 0.0999 - val_loss: 0.0234 - val_mae: 0.1128\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0234 - val_mae: 0.1124\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0233 - val_mae: 0.1121\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0233 - val_mae: 0.1118\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0232 - val_mae: 0.1115\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0232 - val_mae: 0.1111\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0232 - val_mae: 0.1108\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0231 - val_mae: 0.1105\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0231 - val_mae: 0.1102\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0974 - val_loss: 0.0230 - val_mae: 0.1098\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0082 - mae: 0.0954 - val_loss: 0.0230 - val_mae: 0.1095\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0229 - val_mae: 0.1092\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0229 - val_mae: 0.1089\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0229 - val_mae: 0.1085\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0228 - val_mae: 0.1082\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0228 - val_mae: 0.1078\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1075\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1071\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0226 - val_mae: 0.1068\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0079 - mae: 0.0944 - val_loss: 0.0226 - val_mae: 0.1064\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0225 - val_mae: 0.1060\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0225 - val_mae: 0.1057\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0224 - val_mae: 0.1053\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0224 - val_mae: 0.1049\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0224 - val_mae: 0.1045\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0223 - val_mae: 0.1042\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0882 - val_loss: 0.0223 - val_mae: 0.1038\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0222 - val_mae: 0.1034\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0074 - mae: 0.0900 - val_loss: 0.0222 - val_mae: 0.1030\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0072 - mae: 0.0875 - val_loss: 0.0221 - val_mae: 0.1026\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0221 - val_mae: 0.1022\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0220 - val_mae: 0.1018\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0220 - val_mae: 0.1014\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0219 - val_mae: 0.1010\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0868 - val_loss: 0.0219 - val_mae: 0.1006\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0074 - mae: 0.0856 - val_loss: 0.0218 - val_mae: 0.1002\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0889 - val_loss: 0.0218 - val_mae: 0.0998\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0069 - mae: 0.0840 - val_loss: 0.0217 - val_mae: 0.0994\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0217 - val_mae: 0.0990\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0858 - val_loss: 0.0216 - val_mae: 0.0986\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0875 - val_loss: 0.0216 - val_mae: 0.0983\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0215 - val_mae: 0.0979\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0215 - val_mae: 0.0975\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0072 - mae: 0.0853 - val_loss: 0.0215 - val_mae: 0.0971\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0214 - val_mae: 0.0968\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0843 - val_loss: 0.0214 - val_mae: 0.0964\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0213 - val_mae: 0.0960\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0213 - val_mae: 0.0957\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0069 - mae: 0.0848 - val_loss: 0.0212 - val_mae: 0.0953\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - mae: 0.0836 - val_loss: 0.0212 - val_mae: 0.0950\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0211 - val_mae: 0.0946\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0943\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0210 - val_mae: 0.0939\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - mae: 0.0813 - val_loss: 0.0210 - val_mae: 0.0936\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0209 - val_mae: 0.0933\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0209 - val_mae: 0.0929\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0065 - mae: 0.0807 - val_loss: 0.0208 - val_mae: 0.0926\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0070 - mae: 0.0811 - val_loss: 0.0208 - val_mae: 0.0923\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0208 - val_mae: 0.0919\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0064 - mae: 0.0788 - val_loss: 0.0207 - val_mae: 0.0916\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0207 - val_mae: 0.0913\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0206 - val_mae: 0.0910\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0206 - val_mae: 0.0907\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0205 - val_mae: 0.0903\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0205 - val_mae: 0.0900\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0066 - mae: 0.0827 - val_loss: 0.0204 - val_mae: 0.0897\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0799 - val_loss: 0.0204 - val_mae: 0.0894\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0203 - val_mae: 0.0890\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0061 - mae: 0.0766 - val_loss: 0.0203 - val_mae: 0.0887\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0063 - mae: 0.0808 - val_loss: 0.0202 - val_mae: 0.0884\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0067 - mae: 0.0805 - val_loss: 0.0202 - val_mae: 0.0881\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0768 - val_loss: 0.0201 - val_mae: 0.0878\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0201 - val_mae: 0.0875\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0200 - val_mae: 0.0872\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - mae: 0.0802 - val_loss: 0.0200 - val_mae: 0.0869\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061 - mae: 0.0759 - val_loss: 0.0199 - val_mae: 0.0867\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0063 - mae: 0.0765 - val_loss: 0.0199 - val_mae: 0.0864\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0751 - val_loss: 0.0198 - val_mae: 0.0861\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0061 - mae: 0.0785 - val_loss: 0.0198 - val_mae: 0.0858\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0759 - val_loss: 0.0198 - val_mae: 0.0855\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061 - mae: 0.0752 - val_loss: 0.0197 - val_mae: 0.0853\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061 - mae: 0.0767 - val_loss: 0.0197 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0196 - val_mae: 0.0848\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0196 - val_mae: 0.0845\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0196 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0195 - val_mae: 0.0840\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0060 - mae: 0.0777 - val_loss: 0.0195 - val_mae: 0.0838\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0194 - val_mae: 0.0836\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0060 - mae: 0.0749 - val_loss: 0.0194 - val_mae: 0.0833\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0060 - mae: 0.0755 - val_loss: 0.0194 - val_mae: 0.0831\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0062 - mae: 0.0796 - val_loss: 0.0193 - val_mae: 0.0829\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0053 - mae: 0.0734 - val_loss: 0.0193 - val_mae: 0.0826\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0062 - mae: 0.0790 - val_loss: 0.0192 - val_mae: 0.0824\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0055 - mae: 0.0754 - val_loss: 0.0192 - val_mae: 0.0822\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0060 - mae: 0.0782 - val_loss: 0.0192 - val_mae: 0.0820\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0191 - val_mae: 0.0818\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0191 - val_mae: 0.0816\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0191 - val_mae: 0.0814\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0190 - val_mae: 0.0813\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0190 - val_mae: 0.0811\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0190 - val_mae: 0.0810\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0189 - val_mae: 0.0809\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0057 - mae: 0.0759 - val_loss: 0.0189 - val_mae: 0.0808\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0189 - val_mae: 0.0807\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0052 - mae: 0.0704 - val_loss: 0.0188 - val_mae: 0.0806\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0188 - val_mae: 0.0806\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0761 - val_loss: 0.0188 - val_mae: 0.0805\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0054 - mae: 0.0715 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0060 - mae: 0.0751 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0187 - val_mae: 0.0803\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0053 - mae: 0.0732 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0056 - mae: 0.0719 - val_loss: 0.0186 - val_mae: 0.0801\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0057 - mae: 0.0737 - val_loss: 0.0185 - val_mae: 0.0801\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0057 - mae: 0.0728 - val_loss: 0.0185 - val_mae: 0.0800\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0053 - mae: 0.0732 - val_loss: 0.0185 - val_mae: 0.0800\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0053 - mae: 0.0731 - val_loss: 0.0185 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0050 - mae: 0.0696 - val_loss: 0.0184 - val_mae: 0.0799\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0184 - val_mae: 0.0798\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0184 - val_mae: 0.0797\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0184 - val_mae: 0.0797\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0056 - mae: 0.0747 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0047 - mae: 0.0674 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0183 - val_mae: 0.0795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0059 - mae: 0.0746 - val_loss: 0.0183 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0183 - val_mae: 0.0794\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0182 - val_mae: 0.0793\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0182 - val_mae: 0.0792\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0182 - val_mae: 0.0791\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0055 - mae: 0.0747 - val_loss: 0.0181 - val_mae: 0.0790\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0691 - val_loss: 0.0181 - val_mae: 0.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:13:58,445] Trial 22 finished with value: 0.07896189391613007 and parameters: {'learning_rate': 3.3276177407157586e-05, 'weight_decay': 1.0070710861779599e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0243 - val_mae: 0.1198\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0238 - val_mae: 0.1160\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0234 - val_mae: 0.1122\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0083 - mae: 0.0981 - val_loss: 0.0230 - val_mae: 0.1086\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0079 - mae: 0.0935 - val_loss: 0.0226 - val_mae: 0.1053\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0222 - val_mae: 0.1021\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0218 - val_mae: 0.0991\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0071 - mae: 0.0845 - val_loss: 0.0215 - val_mae: 0.0963\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0068 - mae: 0.0833 - val_loss: 0.0210 - val_mae: 0.0939\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0206 - val_mae: 0.0919\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0063 - mae: 0.0793 - val_loss: 0.0202 - val_mae: 0.0906\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0892\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0056 - mae: 0.0739 - val_loss: 0.0194 - val_mae: 0.0878\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0191 - val_mae: 0.0866\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0050 - mae: 0.0712 - val_loss: 0.0187 - val_mae: 0.0859\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0718 - val_loss: 0.0184 - val_mae: 0.0852\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0182 - val_mae: 0.0846\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0048 - mae: 0.0709 - val_loss: 0.0180 - val_mae: 0.0840\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0838\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0042 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0834\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0176 - val_mae: 0.0830\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0820\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0815\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0041 - mae: 0.0649 - val_loss: 0.0174 - val_mae: 0.0809\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0174 - val_mae: 0.0803\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0045 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0042 - mae: 0.0617 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0798\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0629 - val_loss: 0.0171 - val_mae: 0.0801\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0809\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0817\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0812\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0039 - mae: 0.0642 - val_loss: 0.0169 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0800\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0796\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0800\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0169 - val_mae: 0.0806\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0812\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0821\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0038 - mae: 0.0652 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0818\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0813\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0172 - val_mae: 0.0789\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0037 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0036 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - mae: 0.0563 - val_loss: 0.0172 - val_mae: 0.0795\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0805\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0819\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0821\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0848\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0844\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0833\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0836\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0848\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0848\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0828\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0840\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0838\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0820\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:14:20,692] Trial 23 finished with value: 0.08378052711486816 and parameters: {'learning_rate': 0.000540546825940738, 'weight_decay': 1.457719683578471e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0105 - mae: 0.1145 - val_loss: 0.0248 - val_mae: 0.1281\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0103 - mae: 0.1121 - val_loss: 0.0248 - val_mae: 0.1279\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0109 - mae: 0.1149 - val_loss: 0.0248 - val_mae: 0.1278\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - mae: 0.1136 - val_loss: 0.0248 - val_mae: 0.1277\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0248 - val_mae: 0.1275\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0106 - mae: 0.1133 - val_loss: 0.0247 - val_mae: 0.1274\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0247 - val_mae: 0.1273\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0247 - val_mae: 0.1271\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0105 - mae: 0.1161 - val_loss: 0.0247 - val_mae: 0.1270\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0103 - mae: 0.1112 - val_loss: 0.0247 - val_mae: 0.1268\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0247 - val_mae: 0.1267\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0105 - mae: 0.1125 - val_loss: 0.0246 - val_mae: 0.1266\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0106 - mae: 0.1135 - val_loss: 0.0246 - val_mae: 0.1264\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0107 - mae: 0.1148 - val_loss: 0.0246 - val_mae: 0.1263\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0246 - val_mae: 0.1262\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0246 - val_mae: 0.1260\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0105 - mae: 0.1131 - val_loss: 0.0246 - val_mae: 0.1259\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0103 - mae: 0.1115 - val_loss: 0.0245 - val_mae: 0.1257\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0245 - val_mae: 0.1256\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0099 - mae: 0.1099 - val_loss: 0.0245 - val_mae: 0.1255\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0104 - mae: 0.1116 - val_loss: 0.0245 - val_mae: 0.1253\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0245 - val_mae: 0.1252\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0245 - val_mae: 0.1251\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0103 - mae: 0.1127 - val_loss: 0.0245 - val_mae: 0.1249\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0244 - val_mae: 0.1248\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0104 - mae: 0.1114 - val_loss: 0.0244 - val_mae: 0.1247\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0102 - mae: 0.1126 - val_loss: 0.0244 - val_mae: 0.1245\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0244 - val_mae: 0.1244\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0244 - val_mae: 0.1243\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0244 - val_mae: 0.1241\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0243 - val_mae: 0.1240\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0243 - val_mae: 0.1239\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0243 - val_mae: 0.1238\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0243 - val_mae: 0.1236\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0243 - val_mae: 0.1235\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0243 - val_mae: 0.1234\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0243 - val_mae: 0.1233\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0101 - mae: 0.1097 - val_loss: 0.0242 - val_mae: 0.1231\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0242 - val_mae: 0.1230\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0102 - mae: 0.1111 - val_loss: 0.0242 - val_mae: 0.1229\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0242 - val_mae: 0.1228\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0242 - val_mae: 0.1227\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0098 - mae: 0.1101 - val_loss: 0.0242 - val_mae: 0.1225\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0242 - val_mae: 0.1224\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0242 - val_mae: 0.1223\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0241 - val_mae: 0.1222\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0241 - val_mae: 0.1221\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0241 - val_mae: 0.1220\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1090 - val_loss: 0.0241 - val_mae: 0.1218\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0241 - val_mae: 0.1217\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0241 - val_mae: 0.1216\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0241 - val_mae: 0.1215\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0240 - val_mae: 0.1214\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0240 - val_mae: 0.1213\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0240 - val_mae: 0.1212\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0240 - val_mae: 0.1211\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1073 - val_loss: 0.0240 - val_mae: 0.1209\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0240 - val_mae: 0.1208\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0100 - mae: 0.1093 - val_loss: 0.0240 - val_mae: 0.1207\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0098 - mae: 0.1058 - val_loss: 0.0240 - val_mae: 0.1206\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0240 - val_mae: 0.1205\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1060 - val_loss: 0.0239 - val_mae: 0.1204\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1203\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0239 - val_mae: 0.1202\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0239 - val_mae: 0.1201\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0239 - val_mae: 0.1200\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0239 - val_mae: 0.1198\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1197\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1196\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0238 - val_mae: 0.1195\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0238 - val_mae: 0.1194\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0238 - val_mae: 0.1193\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0238 - val_mae: 0.1192\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0238 - val_mae: 0.1191\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0238 - val_mae: 0.1190\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0238 - val_mae: 0.1189\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0238 - val_mae: 0.1188\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1187\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0093 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1186\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1185\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0237 - val_mae: 0.1184\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1183\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1182\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1181\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1180\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1179\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1178\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0236 - val_mae: 0.1177\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0236 - val_mae: 0.1176\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0236 - val_mae: 0.1175\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0236 - val_mae: 0.1174\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0236 - val_mae: 0.1173\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0236 - val_mae: 0.1172\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0236 - val_mae: 0.1171\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0236 - val_mae: 0.1170\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0236 - val_mae: 0.1169\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0235 - val_mae: 0.1168\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0235 - val_mae: 0.1167\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1009 - val_loss: 0.0235 - val_mae: 0.1166\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0091 - mae: 0.1027 - val_loss: 0.0235 - val_mae: 0.1165\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0235 - val_mae: 0.1164\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.0994 - val_loss: 0.0235 - val_mae: 0.1163\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0235 - val_mae: 0.1162\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0235 - val_mae: 0.1161\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0235 - val_mae: 0.1160\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0234 - val_mae: 0.1159\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0093 - mae: 0.1032 - val_loss: 0.0234 - val_mae: 0.1158\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0234 - val_mae: 0.1156\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0234 - val_mae: 0.1155\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1004 - val_loss: 0.0234 - val_mae: 0.1154\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0234 - val_mae: 0.1153\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0234 - val_mae: 0.1153\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090 - mae: 0.1018 - val_loss: 0.0234 - val_mae: 0.1152\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0234 - val_mae: 0.1151\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0233 - val_mae: 0.1150\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0233 - val_mae: 0.1149\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0233 - val_mae: 0.1148\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0233 - val_mae: 0.1147\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - mae: 0.0993 - val_loss: 0.0233 - val_mae: 0.1146\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0233 - val_mae: 0.1145\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0233 - val_mae: 0.1144\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0233 - val_mae: 0.1143\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.1010 - val_loss: 0.0233 - val_mae: 0.1142\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0997 - val_loss: 0.0233 - val_mae: 0.1141\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1140\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0232 - val_mae: 0.1139\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0232 - val_mae: 0.1138\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0232 - val_mae: 0.1137\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0232 - val_mae: 0.1136\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1135\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0232 - val_mae: 0.1134\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0232 - val_mae: 0.1133\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0232 - val_mae: 0.1132\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0090 - mae: 0.1013 - val_loss: 0.0232 - val_mae: 0.1132\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0231 - val_mae: 0.1131\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0999 - val_loss: 0.0231 - val_mae: 0.1130\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1129\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1128\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0231 - val_mae: 0.1127\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.0991 - val_loss: 0.0231 - val_mae: 0.1126\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0231 - val_mae: 0.1125\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0231 - val_mae: 0.1124\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0976 - val_loss: 0.0231 - val_mae: 0.1123\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0230 - val_mae: 0.1122\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0230 - val_mae: 0.1121\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0230 - val_mae: 0.1120\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0998 - val_loss: 0.0230 - val_mae: 0.1119\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0990 - val_loss: 0.0230 - val_mae: 0.1118\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0230 - val_mae: 0.1118\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0230 - val_mae: 0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-05 14:14:40,336] Trial 24 finished with value: 0.11166665703058243 and parameters: {'learning_rate': 1.105483294881433e-05, 'weight_decay': 1.093595186502231e-09}. Best is trial 6 with value: 0.07804609090089798.\n"
     ]
    }
   ],
   "source": [
    "cnn_study = create_study(model_fun=cnn_model,\n",
    "                         train=train_df,\n",
    "                         val=val_df,\n",
    "                         n_steps=N_STEPS,\n",
    "                         n_horizon=N_HORIZON,\n",
    "                         n_features=N_FEATURES)\n",
    "lstm_study = create_study(model_fun=lstm_model,\n",
    "                          train=train_df,\n",
    "                          val=val_df,\n",
    "                          n_steps=N_STEPS,\n",
    "                          n_horizon=N_HORIZON,\n",
    "                          n_features=N_FEATURES)\n",
    "stacked_study = create_study(model_fun=lstm_cnn_model,\n",
    "                             train=train_df,\n",
    "                             val=val_df,\n",
    "                             n_steps=N_STEPS,\n",
    "                             n_horizon=N_HORIZON,\n",
    "                             n_features=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07796110212802887\n",
      "\n",
      "LSTM Study Results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07773890346288681\n",
      "\n",
      "LSTM-CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07804609090089798\n"
     ]
    }
   ],
   "source": [
    "print('CNN Study Results')\n",
    "cnn_params = get_optimized_parameters(cnn_study)\n",
    "print('\\nLSTM Study Results')\n",
    "lstm_params = get_optimized_parameters(lstm_study)\n",
    "print('\\nLSTM-CNN Study Results')\n",
    "stacked_params = get_optimized_parameters(stacked_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = dict()\n",
    "path = './src/rv_sentiment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Compile Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            832       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               123008    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139288 (544.09 KB)\n",
      "Trainable params: 139288 (544.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_model(cnn_params['learning_rate'], cnn_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 72, 72)            21600     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54200 (211.72 KB)\n",
      "Trainable params: 54200 (211.72 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(lstm_params['learning_rate'], lstm_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            832       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 72)            39456     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85240 (332.97 KB)\n",
      "Trainable params: 85240 (332.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked = lstm_cnn_model(stacked_params['learning_rate'], stacked_params['weight_decay'], n_steps=N_STEPS, n_horizon=N_HORIZON, n_features=N_FEATURES)\n",
    "stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0291 - mae: 0.1883 - val_loss: 0.0346 - val_mae: 0.1715\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0278 - mae: 0.1895 - val_loss: 0.0341 - val_mae: 0.1692\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0321 - mae: 0.2054 - val_loss: 0.0336 - val_mae: 0.1667\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0332 - mae: 0.2054 - val_loss: 0.0330 - val_mae: 0.1643\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0266 - mae: 0.1826 - val_loss: 0.0325 - val_mae: 0.1618\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0236 - mae: 0.1766 - val_loss: 0.0320 - val_mae: 0.1594\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0280 - mae: 0.1930 - val_loss: 0.0315 - val_mae: 0.1570\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0252 - mae: 0.1801 - val_loss: 0.0310 - val_mae: 0.1546\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0226 - mae: 0.1706 - val_loss: 0.0305 - val_mae: 0.1522\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0251 - mae: 0.1795 - val_loss: 0.0301 - val_mae: 0.1499\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0205 - mae: 0.1649 - val_loss: 0.0296 - val_mae: 0.1476\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0260 - mae: 0.1754 - val_loss: 0.0292 - val_mae: 0.1453\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0266 - mae: 0.1838 - val_loss: 0.0287 - val_mae: 0.1431\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0203 - mae: 0.1602 - val_loss: 0.0283 - val_mae: 0.1410\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0243 - mae: 0.1778 - val_loss: 0.0279 - val_mae: 0.1388\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0251 - mae: 0.1775 - val_loss: 0.0275 - val_mae: 0.1368\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0215 - mae: 0.1678 - val_loss: 0.0272 - val_mae: 0.1347\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0205 - mae: 0.1629 - val_loss: 0.0268 - val_mae: 0.1328\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0235 - mae: 0.1697 - val_loss: 0.0265 - val_mae: 0.1308\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0226 - mae: 0.1693 - val_loss: 0.0261 - val_mae: 0.1289\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0209 - mae: 0.1647 - val_loss: 0.0258 - val_mae: 0.1270\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0186 - mae: 0.1574 - val_loss: 0.0255 - val_mae: 0.1253\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0216 - mae: 0.1639 - val_loss: 0.0252 - val_mae: 0.1236\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0159 - mae: 0.1420 - val_loss: 0.0249 - val_mae: 0.1220\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0156 - mae: 0.1402 - val_loss: 0.0247 - val_mae: 0.1204\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0175 - mae: 0.1466 - val_loss: 0.0244 - val_mae: 0.1189\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0195 - mae: 0.1557 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0210 - mae: 0.1656 - val_loss: 0.0239 - val_mae: 0.1159\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0210 - mae: 0.1631 - val_loss: 0.0237 - val_mae: 0.1144\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0179 - mae: 0.1494 - val_loss: 0.0234 - val_mae: 0.1129\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0173 - mae: 0.1447 - val_loss: 0.0232 - val_mae: 0.1115\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0172 - mae: 0.1492 - val_loss: 0.0230 - val_mae: 0.1101\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0197 - mae: 0.1520 - val_loss: 0.0228 - val_mae: 0.1088\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0178 - mae: 0.1465 - val_loss: 0.0226 - val_mae: 0.1075\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0169 - mae: 0.1420 - val_loss: 0.0224 - val_mae: 0.1062\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0196 - mae: 0.1568 - val_loss: 0.0222 - val_mae: 0.1049\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0166 - mae: 0.1413 - val_loss: 0.0221 - val_mae: 0.1036\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0166 - mae: 0.1448 - val_loss: 0.0219 - val_mae: 0.1024\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0165 - mae: 0.1417 - val_loss: 0.0217 - val_mae: 0.1012\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0154 - mae: 0.1398 - val_loss: 0.0216 - val_mae: 0.1000\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0144 - mae: 0.1348 - val_loss: 0.0214 - val_mae: 0.0988\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0144 - mae: 0.1369 - val_loss: 0.0212 - val_mae: 0.0978\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0159 - mae: 0.1350 - val_loss: 0.0211 - val_mae: 0.0967\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0153 - mae: 0.1374 - val_loss: 0.0209 - val_mae: 0.0957\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0146 - mae: 0.1352 - val_loss: 0.0208 - val_mae: 0.0948\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0155 - mae: 0.1436 - val_loss: 0.0207 - val_mae: 0.0939\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0153 - mae: 0.1394 - val_loss: 0.0205 - val_mae: 0.0931\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0176 - mae: 0.1447 - val_loss: 0.0204 - val_mae: 0.0923\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0169 - mae: 0.1489 - val_loss: 0.0203 - val_mae: 0.0916\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0131 - mae: 0.1260 - val_loss: 0.0202 - val_mae: 0.0909\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0125 - mae: 0.1249 - val_loss: 0.0201 - val_mae: 0.0902\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0127 - mae: 0.1302 - val_loss: 0.0200 - val_mae: 0.0896\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0140 - mae: 0.1331 - val_loss: 0.0199 - val_mae: 0.0890\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0161 - mae: 0.1437 - val_loss: 0.0198 - val_mae: 0.0885\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0141 - mae: 0.1342 - val_loss: 0.0197 - val_mae: 0.0881\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0138 - mae: 0.1292 - val_loss: 0.0196 - val_mae: 0.0877\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0157 - mae: 0.1407 - val_loss: 0.0195 - val_mae: 0.0873\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0121 - mae: 0.1230 - val_loss: 0.0194 - val_mae: 0.0869\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0137 - mae: 0.1278 - val_loss: 0.0194 - val_mae: 0.0866\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0149 - mae: 0.1382 - val_loss: 0.0193 - val_mae: 0.0862\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0135 - mae: 0.1266 - val_loss: 0.0192 - val_mae: 0.0859\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0151 - mae: 0.1307 - val_loss: 0.0192 - val_mae: 0.0856\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0117 - mae: 0.1247 - val_loss: 0.0191 - val_mae: 0.0854\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0121 - mae: 0.1212 - val_loss: 0.0191 - val_mae: 0.0851\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0111 - mae: 0.1168 - val_loss: 0.0190 - val_mae: 0.0848\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0119 - mae: 0.1239 - val_loss: 0.0189 - val_mae: 0.0846\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0107 - mae: 0.1138 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0146 - mae: 0.1348 - val_loss: 0.0188 - val_mae: 0.0840\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0149 - mae: 0.1344 - val_loss: 0.0188 - val_mae: 0.0838\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0117 - mae: 0.1237 - val_loss: 0.0187 - val_mae: 0.0835\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0128 - mae: 0.1265 - val_loss: 0.0187 - val_mae: 0.0832\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0187 - val_mae: 0.0829\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0116 - mae: 0.1229 - val_loss: 0.0186 - val_mae: 0.0827\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0117 - mae: 0.1193 - val_loss: 0.0186 - val_mae: 0.0825\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0123 - mae: 0.1225 - val_loss: 0.0185 - val_mae: 0.0822\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0128 - mae: 0.1252 - val_loss: 0.0185 - val_mae: 0.0820\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0124 - mae: 0.1266 - val_loss: 0.0185 - val_mae: 0.0818\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0125 - mae: 0.1209 - val_loss: 0.0185 - val_mae: 0.0816\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0123 - mae: 0.1225 - val_loss: 0.0184 - val_mae: 0.0814\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0110 - mae: 0.1177 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0115 - mae: 0.1197 - val_loss: 0.0184 - val_mae: 0.0810\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0136 - mae: 0.1254 - val_loss: 0.0184 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0120 - mae: 0.1266 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0104 - mae: 0.1161 - val_loss: 0.0183 - val_mae: 0.0805\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0147 - mae: 0.1324 - val_loss: 0.0183 - val_mae: 0.0804\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0108 - mae: 0.1184 - val_loss: 0.0183 - val_mae: 0.0804\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0183 - val_mae: 0.0804\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0183 - val_mae: 0.0803\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0183 - val_mae: 0.0803\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0118 - mae: 0.1193 - val_loss: 0.0182 - val_mae: 0.0803\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0107 - mae: 0.1140 - val_loss: 0.0182 - val_mae: 0.0803\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0118 - mae: 0.1226 - val_loss: 0.0182 - val_mae: 0.0803\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0109 - mae: 0.1173 - val_loss: 0.0182 - val_mae: 0.0802\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0113 - mae: 0.1183 - val_loss: 0.0182 - val_mae: 0.0802\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0125 - mae: 0.1262 - val_loss: 0.0181 - val_mae: 0.0801\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0118 - mae: 0.1190 - val_loss: 0.0181 - val_mae: 0.0800\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0096 - mae: 0.1097 - val_loss: 0.0181 - val_mae: 0.0800\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0115 - mae: 0.1195 - val_loss: 0.0181 - val_mae: 0.0799\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0110 - mae: 0.1165 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0100 - mae: 0.1144 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0118 - mae: 0.1199 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0105 - mae: 0.1161 - val_loss: 0.0181 - val_mae: 0.0798\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0108 - mae: 0.1142 - val_loss: 0.0180 - val_mae: 0.0798\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0097 - mae: 0.1108 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0104 - mae: 0.1102 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0180 - val_mae: 0.0796\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0107 - mae: 0.1153 - val_loss: 0.0180 - val_mae: 0.0796\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0100 - mae: 0.1061 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0097 - mae: 0.1098 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0118 - mae: 0.1234 - val_loss: 0.0180 - val_mae: 0.0795\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0111 - mae: 0.1165 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0097 - mae: 0.1112 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0179 - val_mae: 0.0794\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0104 - mae: 0.1152 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0098 - mae: 0.1112 - val_loss: 0.0179 - val_mae: 0.0793\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0107 - mae: 0.1136 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0090 - mae: 0.1066 - val_loss: 0.0179 - val_mae: 0.0791\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0091 - mae: 0.1073 - val_loss: 0.0179 - val_mae: 0.0790\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0179 - val_mae: 0.0789\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0099 - mae: 0.1122 - val_loss: 0.0179 - val_mae: 0.0789\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0083 - mae: 0.0986 - val_loss: 0.0179 - val_mae: 0.0788\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0106 - mae: 0.1145 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0091 - mae: 0.1049 - val_loss: 0.0179 - val_mae: 0.0786\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0092 - mae: 0.1064 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0179 - val_mae: 0.0785\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0103 - mae: 0.1139 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0103 - mae: 0.1126 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0085 - mae: 0.1021 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0086 - mae: 0.1038 - val_loss: 0.0179 - val_mae: 0.0784\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0094 - mae: 0.1092 - val_loss: 0.0178 - val_mae: 0.0784\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0095 - mae: 0.1084 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093 - mae: 0.1074 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0088 - mae: 0.1037 - val_loss: 0.0178 - val_mae: 0.0783\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0082 - mae: 0.0995 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0102 - mae: 0.1101 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0085 - mae: 0.1038 - val_loss: 0.0178 - val_mae: 0.0782\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0099 - mae: 0.1103 - val_loss: 0.0178 - val_mae: 0.0781\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0961 - val_loss: 0.0178 - val_mae: 0.0781\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0085 - mae: 0.1048 - val_loss: 0.0178 - val_mae: 0.0781\n",
      "--- Training LSTM ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0326 - mae: 0.2058 - val_loss: 0.0314 - val_mae: 0.1707\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0242 - mae: 0.1764 - val_loss: 0.0291 - val_mae: 0.1588\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0251 - mae: 0.1827 - val_loss: 0.0271 - val_mae: 0.1473\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0213 - mae: 0.1641 - val_loss: 0.0253 - val_mae: 0.1359\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0228 - mae: 0.1699 - val_loss: 0.0238 - val_mae: 0.1255\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0233 - mae: 0.1664 - val_loss: 0.0225 - val_mae: 0.1159\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0173 - mae: 0.1513 - val_loss: 0.0215 - val_mae: 0.1077\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0159 - mae: 0.1422 - val_loss: 0.0207 - val_mae: 0.1015\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0146 - mae: 0.1345 - val_loss: 0.0200 - val_mae: 0.0967\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0134 - mae: 0.1307 - val_loss: 0.0195 - val_mae: 0.0926\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0149 - mae: 0.1367 - val_loss: 0.0191 - val_mae: 0.0898\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0162 - mae: 0.1428 - val_loss: 0.0187 - val_mae: 0.0877\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0134 - mae: 0.1288 - val_loss: 0.0184 - val_mae: 0.0867\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0149 - mae: 0.1352 - val_loss: 0.0183 - val_mae: 0.0863\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0142 - mae: 0.1293 - val_loss: 0.0182 - val_mae: 0.0864\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0114 - mae: 0.1184 - val_loss: 0.0181 - val_mae: 0.0867\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0124 - mae: 0.1249 - val_loss: 0.0181 - val_mae: 0.0872\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0129 - mae: 0.1269 - val_loss: 0.0181 - val_mae: 0.0876\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0181 - val_mae: 0.0877\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0129 - mae: 0.1263 - val_loss: 0.0181 - val_mae: 0.0876\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0120 - mae: 0.1233 - val_loss: 0.0181 - val_mae: 0.0874\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0106 - mae: 0.1122 - val_loss: 0.0181 - val_mae: 0.0870\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0102 - mae: 0.1132 - val_loss: 0.0181 - val_mae: 0.0866\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0112 - mae: 0.1158 - val_loss: 0.0181 - val_mae: 0.0862\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0181 - val_mae: 0.0858\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0181 - val_mae: 0.0852\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0180 - val_mae: 0.0846\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0122 - mae: 0.1188 - val_loss: 0.0180 - val_mae: 0.0840\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0100 - mae: 0.1068 - val_loss: 0.0180 - val_mae: 0.0835\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0099 - mae: 0.1039 - val_loss: 0.0179 - val_mae: 0.0829\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0080 - mae: 0.0994 - val_loss: 0.0179 - val_mae: 0.0825\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0094 - mae: 0.1075 - val_loss: 0.0179 - val_mae: 0.0822\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0179 - val_mae: 0.0819\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0179 - val_mae: 0.0817\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0082 - mae: 0.1006 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0076 - mae: 0.0930 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0075 - mae: 0.0985 - val_loss: 0.0179 - val_mae: 0.0815\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0078 - mae: 0.0984 - val_loss: 0.0179 - val_mae: 0.0816\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0073 - mae: 0.0932 - val_loss: 0.0179 - val_mae: 0.0816\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - mae: 0.0913 - val_loss: 0.0179 - val_mae: 0.0816\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - mae: 0.0910 - val_loss: 0.0179 - val_mae: 0.0816\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0064 - mae: 0.0860 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0067 - mae: 0.0890 - val_loss: 0.0180 - val_mae: 0.0814\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0076 - mae: 0.0929 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0071 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0068 - mae: 0.0910 - val_loss: 0.0181 - val_mae: 0.0812\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0181 - val_mae: 0.0811\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0181 - val_mae: 0.0810\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0055 - mae: 0.0775 - val_loss: 0.0181 - val_mae: 0.0810\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - mae: 0.0880 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0061 - mae: 0.0864 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0060 - mae: 0.0848 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - mae: 0.0788 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0062 - mae: 0.0860 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0070 - mae: 0.0890 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0054 - mae: 0.0789 - val_loss: 0.0182 - val_mae: 0.0808\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0051 - mae: 0.0756 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0062 - mae: 0.0834 - val_loss: 0.0182 - val_mae: 0.0806\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - mae: 0.0763 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - mae: 0.0746 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0061 - mae: 0.0849 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0058 - mae: 0.0829 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - mae: 0.0803 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0775 - val_loss: 0.0182 - val_mae: 0.0806\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - mae: 0.0765 - val_loss: 0.0181 - val_mae: 0.0805\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - mae: 0.0745 - val_loss: 0.0181 - val_mae: 0.0804\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0803\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0058 - mae: 0.0836 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0049 - mae: 0.0743 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0053 - mae: 0.0773 - val_loss: 0.0180 - val_mae: 0.0803\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0056 - mae: 0.0778 - val_loss: 0.0180 - val_mae: 0.0803\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - mae: 0.0727 - val_loss: 0.0180 - val_mae: 0.0805\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - mae: 0.0770 - val_loss: 0.0180 - val_mae: 0.0806\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - mae: 0.0774 - val_loss: 0.0180 - val_mae: 0.0808\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050 - mae: 0.0728 - val_loss: 0.0180 - val_mae: 0.0810\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - mae: 0.0756 - val_loss: 0.0180 - val_mae: 0.0811\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0053 - mae: 0.0762 - val_loss: 0.0180 - val_mae: 0.0812\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mae: 0.0726 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0051 - mae: 0.0784 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0047 - mae: 0.0715 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mae: 0.0752 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - mae: 0.0685 - val_loss: 0.0181 - val_mae: 0.0816\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0816\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - mae: 0.0664 - val_loss: 0.0181 - val_mae: 0.0817\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0818\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0181 - val_mae: 0.0820\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - mae: 0.0685 - val_loss: 0.0181 - val_mae: 0.0821\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0698 - val_loss: 0.0181 - val_mae: 0.0822\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0044 - mae: 0.0687 - val_loss: 0.0181 - val_mae: 0.0823\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0824\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0048 - mae: 0.0715 - val_loss: 0.0181 - val_mae: 0.0824\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0824\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0673 - val_loss: 0.0180 - val_mae: 0.0825\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0655 - val_loss: 0.0180 - val_mae: 0.0825\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0042 - mae: 0.0673 - val_loss: 0.0180 - val_mae: 0.0824\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0041 - mae: 0.0679 - val_loss: 0.0180 - val_mae: 0.0824\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - mae: 0.0693 - val_loss: 0.0180 - val_mae: 0.0823\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mae: 0.0653 - val_loss: 0.0179 - val_mae: 0.0822\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0179 - val_mae: 0.0821\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0039 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0821\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0179 - val_mae: 0.0820\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - mae: 0.0657 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0819\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0046 - mae: 0.0718 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0699 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - mae: 0.0680 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0046 - mae: 0.0690 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0178 - val_mae: 0.0818\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0178 - val_mae: 0.0819\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0178 - val_mae: 0.0819\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0178 - val_mae: 0.0819\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0655 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0178 - val_mae: 0.0820\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - mae: 0.0635 - val_loss: 0.0178 - val_mae: 0.0822\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0040 - mae: 0.0645 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0048 - mae: 0.0708 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0177 - val_mae: 0.0822\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0177 - val_mae: 0.0821\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0177 - val_mae: 0.0814\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0177 - val_mae: 0.0813\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0177 - val_mae: 0.0813\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0177 - val_mae: 0.0814\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0629 - val_loss: 0.0177 - val_mae: 0.0815\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0177 - val_mae: 0.0817\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0177 - val_mae: 0.0820\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0177 - val_mae: 0.0822\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0179 - val_mae: 0.0827\n",
      "--- Training LSTM-CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - mae: 0.1525 - val_loss: 0.0248 - val_mae: 0.1246\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0170 - mae: 0.1441 - val_loss: 0.0240 - val_mae: 0.1192\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0138 - mae: 0.1309 - val_loss: 0.0233 - val_mae: 0.1137\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0138 - mae: 0.1217 - val_loss: 0.0226 - val_mae: 0.1086\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0123 - mae: 0.1179 - val_loss: 0.0220 - val_mae: 0.1041\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0113 - mae: 0.1164 - val_loss: 0.0215 - val_mae: 0.1002\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0102 - mae: 0.1050 - val_loss: 0.0210 - val_mae: 0.0965\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0106 - mae: 0.1108 - val_loss: 0.0205 - val_mae: 0.0931\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0124 - mae: 0.1206 - val_loss: 0.0202 - val_mae: 0.0900\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0198 - val_mae: 0.0876\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0195 - val_mae: 0.0859\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0093 - mae: 0.1036 - val_loss: 0.0193 - val_mae: 0.0846\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0087 - mae: 0.1013 - val_loss: 0.0191 - val_mae: 0.0834\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0189 - val_mae: 0.0822\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0083 - mae: 0.0987 - val_loss: 0.0187 - val_mae: 0.0819\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0078 - mae: 0.0965 - val_loss: 0.0186 - val_mae: 0.0819\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0080 - mae: 0.0966 - val_loss: 0.0184 - val_mae: 0.0820\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0074 - mae: 0.0919 - val_loss: 0.0183 - val_mae: 0.0820\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0073 - mae: 0.0981 - val_loss: 0.0182 - val_mae: 0.0820\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0068 - mae: 0.0907 - val_loss: 0.0181 - val_mae: 0.0821\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0069 - mae: 0.0902 - val_loss: 0.0180 - val_mae: 0.0823\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0074 - mae: 0.0953 - val_loss: 0.0179 - val_mae: 0.0825\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0079 - mae: 0.0979 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0070 - mae: 0.0921 - val_loss: 0.0178 - val_mae: 0.0828\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0068 - mae: 0.0872 - val_loss: 0.0178 - val_mae: 0.0830\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0069 - mae: 0.0913 - val_loss: 0.0177 - val_mae: 0.0833\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0064 - mae: 0.0898 - val_loss: 0.0177 - val_mae: 0.0835\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0874 - val_loss: 0.0177 - val_mae: 0.0837\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0072 - mae: 0.0875 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0061 - mae: 0.0831 - val_loss: 0.0176 - val_mae: 0.0839\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0062 - mae: 0.0858 - val_loss: 0.0176 - val_mae: 0.0840\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0062 - mae: 0.0826 - val_loss: 0.0176 - val_mae: 0.0841\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0074 - mae: 0.0901 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0065 - mae: 0.0885 - val_loss: 0.0176 - val_mae: 0.0843\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0066 - mae: 0.0871 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0060 - mae: 0.0837 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0056 - mae: 0.0808 - val_loss: 0.0176 - val_mae: 0.0842\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0064 - mae: 0.0874 - val_loss: 0.0176 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - mae: 0.0838 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0054 - mae: 0.0824 - val_loss: 0.0175 - val_mae: 0.0838\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0748 - val_loss: 0.0175 - val_mae: 0.0836\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0749 - val_loss: 0.0175 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mae: 0.0762 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0052 - mae: 0.0789 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - mae: 0.0785 - val_loss: 0.0175 - val_mae: 0.0830\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0059 - mae: 0.0861 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0059 - mae: 0.0799 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0055 - mae: 0.0780 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mae: 0.0751 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0056 - mae: 0.0815 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - mae: 0.0787 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0780 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0059 - mae: 0.0790 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mae: 0.0760 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - mae: 0.0725 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0052 - mae: 0.0759 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0056 - mae: 0.0782 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0051 - mae: 0.0769 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0051 - mae: 0.0742 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0053 - mae: 0.0749 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0737 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0051 - mae: 0.0760 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0047 - mae: 0.0705 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0048 - mae: 0.0732 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mae: 0.0715 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mae: 0.0716 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0708 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0050 - mae: 0.0746 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0049 - mae: 0.0745 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0682 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0055 - mae: 0.0777 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0042 - mae: 0.0699 - val_loss: 0.0174 - val_mae: 0.0824\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0050 - mae: 0.0727 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0045 - mae: 0.0703 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mae: 0.0687 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0042 - mae: 0.0668 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0048 - mae: 0.0739 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0717 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0832\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0174 - val_mae: 0.0833\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0740 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mae: 0.0648 - val_loss: 0.0174 - val_mae: 0.0834\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0042 - mae: 0.0684 - val_loss: 0.0174 - val_mae: 0.0833\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0174 - val_mae: 0.0832\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - mae: 0.0704 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0047 - mae: 0.0729 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0043 - mae: 0.0673 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - mae: 0.0714 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0047 - mae: 0.0725 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0044 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0042 - mae: 0.0695 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0684 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0716 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mae: 0.0630 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0044 - mae: 0.0695 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mae: 0.0652 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mae: 0.0683 - val_loss: 0.0173 - val_mae: 0.0820\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mae: 0.0633 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0689 - val_loss: 0.0173 - val_mae: 0.0823\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0679 - val_loss: 0.0173 - val_mae: 0.0824\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0173 - val_mae: 0.0826\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0039 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - mae: 0.0644 - val_loss: 0.0173 - val_mae: 0.0827\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mae: 0.0659 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0039 - mae: 0.0640 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0038 - mae: 0.0659 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - mae: 0.0636 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0037 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0039 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0041 - mae: 0.0661 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0173 - val_mae: 0.0831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--- Training CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=cnn_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)\n",
    "print('--- Training LSTM ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=lstm_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)\n",
    "print('--- Training LSTM-CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM-CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=stacked_params,\n",
    "          n_steps=N_STEPS,\n",
    "          n_horizon=N_HORIZON,\n",
    "          n_features=N_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Training/Validation Results\n",
    "\n",
    "Loss curves across the models are fairly stable. All models show a decreasing validation curve with different epoch thresholds for when the model stops learning against the validation set. The LSTM appears to begin to have the slowest learning curve, while the CNN takes around 20 epochs to reach a loss close to 0. Some options to help improve this are to introduce learning rate decline, or train on longer input sequences.\n",
    "\n",
    "Plots of the MAE show a similar pattern to the loss plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = list()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "\n",
    "def plot_graphs(metric, val, ax, upper):\n",
    "    ax.plot(val['history'].history[metric])\n",
    "    ax.plot(val['history'].history[f'val_{metric}'])\n",
    "    ax.set_title(key)\n",
    "    ax.legend([metric, f\"val_{metric}\"])\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim([0, upper])\n",
    "    \n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    \n",
    "    plot_graphs('loss', val, ax, 0.05)\n",
    "print(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MAE Curves\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs('mae', val, ax, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Test Results\n",
    "It's surprising to see how well a CNN did. LSTM would be expected to perform well because of its ability to learn and remember longer trends in the data.\n",
    "\n",
    "Putting the models' performance in perspective however the results show how with a limited lookback window, and simple features a lstm, and a cnn stacked with an lstm are a good starting choice for architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0019 - mae: 0.0538\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0571\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - mae: 0.0615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.053788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.057086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM-CNN</th>\n",
       "      <td>0.061503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae\n",
       "CNN       0.053788\n",
       "LSTM      0.057086\n",
       "LSTM-CNN  0.061503"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list()\n",
    "performance = list()\n",
    "\n",
    "for key, value in model_configs.items():\n",
    "    names.append(key)\n",
    "    mae = value['model'].evaluate(value['test_ds'])\n",
    "    performance.append(mae[1])\n",
    "    \n",
    "performance_df = pd.DataFrame(performance, index=names, columns=['mae'])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions\n",
    "\n",
    "Plot the actual and predicted 24 hour intervals. Below is the first 14 days of predictions. Interesting to note how the LSTM appears to oscilate over a longer frequency compared with the other models. The CNN also seems to capture the intra day oscillations (within the 24 hour period). Looking at the CNN stacked LSTM we can see how these two characteristics of the model's learning combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(18, 10))\n",
    "days = 5\n",
    "\n",
    "vline = np.linspace(0, days*24, days+1)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "\n",
    "    test = val['test_ds']\n",
    "    preds = val['model'].predict(test)\n",
    "\n",
    "    xbatch, ybatch = iter(test).get_next()\n",
    "\n",
    "    ax.plot(ybatch.numpy()[:days].reshape(-1))\n",
    "    ax.plot(preds[:days].reshape(-1))\n",
    "    ax.set_title(key)\n",
    "    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "    ax.legend([\"Actual RV\", \"Predicted RV\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
