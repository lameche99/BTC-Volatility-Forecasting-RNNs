{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:38:25.324127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from handler import build_dataset\n",
    "from models import cnn_model, lstm_model, lstm_cnn_model, run_model\n",
    "from tuning import create_study, get_optimized_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = build_dataset(path='./src/rv_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/fintech/lib/python3.10/site-packages/optuna/samplers/_tpe/sampler.py:295: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2023-12-04 18:42:40,236] A new study created in RDB with name: no-name-09d75dc2-5941-48b0-a3f0-654f098b84fa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0439 - mae: 0.2295 - val_loss: 0.5052 - val_mae: 0.8823\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5836 - mae: 0.9529 - val_loss: 0.3337 - val_mae: 0.7179\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2958 - mae: 0.6610 - val_loss: 0.0294 - val_mae: 0.1454\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0146 - mae: 0.1367 - val_loss: 0.0223 - val_mae: 0.1140\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0199 - val_mae: 0.0867\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0049 - mae: 0.0728 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0715 - val_loss: 0.0203 - val_mae: 0.0886\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0818 - val_loss: 0.0193 - val_mae: 0.0863\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0196 - val_mae: 0.1374\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0879 - val_loss: 0.0184 - val_mae: 0.0843\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0828\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0165 - val_mae: 0.0857\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0656 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0166 - val_mae: 0.0900\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0688 - val_loss: 0.0170 - val_mae: 0.0926\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0041 - mae: 0.0722 - val_loss: 0.0174 - val_mae: 0.0950\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0720 - val_loss: 0.0177 - val_mae: 0.0960\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0044 - mae: 0.0704 - val_loss: 0.0177 - val_mae: 0.0952\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0690 - val_loss: 0.0175 - val_mae: 0.0937\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0730 - val_loss: 0.0171 - val_mae: 0.0917\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0687 - val_loss: 0.0168 - val_mae: 0.0902\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0677 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0037 - mae: 0.0680 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0166 - val_mae: 0.0868\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0663 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0660 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0820\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0816\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0823\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0167 - val_mae: 0.0824\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0840\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0823\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0165 - val_mae: 0.0865\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0851\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0855\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0857\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0165 - val_mae: 0.0839\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.0841\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0875\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0166 - val_mae: 0.0878\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0873\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0873\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0865\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0638 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0850\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0165 - val_mae: 0.0856\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0163 - val_mae: 0.0857\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0164 - val_mae: 0.0881\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - mae: 0.0656 - val_loss: 0.0165 - val_mae: 0.0876\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0176 - val_mae: 0.0855\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0177 - val_mae: 0.0854\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0866\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0867\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0636 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0640 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0171 - val_mae: 0.0849\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:42:51,500] Trial 0 finished with value: 0.08503767848014832 and parameters: {'learning_rate': 0.017352599516071498, 'weight_decay': 8.69895482936706e-05}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0500 - mae: 0.2528 - val_loss: 0.0320 - val_mae: 0.1594\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0456 - mae: 0.2365 - val_loss: 0.0318 - val_mae: 0.1587\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0551 - mae: 0.2597 - val_loss: 0.0316 - val_mae: 0.1579\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0574 - mae: 0.2696 - val_loss: 0.0314 - val_mae: 0.1571\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0629 - mae: 0.2795 - val_loss: 0.0312 - val_mae: 0.1563\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0567 - mae: 0.2698 - val_loss: 0.0310 - val_mae: 0.1554\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0458 - mae: 0.2476 - val_loss: 0.0308 - val_mae: 0.1546\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0475 - mae: 0.2466 - val_loss: 0.0306 - val_mae: 0.1537\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0396 - mae: 0.2244 - val_loss: 0.0304 - val_mae: 0.1528\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0783 - mae: 0.3004 - val_loss: 0.0302 - val_mae: 0.1520\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0477 - mae: 0.2459 - val_loss: 0.0300 - val_mae: 0.1511\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0521 - mae: 0.2527 - val_loss: 0.0298 - val_mae: 0.1502\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0568 - mae: 0.2631 - val_loss: 0.0296 - val_mae: 0.1492\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0482 - mae: 0.2419 - val_loss: 0.0294 - val_mae: 0.1483\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0487 - mae: 0.2483 - val_loss: 0.0292 - val_mae: 0.1474\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0399 - mae: 0.2157 - val_loss: 0.0290 - val_mae: 0.1465\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0515 - mae: 0.2530 - val_loss: 0.0288 - val_mae: 0.1457\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0466 - mae: 0.2405 - val_loss: 0.0286 - val_mae: 0.1448\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0412 - mae: 0.2217 - val_loss: 0.0284 - val_mae: 0.1440\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0422 - mae: 0.2373 - val_loss: 0.0283 - val_mae: 0.1432\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0445 - mae: 0.2321 - val_loss: 0.0281 - val_mae: 0.1424\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0575 - mae: 0.2607 - val_loss: 0.0279 - val_mae: 0.1416\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0475 - mae: 0.2457 - val_loss: 0.0278 - val_mae: 0.1408\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0458 - mae: 0.2338 - val_loss: 0.0276 - val_mae: 0.1401\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0485 - mae: 0.2468 - val_loss: 0.0275 - val_mae: 0.1393\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0398 - mae: 0.2265 - val_loss: 0.0273 - val_mae: 0.1386\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0439 - mae: 0.2342 - val_loss: 0.0272 - val_mae: 0.1378\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0414 - mae: 0.2194 - val_loss: 0.0270 - val_mae: 0.1371\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0482 - mae: 0.2475 - val_loss: 0.0269 - val_mae: 0.1364\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0448 - mae: 0.2375 - val_loss: 0.0267 - val_mae: 0.1357\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0442 - mae: 0.2408 - val_loss: 0.0266 - val_mae: 0.1350\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0559 - mae: 0.2627 - val_loss: 0.0265 - val_mae: 0.1343\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0471 - mae: 0.2332 - val_loss: 0.0263 - val_mae: 0.1335\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0459 - mae: 0.2424 - val_loss: 0.0262 - val_mae: 0.1328\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0420 - mae: 0.2321 - val_loss: 0.0261 - val_mae: 0.1321\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0418 - mae: 0.2277 - val_loss: 0.0260 - val_mae: 0.1314\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0419 - mae: 0.2306 - val_loss: 0.0258 - val_mae: 0.1308\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0512 - mae: 0.2459 - val_loss: 0.0257 - val_mae: 0.1301\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0421 - mae: 0.2305 - val_loss: 0.0256 - val_mae: 0.1294\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0519 - mae: 0.2504 - val_loss: 0.0255 - val_mae: 0.1288\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0488 - mae: 0.2464 - val_loss: 0.0253 - val_mae: 0.1281\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0483 - mae: 0.2397 - val_loss: 0.0252 - val_mae: 0.1274\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0333 - mae: 0.2044 - val_loss: 0.0251 - val_mae: 0.1267\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - mae: 0.2227 - val_loss: 0.0250 - val_mae: 0.1260\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2211 - val_loss: 0.0249 - val_mae: 0.1254\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0399 - mae: 0.2192 - val_loss: 0.0247 - val_mae: 0.1248\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0464 - mae: 0.2320 - val_loss: 0.0246 - val_mae: 0.1242\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0432 - mae: 0.2339 - val_loss: 0.0245 - val_mae: 0.1235\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0394 - mae: 0.2199 - val_loss: 0.0244 - val_mae: 0.1229\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - mae: 0.2225 - val_loss: 0.0243 - val_mae: 0.1223\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0434 - mae: 0.2301 - val_loss: 0.0242 - val_mae: 0.1218\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0413 - mae: 0.2266 - val_loss: 0.0241 - val_mae: 0.1212\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0366 - mae: 0.2125 - val_loss: 0.0240 - val_mae: 0.1206\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0379 - mae: 0.2221 - val_loss: 0.0239 - val_mae: 0.1201\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0349 - mae: 0.2057 - val_loss: 0.0238 - val_mae: 0.1195\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0375 - mae: 0.2153 - val_loss: 0.0237 - val_mae: 0.1190\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0416 - mae: 0.2200 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0404 - mae: 0.2277 - val_loss: 0.0235 - val_mae: 0.1180\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0345 - mae: 0.2036 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0333 - mae: 0.2061 - val_loss: 0.0234 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0370 - mae: 0.2147 - val_loss: 0.0233 - val_mae: 0.1164\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0372 - mae: 0.2132 - val_loss: 0.0232 - val_mae: 0.1159\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0360 - mae: 0.2117 - val_loss: 0.0231 - val_mae: 0.1153\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0383 - mae: 0.2157 - val_loss: 0.0230 - val_mae: 0.1148\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0323 - mae: 0.1961 - val_loss: 0.0229 - val_mae: 0.1143\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0348 - mae: 0.2074 - val_loss: 0.0228 - val_mae: 0.1138\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0386 - mae: 0.2204 - val_loss: 0.0227 - val_mae: 0.1133\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0344 - mae: 0.2043 - val_loss: 0.0226 - val_mae: 0.1128\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0329 - mae: 0.2006 - val_loss: 0.0225 - val_mae: 0.1123\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0405 - mae: 0.2233 - val_loss: 0.0225 - val_mae: 0.1118\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0416 - mae: 0.2273 - val_loss: 0.0224 - val_mae: 0.1113\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0432 - mae: 0.2361 - val_loss: 0.0223 - val_mae: 0.1108\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0359 - mae: 0.2100 - val_loss: 0.0222 - val_mae: 0.1103\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0387 - mae: 0.2213 - val_loss: 0.0221 - val_mae: 0.1099\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0372 - mae: 0.2104 - val_loss: 0.0221 - val_mae: 0.1094\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0415 - mae: 0.2248 - val_loss: 0.0220 - val_mae: 0.1090\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0307 - mae: 0.1979 - val_loss: 0.0219 - val_mae: 0.1086\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0352 - mae: 0.2057 - val_loss: 0.0218 - val_mae: 0.1082\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2245 - val_loss: 0.0218 - val_mae: 0.1079\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0315 - mae: 0.1888 - val_loss: 0.0217 - val_mae: 0.1076\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0451 - mae: 0.2299 - val_loss: 0.0217 - val_mae: 0.1073\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0327 - mae: 0.2021 - val_loss: 0.0216 - val_mae: 0.1070\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0325 - mae: 0.1936 - val_loss: 0.0215 - val_mae: 0.1067\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0290 - mae: 0.1876 - val_loss: 0.0215 - val_mae: 0.1064\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0312 - mae: 0.1913 - val_loss: 0.0214 - val_mae: 0.1062\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0317 - mae: 0.1986 - val_loss: 0.0214 - val_mae: 0.1059\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0306 - mae: 0.1928 - val_loss: 0.0213 - val_mae: 0.1056\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0342 - mae: 0.2079 - val_loss: 0.0213 - val_mae: 0.1053\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0306 - mae: 0.1971 - val_loss: 0.0212 - val_mae: 0.1051\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0337 - mae: 0.2083 - val_loss: 0.0211 - val_mae: 0.1048\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0409 - mae: 0.2274 - val_loss: 0.0211 - val_mae: 0.1045\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0331 - mae: 0.2044 - val_loss: 0.0210 - val_mae: 0.1043\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0308 - mae: 0.1949 - val_loss: 0.0210 - val_mae: 0.1040\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0387 - mae: 0.2181 - val_loss: 0.0209 - val_mae: 0.1038\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0379 - mae: 0.2266 - val_loss: 0.0209 - val_mae: 0.1035\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0285 - mae: 0.1822 - val_loss: 0.0208 - val_mae: 0.1033\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0362 - mae: 0.2043 - val_loss: 0.0208 - val_mae: 0.1031\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0344 - mae: 0.2014 - val_loss: 0.0207 - val_mae: 0.1028\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0349 - mae: 0.2029 - val_loss: 0.0207 - val_mae: 0.1026\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0354 - mae: 0.2133 - val_loss: 0.0207 - val_mae: 0.1024\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0326 - mae: 0.2006 - val_loss: 0.0206 - val_mae: 0.1022\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - mae: 0.2057 - val_loss: 0.0206 - val_mae: 0.1020\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0340 - mae: 0.2056 - val_loss: 0.0205 - val_mae: 0.1018\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0331 - mae: 0.2021 - val_loss: 0.0205 - val_mae: 0.1017\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0339 - mae: 0.2035 - val_loss: 0.0205 - val_mae: 0.1015\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0336 - mae: 0.2011 - val_loss: 0.0204 - val_mae: 0.1013\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0316 - mae: 0.2035 - val_loss: 0.0204 - val_mae: 0.1012\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0348 - mae: 0.2031 - val_loss: 0.0204 - val_mae: 0.1010\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0315 - mae: 0.1994 - val_loss: 0.0203 - val_mae: 0.1008\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0266 - mae: 0.1830 - val_loss: 0.0203 - val_mae: 0.1006\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0288 - mae: 0.1809 - val_loss: 0.0203 - val_mae: 0.1005\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0253 - mae: 0.1741 - val_loss: 0.0202 - val_mae: 0.1003\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0297 - mae: 0.1951 - val_loss: 0.0202 - val_mae: 0.1002\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0338 - mae: 0.2107 - val_loss: 0.0202 - val_mae: 0.1000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0275 - mae: 0.1867 - val_loss: 0.0201 - val_mae: 0.0999\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0294 - mae: 0.1917 - val_loss: 0.0201 - val_mae: 0.0997\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0292 - mae: 0.1904 - val_loss: 0.0201 - val_mae: 0.0995\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0409 - mae: 0.2225 - val_loss: 0.0200 - val_mae: 0.0993\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0319 - mae: 0.1973 - val_loss: 0.0200 - val_mae: 0.0992\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0339 - mae: 0.2004 - val_loss: 0.0199 - val_mae: 0.0990\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0284 - mae: 0.1859 - val_loss: 0.0199 - val_mae: 0.0988\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0284 - mae: 0.1916 - val_loss: 0.0199 - val_mae: 0.0986\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0297 - mae: 0.1968 - val_loss: 0.0198 - val_mae: 0.0985\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - mae: 0.2032 - val_loss: 0.0198 - val_mae: 0.0983\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0333 - mae: 0.1948 - val_loss: 0.0197 - val_mae: 0.0981\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0322 - mae: 0.2041 - val_loss: 0.0197 - val_mae: 0.0980\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0279 - mae: 0.1858 - val_loss: 0.0197 - val_mae: 0.0978\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0251 - mae: 0.1784 - val_loss: 0.0196 - val_mae: 0.0976\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0274 - mae: 0.1873 - val_loss: 0.0196 - val_mae: 0.0975\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0269 - mae: 0.1837 - val_loss: 0.0196 - val_mae: 0.0973\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0359 - mae: 0.2134 - val_loss: 0.0196 - val_mae: 0.0972\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0254 - mae: 0.1808 - val_loss: 0.0195 - val_mae: 0.0970\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0331 - mae: 0.1962 - val_loss: 0.0195 - val_mae: 0.0969\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0260 - mae: 0.1815 - val_loss: 0.0195 - val_mae: 0.0967\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0266 - mae: 0.1801 - val_loss: 0.0195 - val_mae: 0.0966\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0331 - mae: 0.1947 - val_loss: 0.0194 - val_mae: 0.0964\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - mae: 0.2054 - val_loss: 0.0194 - val_mae: 0.0963\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0279 - mae: 0.1934 - val_loss: 0.0194 - val_mae: 0.0961\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0275 - mae: 0.1893 - val_loss: 0.0193 - val_mae: 0.0960\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0293 - mae: 0.1976 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0272 - mae: 0.1856 - val_loss: 0.0193 - val_mae: 0.0957\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0287 - mae: 0.1866 - val_loss: 0.0193 - val_mae: 0.0955\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0276 - mae: 0.1934 - val_loss: 0.0192 - val_mae: 0.0954\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0369 - mae: 0.2111 - val_loss: 0.0192 - val_mae: 0.0953\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0353 - mae: 0.2037 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0291 - mae: 0.1944 - val_loss: 0.0192 - val_mae: 0.0951\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0294 - mae: 0.1983 - val_loss: 0.0192 - val_mae: 0.0949\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0273 - mae: 0.1852 - val_loss: 0.0191 - val_mae: 0.0948\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0275 - mae: 0.1807 - val_loss: 0.0191 - val_mae: 0.0947\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0216 - mae: 0.1624 - val_loss: 0.0191 - val_mae: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:02,718] Trial 1 finished with value: 0.09461578726768494 and parameters: {'learning_rate': 7.173612948658869e-06, 'weight_decay': 0.0001298913434059281}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0935 - mae: 0.3552 - val_loss: 0.0544 - val_mae: 0.2537\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0792 - mae: 0.3169 - val_loss: 0.0500 - val_mae: 0.2403\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0748 - mae: 0.3143 - val_loss: 0.0459 - val_mae: 0.2268\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0768 - mae: 0.3101 - val_loss: 0.0422 - val_mae: 0.2144\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0657 - mae: 0.2847 - val_loss: 0.0388 - val_mae: 0.2029\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0630 - mae: 0.2756 - val_loss: 0.0357 - val_mae: 0.1919\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0559 - mae: 0.2635 - val_loss: 0.0331 - val_mae: 0.1812\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0553 - mae: 0.2614 - val_loss: 0.0309 - val_mae: 0.1710\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0397 - mae: 0.2235 - val_loss: 0.0289 - val_mae: 0.1613\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0398 - mae: 0.2287 - val_loss: 0.0273 - val_mae: 0.1523\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0376 - mae: 0.2269 - val_loss: 0.0259 - val_mae: 0.1448\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0351 - mae: 0.2128 - val_loss: 0.0248 - val_mae: 0.1387\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0394 - mae: 0.2216 - val_loss: 0.0238 - val_mae: 0.1335\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0370 - mae: 0.2143 - val_loss: 0.0230 - val_mae: 0.1294\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0340 - mae: 0.2164 - val_loss: 0.0223 - val_mae: 0.1255\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0323 - mae: 0.2025 - val_loss: 0.0218 - val_mae: 0.1219\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0291 - mae: 0.1889 - val_loss: 0.0214 - val_mae: 0.1187\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0317 - mae: 0.2051 - val_loss: 0.0210 - val_mae: 0.1155\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0283 - mae: 0.1808 - val_loss: 0.0208 - val_mae: 0.1126\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0327 - mae: 0.1992 - val_loss: 0.0206 - val_mae: 0.1105\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0276 - mae: 0.1927 - val_loss: 0.0204 - val_mae: 0.1086\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0235 - mae: 0.1736 - val_loss: 0.0203 - val_mae: 0.1072\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - mae: 0.1719 - val_loss: 0.0202 - val_mae: 0.1060\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0282 - mae: 0.1819 - val_loss: 0.0201 - val_mae: 0.1050\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0258 - mae: 0.1788 - val_loss: 0.0200 - val_mae: 0.1040\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0258 - mae: 0.1844 - val_loss: 0.0200 - val_mae: 0.1035\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0189 - mae: 0.1594 - val_loss: 0.0199 - val_mae: 0.1033\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0201 - mae: 0.1578 - val_loss: 0.0198 - val_mae: 0.1032\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0270 - mae: 0.1836 - val_loss: 0.0198 - val_mae: 0.1030\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0263 - mae: 0.1842 - val_loss: 0.0198 - val_mae: 0.1028\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0225 - mae: 0.1714 - val_loss: 0.0198 - val_mae: 0.1027\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0231 - mae: 0.1631 - val_loss: 0.0198 - val_mae: 0.1025\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0191 - mae: 0.1489 - val_loss: 0.0198 - val_mae: 0.1024\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0165 - mae: 0.1438 - val_loss: 0.0199 - val_mae: 0.1022\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0195 - mae: 0.1545 - val_loss: 0.0199 - val_mae: 0.1020\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0225 - mae: 0.1699 - val_loss: 0.0199 - val_mae: 0.1019\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0187 - mae: 0.1511 - val_loss: 0.0199 - val_mae: 0.1017\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0203 - mae: 0.1575 - val_loss: 0.0199 - val_mae: 0.1015\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0180 - mae: 0.1529 - val_loss: 0.0199 - val_mae: 0.1013\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - mae: 0.1455 - val_loss: 0.0199 - val_mae: 0.1010\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0173 - mae: 0.1525 - val_loss: 0.0198 - val_mae: 0.1007\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0163 - mae: 0.1456 - val_loss: 0.0198 - val_mae: 0.1005\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0183 - mae: 0.1581 - val_loss: 0.0197 - val_mae: 0.1002\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0195 - mae: 0.1519 - val_loss: 0.0197 - val_mae: 0.1000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0142 - mae: 0.1301 - val_loss: 0.0196 - val_mae: 0.0997\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0189 - mae: 0.1506 - val_loss: 0.0196 - val_mae: 0.0995\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0177 - mae: 0.1519 - val_loss: 0.0196 - val_mae: 0.0993\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0160 - mae: 0.1404 - val_loss: 0.0196 - val_mae: 0.0991\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0152 - mae: 0.1384 - val_loss: 0.0196 - val_mae: 0.0989\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0181 - mae: 0.1489 - val_loss: 0.0196 - val_mae: 0.0987\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - mae: 0.1476 - val_loss: 0.0195 - val_mae: 0.0986\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0133 - mae: 0.1326 - val_loss: 0.0195 - val_mae: 0.0985\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0149 - mae: 0.1397 - val_loss: 0.0195 - val_mae: 0.0983\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - mae: 0.1365 - val_loss: 0.0195 - val_mae: 0.0982\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0162 - mae: 0.1460 - val_loss: 0.0195 - val_mae: 0.0981\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0168 - mae: 0.1477 - val_loss: 0.0195 - val_mae: 0.0980\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0112 - mae: 0.1209 - val_loss: 0.0195 - val_mae: 0.0979\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0132 - mae: 0.1254 - val_loss: 0.0194 - val_mae: 0.0977\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0144 - mae: 0.1260 - val_loss: 0.0194 - val_mae: 0.0974\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0129 - mae: 0.1251 - val_loss: 0.0194 - val_mae: 0.0971\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0127 - mae: 0.1243 - val_loss: 0.0194 - val_mae: 0.0966\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0134 - mae: 0.1265 - val_loss: 0.0194 - val_mae: 0.0963\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0146 - mae: 0.1398 - val_loss: 0.0194 - val_mae: 0.0962\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0137 - mae: 0.1309 - val_loss: 0.0194 - val_mae: 0.0960\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0132 - mae: 0.1243 - val_loss: 0.0194 - val_mae: 0.0959\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0113 - mae: 0.1200 - val_loss: 0.0194 - val_mae: 0.0957\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0127 - mae: 0.1228 - val_loss: 0.0194 - val_mae: 0.0955\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0142 - mae: 0.1302 - val_loss: 0.0194 - val_mae: 0.0954\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0116 - mae: 0.1207 - val_loss: 0.0194 - val_mae: 0.0953\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0109 - mae: 0.1200 - val_loss: 0.0194 - val_mae: 0.0952\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0153 - mae: 0.1424 - val_loss: 0.0194 - val_mae: 0.0951\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0137 - mae: 0.1260 - val_loss: 0.0194 - val_mae: 0.0950\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0113 - mae: 0.1165 - val_loss: 0.0194 - val_mae: 0.0950\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0119 - mae: 0.1235 - val_loss: 0.0194 - val_mae: 0.0949\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0130 - mae: 0.1257 - val_loss: 0.0193 - val_mae: 0.0948\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0123 - mae: 0.1169 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0112 - mae: 0.1201 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0140 - mae: 0.1271 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0116 - mae: 0.1190 - val_loss: 0.0193 - val_mae: 0.0947\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0109 - mae: 0.1169 - val_loss: 0.0192 - val_mae: 0.0948\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - mae: 0.1117 - val_loss: 0.0192 - val_mae: 0.0949\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0137 - mae: 0.1246 - val_loss: 0.0192 - val_mae: 0.0950\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0108 - mae: 0.1137 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0103 - mae: 0.1155 - val_loss: 0.0192 - val_mae: 0.0954\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0192 - val_mae: 0.0955\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1161 - val_loss: 0.0191 - val_mae: 0.0957\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0191 - val_mae: 0.0960\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0088 - mae: 0.1041 - val_loss: 0.0191 - val_mae: 0.0963\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0191 - val_mae: 0.0965\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0191 - val_mae: 0.0968\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0191 - val_mae: 0.0971\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0090 - mae: 0.1075 - val_loss: 0.0191 - val_mae: 0.0973\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094 - mae: 0.1093 - val_loss: 0.0191 - val_mae: 0.0974\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0101 - mae: 0.1134 - val_loss: 0.0191 - val_mae: 0.0976\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0191 - val_mae: 0.0978\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0191 - val_mae: 0.0979\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0077 - mae: 0.0983 - val_loss: 0.0191 - val_mae: 0.0980\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0077 - mae: 0.0980 - val_loss: 0.0192 - val_mae: 0.0982\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0081 - mae: 0.1026 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0097 - mae: 0.1119 - val_loss: 0.0192 - val_mae: 0.0983\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0081 - mae: 0.1013 - val_loss: 0.0192 - val_mae: 0.0985\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0966 - val_loss: 0.0191 - val_mae: 0.0988\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0192 - val_mae: 0.0990\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0076 - mae: 0.0960 - val_loss: 0.0192 - val_mae: 0.0993\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0922 - val_loss: 0.0192 - val_mae: 0.0995\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0069 - mae: 0.0929 - val_loss: 0.0192 - val_mae: 0.0997\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0075 - mae: 0.0968 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0078 - mae: 0.0964 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.1028 - val_loss: 0.0192 - val_mae: 0.0999\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0080 - mae: 0.1018 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0986 - val_loss: 0.0192 - val_mae: 0.0998\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - mae: 0.0963 - val_loss: 0.0191 - val_mae: 0.0997\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0080 - mae: 0.0951 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0086 - mae: 0.1062 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0086 - mae: 0.1029 - val_loss: 0.0191 - val_mae: 0.0995\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0079 - mae: 0.0990 - val_loss: 0.0191 - val_mae: 0.0995\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0077 - mae: 0.0946 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0967 - val_loss: 0.0191 - val_mae: 0.0997\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0072 - mae: 0.0925 - val_loss: 0.0191 - val_mae: 0.0998\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0070 - mae: 0.0921 - val_loss: 0.0191 - val_mae: 0.0999\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0062 - mae: 0.0873 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.1030 - val_loss: 0.0191 - val_mae: 0.1000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0062 - mae: 0.0903 - val_loss: 0.0191 - val_mae: 0.1001\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0902 - val_loss: 0.0190 - val_mae: 0.1000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0067 - mae: 0.0933 - val_loss: 0.0190 - val_mae: 0.0999\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - mae: 0.0900 - val_loss: 0.0190 - val_mae: 0.0998\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - mae: 0.0945 - val_loss: 0.0189 - val_mae: 0.0997\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0080 - mae: 0.0991 - val_loss: 0.0189 - val_mae: 0.0997\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0071 - mae: 0.0956 - val_loss: 0.0189 - val_mae: 0.0996\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0066 - mae: 0.0883 - val_loss: 0.0189 - val_mae: 0.0994\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0073 - mae: 0.0952 - val_loss: 0.0189 - val_mae: 0.0993\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0068 - mae: 0.0899 - val_loss: 0.0188 - val_mae: 0.0992\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0872 - val_loss: 0.0188 - val_mae: 0.0991\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - mae: 0.0868 - val_loss: 0.0188 - val_mae: 0.0990\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0889 - val_loss: 0.0188 - val_mae: 0.0990\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0057 - mae: 0.0830 - val_loss: 0.0188 - val_mae: 0.0989\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0062 - mae: 0.0869 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - mae: 0.0869 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0787 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0860 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0836 - val_loss: 0.0187 - val_mae: 0.0988\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0065 - mae: 0.0869 - val_loss: 0.0186 - val_mae: 0.0988\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0059 - mae: 0.0840 - val_loss: 0.0186 - val_mae: 0.0988\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - mae: 0.0802 - val_loss: 0.0186 - val_mae: 0.0987\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0066 - mae: 0.0881 - val_loss: 0.0186 - val_mae: 0.0986\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0066 - mae: 0.0899 - val_loss: 0.0186 - val_mae: 0.0985\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0065 - mae: 0.0903 - val_loss: 0.0186 - val_mae: 0.0984\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0868 - val_loss: 0.0186 - val_mae: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:13,940] Trial 2 finished with value: 0.09827699512243271 and parameters: {'learning_rate': 8.184076241648664e-05, 'weight_decay': 4.822966418376956e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0534 - mae: 0.2611 - val_loss: 0.0410 - val_mae: 0.2294\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0456 - mae: 0.2423 - val_loss: 0.0172 - val_mae: 0.1052\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0835 - val_loss: 0.0194 - val_mae: 0.0874\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0192 - val_mae: 0.0845\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0188 - val_mae: 0.0842\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0182 - val_mae: 0.0860\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0888\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0718 - val_loss: 0.0176 - val_mae: 0.0933\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0042 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0929\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0045 - mae: 0.0688 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0866\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0906\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0162 - val_mae: 0.0961\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0158 - val_mae: 0.0992\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0156 - val_mae: 0.0951\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0155 - val_mae: 0.0909\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0870\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0152 - val_mae: 0.0856\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0545 - val_loss: 0.0149 - val_mae: 0.0878\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0147 - val_mae: 0.0938\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0147 - val_mae: 0.0915\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0147 - val_mae: 0.0888\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0148 - val_mae: 0.0884\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0512 - val_loss: 0.0149 - val_mae: 0.0877\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0148 - val_mae: 0.0897\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0146 - val_mae: 0.0903\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0145 - val_mae: 0.0903\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0143 - val_mae: 0.0903\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0143 - val_mae: 0.0881\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0145 - val_mae: 0.0855\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0146 - val_mae: 0.0855\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.0904\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0146 - val_mae: 0.0925\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0496 - val_loss: 0.0148 - val_mae: 0.0923\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0147 - val_mae: 0.0959\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0152 - val_mae: 0.0884\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0157 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0143 - val_mae: 0.0939\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0140 - val_mae: 0.0972\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0144 - val_mae: 0.0886\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0144 - val_mae: 0.0913\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0143 - val_mae: 0.0930\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0411 - val_loss: 0.0145 - val_mae: 0.0898\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0429 - val_loss: 0.0148 - val_mae: 0.0861\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0145 - val_mae: 0.0884\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0142 - val_mae: 0.0941\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0141 - val_mae: 0.1056\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0143 - val_mae: 0.1044\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0410 - val_loss: 0.0147 - val_mae: 0.0909\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0408 - val_loss: 0.0158 - val_mae: 0.0821\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0414 - val_loss: 0.0157 - val_mae: 0.0824\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0404 - val_loss: 0.0151 - val_mae: 0.0846\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0144 - val_mae: 0.0902\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0142 - val_mae: 0.0966\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0151 - val_mae: 0.0896\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0160 - val_mae: 0.0887\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0161 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0158 - val_mae: 0.0884\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0150 - val_mae: 0.0899\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0441 - val_loss: 0.0146 - val_mae: 0.0926\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0919\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0491 - val_loss: 0.0151 - val_mae: 0.0821\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0159 - val_mae: 0.0788\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0389 - val_loss: 0.0162 - val_mae: 0.0801\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0158 - val_mae: 0.0837\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0152 - val_mae: 0.0879\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 0.0148 - val_mae: 0.0937\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0147 - val_mae: 0.0976\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0147 - val_mae: 0.0924\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0442 - val_loss: 0.0148 - val_mae: 0.0874\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0149 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0417 - val_loss: 0.0150 - val_mae: 0.0839\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.0152 - val_mae: 0.0857\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0153 - val_mae: 0.0871\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0422 - val_loss: 0.0155 - val_mae: 0.0864\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.9650e-04 - mae: 0.0340 - val_loss: 0.0157 - val_mae: 0.0860\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0405 - val_loss: 0.0156 - val_mae: 0.0889\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0156 - val_mae: 0.0948\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0363 - val_loss: 0.0156 - val_mae: 0.1002\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0449 - val_loss: 0.0155 - val_mae: 0.1000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0396 - val_loss: 0.0153 - val_mae: 0.0964\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0150 - val_mae: 0.0933\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0150 - val_mae: 0.0867\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0347 - val_loss: 0.0153 - val_mae: 0.0818\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0154 - val_mae: 0.0821\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0154 - val_mae: 0.0845\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0155 - val_mae: 0.0888\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0369 - val_loss: 0.0155 - val_mae: 0.0878\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0155 - val_mae: 0.0849\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0011 - mae: 0.0370 - val_loss: 0.0155 - val_mae: 0.0828\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0154 - val_mae: 0.0855\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0153 - val_mae: 0.0877\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0155 - val_mae: 0.0888\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.0734e-04 - mae: 0.0291 - val_loss: 0.0153 - val_mae: 0.0886\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0151 - val_mae: 0.0873\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0155 - val_mae: 0.0866\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0154 - val_mae: 0.0851\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 0.0151 - val_mae: 0.0848\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0401 - val_loss: 0.0151 - val_mae: 0.0850\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.0153 - val_mae: 0.0858\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 0.0160 - val_mae: 0.0874\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.5995e-04 - mae: 0.0325 - val_loss: 0.0162 - val_mae: 0.0881\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0394 - val_loss: 0.0164 - val_mae: 0.0853\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0407 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0153 - val_mae: 0.0818\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0584e-04 - mae: 0.0314 - val_loss: 0.0150 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0147 - val_mae: 0.0851\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0010 - mae: 0.0342 - val_loss: 0.0146 - val_mae: 0.0883\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 0.0143 - val_mae: 0.0912\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5716e-04 - mae: 0.0334 - val_loss: 0.0145 - val_mae: 0.0925\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0155 - val_mae: 0.0890\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0160 - val_mae: 0.0867\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.0860\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 0.0160 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6734e-04 - mae: 0.0315 - val_loss: 0.0157 - val_mae: 0.0839\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4555e-04 - mae: 0.0292 - val_loss: 0.0155 - val_mae: 0.0849\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.1791e-04 - mae: 0.0292 - val_loss: 0.0156 - val_mae: 0.0870\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.7401e-04 - mae: 0.0282 - val_loss: 0.0157 - val_mae: 0.0869\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.4249e-04 - mae: 0.0310 - val_loss: 0.0156 - val_mae: 0.0840\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.3223e-04 - mae: 0.0307 - val_loss: 0.0155 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.9203e-04 - mae: 0.0326 - val_loss: 0.0153 - val_mae: 0.0835\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0319 - val_loss: 0.0152 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0369 - val_loss: 0.0153 - val_mae: 0.0870\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.8086e-04 - mae: 0.0302 - val_loss: 0.0155 - val_mae: 0.0889\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.2615e-04 - mae: 0.0313 - val_loss: 0.0157 - val_mae: 0.0907\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0405 - val_loss: 0.0159 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.4576e-04 - mae: 0.0248 - val_loss: 0.0161 - val_mae: 0.0816\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0826e-04 - mae: 0.0309 - val_loss: 0.0163 - val_mae: 0.0799\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1577e-04 - mae: 0.0273 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0156 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 0.0148 - val_mae: 0.0819\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.5525e-04 - mae: 0.0324 - val_loss: 0.0147 - val_mae: 0.0862\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.5865e-04 - mae: 0.0322 - val_loss: 0.0148 - val_mae: 0.0886\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.8138e-04 - mae: 0.0307 - val_loss: 0.0152 - val_mae: 0.0881\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0159 - val_mae: 0.0883\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.7982e-04 - mae: 0.0284 - val_loss: 0.0163 - val_mae: 0.0881\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.4630e-04 - mae: 0.0284 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.0576e-04 - mae: 0.0286 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.9681e-04 - mae: 0.0273 - val_loss: 0.0156 - val_mae: 0.0832\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.3356e-04 - mae: 0.0267 - val_loss: 0.0154 - val_mae: 0.0828\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 6.2626e-04 - mae: 0.0269 - val_loss: 0.0152 - val_mae: 0.0834\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7851e-04 - mae: 0.0285 - val_loss: 0.0154 - val_mae: 0.0847\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.2351e-04 - mae: 0.0282 - val_loss: 0.0157 - val_mae: 0.0861\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.5528e-04 - mae: 0.0246 - val_loss: 0.0158 - val_mae: 0.0888\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0010 - mae: 0.0347 - val_loss: 0.0158 - val_mae: 0.0878\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.0166e-04 - mae: 0.0315 - val_loss: 0.0155 - val_mae: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:25,280] Trial 3 finished with value: 0.08510519564151764 and parameters: {'learning_rate': 0.003630024147729035, 'weight_decay': 0.000312443332199213}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0547 - mae: 0.2608 - val_loss: 0.0310 - val_mae: 0.1710\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0379 - mae: 0.2123 - val_loss: 0.0272 - val_mae: 0.1556\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0478 - mae: 0.2415 - val_loss: 0.0244 - val_mae: 0.1419\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0333 - mae: 0.2098 - val_loss: 0.0225 - val_mae: 0.1315\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0323 - mae: 0.1944 - val_loss: 0.0212 - val_mae: 0.1242\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0286 - mae: 0.1853 - val_loss: 0.0206 - val_mae: 0.1196\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0254 - mae: 0.1759 - val_loss: 0.0204 - val_mae: 0.1165\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0223 - mae: 0.1623 - val_loss: 0.0204 - val_mae: 0.1142\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1611 - val_loss: 0.0205 - val_mae: 0.1130\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0200 - mae: 0.1572 - val_loss: 0.0205 - val_mae: 0.1118\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0182 - mae: 0.1493 - val_loss: 0.0206 - val_mae: 0.1105\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0183 - mae: 0.1510 - val_loss: 0.0206 - val_mae: 0.1091\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0179 - mae: 0.1458 - val_loss: 0.0205 - val_mae: 0.1076\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0137 - mae: 0.1276 - val_loss: 0.0204 - val_mae: 0.1060\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0143 - mae: 0.1320 - val_loss: 0.0202 - val_mae: 0.1048\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0133 - mae: 0.1287 - val_loss: 0.0200 - val_mae: 0.1034\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0170 - mae: 0.1394 - val_loss: 0.0197 - val_mae: 0.1019\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0163 - mae: 0.1426 - val_loss: 0.0194 - val_mae: 0.1002\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0192 - val_mae: 0.0985\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0133 - mae: 0.1294 - val_loss: 0.0190 - val_mae: 0.0969\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0119 - mae: 0.1193 - val_loss: 0.0189 - val_mae: 0.0956\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0125 - mae: 0.1202 - val_loss: 0.0187 - val_mae: 0.0944\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0118 - mae: 0.1183 - val_loss: 0.0186 - val_mae: 0.0934\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0111 - mae: 0.1190 - val_loss: 0.0185 - val_mae: 0.0925\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0106 - mae: 0.1175 - val_loss: 0.0184 - val_mae: 0.0917\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0113 - mae: 0.1170 - val_loss: 0.0183 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1058 - val_loss: 0.0183 - val_mae: 0.0905\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0093 - mae: 0.1085 - val_loss: 0.0182 - val_mae: 0.0901\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0182 - val_mae: 0.0901\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1087 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0110 - mae: 0.1120 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0181 - val_mae: 0.0901\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0081 - mae: 0.0996 - val_loss: 0.0181 - val_mae: 0.0899\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0075 - mae: 0.0960 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0076 - mae: 0.0948 - val_loss: 0.0180 - val_mae: 0.0903\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0942 - val_loss: 0.0180 - val_mae: 0.0906\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0072 - mae: 0.0925 - val_loss: 0.0179 - val_mae: 0.0910\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0907 - val_loss: 0.0179 - val_mae: 0.0913\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0076 - mae: 0.0930 - val_loss: 0.0179 - val_mae: 0.0916\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0071 - mae: 0.0903 - val_loss: 0.0179 - val_mae: 0.0919\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0068 - mae: 0.0896 - val_loss: 0.0178 - val_mae: 0.0920\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0876 - val_loss: 0.0178 - val_mae: 0.0921\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0062 - mae: 0.0865 - val_loss: 0.0177 - val_mae: 0.0920\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - mae: 0.0865 - val_loss: 0.0177 - val_mae: 0.0918\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0851 - val_loss: 0.0176 - val_mae: 0.0916\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0868 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0059 - mae: 0.0825 - val_loss: 0.0176 - val_mae: 0.0912\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0059 - mae: 0.0812 - val_loss: 0.0175 - val_mae: 0.0909\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0052 - mae: 0.0776 - val_loss: 0.0175 - val_mae: 0.0906\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0061 - mae: 0.0846 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0794 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0833 - val_loss: 0.0174 - val_mae: 0.0896\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - mae: 0.0793 - val_loss: 0.0173 - val_mae: 0.0894\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0770 - val_loss: 0.0173 - val_mae: 0.0891\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0051 - mae: 0.0752 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0705 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0054 - mae: 0.0811 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0050 - mae: 0.0733 - val_loss: 0.0172 - val_mae: 0.0891\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0704 - val_loss: 0.0171 - val_mae: 0.0891\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0723 - val_loss: 0.0171 - val_mae: 0.0889\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0774 - val_loss: 0.0171 - val_mae: 0.0887\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.0886\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0724 - val_loss: 0.0171 - val_mae: 0.0883\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0171 - val_mae: 0.0881\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0880\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0719 - val_loss: 0.0171 - val_mae: 0.0881\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0735 - val_loss: 0.0171 - val_mae: 0.0883\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0171 - val_mae: 0.0889\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0655 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0038 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - mae: 0.0714 - val_loss: 0.0171 - val_mae: 0.0895\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0706 - val_loss: 0.0171 - val_mae: 0.0899\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0171 - val_mae: 0.0903\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - mae: 0.0702 - val_loss: 0.0171 - val_mae: 0.0906\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - mae: 0.0728 - val_loss: 0.0171 - val_mae: 0.0909\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0672 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0723 - val_loss: 0.0169 - val_mae: 0.0914\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0661 - val_loss: 0.0169 - val_mae: 0.0912\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0044 - mae: 0.0691 - val_loss: 0.0169 - val_mae: 0.0911\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0669 - val_loss: 0.0169 - val_mae: 0.0910\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0648 - val_loss: 0.0168 - val_mae: 0.0909\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0040 - mae: 0.0689 - val_loss: 0.0168 - val_mae: 0.0907\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0632 - val_loss: 0.0168 - val_mae: 0.0905\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0901\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0899\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0167 - val_mae: 0.0898\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0897\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0898\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0900\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0902\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0904\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0166 - val_mae: 0.0905\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0906\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0165 - val_mae: 0.0908\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0165 - val_mae: 0.0910\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0165 - val_mae: 0.0912\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0595 - val_loss: 0.0165 - val_mae: 0.0912\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0165 - val_mae: 0.0914\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0916\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0918\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0165 - val_mae: 0.0919\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0918\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0165 - val_mae: 0.0917\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0166 - val_mae: 0.0915\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0166 - val_mae: 0.0914\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0559 - val_loss: 0.0166 - val_mae: 0.0915\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0166 - val_mae: 0.0917\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0166 - val_mae: 0.0919\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0921\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0030 - mae: 0.0587 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0166 - val_mae: 0.0925\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0166 - val_mae: 0.0926\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0165 - val_mae: 0.0926\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.0927\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0165 - val_mae: 0.0928\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0165 - val_mae: 0.0930\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0165 - val_mae: 0.0933\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0588 - val_loss: 0.0165 - val_mae: 0.0939\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0165 - val_mae: 0.0943\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0947\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0165 - val_mae: 0.0951\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0573 - val_loss: 0.0165 - val_mae: 0.0954\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0165 - val_mae: 0.0955\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0957\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0165 - val_mae: 0.0960\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - mae: 0.0523 - val_loss: 0.0165 - val_mae: 0.0963\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0967\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0165 - val_mae: 0.0970\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0024 - mae: 0.0533 - val_loss: 0.0165 - val_mae: 0.0971\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0973\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0532 - val_loss: 0.0165 - val_mae: 0.0972\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0510 - val_loss: 0.0164 - val_mae: 0.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:37,179] Trial 4 finished with value: 0.09693402051925659 and parameters: {'learning_rate': 0.00017596799005821075, 'weight_decay': 7.223387288213484e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0963 - mae: 0.3558 - val_loss: 0.0520 - val_mae: 0.2416\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0843 - mae: 0.3243 - val_loss: 0.0512 - val_mae: 0.2394\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0879 - mae: 0.3303 - val_loss: 0.0504 - val_mae: 0.2371\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0827 - mae: 0.3227 - val_loss: 0.0496 - val_mae: 0.2348\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0941 - mae: 0.3552 - val_loss: 0.0488 - val_mae: 0.2324\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0847 - mae: 0.3231 - val_loss: 0.0480 - val_mae: 0.2301\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0762 - mae: 0.2953 - val_loss: 0.0472 - val_mae: 0.2278\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0727 - mae: 0.3036 - val_loss: 0.0464 - val_mae: 0.2255\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0710 - mae: 0.3038 - val_loss: 0.0457 - val_mae: 0.2233\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0807 - mae: 0.3156 - val_loss: 0.0450 - val_mae: 0.2212\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0552 - mae: 0.2661 - val_loss: 0.0443 - val_mae: 0.2191\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0792 - mae: 0.3185 - val_loss: 0.0436 - val_mae: 0.2169\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0703 - mae: 0.2999 - val_loss: 0.0429 - val_mae: 0.2149\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0759 - mae: 0.3051 - val_loss: 0.0422 - val_mae: 0.2128\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0610 - mae: 0.2803 - val_loss: 0.0415 - val_mae: 0.2107\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0740 - mae: 0.3112 - val_loss: 0.0409 - val_mae: 0.2088\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0661 - mae: 0.2797 - val_loss: 0.0403 - val_mae: 0.2068\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0677 - mae: 0.2915 - val_loss: 0.0397 - val_mae: 0.2049\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0644 - mae: 0.2860 - val_loss: 0.0391 - val_mae: 0.2030\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0719 - mae: 0.2975 - val_loss: 0.0386 - val_mae: 0.2011\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0632 - mae: 0.2690 - val_loss: 0.0380 - val_mae: 0.1992\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0585 - mae: 0.2723 - val_loss: 0.0375 - val_mae: 0.1974\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0704 - mae: 0.3038 - val_loss: 0.0370 - val_mae: 0.1957\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0621 - mae: 0.2732 - val_loss: 0.0365 - val_mae: 0.1939\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0525 - mae: 0.2618 - val_loss: 0.0360 - val_mae: 0.1921\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0649 - mae: 0.2821 - val_loss: 0.0355 - val_mae: 0.1904\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0629 - mae: 0.2763 - val_loss: 0.0351 - val_mae: 0.1887\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0501 - mae: 0.2551 - val_loss: 0.0346 - val_mae: 0.1870\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0564 - mae: 0.2534 - val_loss: 0.0342 - val_mae: 0.1854\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0559 - mae: 0.2631 - val_loss: 0.0338 - val_mae: 0.1838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0635 - mae: 0.2691 - val_loss: 0.0334 - val_mae: 0.1823\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0489 - mae: 0.2479 - val_loss: 0.0330 - val_mae: 0.1808\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0563 - mae: 0.2698 - val_loss: 0.0326 - val_mae: 0.1793\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0591 - mae: 0.2676 - val_loss: 0.0323 - val_mae: 0.1778\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0611 - mae: 0.2768 - val_loss: 0.0319 - val_mae: 0.1763\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0494 - mae: 0.2485 - val_loss: 0.0316 - val_mae: 0.1749\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0540 - mae: 0.2622 - val_loss: 0.0312 - val_mae: 0.1734\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0476 - mae: 0.2409 - val_loss: 0.0309 - val_mae: 0.1720\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0563 - mae: 0.2641 - val_loss: 0.0306 - val_mae: 0.1706\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0512 - mae: 0.2450 - val_loss: 0.0303 - val_mae: 0.1692\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0569 - mae: 0.2705 - val_loss: 0.0300 - val_mae: 0.1678\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0514 - mae: 0.2552 - val_loss: 0.0297 - val_mae: 0.1664\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0425 - mae: 0.2330 - val_loss: 0.0294 - val_mae: 0.1651\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0465 - mae: 0.2453 - val_loss: 0.0291 - val_mae: 0.1637\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0480 - mae: 0.2490 - val_loss: 0.0289 - val_mae: 0.1624\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0478 - mae: 0.2366 - val_loss: 0.0286 - val_mae: 0.1611\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0518 - mae: 0.2566 - val_loss: 0.0284 - val_mae: 0.1598\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0471 - mae: 0.2481 - val_loss: 0.0281 - val_mae: 0.1586\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0422 - mae: 0.2269 - val_loss: 0.0279 - val_mae: 0.1574\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0546 - mae: 0.2616 - val_loss: 0.0276 - val_mae: 0.1562\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0475 - mae: 0.2450 - val_loss: 0.0274 - val_mae: 0.1550\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0421 - mae: 0.2330 - val_loss: 0.0272 - val_mae: 0.1539\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0399 - mae: 0.2214 - val_loss: 0.0270 - val_mae: 0.1529\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0488 - mae: 0.2468 - val_loss: 0.0268 - val_mae: 0.1518\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0417 - mae: 0.2203 - val_loss: 0.0266 - val_mae: 0.1508\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0505 - mae: 0.2533 - val_loss: 0.0264 - val_mae: 0.1498\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0506 - mae: 0.2455 - val_loss: 0.0262 - val_mae: 0.1488\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0391 - mae: 0.2165 - val_loss: 0.0260 - val_mae: 0.1479\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0417 - mae: 0.2203 - val_loss: 0.0258 - val_mae: 0.1469\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0379 - mae: 0.2160 - val_loss: 0.0257 - val_mae: 0.1460\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0377 - mae: 0.2214 - val_loss: 0.0255 - val_mae: 0.1451\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0388 - mae: 0.2215 - val_loss: 0.0253 - val_mae: 0.1442\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0380 - mae: 0.2226 - val_loss: 0.0252 - val_mae: 0.1433\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0335 - mae: 0.2042 - val_loss: 0.0250 - val_mae: 0.1424\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0432 - mae: 0.2307 - val_loss: 0.0249 - val_mae: 0.1416\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0410 - mae: 0.2339 - val_loss: 0.0247 - val_mae: 0.1408\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0353 - mae: 0.2101 - val_loss: 0.0246 - val_mae: 0.1400\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0392 - mae: 0.2249 - val_loss: 0.0244 - val_mae: 0.1392\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0349 - mae: 0.2048 - val_loss: 0.0243 - val_mae: 0.1384\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0349 - mae: 0.2067 - val_loss: 0.0242 - val_mae: 0.1376\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0388 - mae: 0.2264 - val_loss: 0.0241 - val_mae: 0.1369\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0431 - mae: 0.2289 - val_loss: 0.0239 - val_mae: 0.1362\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0463 - mae: 0.2342 - val_loss: 0.0238 - val_mae: 0.1355\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0315 - mae: 0.2005 - val_loss: 0.0237 - val_mae: 0.1347\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0361 - mae: 0.2153 - val_loss: 0.0236 - val_mae: 0.1340\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0380 - mae: 0.2137 - val_loss: 0.0235 - val_mae: 0.1333\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0320 - mae: 0.2013 - val_loss: 0.0233 - val_mae: 0.1326\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0338 - mae: 0.2037 - val_loss: 0.0232 - val_mae: 0.1319\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0401 - mae: 0.2292 - val_loss: 0.0231 - val_mae: 0.1311\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0444 - mae: 0.2310 - val_loss: 0.0230 - val_mae: 0.1305\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0348 - mae: 0.2127 - val_loss: 0.0229 - val_mae: 0.1298\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0319 - mae: 0.1967 - val_loss: 0.0228 - val_mae: 0.1292\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0354 - mae: 0.2094 - val_loss: 0.0227 - val_mae: 0.1286\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0345 - mae: 0.2034 - val_loss: 0.0226 - val_mae: 0.1281\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0415 - mae: 0.2268 - val_loss: 0.0225 - val_mae: 0.1276\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0357 - mae: 0.2096 - val_loss: 0.0225 - val_mae: 0.1271\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0380 - mae: 0.2186 - val_loss: 0.0224 - val_mae: 0.1266\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0334 - mae: 0.2071 - val_loss: 0.0223 - val_mae: 0.1261\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0362 - mae: 0.2101 - val_loss: 0.0222 - val_mae: 0.1255\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0282 - mae: 0.1845 - val_loss: 0.0221 - val_mae: 0.1250\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0419 - mae: 0.2278 - val_loss: 0.0220 - val_mae: 0.1245\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - mae: 0.2030 - val_loss: 0.0220 - val_mae: 0.1239\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0306 - mae: 0.1997 - val_loss: 0.0219 - val_mae: 0.1234\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0321 - mae: 0.1980 - val_loss: 0.0218 - val_mae: 0.1229\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0459 - mae: 0.2367 - val_loss: 0.0217 - val_mae: 0.1223\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0343 - mae: 0.2088 - val_loss: 0.0216 - val_mae: 0.1218\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0370 - mae: 0.2168 - val_loss: 0.0215 - val_mae: 0.1213\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0388 - mae: 0.2188 - val_loss: 0.0215 - val_mae: 0.1207\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0331 - mae: 0.1970 - val_loss: 0.0214 - val_mae: 0.1202\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - mae: 0.2005 - val_loss: 0.0213 - val_mae: 0.1197\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0381 - mae: 0.2143 - val_loss: 0.0212 - val_mae: 0.1191\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0346 - mae: 0.2114 - val_loss: 0.0212 - val_mae: 0.1187\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0308 - mae: 0.1950 - val_loss: 0.0211 - val_mae: 0.1182\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0324 - mae: 0.2009 - val_loss: 0.0210 - val_mae: 0.1177\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0299 - mae: 0.1976 - val_loss: 0.0209 - val_mae: 0.1173\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - mae: 0.1982 - val_loss: 0.0209 - val_mae: 0.1169\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0303 - mae: 0.1942 - val_loss: 0.0208 - val_mae: 0.1165\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0293 - mae: 0.1925 - val_loss: 0.0208 - val_mae: 0.1160\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0273 - mae: 0.1877 - val_loss: 0.0207 - val_mae: 0.1156\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0331 - mae: 0.2023 - val_loss: 0.0207 - val_mae: 0.1153\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0326 - mae: 0.2050 - val_loss: 0.0206 - val_mae: 0.1149\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0318 - mae: 0.1991 - val_loss: 0.0206 - val_mae: 0.1146\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.2008 - val_loss: 0.0205 - val_mae: 0.1143\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0302 - mae: 0.2004 - val_loss: 0.0204 - val_mae: 0.1140\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0313 - mae: 0.1996 - val_loss: 0.0204 - val_mae: 0.1137\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0275 - mae: 0.1872 - val_loss: 0.0203 - val_mae: 0.1134\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0332 - mae: 0.2039 - val_loss: 0.0203 - val_mae: 0.1131\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0290 - mae: 0.1919 - val_loss: 0.0202 - val_mae: 0.1128\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0314 - mae: 0.1970 - val_loss: 0.0202 - val_mae: 0.1125\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0319 - mae: 0.2041 - val_loss: 0.0201 - val_mae: 0.1122\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0293 - mae: 0.1910 - val_loss: 0.0201 - val_mae: 0.1119\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0264 - mae: 0.1789 - val_loss: 0.0201 - val_mae: 0.1117\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0302 - mae: 0.1963 - val_loss: 0.0200 - val_mae: 0.1115\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0265 - mae: 0.1839 - val_loss: 0.0200 - val_mae: 0.1113\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0311 - mae: 0.1963 - val_loss: 0.0200 - val_mae: 0.1111\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0313 - mae: 0.1941 - val_loss: 0.0200 - val_mae: 0.1109\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0267 - mae: 0.1838 - val_loss: 0.0199 - val_mae: 0.1107\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0314 - mae: 0.2025 - val_loss: 0.0199 - val_mae: 0.1105\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0254 - mae: 0.1751 - val_loss: 0.0199 - val_mae: 0.1103\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0246 - mae: 0.1741 - val_loss: 0.0199 - val_mae: 0.1101\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0321 - mae: 0.1979 - val_loss: 0.0199 - val_mae: 0.1100\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0275 - mae: 0.1890 - val_loss: 0.0199 - val_mae: 0.1098\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0256 - mae: 0.1816 - val_loss: 0.0198 - val_mae: 0.1096\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0267 - mae: 0.1824 - val_loss: 0.0198 - val_mae: 0.1094\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0284 - mae: 0.1883 - val_loss: 0.0198 - val_mae: 0.1092\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0267 - mae: 0.1872 - val_loss: 0.0198 - val_mae: 0.1091\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0314 - mae: 0.2004 - val_loss: 0.0197 - val_mae: 0.1090\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0236 - mae: 0.1726 - val_loss: 0.0197 - val_mae: 0.1088\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0277 - mae: 0.1967 - val_loss: 0.0197 - val_mae: 0.1087\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0234 - mae: 0.1779 - val_loss: 0.0197 - val_mae: 0.1085\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0322 - mae: 0.1957 - val_loss: 0.0197 - val_mae: 0.1084\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0285 - mae: 0.1846 - val_loss: 0.0196 - val_mae: 0.1082\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - mae: 0.1836 - val_loss: 0.0196 - val_mae: 0.1081\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0253 - mae: 0.1791 - val_loss: 0.0196 - val_mae: 0.1080\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0313 - mae: 0.1971 - val_loss: 0.0196 - val_mae: 0.1079\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0313 - mae: 0.1954 - val_loss: 0.0196 - val_mae: 0.1077\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0324 - mae: 0.1935 - val_loss: 0.0195 - val_mae: 0.1076\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0267 - mae: 0.1789 - val_loss: 0.0195 - val_mae: 0.1075\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0285 - mae: 0.1854 - val_loss: 0.0195 - val_mae: 0.1074\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0247 - mae: 0.1748 - val_loss: 0.0195 - val_mae: 0.1073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:48,311] Trial 5 finished with value: 0.10726500302553177 and parameters: {'learning_rate': 1.4198047141564276e-05, 'weight_decay': 5.9621886024668284e-05}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0779 - mae: 0.3096 - val_loss: 0.0482 - val_mae: 0.2300\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0649 - mae: 0.2962 - val_loss: 0.0480 - val_mae: 0.2291\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0649 - mae: 0.2913 - val_loss: 0.0477 - val_mae: 0.2282\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0731 - mae: 0.3073 - val_loss: 0.0474 - val_mae: 0.2273\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0711 - mae: 0.3013 - val_loss: 0.0471 - val_mae: 0.2263\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0696 - mae: 0.2870 - val_loss: 0.0469 - val_mae: 0.2254\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0759 - mae: 0.3015 - val_loss: 0.0466 - val_mae: 0.2245\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0657 - mae: 0.2853 - val_loss: 0.0463 - val_mae: 0.2236\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0634 - mae: 0.2815 - val_loss: 0.0460 - val_mae: 0.2226\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0679 - mae: 0.2853 - val_loss: 0.0458 - val_mae: 0.2217\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0624 - mae: 0.2895 - val_loss: 0.0455 - val_mae: 0.2207\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0680 - mae: 0.2967 - val_loss: 0.0453 - val_mae: 0.2198\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0601 - mae: 0.2715 - val_loss: 0.0450 - val_mae: 0.2189\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0776 - mae: 0.3061 - val_loss: 0.0447 - val_mae: 0.2179\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0680 - mae: 0.2838 - val_loss: 0.0445 - val_mae: 0.2170\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0808 - mae: 0.3190 - val_loss: 0.0442 - val_mae: 0.2160\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0698 - mae: 0.2793 - val_loss: 0.0439 - val_mae: 0.2151\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0740 - mae: 0.3102 - val_loss: 0.0437 - val_mae: 0.2142\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0704 - mae: 0.2972 - val_loss: 0.0434 - val_mae: 0.2132\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0572 - mae: 0.2676 - val_loss: 0.0432 - val_mae: 0.2123\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0630 - mae: 0.2835 - val_loss: 0.0429 - val_mae: 0.2114\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0755 - mae: 0.3115 - val_loss: 0.0427 - val_mae: 0.2105\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0664 - mae: 0.2941 - val_loss: 0.0424 - val_mae: 0.2096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0658 - mae: 0.2868 - val_loss: 0.0422 - val_mae: 0.2087\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0651 - mae: 0.2825 - val_loss: 0.0419 - val_mae: 0.2078\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0639 - mae: 0.2895 - val_loss: 0.0417 - val_mae: 0.2068\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0677 - mae: 0.2855 - val_loss: 0.0414 - val_mae: 0.2060\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0601 - mae: 0.2716 - val_loss: 0.0412 - val_mae: 0.2051\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0641 - mae: 0.2818 - val_loss: 0.0409 - val_mae: 0.2042\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0583 - mae: 0.2714 - val_loss: 0.0407 - val_mae: 0.2034\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0662 - mae: 0.2885 - val_loss: 0.0405 - val_mae: 0.2025\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0526 - mae: 0.2529 - val_loss: 0.0403 - val_mae: 0.2017\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0613 - mae: 0.2757 - val_loss: 0.0400 - val_mae: 0.2009\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0592 - mae: 0.2689 - val_loss: 0.0398 - val_mae: 0.2000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0615 - mae: 0.2823 - val_loss: 0.0396 - val_mae: 0.1992\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0570 - mae: 0.2710 - val_loss: 0.0394 - val_mae: 0.1984\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0646 - mae: 0.2847 - val_loss: 0.0391 - val_mae: 0.1976\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0509 - mae: 0.2509 - val_loss: 0.0389 - val_mae: 0.1968\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0631 - mae: 0.2914 - val_loss: 0.0387 - val_mae: 0.1960\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0653 - mae: 0.2871 - val_loss: 0.0385 - val_mae: 0.1952\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0598 - mae: 0.2776 - val_loss: 0.0383 - val_mae: 0.1944\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0583 - mae: 0.2676 - val_loss: 0.0381 - val_mae: 0.1936\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0670 - mae: 0.2905 - val_loss: 0.0379 - val_mae: 0.1928\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0625 - mae: 0.2746 - val_loss: 0.0376 - val_mae: 0.1920\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0548 - mae: 0.2578 - val_loss: 0.0374 - val_mae: 0.1913\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0616 - mae: 0.2824 - val_loss: 0.0372 - val_mae: 0.1905\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0574 - mae: 0.2677 - val_loss: 0.0370 - val_mae: 0.1897\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0573 - mae: 0.2754 - val_loss: 0.0369 - val_mae: 0.1890\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0501 - mae: 0.2492 - val_loss: 0.0367 - val_mae: 0.1882\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0532 - mae: 0.2617 - val_loss: 0.0365 - val_mae: 0.1875\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0597 - mae: 0.2764 - val_loss: 0.0363 - val_mae: 0.1867\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0485 - mae: 0.2528 - val_loss: 0.0361 - val_mae: 0.1860\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0578 - mae: 0.2668 - val_loss: 0.0359 - val_mae: 0.1852\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0607 - mae: 0.2786 - val_loss: 0.0357 - val_mae: 0.1845\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0491 - mae: 0.2535 - val_loss: 0.0355 - val_mae: 0.1838\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0622 - mae: 0.2669 - val_loss: 0.0353 - val_mae: 0.1830\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0645 - mae: 0.2836 - val_loss: 0.0352 - val_mae: 0.1823\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0536 - mae: 0.2652 - val_loss: 0.0350 - val_mae: 0.1815\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0601 - mae: 0.2708 - val_loss: 0.0348 - val_mae: 0.1808\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0558 - mae: 0.2621 - val_loss: 0.0346 - val_mae: 0.1801\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0580 - mae: 0.2668 - val_loss: 0.0345 - val_mae: 0.1794\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0462 - mae: 0.2368 - val_loss: 0.0343 - val_mae: 0.1786\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0470 - mae: 0.2399 - val_loss: 0.0341 - val_mae: 0.1779\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0546 - mae: 0.2594 - val_loss: 0.0340 - val_mae: 0.1772\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0527 - mae: 0.2611 - val_loss: 0.0338 - val_mae: 0.1765\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0469 - mae: 0.2476 - val_loss: 0.0336 - val_mae: 0.1758\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0522 - mae: 0.2545 - val_loss: 0.0335 - val_mae: 0.1751\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0461 - mae: 0.2455 - val_loss: 0.0333 - val_mae: 0.1744\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0509 - mae: 0.2504 - val_loss: 0.0332 - val_mae: 0.1738\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0532 - mae: 0.2584 - val_loss: 0.0330 - val_mae: 0.1732\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0475 - mae: 0.2426 - val_loss: 0.0329 - val_mae: 0.1725\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0443 - mae: 0.2337 - val_loss: 0.0327 - val_mae: 0.1719\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0603 - mae: 0.2720 - val_loss: 0.0326 - val_mae: 0.1713\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0513 - mae: 0.2477 - val_loss: 0.0324 - val_mae: 0.1706\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0553 - mae: 0.2636 - val_loss: 0.0323 - val_mae: 0.1700\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0503 - mae: 0.2468 - val_loss: 0.0322 - val_mae: 0.1694\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0490 - mae: 0.2442 - val_loss: 0.0320 - val_mae: 0.1687\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0571 - mae: 0.2697 - val_loss: 0.0319 - val_mae: 0.1681\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0460 - mae: 0.2359 - val_loss: 0.0317 - val_mae: 0.1675\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0511 - mae: 0.2462 - val_loss: 0.0316 - val_mae: 0.1668\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0547 - mae: 0.2633 - val_loss: 0.0315 - val_mae: 0.1662\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0553 - mae: 0.2574 - val_loss: 0.0313 - val_mae: 0.1656\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0543 - mae: 0.2578 - val_loss: 0.0312 - val_mae: 0.1650\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0495 - mae: 0.2505 - val_loss: 0.0311 - val_mae: 0.1643\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0405 - mae: 0.2340 - val_loss: 0.0309 - val_mae: 0.1637\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0456 - mae: 0.2251 - val_loss: 0.0308 - val_mae: 0.1631\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0589 - mae: 0.2760 - val_loss: 0.0307 - val_mae: 0.1625\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0578 - mae: 0.2739 - val_loss: 0.0306 - val_mae: 0.1619\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0458 - mae: 0.2446 - val_loss: 0.0304 - val_mae: 0.1613\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0532 - mae: 0.2521 - val_loss: 0.0303 - val_mae: 0.1608\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0522 - mae: 0.2607 - val_loss: 0.0302 - val_mae: 0.1602\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0555 - mae: 0.2649 - val_loss: 0.0301 - val_mae: 0.1597\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0528 - mae: 0.2546 - val_loss: 0.0300 - val_mae: 0.1591\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0453 - mae: 0.2339 - val_loss: 0.0298 - val_mae: 0.1586\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0398 - mae: 0.2231 - val_loss: 0.0297 - val_mae: 0.1581\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0436 - mae: 0.2286 - val_loss: 0.0296 - val_mae: 0.1575\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0470 - mae: 0.2458 - val_loss: 0.0295 - val_mae: 0.1570\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0463 - mae: 0.2354 - val_loss: 0.0294 - val_mae: 0.1565\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0433 - mae: 0.2283 - val_loss: 0.0293 - val_mae: 0.1560\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0473 - mae: 0.2490 - val_loss: 0.0292 - val_mae: 0.1555\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0463 - mae: 0.2365 - val_loss: 0.0290 - val_mae: 0.1550\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0519 - mae: 0.2464 - val_loss: 0.0289 - val_mae: 0.1546\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0516 - mae: 0.2565 - val_loss: 0.0288 - val_mae: 0.1541\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0502 - mae: 0.2442 - val_loss: 0.0287 - val_mae: 0.1536\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0429 - mae: 0.2301 - val_loss: 0.0286 - val_mae: 0.1531\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0448 - mae: 0.2401 - val_loss: 0.0285 - val_mae: 0.1527\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0439 - mae: 0.2312 - val_loss: 0.0284 - val_mae: 0.1522\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0486 - mae: 0.2315 - val_loss: 0.0283 - val_mae: 0.1517\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0406 - mae: 0.2301 - val_loss: 0.0282 - val_mae: 0.1513\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0423 - mae: 0.2397 - val_loss: 0.0281 - val_mae: 0.1508\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0430 - mae: 0.2279 - val_loss: 0.0280 - val_mae: 0.1504\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0470 - mae: 0.2440 - val_loss: 0.0279 - val_mae: 0.1499\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0492 - mae: 0.2485 - val_loss: 0.0278 - val_mae: 0.1495\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0427 - mae: 0.2277 - val_loss: 0.0278 - val_mae: 0.1490\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0512 - mae: 0.2443 - val_loss: 0.0277 - val_mae: 0.1486\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0373 - mae: 0.2208 - val_loss: 0.0276 - val_mae: 0.1481\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0395 - mae: 0.2247 - val_loss: 0.0275 - val_mae: 0.1477\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0499 - mae: 0.2507 - val_loss: 0.0274 - val_mae: 0.1472\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0412 - mae: 0.2248 - val_loss: 0.0273 - val_mae: 0.1468\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0403 - mae: 0.2298 - val_loss: 0.0272 - val_mae: 0.1464\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0401 - mae: 0.2179 - val_loss: 0.0271 - val_mae: 0.1459\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0434 - mae: 0.2279 - val_loss: 0.0271 - val_mae: 0.1455\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0382 - mae: 0.2163 - val_loss: 0.0270 - val_mae: 0.1451\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0432 - mae: 0.2258 - val_loss: 0.0269 - val_mae: 0.1446\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0463 - mae: 0.2355 - val_loss: 0.0268 - val_mae: 0.1442\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0381 - mae: 0.2132 - val_loss: 0.0267 - val_mae: 0.1437\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0432 - mae: 0.2273 - val_loss: 0.0267 - val_mae: 0.1433\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0390 - mae: 0.2203 - val_loss: 0.0266 - val_mae: 0.1429\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0407 - mae: 0.2153 - val_loss: 0.0265 - val_mae: 0.1425\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0384 - mae: 0.2216 - val_loss: 0.0264 - val_mae: 0.1420\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0485 - mae: 0.2528 - val_loss: 0.0264 - val_mae: 0.1416\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0415 - mae: 0.2260 - val_loss: 0.0263 - val_mae: 0.1412\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0454 - mae: 0.2440 - val_loss: 0.0262 - val_mae: 0.1408\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0365 - mae: 0.2119 - val_loss: 0.0261 - val_mae: 0.1404\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0416 - mae: 0.2262 - val_loss: 0.0261 - val_mae: 0.1401\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0427 - mae: 0.2304 - val_loss: 0.0260 - val_mae: 0.1397\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0491 - mae: 0.2495 - val_loss: 0.0259 - val_mae: 0.1393\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0401 - mae: 0.2216 - val_loss: 0.0258 - val_mae: 0.1389\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0443 - mae: 0.2301 - val_loss: 0.0258 - val_mae: 0.1385\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0425 - mae: 0.2289 - val_loss: 0.0257 - val_mae: 0.1381\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0393 - mae: 0.2224 - val_loss: 0.0256 - val_mae: 0.1377\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0401 - mae: 0.2221 - val_loss: 0.0255 - val_mae: 0.1373\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0382 - mae: 0.2226 - val_loss: 0.0255 - val_mae: 0.1368\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0456 - mae: 0.2413 - val_loss: 0.0254 - val_mae: 0.1364\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0410 - mae: 0.2230 - val_loss: 0.0253 - val_mae: 0.1360\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0314 - mae: 0.2048 - val_loss: 0.0253 - val_mae: 0.1356\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0397 - mae: 0.2212 - val_loss: 0.0252 - val_mae: 0.1353\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0370 - mae: 0.2217 - val_loss: 0.0251 - val_mae: 0.1349\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0383 - mae: 0.2137 - val_loss: 0.0251 - val_mae: 0.1346\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0357 - mae: 0.2165 - val_loss: 0.0250 - val_mae: 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:43:59,681] Trial 6 finished with value: 0.13425305485725403 and parameters: {'learning_rate': 5.1964494607677525e-06, 'weight_decay': 1.0486107471664106e-06}. Best is trial 0 with value: 0.08503767848014832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1062 - mae: 0.3705 - val_loss: 1.5243 - val_mae: 1.9996\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.8264 - mae: 2.2930 - val_loss: 0.0635 - val_mae: 0.2880\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0838 - mae: 0.3260 - val_loss: 0.0300 - val_mae: 0.1425\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0191 - mae: 0.1566 - val_loss: 0.0252 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0115 - mae: 0.1190 - val_loss: 0.0211 - val_mae: 0.0966\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0918 - val_loss: 0.0205 - val_mae: 0.0931\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0056 - mae: 0.0770 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0060 - mae: 0.0794 - val_loss: 0.0219 - val_mae: 0.0997\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0198 - val_mae: 0.0906\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0048 - mae: 0.0713 - val_loss: 0.0187 - val_mae: 0.0982\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0847 - val_loss: 0.0196 - val_mae: 0.0855\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0218 - val_mae: 0.1035\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0744 - val_loss: 0.0197 - val_mae: 0.0844\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0630 - val_loss: 0.0194 - val_mae: 0.0817\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0634 - val_loss: 0.0191 - val_mae: 0.0836\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0666 - val_loss: 0.0188 - val_mae: 0.0853\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0185 - val_mae: 0.0868\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0181 - val_mae: 0.0872\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0865\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0305 - val_mae: 0.1862\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0214 - mae: 0.1595 - val_loss: 0.0177 - val_mae: 0.0961\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0755 - val_loss: 0.0183 - val_mae: 0.1086\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0813 - val_loss: 0.0182 - val_mae: 0.1076\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0053 - mae: 0.0843 - val_loss: 0.0179 - val_mae: 0.1061\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0825 - val_loss: 0.0173 - val_mae: 0.1012\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0046 - mae: 0.0785 - val_loss: 0.0168 - val_mae: 0.0941\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0043 - mae: 0.0717 - val_loss: 0.0164 - val_mae: 0.0886\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0039 - mae: 0.0674 - val_loss: 0.0163 - val_mae: 0.0856\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0708 - val_loss: 0.0165 - val_mae: 0.0837\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0164 - val_mae: 0.0824\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0899\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0915\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0683 - val_loss: 0.0175 - val_mae: 0.0907\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0881\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0805\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0606 - val_loss: 0.0172 - val_mae: 0.0795\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0172 - val_mae: 0.0799\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0565 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0596 - val_loss: 0.0171 - val_mae: 0.0817\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0171 - val_mae: 0.0835\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0857\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0876\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0660 - val_loss: 0.0172 - val_mae: 0.0881\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0171 - val_mae: 0.0878\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0869\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0836\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0166 - val_mae: 0.0846\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0864\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0169 - val_mae: 0.0862\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:10,611] Trial 7 finished with value: 0.08398724347352982 and parameters: {'learning_rate': 0.014184182629741164, 'weight_decay': 0.005230149332101854}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1280 - mae: 0.4122 - val_loss: 0.0680 - val_mae: 0.2694\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1083 - mae: 0.3602 - val_loss: 0.0672 - val_mae: 0.2674\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1044 - mae: 0.3699 - val_loss: 0.0664 - val_mae: 0.2653\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1272 - mae: 0.4184 - val_loss: 0.0656 - val_mae: 0.2632\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1139 - mae: 0.3810 - val_loss: 0.0648 - val_mae: 0.2610\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1068 - mae: 0.3695 - val_loss: 0.0640 - val_mae: 0.2589\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1002 - mae: 0.3545 - val_loss: 0.0632 - val_mae: 0.2567\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1106 - mae: 0.3768 - val_loss: 0.0624 - val_mae: 0.2545\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1033 - mae: 0.3462 - val_loss: 0.0617 - val_mae: 0.2523\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0907 - mae: 0.3380 - val_loss: 0.0609 - val_mae: 0.2501\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0968 - mae: 0.3494 - val_loss: 0.0601 - val_mae: 0.2480\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0958 - mae: 0.3487 - val_loss: 0.0594 - val_mae: 0.2459\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1001 - mae: 0.3583 - val_loss: 0.0587 - val_mae: 0.2438\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1226 - mae: 0.3895 - val_loss: 0.0579 - val_mae: 0.2416\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0986 - mae: 0.3643 - val_loss: 0.0572 - val_mae: 0.2395\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1103 - mae: 0.3717 - val_loss: 0.0565 - val_mae: 0.2375\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0844 - mae: 0.3307 - val_loss: 0.0558 - val_mae: 0.2355\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1103 - mae: 0.3777 - val_loss: 0.0551 - val_mae: 0.2334\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1081 - mae: 0.3633 - val_loss: 0.0544 - val_mae: 0.2314\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1128 - mae: 0.3735 - val_loss: 0.0537 - val_mae: 0.2295\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0970 - mae: 0.3542 - val_loss: 0.0531 - val_mae: 0.2277\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0890 - mae: 0.3282 - val_loss: 0.0524 - val_mae: 0.2258\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0993 - mae: 0.3564 - val_loss: 0.0518 - val_mae: 0.2240\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0979 - mae: 0.3591 - val_loss: 0.0512 - val_mae: 0.2222\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1025 - mae: 0.3642 - val_loss: 0.0506 - val_mae: 0.2203\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0779 - mae: 0.3143 - val_loss: 0.0500 - val_mae: 0.2185\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0859 - mae: 0.3358 - val_loss: 0.0494 - val_mae: 0.2167\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0952 - mae: 0.3490 - val_loss: 0.0488 - val_mae: 0.2149\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0870 - mae: 0.3291 - val_loss: 0.0482 - val_mae: 0.2131\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0756 - mae: 0.3048 - val_loss: 0.0477 - val_mae: 0.2114\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0949 - mae: 0.3471 - val_loss: 0.0471 - val_mae: 0.2097\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0852 - mae: 0.3271 - val_loss: 0.0466 - val_mae: 0.2080\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0961 - mae: 0.3453 - val_loss: 0.0461 - val_mae: 0.2063\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0791 - mae: 0.3282 - val_loss: 0.0456 - val_mae: 0.2047\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0833 - mae: 0.3293 - val_loss: 0.0451 - val_mae: 0.2030\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0791 - mae: 0.3125 - val_loss: 0.0446 - val_mae: 0.2014\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0780 - mae: 0.3062 - val_loss: 0.0441 - val_mae: 0.1999\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0784 - mae: 0.3052 - val_loss: 0.0437 - val_mae: 0.1983\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0776 - mae: 0.3163 - val_loss: 0.0432 - val_mae: 0.1968\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0798 - mae: 0.3222 - val_loss: 0.0428 - val_mae: 0.1954\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0718 - mae: 0.3006 - val_loss: 0.0424 - val_mae: 0.1939\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0686 - mae: 0.2934 - val_loss: 0.0420 - val_mae: 0.1925\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0849 - mae: 0.3256 - val_loss: 0.0416 - val_mae: 0.1911\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0800 - mae: 0.3244 - val_loss: 0.0412 - val_mae: 0.1897\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0889 - mae: 0.3347 - val_loss: 0.0408 - val_mae: 0.1883\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0827 - mae: 0.3322 - val_loss: 0.0404 - val_mae: 0.1869\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0906 - mae: 0.3501 - val_loss: 0.0400 - val_mae: 0.1856\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0772 - mae: 0.3225 - val_loss: 0.0397 - val_mae: 0.1842\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0780 - mae: 0.3125 - val_loss: 0.0393 - val_mae: 0.1829\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0810 - mae: 0.3194 - val_loss: 0.0389 - val_mae: 0.1816\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0903 - mae: 0.3428 - val_loss: 0.0386 - val_mae: 0.1803\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0758 - mae: 0.3102 - val_loss: 0.0383 - val_mae: 0.1790\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0761 - mae: 0.3155 - val_loss: 0.0379 - val_mae: 0.1776\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0650 - mae: 0.2860 - val_loss: 0.0376 - val_mae: 0.1764\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0816 - mae: 0.3103 - val_loss: 0.0373 - val_mae: 0.1751\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0704 - mae: 0.2967 - val_loss: 0.0370 - val_mae: 0.1738\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0744 - mae: 0.3052 - val_loss: 0.0367 - val_mae: 0.1726\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0804 - mae: 0.3269 - val_loss: 0.0364 - val_mae: 0.1714\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0828 - mae: 0.3176 - val_loss: 0.0361 - val_mae: 0.1703\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0746 - mae: 0.2933 - val_loss: 0.0358 - val_mae: 0.1691\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0750 - mae: 0.3099 - val_loss: 0.0355 - val_mae: 0.1679\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0812 - mae: 0.3206 - val_loss: 0.0352 - val_mae: 0.1668\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0729 - mae: 0.3129 - val_loss: 0.0349 - val_mae: 0.1657\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0707 - mae: 0.2940 - val_loss: 0.0346 - val_mae: 0.1645\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0716 - mae: 0.2991 - val_loss: 0.0343 - val_mae: 0.1634\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0680 - mae: 0.2973 - val_loss: 0.0340 - val_mae: 0.1623\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0612 - mae: 0.2814 - val_loss: 0.0338 - val_mae: 0.1612\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0679 - mae: 0.2945 - val_loss: 0.0335 - val_mae: 0.1601\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0668 - mae: 0.2900 - val_loss: 0.0333 - val_mae: 0.1591\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0695 - mae: 0.2870 - val_loss: 0.0330 - val_mae: 0.1581\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0582 - mae: 0.2646 - val_loss: 0.0328 - val_mae: 0.1571\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0616 - mae: 0.2812 - val_loss: 0.0325 - val_mae: 0.1561\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0700 - mae: 0.3017 - val_loss: 0.0323 - val_mae: 0.1551\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0616 - mae: 0.2787 - val_loss: 0.0321 - val_mae: 0.1541\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0671 - mae: 0.2853 - val_loss: 0.0319 - val_mae: 0.1532\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0596 - mae: 0.2795 - val_loss: 0.0316 - val_mae: 0.1522\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0622 - mae: 0.2823 - val_loss: 0.0314 - val_mae: 0.1513\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0735 - mae: 0.3065 - val_loss: 0.0312 - val_mae: 0.1504\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0635 - mae: 0.2795 - val_loss: 0.0310 - val_mae: 0.1495\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2749 - val_loss: 0.0308 - val_mae: 0.1486\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0662 - mae: 0.2838 - val_loss: 0.0306 - val_mae: 0.1477\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0534 - mae: 0.2544 - val_loss: 0.0304 - val_mae: 0.1469\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0828 - mae: 0.3290 - val_loss: 0.0302 - val_mae: 0.1461\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0675 - mae: 0.2992 - val_loss: 0.0300 - val_mae: 0.1454\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0686 - mae: 0.2989 - val_loss: 0.0298 - val_mae: 0.1446\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0649 - mae: 0.2956 - val_loss: 0.0297 - val_mae: 0.1438\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0565 - mae: 0.2603 - val_loss: 0.0295 - val_mae: 0.1431\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0536 - mae: 0.2631 - val_loss: 0.0293 - val_mae: 0.1424\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0722 - mae: 0.3071 - val_loss: 0.0291 - val_mae: 0.1418\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0728 - mae: 0.3090 - val_loss: 0.0290 - val_mae: 0.1410\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0600 - mae: 0.2791 - val_loss: 0.0288 - val_mae: 0.1403\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0579 - mae: 0.2718 - val_loss: 0.0287 - val_mae: 0.1396\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0608 - mae: 0.2904 - val_loss: 0.0285 - val_mae: 0.1390\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0554 - mae: 0.2578 - val_loss: 0.0284 - val_mae: 0.1383\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0625 - mae: 0.2777 - val_loss: 0.0282 - val_mae: 0.1377\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0525 - mae: 0.2536 - val_loss: 0.0281 - val_mae: 0.1372\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0600 - mae: 0.2790 - val_loss: 0.0279 - val_mae: 0.1366\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0613 - mae: 0.2781 - val_loss: 0.0278 - val_mae: 0.1361\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0551 - mae: 0.2625 - val_loss: 0.0277 - val_mae: 0.1356\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0541 - mae: 0.2593 - val_loss: 0.0275 - val_mae: 0.1351\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0633 - mae: 0.2854 - val_loss: 0.0274 - val_mae: 0.1345\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0544 - mae: 0.2611 - val_loss: 0.0273 - val_mae: 0.1339\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0584 - mae: 0.2786 - val_loss: 0.0271 - val_mae: 0.1333\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0602 - mae: 0.2728 - val_loss: 0.0270 - val_mae: 0.1327\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0623 - mae: 0.2835 - val_loss: 0.0269 - val_mae: 0.1321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0490 - mae: 0.2462 - val_loss: 0.0267 - val_mae: 0.1315\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0558 - mae: 0.2694 - val_loss: 0.0266 - val_mae: 0.1310\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0554 - mae: 0.2739 - val_loss: 0.0265 - val_mae: 0.1305\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0525 - mae: 0.2659 - val_loss: 0.0263 - val_mae: 0.1300\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0554 - mae: 0.2656 - val_loss: 0.0262 - val_mae: 0.1295\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0541 - mae: 0.2641 - val_loss: 0.0261 - val_mae: 0.1290\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0604 - mae: 0.2775 - val_loss: 0.0259 - val_mae: 0.1285\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0595 - mae: 0.2733 - val_loss: 0.0258 - val_mae: 0.1281\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0635 - mae: 0.2840 - val_loss: 0.0257 - val_mae: 0.1276\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0585 - mae: 0.2707 - val_loss: 0.0256 - val_mae: 0.1271\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0603 - mae: 0.2846 - val_loss: 0.0255 - val_mae: 0.1267\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0529 - mae: 0.2594 - val_loss: 0.0254 - val_mae: 0.1262\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0613 - mae: 0.2813 - val_loss: 0.0253 - val_mae: 0.1257\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0532 - mae: 0.2652 - val_loss: 0.0252 - val_mae: 0.1252\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0534 - mae: 0.2563 - val_loss: 0.0251 - val_mae: 0.1247\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0626 - mae: 0.2752 - val_loss: 0.0250 - val_mae: 0.1243\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0533 - mae: 0.2634 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0483 - mae: 0.2409 - val_loss: 0.0248 - val_mae: 0.1235\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0619 - mae: 0.2803 - val_loss: 0.0247 - val_mae: 0.1231\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0604 - mae: 0.2747 - val_loss: 0.0246 - val_mae: 0.1227\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0522 - mae: 0.2580 - val_loss: 0.0246 - val_mae: 0.1224\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0550 - mae: 0.2568 - val_loss: 0.0245 - val_mae: 0.1220\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0447 - mae: 0.2404 - val_loss: 0.0244 - val_mae: 0.1217\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0522 - mae: 0.2591 - val_loss: 0.0243 - val_mae: 0.1214\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0522 - mae: 0.2580 - val_loss: 0.0242 - val_mae: 0.1210\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0541 - mae: 0.2671 - val_loss: 0.0242 - val_mae: 0.1206\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0595 - mae: 0.2750 - val_loss: 0.0241 - val_mae: 0.1203\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0484 - mae: 0.2490 - val_loss: 0.0240 - val_mae: 0.1199\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0416 - mae: 0.2360 - val_loss: 0.0239 - val_mae: 0.1196\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0623 - mae: 0.2877 - val_loss: 0.0238 - val_mae: 0.1192\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0524 - mae: 0.2535 - val_loss: 0.0237 - val_mae: 0.1188\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0596 - mae: 0.2739 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0472 - mae: 0.2404 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0548 - mae: 0.2718 - val_loss: 0.0234 - val_mae: 0.1177\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0454 - mae: 0.2365 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0532 - mae: 0.2636 - val_loss: 0.0233 - val_mae: 0.1170\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0552 - mae: 0.2608 - val_loss: 0.0232 - val_mae: 0.1167\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0472 - mae: 0.2383 - val_loss: 0.0232 - val_mae: 0.1163\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0506 - mae: 0.2535 - val_loss: 0.0231 - val_mae: 0.1160\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0421 - mae: 0.2259 - val_loss: 0.0230 - val_mae: 0.1157\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0583 - mae: 0.2675 - val_loss: 0.0230 - val_mae: 0.1153\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0521 - mae: 0.2593 - val_loss: 0.0229 - val_mae: 0.1150\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0511 - mae: 0.2540 - val_loss: 0.0228 - val_mae: 0.1147\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0452 - mae: 0.2469 - val_loss: 0.0228 - val_mae: 0.1144\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0500 - mae: 0.2484 - val_loss: 0.0227 - val_mae: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:21,584] Trial 8 finished with value: 0.11417494714260101 and parameters: {'learning_rate': 9.723330078432912e-06, 'weight_decay': 0.006508443549129702}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0577 - mae: 0.2716 - val_loss: 0.9041 - val_mae: 1.3223\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0780 - mae: 1.5172 - val_loss: 0.3775 - val_mae: 0.7531\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4531 - mae: 0.8440 - val_loss: 0.0386 - val_mae: 0.1921\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0256 - mae: 0.1799 - val_loss: 1.2638 - val_mae: 1.7166\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5144 - mae: 1.9834 - val_loss: 0.1351 - val_mae: 0.4643\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0939 - mae: 0.3779 - val_loss: 0.1173 - val_mae: 0.4360\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1504 - mae: 0.4936 - val_loss: 0.0260 - val_mae: 0.1139\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1060\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0073 - mae: 0.0881 - val_loss: 0.0239 - val_mae: 0.1014\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.0972\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0217 - val_mae: 0.0935\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0063 - mae: 0.0767 - val_loss: 0.0205 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055 - mae: 0.0713 - val_loss: 0.0194 - val_mae: 0.0869\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0691 - val_loss: 0.0185 - val_mae: 0.0839\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0177 - val_mae: 0.0829\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0720 - val_loss: 0.0166 - val_mae: 0.0855\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0719 - val_loss: 0.0163 - val_mae: 0.0879\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0711 - val_loss: 0.0160 - val_mae: 0.0899\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0044 - mae: 0.0722 - val_loss: 0.0159 - val_mae: 0.0913\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0043 - mae: 0.0723 - val_loss: 0.0159 - val_mae: 0.0926\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0735 - val_loss: 0.0161 - val_mae: 0.0936\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0735 - val_loss: 0.0164 - val_mae: 0.0957\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0043 - mae: 0.0743 - val_loss: 0.0168 - val_mae: 0.0984\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0753 - val_loss: 0.0173 - val_mae: 0.1007\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0047 - mae: 0.0787 - val_loss: 0.0176 - val_mae: 0.1019\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0177 - val_mae: 0.1021\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0733 - val_loss: 0.0177 - val_mae: 0.1011\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0746 - val_loss: 0.0176 - val_mae: 0.0990\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0705 - val_loss: 0.0173 - val_mae: 0.0965\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0042 - mae: 0.0695 - val_loss: 0.0171 - val_mae: 0.0937\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0669 - val_loss: 0.0169 - val_mae: 0.0911\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0041 - mae: 0.0677 - val_loss: 0.0168 - val_mae: 0.0884\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0041 - mae: 0.0652 - val_loss: 0.0167 - val_mae: 0.0865\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0637 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0824\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0818\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0174 - val_mae: 0.0814\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0585 - val_loss: 0.0175 - val_mae: 0.0814\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0628 - val_loss: 0.0175 - val_mae: 0.0818\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0819\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0824\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0167 - val_mae: 0.0840\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0173 - val_mae: 0.0856\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0853\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0829\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0831\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0857\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0855\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0858\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0856\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0853\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:32,995] Trial 9 finished with value: 0.08421843498945236 and parameters: {'learning_rate': 0.023987288201424622, 'weight_decay': 8.744533594516013e-09}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1150 - mae: 0.3878 - val_loss: 0.1797 - val_mae: 0.4984\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2460 - mae: 0.5834 - val_loss: 0.0543 - val_mae: 0.2495\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0716 - mae: 0.2905 - val_loss: 0.0282 - val_mae: 0.1518\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0209 - mae: 0.1603 - val_loss: 0.0235 - val_mae: 0.1187\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0107 - mae: 0.1123 - val_loss: 0.0226 - val_mae: 0.1073\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0223 - val_mae: 0.1040\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1032\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0222 - val_mae: 0.1021\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0075 - mae: 0.0892 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.0994\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0219 - val_mae: 0.0974\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0066 - mae: 0.0815 - val_loss: 0.0214 - val_mae: 0.0949\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0063 - mae: 0.0785 - val_loss: 0.0207 - val_mae: 0.0920\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0194 - val_mae: 0.0892\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0815 - val_loss: 0.0189 - val_mae: 0.0879\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0049 - mae: 0.0712 - val_loss: 0.0187 - val_mae: 0.0862\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0702 - val_loss: 0.0185 - val_mae: 0.0848\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0182 - val_mae: 0.0837\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0826\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0179 - val_mae: 0.0814\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0797\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0795\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0171 - val_mae: 0.0790\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0789\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0160 - val_mae: 0.0792\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0529 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0779\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0157 - val_mae: 0.0783\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0152 - val_mae: 0.0797\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0153 - val_mae: 0.0792\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0158 - val_mae: 0.0779\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0508 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0511 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0154 - val_mae: 0.0781\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0150 - val_mae: 0.0783\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0155 - val_mae: 0.0779\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0155 - val_mae: 0.0777\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0155 - val_mae: 0.0772\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0152 - val_mae: 0.0770\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0149 - val_mae: 0.0770\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0145 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0532 - val_loss: 0.0146 - val_mae: 0.0777\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0147 - val_mae: 0.0772\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0504 - val_loss: 0.0147 - val_mae: 0.0767\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0146 - val_mae: 0.0770\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0493 - val_loss: 0.0146 - val_mae: 0.0772\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - mae: 0.0441 - val_loss: 0.0148 - val_mae: 0.0766\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0460 - val_loss: 0.0149 - val_mae: 0.0763\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0148 - val_mae: 0.0759\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0455 - val_loss: 0.0144 - val_mae: 0.0778\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0779\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0456 - val_loss: 0.0146 - val_mae: 0.0770\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0463 - val_loss: 0.0149 - val_mae: 0.0765\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0147 - val_mae: 0.0769\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0146 - val_mae: 0.0774\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0143 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0141 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0139 - val_mae: 0.0811\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0140 - val_mae: 0.0802\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0449 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0154 - val_mae: 0.0784\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0436 - val_loss: 0.0152 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0144 - val_mae: 0.0787\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0398 - val_loss: 0.0138 - val_mae: 0.0819\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0136 - val_mae: 0.0837\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0142 - val_mae: 0.0788\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0155 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0425 - val_loss: 0.0161 - val_mae: 0.0808\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0017 - mae: 0.0374 - val_loss: 0.0163 - val_mae: 0.0814\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0422 - val_loss: 0.0160 - val_mae: 0.0807\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0417 - val_loss: 0.0153 - val_mae: 0.0788\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0140 - val_mae: 0.0791\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0135 - val_mae: 0.0834\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0134 - val_mae: 0.0845\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0135 - val_mae: 0.0835\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0360 - val_loss: 0.0140 - val_mae: 0.0798\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0405 - val_loss: 0.0146 - val_mae: 0.0783\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0385 - val_loss: 0.0149 - val_mae: 0.0785\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0371 - val_loss: 0.0150 - val_mae: 0.0788\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0389 - val_loss: 0.0145 - val_mae: 0.0784\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - mae: 0.0329 - val_loss: 0.0142 - val_mae: 0.0790\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0385 - val_loss: 0.0139 - val_mae: 0.0804\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0140 - val_mae: 0.0804\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0141 - val_mae: 0.0803\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0140 - val_mae: 0.0803\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0355 - val_loss: 0.0142 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0393 - val_loss: 0.0146 - val_mae: 0.0797\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0367 - val_loss: 0.0147 - val_mae: 0.0803\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0144 - val_mae: 0.0810\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0138 - val_mae: 0.0828\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0141 - val_mae: 0.0814\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0371 - val_loss: 0.0144 - val_mae: 0.0802\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0150 - val_mae: 0.0808\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0150 - val_mae: 0.0813\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0338 - val_loss: 0.0143 - val_mae: 0.0814\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.0140 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0380 - val_loss: 0.0140 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0442 - val_loss: 0.0144 - val_mae: 0.0803\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0146 - val_mae: 0.0801\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0144 - val_mae: 0.0803\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0340 - val_loss: 0.0141 - val_mae: 0.0812\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0138 - val_mae: 0.0824\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0141 - val_mae: 0.0819\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0368 - val_loss: 0.0141 - val_mae: 0.0823\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0323 - val_loss: 0.0142 - val_mae: 0.0823\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0144 - val_mae: 0.0820\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0328 - val_loss: 0.0144 - val_mae: 0.0823\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0014 - mae: 0.0352 - val_loss: 0.0145 - val_mae: 0.0827\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0366 - val_loss: 0.0144 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0365 - val_loss: 0.0143 - val_mae: 0.0832\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0141 - val_mae: 0.0831\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0345 - val_loss: 0.0147 - val_mae: 0.0823\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0014 - mae: 0.0345 - val_loss: 0.0152 - val_mae: 0.0829\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0152 - val_mae: 0.0826\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0379 - val_loss: 0.0145 - val_mae: 0.0816\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - mae: 0.0347 - val_loss: 0.0142 - val_mae: 0.0823\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0139 - val_mae: 0.0848\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0138 - val_mae: 0.0868\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0138 - val_mae: 0.0867\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.0141 - val_mae: 0.0841\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0148 - val_mae: 0.0827\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0155 - val_mae: 0.0836\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0337 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0318 - val_loss: 0.0160 - val_mae: 0.0845\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0385 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.0153 - val_mae: 0.0832\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0379 - val_loss: 0.0142 - val_mae: 0.0830\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7203e-04 - mae: 0.0290 - val_loss: 0.0138 - val_mae: 0.0857\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - mae: 0.0386 - val_loss: 0.0143 - val_mae: 0.0831\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0339 - val_loss: 0.0150 - val_mae: 0.0831\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0348 - val_loss: 0.0153 - val_mae: 0.0841\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0371 - val_loss: 0.0150 - val_mae: 0.0838\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0340 - val_loss: 0.0144 - val_mae: 0.0840\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.0141 - val_mae: 0.0858\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0411 - val_loss: 0.0147 - val_mae: 0.0846\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - mae: 0.0336 - val_loss: 0.0156 - val_mae: 0.0859\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0158 - val_mae: 0.0863\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0156 - val_mae: 0.0852\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0418 - val_loss: 0.0150 - val_mae: 0.0832\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0142 - val_mae: 0.0847\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0350 - val_loss: 0.0139 - val_mae: 0.0867\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0138 - val_mae: 0.0872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:43,908] Trial 10 finished with value: 0.08719658851623535 and parameters: {'learning_rate': 0.0031618314586241364, 'weight_decay': 0.004302204021535236}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0557 - mae: 0.2719 - val_loss: 2.4155 - val_mae: 2.9046\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.5804 - mae: 3.0568 - val_loss: 0.1307 - val_mae: 0.4471\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1478 - mae: 0.4526 - val_loss: 0.0511 - val_mae: 0.2507\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0636 - mae: 0.2854 - val_loss: 0.0323 - val_mae: 0.1698\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0184 - mae: 0.1540 - val_loss: 0.0270 - val_mae: 0.1373\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1103\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0228 - val_mae: 0.1041\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0074 - mae: 0.0888 - val_loss: 0.0216 - val_mae: 0.0968\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0065 - mae: 0.0808 - val_loss: 0.0206 - val_mae: 0.0970\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0059 - mae: 0.0787 - val_loss: 0.0201 - val_mae: 0.1028\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0053 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.1100\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0792 - val_loss: 0.0203 - val_mae: 0.1197\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0051 - mae: 0.0782 - val_loss: 0.0191 - val_mae: 0.1128\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0050 - mae: 0.0775 - val_loss: 0.0171 - val_mae: 0.0931\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0721 - val_loss: 0.0173 - val_mae: 0.1015\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.1065\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0171 - val_mae: 0.1036\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0704 - val_loss: 0.0166 - val_mae: 0.0942\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0703 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0165 - val_mae: 0.0907\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0629 - val_loss: 0.0179 - val_mae: 0.1157\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0809 - val_loss: 0.0175 - val_mae: 0.1100\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0756 - val_loss: 0.0167 - val_mae: 0.0886\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0693 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0730 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0998\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0993\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0929\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0919\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0665 - val_loss: 0.0169 - val_mae: 0.0951\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0965\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0969\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0984\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.1000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0956\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0895\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0168 - val_mae: 0.0870\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0167 - val_mae: 0.0917\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.1011\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.1014\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0999\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0955\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0932\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0898\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0882\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0552 - val_loss: 0.0170 - val_mae: 0.0889\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0906\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0170 - val_mae: 0.0963\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0170 - val_mae: 0.1021\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.1000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0974\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0692 - val_loss: 0.0169 - val_mae: 0.0977\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0984\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0672 - val_loss: 0.0168 - val_mae: 0.0993\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0710 - val_loss: 0.0167 - val_mae: 0.0970\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0681 - val_loss: 0.0167 - val_mae: 0.0925\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0541 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0166 - val_mae: 0.0873\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0898\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0877\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0527 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0168 - val_mae: 0.0924\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0934\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0169 - val_mae: 0.0935\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0508 - val_loss: 0.0169 - val_mae: 0.0938\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0949\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0170 - val_mae: 0.0957\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0971\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0988\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0994\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.0973\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0949\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0918\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0167 - val_mae: 0.0926\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0970\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0166 - val_mae: 0.0943\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0166 - val_mae: 0.0929\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0166 - val_mae: 0.0923\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0166 - val_mae: 0.0929\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0167 - val_mae: 0.0950\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0964\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.0985\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0981\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0170 - val_mae: 0.0954\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0170 - val_mae: 0.0945\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0943\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0957\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0171 - val_mae: 0.1003\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.1020\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0982\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0166 - val_mae: 0.0945\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0166 - val_mae: 0.0937\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0166 - val_mae: 0.0946\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0987\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0170 - val_mae: 0.1030\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0998\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0167 - val_mae: 0.0960\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0167 - val_mae: 0.0935\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0168 - val_mae: 0.0948\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0169 - val_mae: 0.0959\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0965\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0171 - val_mae: 0.0955\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0171 - val_mae: 0.0950\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0171 - val_mae: 0.0950\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0171 - val_mae: 0.0934\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0924\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0171 - val_mae: 0.0943\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0172 - val_mae: 0.0987\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0173 - val_mae: 0.1021\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0994\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0962\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0167 - val_mae: 0.0949\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.0970\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.1014\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0551 - val_loss: 0.0168 - val_mae: 0.1014\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0167 - val_mae: 0.0983\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0958\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0167 - val_mae: 0.0941\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0942\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0526 - val_loss: 0.0168 - val_mae: 0.0980\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0998\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0969\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0170 - val_mae: 0.0944\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0171 - val_mae: 0.0932\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0171 - val_mae: 0.0928\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0511 - val_loss: 0.0173 - val_mae: 0.0997\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0997\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0172 - val_mae: 0.0966\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0539 - val_loss: 0.0172 - val_mae: 0.0966\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0172 - val_mae: 0.0967\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0173 - val_mae: 0.0967\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0173 - val_mae: 0.0968\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0548 - val_loss: 0.0174 - val_mae: 0.1019\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0175 - val_mae: 0.1040\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0568 - val_loss: 0.0173 - val_mae: 0.1001\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:44:54,915] Trial 11 finished with value: 0.09484092891216278 and parameters: {'learning_rate': 0.020044232494369173, 'weight_decay': 7.740953401860817e-09}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0445 - mae: 0.2293 - val_loss: 1.9428 - val_mae: 2.3706\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2644 - mae: 2.7229 - val_loss: 0.3995 - val_mae: 0.8313\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5026 - mae: 0.9245 - val_loss: 0.0725 - val_mae: 0.2917\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1012 - mae: 0.3625 - val_loss: 0.0332 - val_mae: 0.1811\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0305 - mae: 0.1900 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0159 - mae: 0.1334 - val_loss: 0.0222 - val_mae: 0.1045\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0193 - val_mae: 0.0887\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - mae: 0.0856 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0785 - val_loss: 0.0180 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0048 - mae: 0.0697 - val_loss: 0.0186 - val_mae: 0.0957\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0066 - mae: 0.0894 - val_loss: 0.0190 - val_mae: 0.1207\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0074 - mae: 0.1001 - val_loss: 0.0179 - val_mae: 0.1071\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0049 - mae: 0.0789 - val_loss: 0.0169 - val_mae: 0.0892\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0816 - val_loss: 0.0173 - val_mae: 0.0891\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0764 - val_loss: 0.0178 - val_mae: 0.0967\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0055 - mae: 0.0821 - val_loss: 0.0179 - val_mae: 0.1001\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - mae: 0.0861 - val_loss: 0.0170 - val_mae: 0.0874\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0045 - mae: 0.0733 - val_loss: 0.0170 - val_mae: 0.0892\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0055 - mae: 0.0792 - val_loss: 0.0184 - val_mae: 0.1144\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.1012 - val_loss: 0.0172 - val_mae: 0.1005\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0053 - mae: 0.0817 - val_loss: 0.0175 - val_mae: 0.0902\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0058 - mae: 0.0839 - val_loss: 0.0171 - val_mae: 0.0861\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0656 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0177 - val_mae: 0.0970\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mae: 0.0766 - val_loss: 0.0171 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0831\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0047 - mae: 0.0707 - val_loss: 0.0183 - val_mae: 0.0856\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0707 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0885\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0871\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0171 - val_mae: 0.0861\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0665 - val_loss: 0.0173 - val_mae: 0.0889\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0716 - val_loss: 0.0169 - val_mae: 0.0884\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0699 - val_loss: 0.0168 - val_mae: 0.0888\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0038 - mae: 0.0674 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0710 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0035 - mae: 0.0619 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0707 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0874\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0169 - val_mae: 0.0879\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0662 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0845\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0634 - val_loss: 0.0166 - val_mae: 0.0876\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0166 - val_mae: 0.0869\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0166 - val_mae: 0.0881\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0883\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0884\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0895\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0914\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0910\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0903\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0907\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0917\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0925\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0913\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0168 - val_mae: 0.0898\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0890\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0896\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0167 - val_mae: 0.0916\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0927\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0930\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0924\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0168 - val_mae: 0.0919\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0925\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0947\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0568 - val_loss: 0.0168 - val_mae: 0.0967\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0169 - val_mae: 0.0976\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0981\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0958\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0551 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0957\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0958\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0170 - val_mae: 0.0972\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0992\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0981\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0172 - val_mae: 0.0967\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0972\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0995\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.1006\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0994\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0174 - val_mae: 0.0990\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0175 - val_mae: 0.0992\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0173 - val_mae: 0.1004\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.1010\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0174 - val_mae: 0.1015\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0173 - val_mae: 0.0998\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0173 - val_mae: 0.0994\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0571 - val_loss: 0.0173 - val_mae: 0.0995\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0580 - val_loss: 0.0174 - val_mae: 0.0990\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0173 - val_mae: 0.0983\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0550 - val_loss: 0.0171 - val_mae: 0.0982\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0171 - val_mae: 0.0993\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0171 - val_mae: 0.0984\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0170 - val_mae: 0.0971\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0172 - val_mae: 0.0973\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0027 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0985\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0511 - val_loss: 0.0171 - val_mae: 0.1000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0172 - val_mae: 0.1008\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0994\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0173 - val_mae: 0.0989\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - mae: 0.0535 - val_loss: 0.0174 - val_mae: 0.0987\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0174 - val_mae: 0.0983\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0495 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0172 - val_mae: 0.0985\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0173 - val_mae: 0.0984\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0173 - val_mae: 0.0978\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0976\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0970\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0173 - val_mae: 0.0974\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0174 - val_mae: 0.0982\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0174 - val_mae: 0.0974\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0532 - val_loss: 0.0175 - val_mae: 0.0973\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0179 - val_mae: 0.0981\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0177 - val_mae: 0.0973\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0490 - val_loss: 0.0175 - val_mae: 0.0986\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0544 - val_loss: 0.0180 - val_mae: 0.1044\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0595 - val_loss: 0.0176 - val_mae: 0.0999\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0578 - val_loss: 0.0175 - val_mae: 0.0967\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0497 - val_loss: 0.0179 - val_mae: 0.0982\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0960\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0990\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0587 - val_loss: 0.0175 - val_mae: 0.1028\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0954\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0175 - val_mae: 0.0952\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0187 - val_mae: 0.1024\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0185 - val_mae: 0.1008\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0173 - val_mae: 0.0958\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0982\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0979\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0032 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0965\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0558 - val_loss: 0.0178 - val_mae: 0.0974\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0026 - mae: 0.0534 - val_loss: 0.0177 - val_mae: 0.0955\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0172 - val_mae: 0.0931\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0581 - val_loss: 0.0171 - val_mae: 0.0929\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0523 - val_loss: 0.0171 - val_mae: 0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:06,648] Trial 12 finished with value: 0.09233224391937256 and parameters: {'learning_rate': 0.02287608448294248, 'weight_decay': 0.005543414928351051}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0572 - mae: 0.2693 - val_loss: 0.0904 - val_mae: 0.3380\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0917 - mae: 0.3289 - val_loss: 0.0193 - val_mae: 0.1032\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0083 - mae: 0.0961 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0075 - mae: 0.0899 - val_loss: 0.0231 - val_mae: 0.1065\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0827 - val_loss: 0.0213 - val_mae: 0.0941\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0203 - val_mae: 0.0892\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0195 - val_mae: 0.0894\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0813 - val_loss: 0.0189 - val_mae: 0.0884\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - mae: 0.0806 - val_loss: 0.0186 - val_mae: 0.0851\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0668 - val_loss: 0.0185 - val_mae: 0.0837\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0184 - val_mae: 0.0835\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0182 - val_mae: 0.0835\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0180 - val_mae: 0.0837\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0176 - val_mae: 0.0860\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0044 - mae: 0.0683 - val_loss: 0.0174 - val_mae: 0.0877\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0038 - mae: 0.0655 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0174 - val_mae: 0.0818\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0166 - val_mae: 0.0896\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0601 - val_loss: 0.0164 - val_mae: 0.0955\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0801\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0803\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0816\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0161 - val_mae: 0.0851\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0612 - val_loss: 0.0157 - val_mae: 0.0959\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0655 - val_loss: 0.0157 - val_mae: 0.0905\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0668 - val_loss: 0.0162 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0560 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0159 - val_mae: 0.0845\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0156 - val_mae: 0.0910\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0650 - val_loss: 0.0155 - val_mae: 0.0948\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0639 - val_loss: 0.0156 - val_mae: 0.0878\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0161 - val_mae: 0.0821\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0158 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0155 - val_mae: 0.0886\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0029 - mae: 0.0587 - val_loss: 0.0154 - val_mae: 0.0898\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0575 - val_loss: 0.0153 - val_mae: 0.0918\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - mae: 0.0618 - val_loss: 0.0154 - val_mae: 0.0880\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0579 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0157 - val_mae: 0.0820\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0156 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0153 - val_mae: 0.0872\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0559 - val_loss: 0.0152 - val_mae: 0.0904\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0152 - val_mae: 0.0899\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0587 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0549 - val_loss: 0.0157 - val_mae: 0.0796\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0156 - val_mae: 0.0807\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0152 - val_mae: 0.0873\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0519 - val_loss: 0.0152 - val_mae: 0.0982\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0549 - val_loss: 0.0150 - val_mae: 0.0942\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0152 - val_mae: 0.0836\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0534 - val_loss: 0.0154 - val_mae: 0.0791\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0512 - val_loss: 0.0151 - val_mae: 0.0813\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0148 - val_mae: 0.0909\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0541 - val_loss: 0.0148 - val_mae: 0.0883\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0506 - val_loss: 0.0149 - val_mae: 0.0835\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0149 - val_mae: 0.0834\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0148 - val_mae: 0.0855\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0496 - val_loss: 0.0147 - val_mae: 0.0901\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0497 - val_loss: 0.0148 - val_mae: 0.0919\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0147 - val_mae: 0.0904\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0147 - val_mae: 0.0867\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - mae: 0.0495 - val_loss: 0.0147 - val_mae: 0.0848\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0146 - val_mae: 0.0861\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0516 - val_loss: 0.0145 - val_mae: 0.0899\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0144 - val_mae: 0.0889\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0143 - val_mae: 0.0863\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0437 - val_loss: 0.0143 - val_mae: 0.0904\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0143 - val_mae: 0.0941\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0142 - val_mae: 0.0896\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0142 - val_mae: 0.0849\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0142 - val_mae: 0.0847\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0143 - val_mae: 0.0942\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0143 - val_mae: 0.0905\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0144 - val_mae: 0.0843\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0450 - val_loss: 0.0145 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0147 - val_mae: 0.0969\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0499 - val_loss: 0.0146 - val_mae: 0.0946\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0145 - val_mae: 0.0880\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0144 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0144 - val_mae: 0.0913\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0142 - val_mae: 0.0898\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0019 - mae: 0.0443 - val_loss: 0.0143 - val_mae: 0.0960\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0147 - val_mae: 0.1022\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0145 - val_mae: 0.0964\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0144 - val_mae: 0.0919\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0412 - val_loss: 0.0145 - val_mae: 0.0913\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0145 - val_mae: 0.0936\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0146 - val_mae: 0.0970\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0144 - val_mae: 0.0974\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0138 - val_mae: 0.0867\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0138 - val_mae: 0.0910\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0137 - val_mae: 0.0889\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0139 - val_mae: 0.0953\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0137 - val_mae: 0.0914\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0138 - val_mae: 0.0929\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0143 - val_mae: 0.1002\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0139 - val_mae: 0.0913\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0143 - val_mae: 0.0940\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0144 - val_mae: 0.0950\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0150 - val_mae: 0.1015\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0942\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0138 - val_mae: 0.0874\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0442 - val_loss: 0.0139 - val_mae: 0.0923\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0148 - val_mae: 0.1044\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0435 - val_loss: 0.0167 - val_mae: 0.1214\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0550 - val_loss: 0.0141 - val_mae: 0.0957\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0412 - val_loss: 0.0137 - val_mae: 0.0879\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0139 - val_mae: 0.0904\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0374 - val_loss: 0.0149 - val_mae: 0.1032\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0393 - val_loss: 0.0165 - val_mae: 0.1161\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0147 - val_mae: 0.0966\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0441 - val_loss: 0.0143 - val_mae: 0.0792\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0473 - val_loss: 0.0146 - val_mae: 0.0768\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0471 - val_loss: 0.0143 - val_mae: 0.0855\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0162 - val_mae: 0.1088\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0166 - val_mae: 0.1104\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0153 - val_mae: 0.0952\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0148 - val_mae: 0.0858\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0405 - val_loss: 0.0149 - val_mae: 0.0852\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0456 - val_loss: 0.0154 - val_mae: 0.0918\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 0.0161 - val_mae: 0.0987\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.1041\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0463 - val_loss: 0.0165 - val_mae: 0.1022\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0447 - val_loss: 0.0160 - val_mae: 0.0968\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0368 - val_loss: 0.0156 - val_mae: 0.0921\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0154 - val_mae: 0.0903\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.0154 - val_mae: 0.0918\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0156 - val_mae: 0.0949\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0389 - val_loss: 0.0161 - val_mae: 0.1011\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0426 - val_loss: 0.0157 - val_mae: 0.0981\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0410 - val_loss: 0.0155 - val_mae: 0.0966\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0359 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0453 - val_loss: 0.0152 - val_mae: 0.0942\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0154 - val_mae: 0.0972\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0422 - val_loss: 0.0160 - val_mae: 0.1036\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0014 - mae: 0.0417 - val_loss: 0.0163 - val_mae: 0.1059\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0160 - val_mae: 0.1032\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.6676e-04 - mae: 0.0342 - val_loss: 0.0149 - val_mae: 0.0920\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0145 - val_mae: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:17,676] Trial 13 finished with value: 0.08677712082862854 and parameters: {'learning_rate': 0.004268080954194253, 'weight_decay': 2.9168736693655427e-08}. Best is trial 7 with value: 0.08398724347352982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - mae: 0.2696 - val_loss: 0.1955 - val_mae: 0.5337\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2288 - mae: 0.5750 - val_loss: 0.0328 - val_mae: 0.1664\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0227 - mae: 0.1695 - val_loss: 0.0274 - val_mae: 0.1473\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0159 - mae: 0.1398 - val_loss: 0.0231 - val_mae: 0.1166\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0232 - val_mae: 0.1090\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0213 - val_mae: 0.0948\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0790 - val_loss: 0.0191 - val_mae: 0.0938\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0067 - mae: 0.0848 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0168 - val_mae: 0.0915\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0716 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0674 - val_loss: 0.0162 - val_mae: 0.0890\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0160 - val_mae: 0.0842\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0582 - val_loss: 0.0153 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0606 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0155 - val_mae: 0.0878\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0158 - val_mae: 0.0887\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0157 - val_mae: 0.0958\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0154 - val_mae: 0.0836\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0148 - val_mae: 0.0932\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0646 - val_loss: 0.0159 - val_mae: 0.0816\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0578 - val_loss: 0.0158 - val_mae: 0.0813\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0151 - val_mae: 0.0861\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0149 - val_mae: 0.0945\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0648 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0547 - val_loss: 0.0160 - val_mae: 0.0811\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0160 - val_mae: 0.0811\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0570 - val_loss: 0.0153 - val_mae: 0.0835\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0531 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0504 - val_loss: 0.0148 - val_mae: 0.0875\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - mae: 0.0563 - val_loss: 0.0146 - val_mae: 0.0892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0559 - val_loss: 0.0148 - val_mae: 0.0840\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0149 - val_mae: 0.0816\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0147 - val_mae: 0.0829\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0143 - val_mae: 0.0875\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0149 - val_mae: 0.0799\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0153 - val_mae: 0.0787\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0150 - val_mae: 0.0794\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0144 - val_mae: 0.0839\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0141 - val_mae: 0.0911\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0159 - val_mae: 0.0786\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0510 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0149 - val_mae: 0.0799\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0144 - val_mae: 0.0953\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0145 - val_mae: 0.0860\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0145 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0023 - mae: 0.0498 - val_loss: 0.0153 - val_mae: 0.0776\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0154 - val_mae: 0.0776\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0472 - val_loss: 0.0149 - val_mae: 0.0800\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0147 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.0858\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0147 - val_mae: 0.0924\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0147 - val_mae: 0.0890\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0162 - val_mae: 0.0817\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0026 - mae: 0.0495 - val_loss: 0.0156 - val_mae: 0.0824\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0473 - val_loss: 0.0149 - val_mae: 0.0903\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0545 - val_loss: 0.0151 - val_mae: 0.0871\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0151 - val_mae: 0.0874\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0475 - val_loss: 0.0151 - val_mae: 0.0871\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0151 - val_mae: 0.0872\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0150 - val_mae: 0.0863\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0156 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0453 - val_loss: 0.0152 - val_mae: 0.0820\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0445 - val_loss: 0.0147 - val_mae: 0.0879\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0148 - val_mae: 0.0849\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0154 - val_mae: 0.0794\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0401 - val_loss: 0.0160 - val_mae: 0.0785\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0463 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0151 - val_mae: 0.0801\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0150 - val_mae: 0.0834\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0152 - val_mae: 0.0810\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0155 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0155 - val_mae: 0.0808\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0163 - val_mae: 0.0806\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0548 - val_loss: 0.0164 - val_mae: 0.0805\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0465 - val_loss: 0.0155 - val_mae: 0.0815\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0152 - val_mae: 0.0866\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0152 - val_mae: 0.0842\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0533 - val_loss: 0.0159 - val_mae: 0.0813\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0814\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0441 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0152 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0151 - val_mae: 0.0905\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0476 - val_loss: 0.0153 - val_mae: 0.0824\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0157 - val_mae: 0.0811\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0455 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0467 - val_loss: 0.0151 - val_mae: 0.0849\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0026 - mae: 0.0512 - val_loss: 0.0150 - val_mae: 0.0856\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0155 - val_mae: 0.0817\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0456 - val_loss: 0.0162 - val_mae: 0.0810\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0506 - val_loss: 0.0160 - val_mae: 0.0817\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0151 - val_mae: 0.0863\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0444 - val_loss: 0.0163 - val_mae: 0.0809\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0444 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0510 - val_loss: 0.0158 - val_mae: 0.0802\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0476 - val_loss: 0.0151 - val_mae: 0.0831\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0023 - mae: 0.0462 - val_loss: 0.0148 - val_mae: 0.0899\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0147 - val_mae: 0.0903\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0147 - val_mae: 0.0873\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0158 - val_mae: 0.0823\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0163 - val_mae: 0.0816\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0163 - val_mae: 0.0827\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0159 - val_mae: 0.0851\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0147 - val_mae: 0.0914\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - mae: 0.0493 - val_loss: 0.0146 - val_mae: 0.0967\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0521 - val_loss: 0.0150 - val_mae: 0.0871\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0161 - val_mae: 0.0839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0155 - val_mae: 0.0825\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0169 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0023 - mae: 0.0464 - val_loss: 0.0158 - val_mae: 0.0811\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0154 - val_mae: 0.0824\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0166 - val_mae: 0.0815\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0019 - mae: 0.0413 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - mae: 0.0507 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0445 - val_loss: 0.0152 - val_mae: 0.0834\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0419 - val_loss: 0.0152 - val_mae: 0.0839\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0408 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0155 - val_mae: 0.0822\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0456 - val_loss: 0.0157 - val_mae: 0.0821\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0370 - val_loss: 0.0158 - val_mae: 0.0816\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0154 - val_mae: 0.0818\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0153 - val_mae: 0.0821\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0014 - mae: 0.0393 - val_loss: 0.0160 - val_mae: 0.0807\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - mae: 0.0423 - val_loss: 0.0163 - val_mae: 0.0802\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0156 - val_mae: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:28,806] Trial 14 finished with value: 0.08045151829719543 and parameters: {'learning_rate': 0.006547253161581226, 'weight_decay': 7.622534278615785e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1125 - mae: 0.3892 - val_loss: 1.4176 - val_mae: 1.8714\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.7655 - mae: 2.2012 - val_loss: 0.1602 - val_mae: 0.4591\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1732 - mae: 0.4910 - val_loss: 0.0674 - val_mae: 0.2943\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0663 - mae: 0.2961 - val_loss: 0.0703 - val_mae: 0.2943\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0797 - mae: 0.3258 - val_loss: 0.0726 - val_mae: 0.3541\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0627 - mae: 0.3180 - val_loss: 0.0318 - val_mae: 0.1874\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0277 - mae: 0.1868 - val_loss: 0.0301 - val_mae: 0.1790\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0313 - mae: 0.1915 - val_loss: 0.0259 - val_mae: 0.1485\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0122 - mae: 0.1247 - val_loss: 0.0245 - val_mae: 0.1405\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0216 - val_mae: 0.1182\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0081 - mae: 0.0990 - val_loss: 0.0188 - val_mae: 0.0893\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0180 - val_mae: 0.0879\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0047 - mae: 0.0711 - val_loss: 0.0195 - val_mae: 0.1104\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0059 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.1308\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0072 - mae: 0.0995 - val_loss: 0.0207 - val_mae: 0.1282\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0083 - mae: 0.1034 - val_loss: 0.0182 - val_mae: 0.1068\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0061 - mae: 0.0902 - val_loss: 0.0166 - val_mae: 0.0916\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0731 - val_loss: 0.0177 - val_mae: 0.1016\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0049 - mae: 0.0781 - val_loss: 0.0200 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0076 - mae: 0.0995 - val_loss: 0.0199 - val_mae: 0.1207\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0082 - mae: 0.1017 - val_loss: 0.0177 - val_mae: 0.1029\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064 - mae: 0.0870 - val_loss: 0.0169 - val_mae: 0.0947\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0765 - val_loss: 0.0179 - val_mae: 0.1008\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0053 - mae: 0.0814 - val_loss: 0.0198 - val_mae: 0.1158\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0071 - mae: 0.0963 - val_loss: 0.0187 - val_mae: 0.1042\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0055 - mae: 0.0825 - val_loss: 0.2936 - val_mae: 0.7344\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3212 - mae: 0.7591 - val_loss: 0.0303 - val_mae: 0.1895\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0167 - mae: 0.1581 - val_loss: 0.0496 - val_mae: 0.2760\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0362 - mae: 0.2500 - val_loss: 0.0562 - val_mae: 0.2991\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0453 - mae: 0.2819 - val_loss: 0.0455 - val_mae: 0.2604\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - mae: 0.2426 - val_loss: 0.0288 - val_mae: 0.1817\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0151 - mae: 0.1501 - val_loss: 0.0181 - val_mae: 0.0976\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0054 - mae: 0.0819 - val_loss: 0.0184 - val_mae: 0.0992\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0060 - mae: 0.0832 - val_loss: 0.0264 - val_mae: 0.1678\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0140 - mae: 0.1429 - val_loss: 0.0340 - val_mae: 0.2108\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0218 - mae: 0.1869 - val_loss: 0.0350 - val_mae: 0.2155\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0210 - mae: 0.1815 - val_loss: 0.0296 - val_mae: 0.1872\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0146 - mae: 0.1478 - val_loss: 0.0222 - val_mae: 0.1367\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0118 - mae: 0.1277 - val_loss: 0.0171 - val_mae: 0.0852\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0699 - val_loss: 0.0174 - val_mae: 0.0908\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0775 - val_loss: 0.0217 - val_mae: 0.1357\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0107 - mae: 0.1206 - val_loss: 0.0255 - val_mae: 0.1636\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0122 - mae: 0.1317 - val_loss: 0.0261 - val_mae: 0.1677\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0127 - mae: 0.1337 - val_loss: 0.0235 - val_mae: 0.1495\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0090 - mae: 0.1122 - val_loss: 0.0198 - val_mae: 0.1168\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0999 - val_loss: 0.0171 - val_mae: 0.0863\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0701 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0046 - mae: 0.0722 - val_loss: 0.0188 - val_mae: 0.1028\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0073 - mae: 0.0944 - val_loss: 0.0204 - val_mae: 0.1195\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0076 - mae: 0.0959 - val_loss: 0.0207 - val_mae: 0.1214\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0073 - mae: 0.0955 - val_loss: 0.0196 - val_mae: 0.1106\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0071 - mae: 0.0931 - val_loss: 0.0181 - val_mae: 0.0939\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0061 - mae: 0.0829 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0706 - val_loss: 0.0172 - val_mae: 0.0881\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0042 - mae: 0.0685 - val_loss: 0.0184 - val_mae: 0.0992\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0754 - val_loss: 0.0196 - val_mae: 0.1120\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0066 - mae: 0.0905 - val_loss: 0.0197 - val_mae: 0.1128\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0899 - val_loss: 0.0188 - val_mae: 0.1039\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0811 - val_loss: 0.0177 - val_mae: 0.0927\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0724 - val_loss: 0.0170 - val_mae: 0.0869\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0044 - mae: 0.0732 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0672 - val_loss: 0.0174 - val_mae: 0.0880\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0047 - mae: 0.0740 - val_loss: 0.0178 - val_mae: 0.0907\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0729 - val_loss: 0.0179 - val_mae: 0.0910\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0732 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0046 - mae: 0.0694 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0678 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0665 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0177 - val_mae: 0.0929\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - mae: 0.0712 - val_loss: 0.0176 - val_mae: 0.0915\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0728 - val_loss: 0.0171 - val_mae: 0.0871\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0040 - mae: 0.0666 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0634 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0658 - val_loss: 0.0169 - val_mae: 0.0856\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0171 - val_mae: 0.0868\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0042 - mae: 0.0677 - val_loss: 0.0172 - val_mae: 0.0875\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0645 - val_loss: 0.0171 - val_mae: 0.0872\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0678 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0861\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0840\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0167 - val_mae: 0.0855\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:39,843] Trial 15 finished with value: 0.084881991147995 and parameters: {'learning_rate': 0.025777226607309283, 'weight_decay': 1.597843996967042e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0796 - mae: 0.3166 - val_loss: 0.0240 - val_mae: 0.1482\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0380 - mae: 0.2174 - val_loss: 0.0258 - val_mae: 0.1619\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0343 - mae: 0.2099 - val_loss: 0.0258 - val_mae: 0.1606\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0308 - mae: 0.2005 - val_loss: 0.0220 - val_mae: 0.1367\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0214 - mae: 0.1662 - val_loss: 0.0192 - val_mae: 0.1119\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0154 - mae: 0.1437 - val_loss: 0.0184 - val_mae: 0.1002\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0114 - mae: 0.1180 - val_loss: 0.0186 - val_mae: 0.0964\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0190 - val_mae: 0.0960\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0194 - val_mae: 0.0973\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0089 - mae: 0.0999 - val_loss: 0.0198 - val_mae: 0.0978\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0068 - mae: 0.0914 - val_loss: 0.0200 - val_mae: 0.0976\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0075 - mae: 0.0917 - val_loss: 0.0202 - val_mae: 0.0964\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0897 - val_loss: 0.0203 - val_mae: 0.0949\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0901 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0057 - mae: 0.0792 - val_loss: 0.0201 - val_mae: 0.0904\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0058 - mae: 0.0782 - val_loss: 0.0199 - val_mae: 0.0877\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0797 - val_loss: 0.0195 - val_mae: 0.0851\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0054 - mae: 0.0751 - val_loss: 0.0190 - val_mae: 0.0832\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0715 - val_loss: 0.0185 - val_mae: 0.0818\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0809\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0703 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0692 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0037 - mae: 0.0643 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0778\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0029 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0760\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0758\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0506 - val_loss: 0.0169 - val_mae: 0.0760\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0027 - mae: 0.0547 - val_loss: 0.0168 - val_mae: 0.0764\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0530 - val_loss: 0.0166 - val_mae: 0.0763\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0544 - val_loss: 0.0166 - val_mae: 0.0760\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0165 - val_mae: 0.0757\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0165 - val_mae: 0.0757\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0163 - val_mae: 0.0765\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0162 - val_mae: 0.0765\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0490 - val_loss: 0.0160 - val_mae: 0.0766\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0417 - val_loss: 0.0158 - val_mae: 0.0769\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0158 - val_mae: 0.0772\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0158 - val_mae: 0.0775\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0159 - val_mae: 0.0774\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0161 - val_mae: 0.0771\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0161 - val_mae: 0.0772\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0159 - val_mae: 0.0778\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0157 - val_mae: 0.0784\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0157 - val_mae: 0.0777\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0157 - val_mae: 0.0774\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0156 - val_mae: 0.0778\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0156 - val_mae: 0.0776\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0157 - val_mae: 0.0769\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0158 - val_mae: 0.0765\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0159 - val_mae: 0.0766\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0159 - val_mae: 0.0771\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0394 - val_loss: 0.0158 - val_mae: 0.0779\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 0.0157 - val_mae: 0.0789\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0377 - val_loss: 0.0157 - val_mae: 0.0799\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - mae: 0.0383 - val_loss: 0.0157 - val_mae: 0.0805\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0400 - val_loss: 0.0156 - val_mae: 0.0814\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0811\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0794\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.8238e-04 - mae: 0.0337 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0370 - val_loss: 0.0160 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0158 - val_mae: 0.0810\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0364 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0423 - val_loss: 0.0155 - val_mae: 0.0869\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0355 - val_loss: 0.0155 - val_mae: 0.0881\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0155 - val_mae: 0.0875\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0159 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0338 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0163 - val_mae: 0.0825\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0162 - val_mae: 0.0826\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0332 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9398e-04 - mae: 0.0348 - val_loss: 0.0160 - val_mae: 0.0837\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0158 - val_mae: 0.0847\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0346 - val_loss: 0.0158 - val_mae: 0.0840\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2569e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1618e-04 - mae: 0.0313 - val_loss: 0.0159 - val_mae: 0.0813\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0159 - val_mae: 0.0798\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 9.1125e-04 - mae: 0.0328 - val_loss: 0.0158 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.4902e-04 - mae: 0.0323 - val_loss: 0.0158 - val_mae: 0.0789\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0355 - val_loss: 0.0156 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.0572e-04 - mae: 0.0311 - val_loss: 0.0157 - val_mae: 0.0800\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 8.5991e-04 - mae: 0.0318 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8142e-04 - mae: 0.0303 - val_loss: 0.0157 - val_mae: 0.0811\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9651e-04 - mae: 0.0324 - val_loss: 0.0157 - val_mae: 0.0824\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.1164e-04 - mae: 0.0303 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0500e-04 - mae: 0.0311 - val_loss: 0.0156 - val_mae: 0.0837\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.3532e-04 - mae: 0.0327 - val_loss: 0.0154 - val_mae: 0.0826\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0437e-04 - mae: 0.0329 - val_loss: 0.0154 - val_mae: 0.0819\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.7837e-04 - mae: 0.0331 - val_loss: 0.0153 - val_mae: 0.0819\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.9532e-04 - mae: 0.0356 - val_loss: 0.0154 - val_mae: 0.0819\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1271e-04 - mae: 0.0322 - val_loss: 0.0154 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3654e-04 - mae: 0.0297 - val_loss: 0.0155 - val_mae: 0.0824\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.3293e-04 - mae: 0.0295 - val_loss: 0.0156 - val_mae: 0.0809\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.7395e-04 - mae: 0.0309 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4667e-04 - mae: 0.0305 - val_loss: 0.0158 - val_mae: 0.0803\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.0296e-04 - mae: 0.0313 - val_loss: 0.0160 - val_mae: 0.0798\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5750e-04 - mae: 0.0278 - val_loss: 0.0162 - val_mae: 0.0797\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.4266e-04 - mae: 0.0314 - val_loss: 0.0163 - val_mae: 0.0798\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0166e-04 - mae: 0.0314 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2888e-04 - mae: 0.0302 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.4189e-04 - mae: 0.0307 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.9594e-04 - mae: 0.0328 - val_loss: 0.0161 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.2949e-04 - mae: 0.0298 - val_loss: 0.0161 - val_mae: 0.0822\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.9086e-04 - mae: 0.0306 - val_loss: 0.0163 - val_mae: 0.0804\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5318e-04 - mae: 0.0302 - val_loss: 0.0164 - val_mae: 0.0789\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0763e-04 - mae: 0.0318 - val_loss: 0.0164 - val_mae: 0.0790\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3541e-04 - mae: 0.0297 - val_loss: 0.0162 - val_mae: 0.0804\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 6.5052e-04 - mae: 0.0273 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0900e-04 - mae: 0.0285 - val_loss: 0.0158 - val_mae: 0.0843\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.1849e-04 - mae: 0.0302 - val_loss: 0.0159 - val_mae: 0.0842\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2135e-04 - mae: 0.0291 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.0939e-04 - mae: 0.0270 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.7565e-04 - mae: 0.0298 - val_loss: 0.0161 - val_mae: 0.0811\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5062e-04 - mae: 0.0308 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8188e-04 - mae: 0.0295 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.4702e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.0808\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0161 - val_mae: 0.0798\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4676e-04 - mae: 0.0284 - val_loss: 0.0164 - val_mae: 0.0796\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.1028e-04 - mae: 0.0267 - val_loss: 0.0168 - val_mae: 0.0795\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8837e-04 - mae: 0.0296 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7658e-04 - mae: 0.0308 - val_loss: 0.0166 - val_mae: 0.0801\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1671e-04 - mae: 0.0274 - val_loss: 0.0163 - val_mae: 0.0810\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6747e-04 - mae: 0.0317 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.8661e-04 - mae: 0.0284 - val_loss: 0.0158 - val_mae: 0.0833\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.2170e-04 - mae: 0.0318 - val_loss: 0.0158 - val_mae: 0.0834\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0513e-04 - mae: 0.0314 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1425e-04 - mae: 0.0295 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9581e-04 - mae: 0.0303 - val_loss: 0.0164 - val_mae: 0.0802\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8668e-04 - mae: 0.0281 - val_loss: 0.0163 - val_mae: 0.0801\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.2252e-04 - mae: 0.0301 - val_loss: 0.0160 - val_mae: 0.0802\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5226e-04 - mae: 0.0243 - val_loss: 0.0159 - val_mae: 0.0805\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0159e-04 - mae: 0.0307 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 8.6975e-04 - mae: 0.0319 - val_loss: 0.0160 - val_mae: 0.0819\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6923e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.0823\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0761e-04 - mae: 0.0321 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9108e-04 - mae: 0.0261 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.8752e-04 - mae: 0.0261 - val_loss: 0.0163 - val_mae: 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:45:50,890] Trial 16 finished with value: 0.08356054872274399 and parameters: {'learning_rate': 0.0011066168053900564, 'weight_decay': 1.4116108524414525e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0873 - mae: 0.3384 - val_loss: 0.0605 - val_mae: 0.2777\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0812 - mae: 0.3327 - val_loss: 0.0305 - val_mae: 0.1893\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0412 - mae: 0.2314 - val_loss: 0.0187 - val_mae: 0.1160\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0161 - mae: 0.1376 - val_loss: 0.0196 - val_mae: 0.1077\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0132 - mae: 0.1272 - val_loss: 0.0215 - val_mae: 0.1175\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0117 - mae: 0.1197 - val_loss: 0.0223 - val_mae: 0.1172\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1135 - val_loss: 0.0222 - val_mae: 0.1133\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0093 - mae: 0.1063 - val_loss: 0.0219 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0073 - mae: 0.0928 - val_loss: 0.0216 - val_mae: 0.1033\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0074 - mae: 0.0877 - val_loss: 0.0211 - val_mae: 0.0970\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0067 - mae: 0.0826 - val_loss: 0.0204 - val_mae: 0.0893\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0196 - val_mae: 0.0832\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0723 - val_loss: 0.0188 - val_mae: 0.0828\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0057 - mae: 0.0778 - val_loss: 0.0184 - val_mae: 0.0871\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mae: 0.0725 - val_loss: 0.0181 - val_mae: 0.0923\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0180 - val_mae: 0.0973\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0046 - mae: 0.0733 - val_loss: 0.0178 - val_mae: 0.0975\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0041 - mae: 0.0696 - val_loss: 0.0176 - val_mae: 0.0926\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0175 - val_mae: 0.0826\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0176 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0544 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0164 - val_mae: 0.0849\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0612 - val_loss: 0.0161 - val_mae: 0.0899\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0161 - val_mae: 0.0896\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0161 - val_mae: 0.0865\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0164 - val_mae: 0.0822\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0524 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0510 - val_loss: 0.0163 - val_mae: 0.0841\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0161 - val_mae: 0.0876\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0511 - val_loss: 0.0160 - val_mae: 0.0891\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0506 - val_loss: 0.0160 - val_mae: 0.0910\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0542 - val_loss: 0.0160 - val_mae: 0.0896\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0161 - val_mae: 0.0893\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0560 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0160 - val_mae: 0.0902\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0910\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0521 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0486 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0160 - val_mae: 0.0872\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0160 - val_mae: 0.0871\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0159 - val_mae: 0.0884\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0488 - val_loss: 0.0158 - val_mae: 0.0926\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0159 - val_mae: 0.0858\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0160 - val_mae: 0.0846\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0158 - val_mae: 0.0883\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0158 - val_mae: 0.0902\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0015 - mae: 0.0439 - val_loss: 0.0158 - val_mae: 0.0890\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0439 - val_loss: 0.0159 - val_mae: 0.0895\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0888\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0159 - val_mae: 0.0868\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0429 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0427 - val_loss: 0.0160 - val_mae: 0.0900\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0930\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0161 - val_mae: 0.0951\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0441 - val_loss: 0.0160 - val_mae: 0.0917\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0161 - val_mae: 0.0913\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0381 - val_loss: 0.0162 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0163 - val_mae: 0.0928\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0164 - val_mae: 0.0958\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0161 - val_mae: 0.0953\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0160 - val_mae: 0.0908\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0159 - val_mae: 0.0874\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0160 - val_mae: 0.0866\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0162 - val_mae: 0.0887\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0164 - val_mae: 0.0927\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0165 - val_mae: 0.0972\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0165 - val_mae: 0.0985\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0355 - val_loss: 0.0162 - val_mae: 0.0928\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0160 - val_mae: 0.0899\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7863e-04 - mae: 0.0327 - val_loss: 0.0159 - val_mae: 0.0890\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2947e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0900\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.0915\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 0.0163 - val_mae: 0.0962\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.8414e-04 - mae: 0.0344 - val_loss: 0.0166 - val_mae: 0.0985\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.6218e-04 - mae: 0.0335 - val_loss: 0.0167 - val_mae: 0.0986\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 0.0161 - val_mae: 0.0877\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 7.3258e-04 - mae: 0.0288 - val_loss: 0.0161 - val_mae: 0.0873\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.7629e-04 - mae: 0.0299 - val_loss: 0.0163 - val_mae: 0.0894\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.4500e-04 - mae: 0.0269 - val_loss: 0.0164 - val_mae: 0.0901\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.9060e-04 - mae: 0.0342 - val_loss: 0.0166 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0372 - val_loss: 0.0167 - val_mae: 0.0962\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.3813e-04 - mae: 0.0287 - val_loss: 0.0167 - val_mae: 0.0976\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - mae: 0.0346 - val_loss: 0.0162 - val_mae: 0.0875\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 7.8498e-04 - mae: 0.0305 - val_loss: 0.0161 - val_mae: 0.0834\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0161 - val_mae: 0.0849\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.5736e-04 - mae: 0.0320 - val_loss: 0.0162 - val_mae: 0.0890\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8647e-04 - mae: 0.0285 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.0611e-04 - mae: 0.0301 - val_loss: 0.0165 - val_mae: 0.0969\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0163 - val_mae: 0.0968\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5689e-04 - mae: 0.0309 - val_loss: 0.0163 - val_mae: 0.0966\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1246e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.0933\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.6205e-04 - mae: 0.0308 - val_loss: 0.0161 - val_mae: 0.0904\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.2664e-04 - mae: 0.0310 - val_loss: 0.0161 - val_mae: 0.0894\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0822e-04 - mae: 0.0315 - val_loss: 0.0161 - val_mae: 0.0896\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7665e-04 - mae: 0.0299 - val_loss: 0.0161 - val_mae: 0.0901\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.2212e-04 - mae: 0.0294 - val_loss: 0.0161 - val_mae: 0.0881\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.8926e-04 - mae: 0.0294 - val_loss: 0.0162 - val_mae: 0.0892\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6202e-04 - mae: 0.0281 - val_loss: 0.0163 - val_mae: 0.0905\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1513e-04 - mae: 0.0288 - val_loss: 0.0163 - val_mae: 0.0881\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.8462e-04 - mae: 0.0318 - val_loss: 0.0163 - val_mae: 0.0884\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2901e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.0882\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.3477e-04 - mae: 0.0313 - val_loss: 0.0160 - val_mae: 0.0836\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4294e-04 - mae: 0.0279 - val_loss: 0.0159 - val_mae: 0.0809\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0162 - val_mae: 0.0848\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3464e-04 - mae: 0.0268 - val_loss: 0.0167 - val_mae: 0.0903\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.8327e-04 - mae: 0.0320 - val_loss: 0.0171 - val_mae: 0.0959\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.3934e-04 - mae: 0.0279 - val_loss: 0.0173 - val_mae: 0.0987\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0163 - val_mae: 0.0893\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.7401e-04 - mae: 0.0287 - val_loss: 0.0160 - val_mae: 0.0784\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0336 - val_loss: 0.0160 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 0.0157 - val_mae: 0.0759\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - mae: 0.0357 - val_loss: 0.0153 - val_mae: 0.0793\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 0.0152 - val_mae: 0.0866\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.7391e-04 - mae: 0.0285 - val_loss: 0.0157 - val_mae: 0.0971\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0161 - val_mae: 0.0995\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3934e-04 - mae: 0.0327 - val_loss: 0.0160 - val_mae: 0.0950\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.0864\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.8823e-04 - mae: 0.0265 - val_loss: 0.0159 - val_mae: 0.0805\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1045e-04 - mae: 0.0325 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.9729e-04 - mae: 0.0328 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.8555e-04 - mae: 0.0332 - val_loss: 0.0160 - val_mae: 0.0836\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 5.3875e-04 - mae: 0.0247 - val_loss: 0.0162 - val_mae: 0.0900\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.2926e-04 - mae: 0.0291 - val_loss: 0.0162 - val_mae: 0.0931\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.9051e-04 - mae: 0.0309 - val_loss: 0.0159 - val_mae: 0.0912\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4828e-04 - mae: 0.0276 - val_loss: 0.0157 - val_mae: 0.0857\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.6069e-04 - mae: 0.0271 - val_loss: 0.0156 - val_mae: 0.0797\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.0000e-04 - mae: 0.0310 - val_loss: 0.0156 - val_mae: 0.0781\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0337 - val_loss: 0.0155 - val_mae: 0.0790\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0467e-04 - mae: 0.0297 - val_loss: 0.0155 - val_mae: 0.0827\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2753e-04 - mae: 0.0273 - val_loss: 0.0156 - val_mae: 0.0873\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6854e-04 - mae: 0.0284 - val_loss: 0.0156 - val_mae: 0.0882\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.0672e-04 - mae: 0.0325 - val_loss: 0.0154 - val_mae: 0.0856\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.1059e-04 - mae: 0.0292 - val_loss: 0.0153 - val_mae: 0.0838\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3222e-04 - mae: 0.0258 - val_loss: 0.0154 - val_mae: 0.0807\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.8047e-04 - mae: 0.0295 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7435e-04 - mae: 0.0273 - val_loss: 0.0155 - val_mae: 0.0810\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 0.0154 - val_mae: 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:02,071] Trial 17 finished with value: 0.08329557627439499 and parameters: {'learning_rate': 0.0019742146903142703, 'weight_decay': 8.307434620137046e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1289 - mae: 0.4142 - val_loss: 0.0462 - val_mae: 0.2258\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0709 - mae: 0.2967 - val_loss: 0.0323 - val_mae: 0.1684\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0557 - mae: 0.2676 - val_loss: 0.0254 - val_mae: 0.1329\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0457 - mae: 0.2420 - val_loss: 0.0225 - val_mae: 0.1156\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0364 - mae: 0.2120 - val_loss: 0.0207 - val_mae: 0.1135\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0343 - mae: 0.2118 - val_loss: 0.0199 - val_mae: 0.1107\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0297 - mae: 0.1931 - val_loss: 0.0191 - val_mae: 0.1081\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0283 - mae: 0.1874 - val_loss: 0.0184 - val_mae: 0.1036\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0265 - mae: 0.1831 - val_loss: 0.0181 - val_mae: 0.1003\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0203 - mae: 0.1574 - val_loss: 0.0180 - val_mae: 0.0977\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0227 - mae: 0.1699 - val_loss: 0.0181 - val_mae: 0.0985\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0170 - mae: 0.1401 - val_loss: 0.0183 - val_mae: 0.0995\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0175 - mae: 0.1487 - val_loss: 0.0188 - val_mae: 0.1006\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1311 - val_loss: 0.0194 - val_mae: 0.1023\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0155 - mae: 0.1407 - val_loss: 0.0197 - val_mae: 0.1029\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0117 - mae: 0.1237 - val_loss: 0.0200 - val_mae: 0.1029\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0113 - mae: 0.1207 - val_loss: 0.0203 - val_mae: 0.1027\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - mae: 0.1076 - val_loss: 0.0205 - val_mae: 0.1024\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0083 - mae: 0.1036 - val_loss: 0.0206 - val_mae: 0.1020\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0207 - val_mae: 0.1012\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0206 - val_mae: 0.1004\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0079 - mae: 0.1001 - val_loss: 0.0206 - val_mae: 0.0996\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0077 - mae: 0.0940 - val_loss: 0.0205 - val_mae: 0.0987\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0068 - mae: 0.0883 - val_loss: 0.0204 - val_mae: 0.0977\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0885 - val_loss: 0.0203 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0202 - val_mae: 0.0960\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0071 - mae: 0.0901 - val_loss: 0.0200 - val_mae: 0.0951\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0069 - mae: 0.0856 - val_loss: 0.0198 - val_mae: 0.0939\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0196 - val_mae: 0.0925\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0056 - mae: 0.0793 - val_loss: 0.0194 - val_mae: 0.0913\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0060 - mae: 0.0806 - val_loss: 0.0192 - val_mae: 0.0902\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054 - mae: 0.0767 - val_loss: 0.0189 - val_mae: 0.0891\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0056 - mae: 0.0803 - val_loss: 0.0187 - val_mae: 0.0882\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0058 - mae: 0.0803 - val_loss: 0.0186 - val_mae: 0.0875\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0051 - mae: 0.0747 - val_loss: 0.0184 - val_mae: 0.0870\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0695 - val_loss: 0.0182 - val_mae: 0.0866\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0181 - val_mae: 0.0864\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0721 - val_loss: 0.0179 - val_mae: 0.0862\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0050 - mae: 0.0743 - val_loss: 0.0177 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0680 - val_loss: 0.0176 - val_mae: 0.0857\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0708 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0049 - mae: 0.0730 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0856\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0040 - mae: 0.0674 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0043 - mae: 0.0673 - val_loss: 0.0171 - val_mae: 0.0865\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - mae: 0.0692 - val_loss: 0.0171 - val_mae: 0.0872\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0659 - val_loss: 0.0171 - val_mae: 0.0878\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0885\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0890\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.0892\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0894\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0637 - val_loss: 0.0171 - val_mae: 0.0895\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0039 - mae: 0.0654 - val_loss: 0.0171 - val_mae: 0.0894\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0895\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0172 - val_mae: 0.0897\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0901\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0904\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0556 - val_loss: 0.0172 - val_mae: 0.0909\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0172 - val_mae: 0.0914\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0540 - val_loss: 0.0172 - val_mae: 0.0918\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0921\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0924\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0172 - val_mae: 0.0923\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0923\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0171 - val_mae: 0.0922\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0556 - val_loss: 0.0170 - val_mae: 0.0917\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0913\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0912\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0907\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0168 - val_mae: 0.0903\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0554 - val_loss: 0.0167 - val_mae: 0.0899\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0899\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0164 - val_mae: 0.0901\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0164 - val_mae: 0.0904\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0163 - val_mae: 0.0917\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0475 - val_loss: 0.0163 - val_mae: 0.0925\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0162 - val_mae: 0.0930\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0596 - val_loss: 0.0162 - val_mae: 0.0927\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0162 - val_mae: 0.0924\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0163 - val_mae: 0.0918\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0163 - val_mae: 0.0914\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0504 - val_loss: 0.0163 - val_mae: 0.0911\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0512 - val_loss: 0.0163 - val_mae: 0.0912\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0163 - val_mae: 0.0913\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0503 - val_loss: 0.0162 - val_mae: 0.0912\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0518 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0162 - val_mae: 0.0911\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0497 - val_loss: 0.0162 - val_mae: 0.0912\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0162 - val_mae: 0.0916\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0162 - val_mae: 0.0919\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0502 - val_loss: 0.0162 - val_mae: 0.0922\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0491 - val_loss: 0.0162 - val_mae: 0.0922\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0163 - val_mae: 0.0920\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0163 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0164 - val_mae: 0.0916\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0023 - mae: 0.0513 - val_loss: 0.0164 - val_mae: 0.0917\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0164 - val_mae: 0.0920\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - mae: 0.0495 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - mae: 0.0478 - val_loss: 0.0165 - val_mae: 0.0923\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0165 - val_mae: 0.0924\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0165 - val_mae: 0.0925\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0483 - val_loss: 0.0165 - val_mae: 0.0932\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0461 - val_loss: 0.0165 - val_mae: 0.0936\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0165 - val_mae: 0.0942\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0443 - val_loss: 0.0165 - val_mae: 0.0942\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0164 - val_mae: 0.0947\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0163 - val_mae: 0.0950\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0483 - val_loss: 0.0163 - val_mae: 0.0950\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0474 - val_loss: 0.0162 - val_mae: 0.0951\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0485 - val_loss: 0.0162 - val_mae: 0.0951\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0451 - val_loss: 0.0161 - val_mae: 0.0946\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0161 - val_mae: 0.0944\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0444 - val_loss: 0.0160 - val_mae: 0.0946\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0393 - val_loss: 0.0160 - val_mae: 0.0947\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0437 - val_loss: 0.0160 - val_mae: 0.0945\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0159 - val_mae: 0.0946\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0159 - val_mae: 0.0949\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0159 - val_mae: 0.0952\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0159 - val_mae: 0.0957\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0159 - val_mae: 0.0966\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0159 - val_mae: 0.0972\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0976\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0421 - val_loss: 0.0159 - val_mae: 0.0972\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0453 - val_loss: 0.0158 - val_mae: 0.0964\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0158 - val_mae: 0.0955\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0157 - val_mae: 0.0945\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0410 - val_loss: 0.0156 - val_mae: 0.0933\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0420 - val_loss: 0.0156 - val_mae: 0.0922\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0156 - val_mae: 0.0921\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0402 - val_loss: 0.0156 - val_mae: 0.0925\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0156 - val_mae: 0.0924\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0407 - val_loss: 0.0156 - val_mae: 0.0923\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0156 - val_mae: 0.0925\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0156 - val_mae: 0.0930\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0399 - val_loss: 0.0156 - val_mae: 0.0935\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0156 - val_mae: 0.0944\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0410 - val_loss: 0.0156 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0156 - val_mae: 0.0959\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0156 - val_mae: 0.0964\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0156 - val_mae: 0.0966\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0385 - val_loss: 0.0156 - val_mae: 0.0962\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0156 - val_mae: 0.0962\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0404 - val_loss: 0.0156 - val_mae: 0.0959\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0409 - val_loss: 0.0156 - val_mae: 0.0960\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0156 - val_mae: 0.0949\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0156 - val_mae: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:12,933] Trial 18 finished with value: 0.09377338737249374 and parameters: {'learning_rate': 0.0004362029281454469, 'weight_decay': 3.297981168995382e-08}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0672 - mae: 0.2985 - val_loss: 0.0834 - val_mae: 0.3432\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1108 - mae: 0.3908 - val_loss: 0.0344 - val_mae: 0.1836\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0312 - mae: 0.1955 - val_loss: 0.0236 - val_mae: 0.1250\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0124 - mae: 0.1241 - val_loss: 0.0235 - val_mae: 0.1080\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0236 - val_mae: 0.1067\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0087 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1050\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0083 - mae: 0.0967 - val_loss: 0.0220 - val_mae: 0.1013\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0203 - val_mae: 0.0911\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0063 - mae: 0.0837 - val_loss: 0.0185 - val_mae: 0.0826\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0057 - mae: 0.0762 - val_loss: 0.0174 - val_mae: 0.0823\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0172 - val_mae: 0.0827\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0048 - mae: 0.0717 - val_loss: 0.0172 - val_mae: 0.0821\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0043 - mae: 0.0694 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0669 - val_loss: 0.0184 - val_mae: 0.0764\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0185 - val_mae: 0.0766\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0180 - val_mae: 0.0782\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0178 - val_mae: 0.0784\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0174 - val_mae: 0.0800\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0817\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0033 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0162 - val_mae: 0.0820\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0164 - val_mae: 0.0791\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0168 - val_mae: 0.0766\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0516 - val_loss: 0.0166 - val_mae: 0.0760\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0163 - val_mae: 0.0773\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0164 - val_mae: 0.0755\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0163 - val_mae: 0.0750\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0156 - val_mae: 0.0778\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0152 - val_mae: 0.0813\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0152 - val_mae: 0.0792\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0483 - val_loss: 0.0155 - val_mae: 0.0771\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0772\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0020 - mae: 0.0435 - val_loss: 0.0153 - val_mae: 0.0795\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0155 - val_mae: 0.0792\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0158 - val_mae: 0.0802\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0461 - val_loss: 0.0159 - val_mae: 0.0815\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0471 - val_loss: 0.0161 - val_mae: 0.0805\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0166 - val_mae: 0.0782\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mae: 0.0403 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0156 - val_mae: 0.0838\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0022 - mae: 0.0493 - val_loss: 0.0154 - val_mae: 0.0859\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - mae: 0.0512 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0160 - val_mae: 0.0782\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0162 - val_mae: 0.0780\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0162 - val_mae: 0.0785\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0158 - val_mae: 0.0794\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0155 - val_mae: 0.0808\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0374 - val_loss: 0.0155 - val_mae: 0.0816\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0155 - val_mae: 0.0811\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0159 - val_mae: 0.0785\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0161 - val_mae: 0.0778\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0390 - val_loss: 0.0160 - val_mae: 0.0783\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0374 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0364 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0157 - val_mae: 0.0799\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0158 - val_mae: 0.0800\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0396 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0159 - val_mae: 0.0804\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0161 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0365 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0161 - val_mae: 0.0809\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.0157e-04 - mae: 0.0318 - val_loss: 0.0159 - val_mae: 0.0814\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0379 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.5946e-04 - mae: 0.0313 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0162 - val_mae: 0.0799\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1119e-04 - mae: 0.0330 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.1617e-04 - mae: 0.0317 - val_loss: 0.0157 - val_mae: 0.0828\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.4289e-04 - mae: 0.0316 - val_loss: 0.0155 - val_mae: 0.0864\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0154 - val_mae: 0.0867\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0340 - val_loss: 0.0157 - val_mae: 0.0812\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0158 - val_mae: 0.0796\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0158 - val_mae: 0.0797\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0373 - val_loss: 0.0156 - val_mae: 0.0810\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.1904e-04 - mae: 0.0333 - val_loss: 0.0157 - val_mae: 0.0801\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - mae: 0.0318 - val_loss: 0.0157 - val_mae: 0.0810\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0156 - val_mae: 0.0828\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0132e-04 - mae: 0.0320 - val_loss: 0.0155 - val_mae: 0.0841\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0348 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8334e-04 - mae: 0.0317 - val_loss: 0.0162 - val_mae: 0.0813\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1275e-04 - mae: 0.0309 - val_loss: 0.0165 - val_mae: 0.0800\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0299 - val_loss: 0.0165 - val_mae: 0.0806\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0010 - mae: 0.0319 - val_loss: 0.0163 - val_mae: 0.0836\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 0.0159 - val_mae: 0.0869\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.7616e-04 - mae: 0.0330 - val_loss: 0.0156 - val_mae: 0.0881\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0156 - val_mae: 0.0845\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0162 - val_mae: 0.0774\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0373 - val_loss: 0.0163 - val_mae: 0.0771\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0163 - val_mae: 0.0792\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.0092e-04 - mae: 0.0306 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8452e-04 - mae: 0.0321 - val_loss: 0.0160 - val_mae: 0.0874\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.4955e-04 - mae: 0.0330 - val_loss: 0.0161 - val_mae: 0.0874\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.8418e-04 - mae: 0.0312 - val_loss: 0.0164 - val_mae: 0.0818\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.3604e-04 - mae: 0.0301 - val_loss: 0.0166 - val_mae: 0.0800\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0341 - val_loss: 0.0166 - val_mae: 0.0801\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0719e-04 - mae: 0.0314 - val_loss: 0.0165 - val_mae: 0.0809\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.3962e-04 - mae: 0.0270 - val_loss: 0.0162 - val_mae: 0.0826\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.3298e-04 - mae: 0.0278 - val_loss: 0.0161 - val_mae: 0.0843\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5243e-04 - mae: 0.0301 - val_loss: 0.0161 - val_mae: 0.0852\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.8487e-04 - mae: 0.0296 - val_loss: 0.0159 - val_mae: 0.0855\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.7290e-04 - mae: 0.0266 - val_loss: 0.0158 - val_mae: 0.0840\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.6957e-04 - mae: 0.0275 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.4641e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.4780e-04 - mae: 0.0322 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7889e-04 - mae: 0.0272 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0485e-04 - mae: 0.0307 - val_loss: 0.0158 - val_mae: 0.0808\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.6290e-04 - mae: 0.0294 - val_loss: 0.0158 - val_mae: 0.0809\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - mae: 0.0345 - val_loss: 0.0157 - val_mae: 0.0819\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0320 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.7413e-04 - mae: 0.0292 - val_loss: 0.0160 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.2966e-04 - mae: 0.0296 - val_loss: 0.0162 - val_mae: 0.0832\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4266e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.1527e-04 - mae: 0.0286 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.5429e-04 - mae: 0.0294 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.9068e-04 - mae: 0.0280 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.9713e-04 - mae: 0.0269 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 7.3843e-04 - mae: 0.0272 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.0903e-04 - mae: 0.0289 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0157 - val_mae: 0.0835\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1527e-04 - mae: 0.0303 - val_loss: 0.0158 - val_mae: 0.0831\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 8.4490e-04 - mae: 0.0291 - val_loss: 0.0160 - val_mae: 0.0824\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.9105e-04 - mae: 0.0295 - val_loss: 0.0160 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.5196e-04 - mae: 0.0294 - val_loss: 0.0161 - val_mae: 0.0775\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 6.1163e-04 - mae: 0.0256 - val_loss: 0.0161 - val_mae: 0.0773\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8121e-04 - mae: 0.0291 - val_loss: 0.0159 - val_mae: 0.0783\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.2508e-04 - mae: 0.0301 - val_loss: 0.0157 - val_mae: 0.0807\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.2273e-04 - mae: 0.0245 - val_loss: 0.0155 - val_mae: 0.0841\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.3877e-04 - mae: 0.0295 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.3860e-04 - mae: 0.0329 - val_loss: 0.0154 - val_mae: 0.0853\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.9672e-04 - mae: 0.0287 - val_loss: 0.0154 - val_mae: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:23,893] Trial 19 finished with value: 0.08468662202358246 and parameters: {'learning_rate': 0.0027804327827490043, 'weight_decay': 4.517394395575848e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0619 - mae: 0.2805 - val_loss: 0.0329 - val_mae: 0.1782\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0452 - mae: 0.2402 - val_loss: 0.0284 - val_mae: 0.1605\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0355 - mae: 0.2131 - val_loss: 0.0249 - val_mae: 0.1454\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0324 - mae: 0.2046 - val_loss: 0.0222 - val_mae: 0.1335\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0340 - mae: 0.2109 - val_loss: 0.0201 - val_mae: 0.1228\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0273 - mae: 0.1879 - val_loss: 0.0186 - val_mae: 0.1141\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0250 - mae: 0.1755 - val_loss: 0.0175 - val_mae: 0.1070\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0222 - mae: 0.1663 - val_loss: 0.0168 - val_mae: 0.1021\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0216 - mae: 0.1652 - val_loss: 0.0162 - val_mae: 0.0993\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0211 - mae: 0.1650 - val_loss: 0.0160 - val_mae: 0.0974\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0214 - mae: 0.1655 - val_loss: 0.0159 - val_mae: 0.0968\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0209 - mae: 0.1655 - val_loss: 0.0158 - val_mae: 0.0973\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0201 - mae: 0.1539 - val_loss: 0.0158 - val_mae: 0.0980\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0226 - mae: 0.1696 - val_loss: 0.0158 - val_mae: 0.0988\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0205 - mae: 0.1609 - val_loss: 0.0160 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0208 - mae: 0.1626 - val_loss: 0.0161 - val_mae: 0.1000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0167 - mae: 0.1421 - val_loss: 0.0162 - val_mae: 0.1004\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0175 - mae: 0.1504 - val_loss: 0.0163 - val_mae: 0.1010\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0189 - mae: 0.1530 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0138 - mae: 0.1314 - val_loss: 0.0166 - val_mae: 0.1019\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0147 - mae: 0.1315 - val_loss: 0.0167 - val_mae: 0.1020\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0135 - mae: 0.1305 - val_loss: 0.0168 - val_mae: 0.1022\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0126 - mae: 0.1271 - val_loss: 0.0170 - val_mae: 0.1023\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0127 - mae: 0.1248 - val_loss: 0.0172 - val_mae: 0.1028\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0102 - mae: 0.1163 - val_loss: 0.0173 - val_mae: 0.1030\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0122 - mae: 0.1217 - val_loss: 0.0173 - val_mae: 0.1033\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0124 - mae: 0.1298 - val_loss: 0.0173 - val_mae: 0.1032\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0127 - mae: 0.1235 - val_loss: 0.0173 - val_mae: 0.1027\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0174 - val_mae: 0.1022\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0118 - mae: 0.1241 - val_loss: 0.0173 - val_mae: 0.1018\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0097 - mae: 0.1111 - val_loss: 0.0173 - val_mae: 0.1015\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0094 - mae: 0.1123 - val_loss: 0.0173 - val_mae: 0.1012\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0107 - mae: 0.1201 - val_loss: 0.0173 - val_mae: 0.1010\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0097 - mae: 0.1106 - val_loss: 0.0173 - val_mae: 0.1003\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0094 - mae: 0.1094 - val_loss: 0.0174 - val_mae: 0.0998\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0098 - mae: 0.1109 - val_loss: 0.0174 - val_mae: 0.0992\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1152 - val_loss: 0.0174 - val_mae: 0.0987\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.1022 - val_loss: 0.0175 - val_mae: 0.0982\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1054 - val_loss: 0.0175 - val_mae: 0.0979\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.1051 - val_loss: 0.0175 - val_mae: 0.0977\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0947 - val_loss: 0.0176 - val_mae: 0.0978\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0935 - val_loss: 0.0176 - val_mae: 0.0979\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0065 - mae: 0.0911 - val_loss: 0.0177 - val_mae: 0.0981\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0074 - mae: 0.0965 - val_loss: 0.0178 - val_mae: 0.0983\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0069 - mae: 0.0920 - val_loss: 0.0178 - val_mae: 0.0985\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0058 - mae: 0.0857 - val_loss: 0.0179 - val_mae: 0.0987\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0068 - mae: 0.0918 - val_loss: 0.0180 - val_mae: 0.0989\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0063 - mae: 0.0880 - val_loss: 0.0180 - val_mae: 0.0991\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0908 - val_loss: 0.0181 - val_mae: 0.0993\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0072 - mae: 0.0957 - val_loss: 0.0181 - val_mae: 0.0994\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - mae: 0.0873 - val_loss: 0.0182 - val_mae: 0.0992\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0068 - mae: 0.0921 - val_loss: 0.0182 - val_mae: 0.0991\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0077 - mae: 0.0936 - val_loss: 0.0182 - val_mae: 0.0988\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - mae: 0.0909 - val_loss: 0.0182 - val_mae: 0.0985\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0787 - val_loss: 0.0181 - val_mae: 0.0983\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0873 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0051 - mae: 0.0808 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.0980\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - mae: 0.0865 - val_loss: 0.0180 - val_mae: 0.0978\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0870 - val_loss: 0.0180 - val_mae: 0.0975\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0052 - mae: 0.0791 - val_loss: 0.0180 - val_mae: 0.0972\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0823 - val_loss: 0.0180 - val_mae: 0.0969\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0757 - val_loss: 0.0180 - val_mae: 0.0967\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0820 - val_loss: 0.0179 - val_mae: 0.0965\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0056 - mae: 0.0824 - val_loss: 0.0179 - val_mae: 0.0963\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0055 - mae: 0.0788 - val_loss: 0.0179 - val_mae: 0.0961\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0790 - val_loss: 0.0179 - val_mae: 0.0958\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0776 - val_loss: 0.0179 - val_mae: 0.0956\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047 - mae: 0.0767 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0055 - mae: 0.0810 - val_loss: 0.0178 - val_mae: 0.0955\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0050 - mae: 0.0783 - val_loss: 0.0178 - val_mae: 0.0956\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0052 - mae: 0.0777 - val_loss: 0.0178 - val_mae: 0.0957\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0707 - val_loss: 0.0178 - val_mae: 0.0959\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0057 - mae: 0.0827 - val_loss: 0.0178 - val_mae: 0.0959\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0740 - val_loss: 0.0178 - val_mae: 0.0960\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0713 - val_loss: 0.0178 - val_mae: 0.0961\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0763 - val_loss: 0.0178 - val_mae: 0.0961\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0682 - val_loss: 0.0177 - val_mae: 0.0962\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0963\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0044 - mae: 0.0711 - val_loss: 0.0177 - val_mae: 0.0962\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0046 - mae: 0.0734 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0048 - mae: 0.0741 - val_loss: 0.0176 - val_mae: 0.0960\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0694 - val_loss: 0.0176 - val_mae: 0.0959\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0042 - mae: 0.0701 - val_loss: 0.0176 - val_mae: 0.0956\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0045 - mae: 0.0720 - val_loss: 0.0176 - val_mae: 0.0955\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0039 - mae: 0.0700 - val_loss: 0.0175 - val_mae: 0.0954\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0953\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0710 - val_loss: 0.0175 - val_mae: 0.0951\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0046 - mae: 0.0730 - val_loss: 0.0175 - val_mae: 0.0949\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0044 - mae: 0.0698 - val_loss: 0.0175 - val_mae: 0.0946\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0647 - val_loss: 0.0175 - val_mae: 0.0944\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0942\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0639 - val_loss: 0.0175 - val_mae: 0.0940\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0175 - val_mae: 0.0939\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0038 - mae: 0.0670 - val_loss: 0.0175 - val_mae: 0.0938\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0937\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0707 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0662 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0659 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0644 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0632 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.0935\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0637 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0938\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0939\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - mae: 0.0615 - val_loss: 0.0176 - val_mae: 0.0941\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0176 - val_mae: 0.0942\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0572 - val_loss: 0.0177 - val_mae: 0.0943\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0621 - val_loss: 0.0177 - val_mae: 0.0944\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0944\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0037 - mae: 0.0660 - val_loss: 0.0177 - val_mae: 0.0945\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0177 - val_mae: 0.0946\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0947\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0646 - val_loss: 0.0177 - val_mae: 0.0949\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - mae: 0.0590 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0176 - val_mae: 0.0952\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0032 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0027 - mae: 0.0588 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0584 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0954\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0608 - val_loss: 0.0176 - val_mae: 0.0952\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0651 - val_loss: 0.0176 - val_mae: 0.0951\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - mae: 0.0562 - val_loss: 0.0176 - val_mae: 0.0950\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0594 - val_loss: 0.0176 - val_mae: 0.0949\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0948\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0579 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0030 - mae: 0.0593 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0594 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0176 - val_mae: 0.0947\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0176 - val_mae: 0.0949\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0527 - val_loss: 0.0177 - val_mae: 0.0951\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0506 - val_loss: 0.0176 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0554 - val_loss: 0.0176 - val_mae: 0.0956\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0557 - val_loss: 0.0176 - val_mae: 0.0958\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0541 - val_loss: 0.0176 - val_mae: 0.0961\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0565 - val_loss: 0.0176 - val_mae: 0.0963\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0965\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0540 - val_loss: 0.0176 - val_mae: 0.0966\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0551 - val_loss: 0.0176 - val_mae: 0.0967\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0511 - val_loss: 0.0176 - val_mae: 0.0967\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0177 - val_mae: 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:35,213] Trial 20 finished with value: 0.09668686985969543 and parameters: {'learning_rate': 0.0001683163977248562, 'weight_decay': 2.048318699209433e-09}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - mae: 0.2471 - val_loss: 0.0224 - val_mae: 0.1401\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0272 - mae: 0.1847 - val_loss: 0.0218 - val_mae: 0.1265\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0218 - mae: 0.1678 - val_loss: 0.0203 - val_mae: 0.1145\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0153 - mae: 0.1380 - val_loss: 0.0203 - val_mae: 0.1135\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0205 - val_mae: 0.1147\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0085 - mae: 0.1054 - val_loss: 0.0203 - val_mae: 0.1122\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0083 - mae: 0.1046 - val_loss: 0.0201 - val_mae: 0.1090\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0926 - val_loss: 0.0198 - val_mae: 0.1045\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0822 - val_loss: 0.0195 - val_mae: 0.1006\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0192 - val_mae: 0.0976\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0063 - mae: 0.0808 - val_loss: 0.0191 - val_mae: 0.0958\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - mae: 0.0791 - val_loss: 0.0188 - val_mae: 0.0953\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0052 - mae: 0.0721 - val_loss: 0.0184 - val_mae: 0.0962\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0181 - val_mae: 0.0982\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0177 - val_mae: 0.1005\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.1035\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0048 - mae: 0.0698 - val_loss: 0.0173 - val_mae: 0.1062\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0043 - mae: 0.0683 - val_loss: 0.0173 - val_mae: 0.1081\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041 - mae: 0.0671 - val_loss: 0.0172 - val_mae: 0.1082\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0038 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.1053\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0655 - val_loss: 0.0165 - val_mae: 0.1010\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0163 - val_mae: 0.0973\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0162 - val_mae: 0.0953\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0162 - val_mae: 0.0953\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0161 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.0995\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.1031\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0161 - val_mae: 0.1056\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0161 - val_mae: 0.1079\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0161 - val_mae: 0.1081\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.1077\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0161 - val_mae: 0.1071\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0503 - val_loss: 0.0160 - val_mae: 0.1060\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0503 - val_loss: 0.0160 - val_mae: 0.1060\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0160 - val_mae: 0.1069\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0492 - val_loss: 0.0160 - val_mae: 0.1083\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0161 - val_mae: 0.1095\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0162 - val_mae: 0.1110\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0161 - val_mae: 0.1106\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0469 - val_loss: 0.0160 - val_mae: 0.1104\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0160 - val_mae: 0.1109\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0159 - val_mae: 0.1117\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0158 - val_mae: 0.1121\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0462 - val_loss: 0.0157 - val_mae: 0.1100\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0438 - val_loss: 0.0155 - val_mae: 0.1084\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0448 - val_loss: 0.0155 - val_mae: 0.1082\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0157 - val_mae: 0.1105\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0159 - val_mae: 0.1127\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0432 - val_loss: 0.0162 - val_mae: 0.1134\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - mae: 0.0412 - val_loss: 0.0163 - val_mae: 0.1120\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.1089\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0414 - val_loss: 0.0162 - val_mae: 0.1090\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.1126\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0418 - val_loss: 0.0162 - val_mae: 0.1144\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0447 - val_loss: 0.0161 - val_mae: 0.1156\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0159 - val_mae: 0.1147\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0156 - val_mae: 0.1113\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0155 - val_mae: 0.1083\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0156 - val_mae: 0.1096\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0379 - val_loss: 0.0157 - val_mae: 0.1105\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0352 - val_loss: 0.0158 - val_mae: 0.1110\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0158 - val_mae: 0.1112\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 0.0158 - val_mae: 0.1107\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0157 - val_mae: 0.1113\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.1106\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - mae: 0.0397 - val_loss: 0.0157 - val_mae: 0.1111\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - mae: 0.0359 - val_loss: 0.0156 - val_mae: 0.1076\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0365 - val_loss: 0.0157 - val_mae: 0.1075\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0326 - val_loss: 0.0159 - val_mae: 0.1092\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0160 - val_mae: 0.1096\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0161 - val_mae: 0.1099\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3661e-04 - mae: 0.0319 - val_loss: 0.0160 - val_mae: 0.1093\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.6040e-04 - mae: 0.0300 - val_loss: 0.0160 - val_mae: 0.1075\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - mae: 0.0345 - val_loss: 0.0160 - val_mae: 0.1058\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6177e-04 - mae: 0.0336 - val_loss: 0.0160 - val_mae: 0.1046\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 0.0160 - val_mae: 0.1067\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1074e-04 - mae: 0.0292 - val_loss: 0.0161 - val_mae: 0.1096\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.5140e-04 - mae: 0.0325 - val_loss: 0.0162 - val_mae: 0.1117\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.9192e-04 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.1114\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 8.7086e-04 - mae: 0.0325 - val_loss: 0.0160 - val_mae: 0.1112\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.8187e-04 - mae: 0.0346 - val_loss: 0.0158 - val_mae: 0.1061\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0158 - val_mae: 0.1018\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0343 - val_loss: 0.0158 - val_mae: 0.1009\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0358 - val_loss: 0.0158 - val_mae: 0.1016\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.9911e-04 - mae: 0.0323 - val_loss: 0.0159 - val_mae: 0.1065\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.8157e-04 - mae: 0.0303 - val_loss: 0.0161 - val_mae: 0.1124\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.1186e-04 - mae: 0.0320 - val_loss: 0.0161 - val_mae: 0.1147\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.9962e-04 - mae: 0.0329 - val_loss: 0.0159 - val_mae: 0.1130\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.2614e-04 - mae: 0.0291 - val_loss: 0.0157 - val_mae: 0.1083\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.6704e-04 - mae: 0.0336 - val_loss: 0.0156 - val_mae: 0.1012\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.4648e-04 - mae: 0.0302 - val_loss: 0.0157 - val_mae: 0.0994\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0341 - val_loss: 0.0159 - val_mae: 0.1028\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.7001e-04 - mae: 0.0277 - val_loss: 0.0161 - val_mae: 0.1070\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.1939e-04 - mae: 0.0279 - val_loss: 0.0163 - val_mae: 0.1130\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.1273e-04 - mae: 0.0311 - val_loss: 0.0163 - val_mae: 0.1136\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.1888e-04 - mae: 0.0317 - val_loss: 0.0160 - val_mae: 0.1107\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.3832e-04 - mae: 0.0288 - val_loss: 0.0157 - val_mae: 0.1055\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9812e-04 - mae: 0.0282 - val_loss: 0.0156 - val_mae: 0.1029\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7109e-04 - mae: 0.0262 - val_loss: 0.0156 - val_mae: 0.1021\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.2528e-04 - mae: 0.0296 - val_loss: 0.0156 - val_mae: 0.1032\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7.2988e-04 - mae: 0.0286 - val_loss: 0.0157 - val_mae: 0.1065\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0149e-04 - mae: 0.0286 - val_loss: 0.0158 - val_mae: 0.1107\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.0775e-04 - mae: 0.0304 - val_loss: 0.0159 - val_mae: 0.1145\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.4829e-04 - mae: 0.0296 - val_loss: 0.0158 - val_mae: 0.1148\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.1548e-04 - mae: 0.0297 - val_loss: 0.0156 - val_mae: 0.1108\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0333 - val_loss: 0.0154 - val_mae: 0.1036\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.9259e-04 - mae: 0.0265 - val_loss: 0.0155 - val_mae: 0.0999\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.5344e-04 - mae: 0.0301 - val_loss: 0.0157 - val_mae: 0.0997\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 6.6130e-04 - mae: 0.0291 - val_loss: 0.0158 - val_mae: 0.0999\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.8288e-04 - mae: 0.0305 - val_loss: 0.0159 - val_mae: 0.1023\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 8.7071e-04 - mae: 0.0305 - val_loss: 0.0161 - val_mae: 0.1076\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8210e-04 - mae: 0.0280 - val_loss: 0.0162 - val_mae: 0.1138\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5928e-04 - mae: 0.0298 - val_loss: 0.0163 - val_mae: 0.1152\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.0839e-04 - mae: 0.0323 - val_loss: 0.0162 - val_mae: 0.1143\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 7.8889e-04 - mae: 0.0299 - val_loss: 0.0160 - val_mae: 0.1125\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.6993e-04 - mae: 0.0326 - val_loss: 0.0157 - val_mae: 0.1081\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.7192e-04 - mae: 0.0287 - val_loss: 0.0153 - val_mae: 0.1020\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.3000e-04 - mae: 0.0306 - val_loss: 0.0152 - val_mae: 0.0988\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.5920e-04 - mae: 0.0271 - val_loss: 0.0153 - val_mae: 0.0975\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.8530e-04 - mae: 0.0284 - val_loss: 0.0154 - val_mae: 0.0987\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.8123e-04 - mae: 0.0314 - val_loss: 0.0155 - val_mae: 0.1013\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 6.4251e-04 - mae: 0.0270 - val_loss: 0.0158 - val_mae: 0.1035\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.0820e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.1040\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.4343e-04 - mae: 0.0273 - val_loss: 0.0158 - val_mae: 0.1038\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2685e-04 - mae: 0.0279 - val_loss: 0.0158 - val_mae: 0.1041\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.0143e-04 - mae: 0.0262 - val_loss: 0.0158 - val_mae: 0.1042\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.9596e-04 - mae: 0.0276 - val_loss: 0.0158 - val_mae: 0.1029\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8081e-04 - mae: 0.0288 - val_loss: 0.0157 - val_mae: 0.1015\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.6594e-04 - mae: 0.0273 - val_loss: 0.0157 - val_mae: 0.1019\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.2871e-04 - mae: 0.0265 - val_loss: 0.0156 - val_mae: 0.1014\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.3656e-04 - mae: 0.0244 - val_loss: 0.0157 - val_mae: 0.1004\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.8692e-04 - mae: 0.0234 - val_loss: 0.0157 - val_mae: 0.0991\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4406e-04 - mae: 0.0297 - val_loss: 0.0157 - val_mae: 0.0986\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 7.7310e-04 - mae: 0.0294 - val_loss: 0.0156 - val_mae: 0.0991\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.1644e-04 - mae: 0.0280 - val_loss: 0.0157 - val_mae: 0.1010\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.5947e-04 - mae: 0.0266 - val_loss: 0.0159 - val_mae: 0.1036\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.4708e-04 - mae: 0.0233 - val_loss: 0.0159 - val_mae: 0.1039\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 6.4017e-04 - mae: 0.0274 - val_loss: 0.0160 - val_mae: 0.1032\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.6329e-04 - mae: 0.0274 - val_loss: 0.0160 - val_mae: 0.1024\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.6477e-04 - mae: 0.0280 - val_loss: 0.0160 - val_mae: 0.1018\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.8968e-04 - mae: 0.0290 - val_loss: 0.0161 - val_mae: 0.1043\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.5880e-04 - mae: 0.0256 - val_loss: 0.0162 - val_mae: 0.1077\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.7631e-04 - mae: 0.0287 - val_loss: 0.0162 - val_mae: 0.1057\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2652e-04 - mae: 0.0265 - val_loss: 0.0162 - val_mae: 0.1037\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.9962e-04 - mae: 0.0244 - val_loss: 0.0162 - val_mae: 0.1015\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.9768e-04 - mae: 0.0283 - val_loss: 0.0162 - val_mae: 0.1012\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.9414e-04 - mae: 0.0244 - val_loss: 0.0162 - val_mae: 0.1014\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.0767e-04 - mae: 0.0259 - val_loss: 0.0162 - val_mae: 0.1024\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.5467e-04 - mae: 0.0238 - val_loss: 0.0161 - val_mae: 0.1017\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8.6036e-04 - mae: 0.0300 - val_loss: 0.0160 - val_mae: 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:46,363] Trial 21 finished with value: 0.10334796458482742 and parameters: {'learning_rate': 0.0011424595761808235, 'weight_decay': 3.2719522473580964e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1391 - mae: 0.4121 - val_loss: 0.3061 - val_mae: 0.6788\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3887 - mae: 0.7678 - val_loss: 0.0311 - val_mae: 0.1889\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0240 - mae: 0.1734 - val_loss: 0.0242 - val_mae: 0.1154\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0111 - mae: 0.1137 - val_loss: 0.0238 - val_mae: 0.1077\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0084 - mae: 0.0968 - val_loss: 0.0230 - val_mae: 0.1051\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0217 - val_mae: 0.0969\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0199 - val_mae: 0.0863\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0060 - mae: 0.0773 - val_loss: 0.0186 - val_mae: 0.0953\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0955\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0053 - mae: 0.0723 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0885\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0043 - mae: 0.0687 - val_loss: 0.0169 - val_mae: 0.0960\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0637 - val_loss: 0.0167 - val_mae: 0.0919\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0871\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0164 - val_mae: 0.0925\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - mae: 0.0623 - val_loss: 0.0163 - val_mae: 0.0957\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0670 - val_loss: 0.0164 - val_mae: 0.0847\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0812\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0552 - val_loss: 0.0158 - val_mae: 0.0954\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0601 - val_loss: 0.0157 - val_mae: 0.0921\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0159 - val_mae: 0.0851\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0157 - val_mae: 0.0870\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0952\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0164 - val_mae: 0.0800\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0549 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0035 - mae: 0.0557 - val_loss: 0.0174 - val_mae: 0.0782\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0037 - mae: 0.0551 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0804\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0171 - val_mae: 0.0796\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0543 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0516 - val_loss: 0.0170 - val_mae: 0.0845\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0152 - val_mae: 0.0919\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0157 - val_mae: 0.1197\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0047 - mae: 0.0736 - val_loss: 0.0160 - val_mae: 0.0831\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0820\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0173 - val_mae: 0.0863\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0644 - val_loss: 0.0167 - val_mae: 0.0826\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0166 - val_mae: 0.0821\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0822\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0823\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0166 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - mae: 0.0543 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0178 - val_mae: 0.0926\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0166 - val_mae: 0.0843\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0841\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0840\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0839\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0166 - val_mae: 0.0837\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0835\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0834\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0836\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0834\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0833\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - mae: 0.0581 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0835\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - mae: 0.0612 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0849\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0848\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0845\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0034 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:46:58,250] Trial 22 finished with value: 0.08396507054567337 and parameters: {'learning_rate': 0.005754092520191024, 'weight_decay': 1.8448355981529016e-06}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0503 - mae: 0.2544 - val_loss: 0.0239 - val_mae: 0.1249\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0294 - mae: 0.1978 - val_loss: 0.0196 - val_mae: 0.1045\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0227 - mae: 0.1691 - val_loss: 0.0187 - val_mae: 0.1093\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0221 - mae: 0.1707 - val_loss: 0.0193 - val_mae: 0.1163\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0177 - mae: 0.1516 - val_loss: 0.0201 - val_mae: 0.1178\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0190 - mae: 0.1597 - val_loss: 0.0204 - val_mae: 0.1149\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0139 - mae: 0.1328 - val_loss: 0.0204 - val_mae: 0.1101\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0136 - mae: 0.1279 - val_loss: 0.0203 - val_mae: 0.1055\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0126 - mae: 0.1240 - val_loss: 0.0202 - val_mae: 0.1019\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0115 - mae: 0.1154 - val_loss: 0.0202 - val_mae: 0.0997\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1063 - val_loss: 0.0202 - val_mae: 0.0981\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0082 - mae: 0.1001 - val_loss: 0.0203 - val_mae: 0.0975\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0089 - mae: 0.1041 - val_loss: 0.0204 - val_mae: 0.0974\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0072 - mae: 0.0924 - val_loss: 0.0203 - val_mae: 0.0969\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0071 - mae: 0.0946 - val_loss: 0.0202 - val_mae: 0.0958\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0078 - mae: 0.0952 - val_loss: 0.0200 - val_mae: 0.0948\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0075 - mae: 0.0934 - val_loss: 0.0198 - val_mae: 0.0932\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0071 - mae: 0.0875 - val_loss: 0.0197 - val_mae: 0.0918\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0060 - mae: 0.0824 - val_loss: 0.0195 - val_mae: 0.0904\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0060 - mae: 0.0801 - val_loss: 0.0192 - val_mae: 0.0888\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0059 - mae: 0.0792 - val_loss: 0.0190 - val_mae: 0.0875\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0051 - mae: 0.0742 - val_loss: 0.0188 - val_mae: 0.0863\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0726 - val_loss: 0.0185 - val_mae: 0.0853\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0051 - mae: 0.0762 - val_loss: 0.0183 - val_mae: 0.0845\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0840\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0049 - mae: 0.0751 - val_loss: 0.0179 - val_mae: 0.0842\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0046 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0844\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0049 - mae: 0.0723 - val_loss: 0.0176 - val_mae: 0.0845\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0676 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0173 - val_mae: 0.0846\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0041 - mae: 0.0670 - val_loss: 0.0172 - val_mae: 0.0842\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0172 - val_mae: 0.0837\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0039 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0037 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0166 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0033 - mae: 0.0613 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0576 - val_loss: 0.0164 - val_mae: 0.0834\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0164 - val_mae: 0.0832\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0163 - val_mae: 0.0829\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0163 - val_mae: 0.0829\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0162 - val_mae: 0.0829\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0162 - val_mae: 0.0827\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0162 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0162 - val_mae: 0.0818\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0162 - val_mae: 0.0814\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0161 - val_mae: 0.0812\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0527 - val_loss: 0.0160 - val_mae: 0.0813\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0160 - val_mae: 0.0814\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0534 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0160 - val_mae: 0.0822\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0160 - val_mae: 0.0825\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0160 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0160 - val_mae: 0.0832\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0514 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0026 - mae: 0.0521 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0159 - val_mae: 0.0835\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0159 - val_mae: 0.0836\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0021 - mae: 0.0497 - val_loss: 0.0160 - val_mae: 0.0833\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0160 - val_mae: 0.0829\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0160 - val_mae: 0.0825\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0458 - val_loss: 0.0160 - val_mae: 0.0823\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0159 - val_mae: 0.0825\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0158 - val_mae: 0.0826\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0158 - val_mae: 0.0828\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0157 - val_mae: 0.0831\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0156 - val_mae: 0.0835\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0500 - val_loss: 0.0155 - val_mae: 0.0838\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0835\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0155 - val_mae: 0.0827\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0824\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0156 - val_mae: 0.0822\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0442 - val_loss: 0.0156 - val_mae: 0.0826\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - mae: 0.0440 - val_loss: 0.0154 - val_mae: 0.0837\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0153 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - mae: 0.0463 - val_loss: 0.0152 - val_mae: 0.0841\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - mae: 0.0431 - val_loss: 0.0152 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0153 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0456 - val_loss: 0.0154 - val_mae: 0.0808\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0155 - val_mae: 0.0804\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0411 - val_loss: 0.0155 - val_mae: 0.0806\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0441 - val_loss: 0.0154 - val_mae: 0.0815\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0153 - val_mae: 0.0825\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0152 - val_mae: 0.0837\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0152 - val_mae: 0.0845\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0152 - val_mae: 0.0850\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0152 - val_mae: 0.0851\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0392 - val_loss: 0.0153 - val_mae: 0.0850\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0017 - mae: 0.0436 - val_loss: 0.0154 - val_mae: 0.0844\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0423 - val_loss: 0.0154 - val_mae: 0.0842\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0154 - val_mae: 0.0840\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0443 - val_loss: 0.0154 - val_mae: 0.0839\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0397 - val_loss: 0.0152 - val_mae: 0.0842\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0017 - mae: 0.0434 - val_loss: 0.0151 - val_mae: 0.0850\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0150 - val_mae: 0.0861\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0016 - mae: 0.0449 - val_loss: 0.0149 - val_mae: 0.0861\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0386 - val_loss: 0.0150 - val_mae: 0.0854\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - mae: 0.0416 - val_loss: 0.0152 - val_mae: 0.0841\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0155 - val_mae: 0.0829\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0157 - val_mae: 0.0823\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0157 - val_mae: 0.0823\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0392 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0415 - val_loss: 0.0153 - val_mae: 0.0861\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0152 - val_mae: 0.0874\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - mae: 0.0389 - val_loss: 0.0151 - val_mae: 0.0881\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0150 - val_mae: 0.0882\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0151 - val_mae: 0.0875\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0151 - val_mae: 0.0859\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0845\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - mae: 0.0395 - val_loss: 0.0152 - val_mae: 0.0833\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0825\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - mae: 0.0327 - val_loss: 0.0152 - val_mae: 0.0820\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0151 - val_mae: 0.0822\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0150 - val_mae: 0.0831\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0391 - val_loss: 0.0149 - val_mae: 0.0839\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - mae: 0.0362 - val_loss: 0.0148 - val_mae: 0.0848\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.0148 - val_mae: 0.0852\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mae: 0.0378 - val_loss: 0.0149 - val_mae: 0.0851\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0013 - mae: 0.0397 - val_loss: 0.0151 - val_mae: 0.0846\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0012 - mae: 0.0390 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - mae: 0.0389 - val_loss: 0.0153 - val_mae: 0.0841\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0154 - val_mae: 0.0842\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 0.0154 - val_mae: 0.0844\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - mae: 0.0356 - val_loss: 0.0153 - val_mae: 0.0848\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - mae: 0.0385 - val_loss: 0.0152 - val_mae: 0.0857\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.0151 - val_mae: 0.0872\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0150 - val_mae: 0.0883\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - mae: 0.0403 - val_loss: 0.0150 - val_mae: 0.0886\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - mae: 0.0375 - val_loss: 0.0150 - val_mae: 0.0878\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.4606e-04 - mae: 0.0332 - val_loss: 0.0152 - val_mae: 0.0865\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.5957e-04 - mae: 0.0331 - val_loss: 0.0153 - val_mae: 0.0858\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - mae: 0.0350 - val_loss: 0.0154 - val_mae: 0.0858\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0154 - val_mae: 0.0866\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - mae: 0.0357 - val_loss: 0.0154 - val_mae: 0.0869\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - mae: 0.0372 - val_loss: 0.0154 - val_mae: 0.0873\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0358 - val_loss: 0.0153 - val_mae: 0.0877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:09,400] Trial 23 finished with value: 0.08773404359817505 and parameters: {'learning_rate': 0.0005455532692229183, 'weight_decay': 6.283510497269223e-07}. Best is trial 14 with value: 0.08045151829719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0923 - mae: 0.3431 - val_loss: 0.0602 - val_mae: 0.2595\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0992 - mae: 0.3477 - val_loss: 0.0601 - val_mae: 0.2593\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0906 - mae: 0.3360 - val_loss: 0.0600 - val_mae: 0.2590\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0730 - mae: 0.3011 - val_loss: 0.0599 - val_mae: 0.2587\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0996 - mae: 0.3532 - val_loss: 0.0598 - val_mae: 0.2585\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0928 - mae: 0.3332 - val_loss: 0.0597 - val_mae: 0.2582\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1045 - mae: 0.3556 - val_loss: 0.0596 - val_mae: 0.2579\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0888 - mae: 0.3302 - val_loss: 0.0595 - val_mae: 0.2576\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1058 - mae: 0.3804 - val_loss: 0.0593 - val_mae: 0.2573\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0906 - mae: 0.3407 - val_loss: 0.0592 - val_mae: 0.2570\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0900 - mae: 0.3376 - val_loss: 0.0591 - val_mae: 0.2568\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1104 - mae: 0.3608 - val_loss: 0.0590 - val_mae: 0.2565\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1077 - mae: 0.3623 - val_loss: 0.0589 - val_mae: 0.2562\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0927 - mae: 0.3500 - val_loss: 0.0588 - val_mae: 0.2559\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1001 - mae: 0.3546 - val_loss: 0.0587 - val_mae: 0.2556\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0977 - mae: 0.3360 - val_loss: 0.0585 - val_mae: 0.2553\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1076 - mae: 0.3656 - val_loss: 0.0584 - val_mae: 0.2550\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1050 - mae: 0.3651 - val_loss: 0.0583 - val_mae: 0.2548\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0923 - mae: 0.3434 - val_loss: 0.0582 - val_mae: 0.2545\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0958 - mae: 0.3437 - val_loss: 0.0581 - val_mae: 0.2542\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0888 - mae: 0.3339 - val_loss: 0.0580 - val_mae: 0.2539\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0850 - mae: 0.3325 - val_loss: 0.0579 - val_mae: 0.2536\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1042 - mae: 0.3600 - val_loss: 0.0578 - val_mae: 0.2534\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0959 - mae: 0.3382 - val_loss: 0.0577 - val_mae: 0.2531\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1088 - mae: 0.3729 - val_loss: 0.0575 - val_mae: 0.2528\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0920 - mae: 0.3448 - val_loss: 0.0574 - val_mae: 0.2525\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0964 - mae: 0.3471 - val_loss: 0.0573 - val_mae: 0.2523\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0985 - mae: 0.3554 - val_loss: 0.0572 - val_mae: 0.2520\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0980 - mae: 0.3594 - val_loss: 0.0571 - val_mae: 0.2517\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0828 - mae: 0.3317 - val_loss: 0.0570 - val_mae: 0.2514\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1029 - mae: 0.3663 - val_loss: 0.0569 - val_mae: 0.2511\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0954 - mae: 0.3416 - val_loss: 0.0568 - val_mae: 0.2509\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0845 - mae: 0.3279 - val_loss: 0.0567 - val_mae: 0.2506\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0901 - mae: 0.3410 - val_loss: 0.0566 - val_mae: 0.2503\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0872 - mae: 0.3334 - val_loss: 0.0565 - val_mae: 0.2500\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0878 - mae: 0.3370 - val_loss: 0.0564 - val_mae: 0.2498\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1022 - mae: 0.3581 - val_loss: 0.0563 - val_mae: 0.2495\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0772 - mae: 0.3036 - val_loss: 0.0562 - val_mae: 0.2492\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1033 - mae: 0.3526 - val_loss: 0.0561 - val_mae: 0.2490\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1080 - mae: 0.3736 - val_loss: 0.0560 - val_mae: 0.2487\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0959 - mae: 0.3481 - val_loss: 0.0559 - val_mae: 0.2484\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0902 - mae: 0.3311 - val_loss: 0.0558 - val_mae: 0.2482\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0920 - mae: 0.3447 - val_loss: 0.0557 - val_mae: 0.2479\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1020 - mae: 0.3535 - val_loss: 0.0556 - val_mae: 0.2477\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0890 - mae: 0.3305 - val_loss: 0.0554 - val_mae: 0.2474\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0821 - mae: 0.3336 - val_loss: 0.0553 - val_mae: 0.2471\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0861 - mae: 0.3361 - val_loss: 0.0552 - val_mae: 0.2469\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1045 - mae: 0.3700 - val_loss: 0.0551 - val_mae: 0.2466\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0892 - mae: 0.3376 - val_loss: 0.0550 - val_mae: 0.2464\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0835 - mae: 0.3191 - val_loss: 0.0549 - val_mae: 0.2461\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0802 - mae: 0.3233 - val_loss: 0.0549 - val_mae: 0.2458\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0838 - mae: 0.3262 - val_loss: 0.0548 - val_mae: 0.2456\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0959 - mae: 0.3552 - val_loss: 0.0547 - val_mae: 0.2453\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0954 - mae: 0.3450 - val_loss: 0.0546 - val_mae: 0.2451\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0932 - mae: 0.3435 - val_loss: 0.0545 - val_mae: 0.2448\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0953 - mae: 0.3556 - val_loss: 0.0544 - val_mae: 0.2446\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0846 - mae: 0.3308 - val_loss: 0.0543 - val_mae: 0.2443\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0905 - mae: 0.3408 - val_loss: 0.0542 - val_mae: 0.2440\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0963 - mae: 0.3475 - val_loss: 0.0541 - val_mae: 0.2438\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0887 - mae: 0.3309 - val_loss: 0.0540 - val_mae: 0.2435\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0801 - mae: 0.3072 - val_loss: 0.0539 - val_mae: 0.2433\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0903 - mae: 0.3499 - val_loss: 0.0538 - val_mae: 0.2430\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0886 - mae: 0.3309 - val_loss: 0.0537 - val_mae: 0.2428\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0769 - mae: 0.3213 - val_loss: 0.0536 - val_mae: 0.2425\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0915 - mae: 0.3374 - val_loss: 0.0535 - val_mae: 0.2423\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1015 - mae: 0.3543 - val_loss: 0.0534 - val_mae: 0.2420\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0888 - mae: 0.3350 - val_loss: 0.0533 - val_mae: 0.2418\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0791 - mae: 0.3249 - val_loss: 0.0532 - val_mae: 0.2415\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1146 - mae: 0.3887 - val_loss: 0.0531 - val_mae: 0.2413\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0832 - mae: 0.3323 - val_loss: 0.0530 - val_mae: 0.2410\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0918 - mae: 0.3478 - val_loss: 0.0529 - val_mae: 0.2408\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0853 - mae: 0.3240 - val_loss: 0.0528 - val_mae: 0.2405\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0842 - mae: 0.3222 - val_loss: 0.0527 - val_mae: 0.2403\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0809 - mae: 0.3228 - val_loss: 0.0526 - val_mae: 0.2400\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1003 - mae: 0.3455 - val_loss: 0.0526 - val_mae: 0.2397\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0997 - mae: 0.3525 - val_loss: 0.0525 - val_mae: 0.2395\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0701 - mae: 0.3080 - val_loss: 0.0524 - val_mae: 0.2392\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0878 - mae: 0.3289 - val_loss: 0.0523 - val_mae: 0.2390\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0890 - mae: 0.3359 - val_loss: 0.0522 - val_mae: 0.2387\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0968 - mae: 0.3581 - val_loss: 0.0521 - val_mae: 0.2385\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0823 - mae: 0.3258 - val_loss: 0.0520 - val_mae: 0.2382\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0812 - mae: 0.3196 - val_loss: 0.0519 - val_mae: 0.2379\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0853 - mae: 0.3360 - val_loss: 0.0518 - val_mae: 0.2377\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0852 - mae: 0.3306 - val_loss: 0.0517 - val_mae: 0.2374\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0907 - mae: 0.3459 - val_loss: 0.0516 - val_mae: 0.2372\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0826 - mae: 0.3289 - val_loss: 0.0516 - val_mae: 0.2369\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0986 - mae: 0.3562 - val_loss: 0.0515 - val_mae: 0.2367\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0737 - mae: 0.3054 - val_loss: 0.0514 - val_mae: 0.2364\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0912 - mae: 0.3473 - val_loss: 0.0513 - val_mae: 0.2362\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1028 - mae: 0.3511 - val_loss: 0.0512 - val_mae: 0.2359\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0953 - mae: 0.3441 - val_loss: 0.0511 - val_mae: 0.2356\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0879 - mae: 0.3349 - val_loss: 0.0510 - val_mae: 0.2354\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0699 - mae: 0.2964 - val_loss: 0.0509 - val_mae: 0.2351\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0952 - mae: 0.3428 - val_loss: 0.0508 - val_mae: 0.2349\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0861 - mae: 0.3224 - val_loss: 0.0507 - val_mae: 0.2346\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0996 - mae: 0.3556 - val_loss: 0.0507 - val_mae: 0.2344\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0823 - mae: 0.3328 - val_loss: 0.0506 - val_mae: 0.2341\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0841 - mae: 0.3342 - val_loss: 0.0505 - val_mae: 0.2339\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0915 - mae: 0.3445 - val_loss: 0.0504 - val_mae: 0.2336\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0946 - mae: 0.3487 - val_loss: 0.0503 - val_mae: 0.2334\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0920 - mae: 0.3424 - val_loss: 0.0502 - val_mae: 0.2331\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0748 - mae: 0.3048 - val_loss: 0.0501 - val_mae: 0.2329\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0776 - mae: 0.3091 - val_loss: 0.0500 - val_mae: 0.2326\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0839 - mae: 0.3271 - val_loss: 0.0500 - val_mae: 0.2324\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0688 - mae: 0.2903 - val_loss: 0.0499 - val_mae: 0.2321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0802 - mae: 0.3207 - val_loss: 0.0498 - val_mae: 0.2319\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0837 - mae: 0.3335 - val_loss: 0.0497 - val_mae: 0.2316\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0760 - mae: 0.3092 - val_loss: 0.0496 - val_mae: 0.2314\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0953 - mae: 0.3413 - val_loss: 0.0495 - val_mae: 0.2312\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0808 - mae: 0.3183 - val_loss: 0.0495 - val_mae: 0.2309\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0839 - mae: 0.3234 - val_loss: 0.0494 - val_mae: 0.2307\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0755 - mae: 0.3061 - val_loss: 0.0493 - val_mae: 0.2304\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0924 - mae: 0.3474 - val_loss: 0.0492 - val_mae: 0.2302\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0910 - mae: 0.3291 - val_loss: 0.0491 - val_mae: 0.2300\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0651 - mae: 0.2946 - val_loss: 0.0491 - val_mae: 0.2297\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0879 - mae: 0.3365 - val_loss: 0.0490 - val_mae: 0.2295\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0781 - mae: 0.3156 - val_loss: 0.0489 - val_mae: 0.2293\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0849 - mae: 0.3257 - val_loss: 0.0488 - val_mae: 0.2290\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0744 - mae: 0.3038 - val_loss: 0.0487 - val_mae: 0.2288\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0773 - mae: 0.3221 - val_loss: 0.0487 - val_mae: 0.2286\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0740 - mae: 0.3049 - val_loss: 0.0486 - val_mae: 0.2283\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0852 - mae: 0.3236 - val_loss: 0.0485 - val_mae: 0.2281\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0827 - mae: 0.3206 - val_loss: 0.0484 - val_mae: 0.2279\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0923 - mae: 0.3536 - val_loss: 0.0484 - val_mae: 0.2276\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0870 - mae: 0.3326 - val_loss: 0.0483 - val_mae: 0.2274\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0906 - mae: 0.3383 - val_loss: 0.0482 - val_mae: 0.2272\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0844 - mae: 0.3231 - val_loss: 0.0481 - val_mae: 0.2269\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0786 - mae: 0.3111 - val_loss: 0.0481 - val_mae: 0.2267\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0809 - mae: 0.3190 - val_loss: 0.0480 - val_mae: 0.2265\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0793 - mae: 0.3198 - val_loss: 0.0479 - val_mae: 0.2262\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0944 - mae: 0.3461 - val_loss: 0.0478 - val_mae: 0.2260\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0903 - mae: 0.3308 - val_loss: 0.0478 - val_mae: 0.2258\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0848 - mae: 0.3230 - val_loss: 0.0477 - val_mae: 0.2256\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0791 - mae: 0.3087 - val_loss: 0.0476 - val_mae: 0.2253\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0845 - mae: 0.3187 - val_loss: 0.0475 - val_mae: 0.2251\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0793 - mae: 0.3196 - val_loss: 0.0475 - val_mae: 0.2249\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0794 - mae: 0.3206 - val_loss: 0.0474 - val_mae: 0.2246\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0806 - mae: 0.3214 - val_loss: 0.0473 - val_mae: 0.2244\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0774 - mae: 0.3169 - val_loss: 0.0472 - val_mae: 0.2242\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0776 - mae: 0.3097 - val_loss: 0.0472 - val_mae: 0.2240\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0708 - mae: 0.2971 - val_loss: 0.0471 - val_mae: 0.2238\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0697 - mae: 0.3014 - val_loss: 0.0470 - val_mae: 0.2235\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0713 - mae: 0.3036 - val_loss: 0.0469 - val_mae: 0.2233\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0976 - mae: 0.3473 - val_loss: 0.0469 - val_mae: 0.2231\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0781 - mae: 0.3221 - val_loss: 0.0468 - val_mae: 0.2229\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0883 - mae: 0.3361 - val_loss: 0.0467 - val_mae: 0.2227\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0862 - mae: 0.3267 - val_loss: 0.0466 - val_mae: 0.2224\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0760 - mae: 0.3068 - val_loss: 0.0466 - val_mae: 0.2222\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0741 - mae: 0.3027 - val_loss: 0.0465 - val_mae: 0.2220\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0745 - mae: 0.3069 - val_loss: 0.0464 - val_mae: 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:20,450] Trial 24 finished with value: 0.22176793217658997 and parameters: {'learning_rate': 1.4277721913203198e-06, 'weight_decay': 7.468173516712232e-09}. Best is trial 14 with value: 0.08045151829719543.\n",
      "[I 2023-12-04 18:47:20,495] A new study created in RDB with name: no-name-750299b0-0b4e-4bf8-b195-df9d3e9aaffd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0240 - val_mae: 0.1185\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0240 - val_mae: 0.1185\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1054 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0240 - val_mae: 0.1184\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0100 - mae: 0.1096 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0097 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1184\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1059 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1054 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0096 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0096 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1182\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1042 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1098 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1026 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1091 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0099 - mae: 0.1056 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0101 - mae: 0.1081 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1181\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1113 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0095 - mae: 0.1038 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1072 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1058 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1043 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1061 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0239 - val_mae: 0.1180\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1035 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0096 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1057 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1036 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0101 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0096 - mae: 0.1045 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1065 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0100 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1179\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0097 - mae: 0.1066 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1044 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1123 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0095 - mae: 0.1031 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1075 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1048 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0239 - val_mae: 0.1178\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1053 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0097 - mae: 0.1069 - val_loss: 0.0239 - val_mae: 0.1177\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1079 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1096 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0101 - mae: 0.1075 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1028 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1027 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0095 - mae: 0.1041 - val_loss: 0.0238 - val_mae: 0.1176\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1073 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0238 - val_mae: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:40,387] Trial 0 finished with value: 0.11750979721546173 and parameters: {'learning_rate': 1.1943576480019415e-06, 'weight_decay': 4.8151753602524324e-05}. Best is trial 0 with value: 0.11750979721546173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1030 - val_loss: 0.0238 - val_mae: 0.1171\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1170\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.1002 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1027 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0088 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1039 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0087 - mae: 0.1007 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0087 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.1010 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0992 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1020 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0086 - mae: 0.1011 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0088 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1032 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1019 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1034 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.1013 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1044 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1026 - val_loss: 0.0237 - val_mae: 0.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:47:59,645] Trial 1 finished with value: 0.11665796488523483 and parameters: {'learning_rate': 5.12932979719174e-07, 'weight_decay': 0.0010695835611072054}. Best is trial 1 with value: 0.11665796488523483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1018\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0961\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0839 - val_loss: 0.0209 - val_mae: 0.0917\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0201 - val_mae: 0.0889\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0193 - val_mae: 0.0876\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0692 - val_loss: 0.0185 - val_mae: 0.0876\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0180 - val_mae: 0.0890\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0050 - mae: 0.0745 - val_loss: 0.0176 - val_mae: 0.0901\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0706 - val_loss: 0.0173 - val_mae: 0.0886\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0715 - val_loss: 0.0172 - val_mae: 0.0860\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0752 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0641 - val_loss: 0.0173 - val_mae: 0.0806\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0176 - val_mae: 0.0776\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0037 - mae: 0.0560 - val_loss: 0.0176 - val_mae: 0.0775\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0038 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0039 - mae: 0.0593 - val_loss: 0.0175 - val_mae: 0.0775\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0544 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0172 - val_mae: 0.0794\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0802\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0034 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0823\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0820\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0550 - val_loss: 0.0174 - val_mae: 0.0816\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0555 - val_loss: 0.0175 - val_mae: 0.0817\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0542 - val_loss: 0.0175 - val_mae: 0.0819\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0175 - val_mae: 0.0823\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0174 - val_mae: 0.0826\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0174 - val_mae: 0.0828\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0173 - val_mae: 0.0829\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0173 - val_mae: 0.0828\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0829\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0832\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0175 - val_mae: 0.0828\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0549 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0176 - val_mae: 0.0826\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0176 - val_mae: 0.0827\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0176 - val_mae: 0.0830\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0176 - val_mae: 0.0829\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0175 - val_mae: 0.0830\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0512 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0536 - val_loss: 0.0175 - val_mae: 0.0840\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0175 - val_mae: 0.0844\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0175 - val_mae: 0.0849\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0174 - val_mae: 0.0845\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0174 - val_mae: 0.0844\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0178 - val_mae: 0.0860\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0177 - val_mae: 0.0845\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0468 - val_loss: 0.0174 - val_mae: 0.0831\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - mae: 0.0522 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0025 - mae: 0.0542 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0484 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0545 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0510 - val_loss: 0.0172 - val_mae: 0.0849\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0515 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0168 - val_mae: 0.0852\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0169 - val_mae: 0.0845\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.0172 - val_mae: 0.0838\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0172 - val_mae: 0.0825\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0816\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0170 - val_mae: 0.0803\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0165 - val_mae: 0.0801\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0017 - mae: 0.0413 - val_loss: 0.0161 - val_mae: 0.0805\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0017 - mae: 0.0444 - val_loss: 0.0161 - val_mae: 0.0807\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0165 - val_mae: 0.0805\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0167 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - mae: 0.0396 - val_loss: 0.0165 - val_mae: 0.0808\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0431 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0157 - val_mae: 0.0848\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0157 - val_mae: 0.0845\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0158 - val_mae: 0.0838\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0159 - val_mae: 0.0839\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0014 - mae: 0.0401 - val_loss: 0.0161 - val_mae: 0.0835\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0160 - val_mae: 0.0873\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0159 - val_mae: 0.0897\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0384 - val_loss: 0.0161 - val_mae: 0.0903\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - mae: 0.0407 - val_loss: 0.0163 - val_mae: 0.0890\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0380 - val_loss: 0.0165 - val_mae: 0.0880\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 0.0165 - val_mae: 0.0883\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0166 - val_mae: 0.0884\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0165 - val_mae: 0.0889\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0166 - val_mae: 0.0900\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0166 - val_mae: 0.0909\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0165 - val_mae: 0.0926\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 0.0165 - val_mae: 0.0938\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0010 - mae: 0.0336 - val_loss: 0.0166 - val_mae: 0.0928\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0385 - val_loss: 0.0168 - val_mae: 0.0935\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0171 - val_mae: 0.0925\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0170 - val_mae: 0.0918\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0169 - val_mae: 0.0903\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0013 - mae: 0.0386 - val_loss: 0.0167 - val_mae: 0.0893\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0167 - val_mae: 0.0875\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0357 - val_loss: 0.0169 - val_mae: 0.0881\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0170 - val_mae: 0.0890\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0010 - mae: 0.0317 - val_loss: 0.0170 - val_mae: 0.0907\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0172 - val_mae: 0.0917\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0369 - val_loss: 0.0172 - val_mae: 0.0910\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0011 - mae: 0.0348 - val_loss: 0.0173 - val_mae: 0.0890\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0171 - val_mae: 0.0880\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.1855e-04 - mae: 0.0326 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0010 - mae: 0.0335 - val_loss: 0.0167 - val_mae: 0.0878\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - mae: 0.0381 - val_loss: 0.0166 - val_mae: 0.0897\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0166 - val_mae: 0.0912\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0167 - val_mae: 0.0922\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0351 - val_loss: 0.0168 - val_mae: 0.0932\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - mae: 0.0353 - val_loss: 0.0171 - val_mae: 0.0925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:18,808] Trial 2 finished with value: 0.09247967600822449 and parameters: {'learning_rate': 0.0015159481638367005, 'weight_decay': 1.772040457956272e-07}. Best is trial 2 with value: 0.09247967600822449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0119 - mae: 0.1248 - val_loss: 0.0228 - val_mae: 0.1082\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0217 - val_mae: 0.0961\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0201 - val_mae: 0.0862\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0053 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0839\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0174 - val_mae: 0.0871\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0707 - val_loss: 0.0171 - val_mae: 0.0860\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0644 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0641 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0826\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0837\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0844\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0859\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0866\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0620 - val_loss: 0.0169 - val_mae: 0.0860\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0853\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0831\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0553 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0828\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0172 - val_mae: 0.0831\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0172 - val_mae: 0.0839\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0563 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0029 - mae: 0.0576 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0840\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0826\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0181 - val_mae: 0.0813\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0181 - val_mae: 0.0802\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0180 - val_mae: 0.0797\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0179 - val_mae: 0.0797\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0030 - mae: 0.0538 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0173 - val_mae: 0.0853\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0500 - val_loss: 0.0177 - val_mae: 0.0857\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0178 - val_mae: 0.0837\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0178 - val_mae: 0.0817\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0455 - val_loss: 0.0178 - val_mae: 0.0804\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0492 - val_loss: 0.0178 - val_mae: 0.0796\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - mae: 0.0488 - val_loss: 0.0178 - val_mae: 0.0795\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0484 - val_loss: 0.0178 - val_mae: 0.0801\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0451 - val_loss: 0.0176 - val_mae: 0.0806\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0514 - val_loss: 0.0180 - val_mae: 0.0813\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0459 - val_loss: 0.0182 - val_mae: 0.0822\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0182 - val_mae: 0.0832\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - mae: 0.0501 - val_loss: 0.0181 - val_mae: 0.0843\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0180 - val_mae: 0.0851\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0178 - val_mae: 0.0855\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0020 - mae: 0.0459 - val_loss: 0.0176 - val_mae: 0.0862\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0019 - mae: 0.0462 - val_loss: 0.0176 - val_mae: 0.0861\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0178 - val_mae: 0.0854\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0179 - val_mae: 0.0846\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0452 - val_loss: 0.0181 - val_mae: 0.0840\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0182 - val_mae: 0.0844\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0184 - val_mae: 0.0852\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.0186 - val_mae: 0.0868\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0432 - val_loss: 0.0188 - val_mae: 0.0890\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0191 - val_mae: 0.0916\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0190 - val_mae: 0.0914\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0187 - val_mae: 0.0904\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0182 - val_mae: 0.0891\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0180 - val_mae: 0.0863\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0404 - val_loss: 0.0180 - val_mae: 0.0847\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0180 - val_mae: 0.0845\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0441 - val_loss: 0.0181 - val_mae: 0.0860\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0430 - val_loss: 0.0183 - val_mae: 0.0878\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.0185 - val_mae: 0.0905\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0020 - mae: 0.0411 - val_loss: 0.0190 - val_mae: 0.0938\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0192 - val_mae: 0.0965\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0193 - val_mae: 0.0982\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0016 - mae: 0.0425 - val_loss: 0.0189 - val_mae: 0.0972\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0015 - mae: 0.0418 - val_loss: 0.0183 - val_mae: 0.0949\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - mae: 0.0442 - val_loss: 0.0177 - val_mae: 0.0912\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0016 - mae: 0.0435 - val_loss: 0.0174 - val_mae: 0.0866\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 9.8541e-04 - mae: 0.0324 - val_loss: 0.0174 - val_mae: 0.0841\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0176 - val_mae: 0.0836\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0017 - mae: 0.0382 - val_loss: 0.0178 - val_mae: 0.0851\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0181 - val_mae: 0.0873\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.9041e-04 - mae: 0.0337 - val_loss: 0.0184 - val_mae: 0.0896\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0012 - mae: 0.0361 - val_loss: 0.0188 - val_mae: 0.0908\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 0.0187 - val_mae: 0.0905\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.0186 - val_mae: 0.0895\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0362 - val_loss: 0.0185 - val_mae: 0.0890\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0380 - val_loss: 0.0184 - val_mae: 0.0886\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0015 - mae: 0.0331 - val_loss: 0.0184 - val_mae: 0.0880\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 0.0185 - val_mae: 0.0885\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0187 - val_mae: 0.0908\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0016 - mae: 0.0379 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0198 - val_mae: 0.1003\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0012 - mae: 0.0366 - val_loss: 0.0206 - val_mae: 0.1053\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0376 - val_loss: 0.0212 - val_mae: 0.1074\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0214 - val_mae: 0.1070\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0211 - val_mae: 0.1035\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0199 - val_mae: 0.0964\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.1787e-04 - mae: 0.0302 - val_loss: 0.0191 - val_mae: 0.0927\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0358 - val_loss: 0.0187 - val_mae: 0.0909\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.6127e-04 - mae: 0.0314 - val_loss: 0.0182 - val_mae: 0.0881\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0180 - val_mae: 0.0868\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0357 - val_loss: 0.0179 - val_mae: 0.0864\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 0.0180 - val_mae: 0.0868\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0429 - val_loss: 0.0183 - val_mae: 0.0874\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0185 - val_mae: 0.0882\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0187 - val_mae: 0.0899\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.3382 - mae: 1.4741 - val_loss: 0.0196 - val_mae: 0.0938\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0458 - val_loss: 0.0194 - val_mae: 0.0920\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - mae: 0.0413 - val_loss: 0.0191 - val_mae: 0.0903\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0190 - val_mae: 0.0903\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0196 - val_mae: 0.0958\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0490 - val_loss: 0.0200 - val_mae: 0.0987\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0538 - val_loss: 0.0209 - val_mae: 0.1029\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0196 - val_mae: 0.1011\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0537 - val_loss: 0.0178 - val_mae: 0.0871\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0175 - val_mae: 0.0777\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0173 - val_mae: 0.0740\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0442 - val_loss: 0.0168 - val_mae: 0.0733\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0420 - val_loss: 0.0167 - val_mae: 0.0740\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0169 - val_mae: 0.0748\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0527 - val_loss: 0.0178 - val_mae: 0.0780\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0560 - val_loss: 0.0175 - val_mae: 0.0799\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0038 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0527 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0849\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.0875\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0168 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0891\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0166 - val_mae: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:38,462] Trial 3 finished with value: 0.08855739235877991 and parameters: {'learning_rate': 0.005614884881432066, 'weight_decay': 0.0001579756451304208}. Best is trial 3 with value: 0.08855739235877991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0111 - mae: 0.1157 - val_loss: 0.0243 - val_mae: 0.1181\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1141\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0232 - val_mae: 0.1102\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.0973 - val_loss: 0.0227 - val_mae: 0.1063\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0222 - val_mae: 0.1023\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0985\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0071 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0944\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0074 - mae: 0.0860 - val_loss: 0.0206 - val_mae: 0.0905\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0201 - val_mae: 0.0870\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0196 - val_mae: 0.0843\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0737 - val_loss: 0.0192 - val_mae: 0.0820\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0057 - mae: 0.0721 - val_loss: 0.0187 - val_mae: 0.0803\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0055 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0796\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0053 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0795\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0048 - mae: 0.0665 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - mae: 0.0682 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0693 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0046 - mae: 0.0675 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0174 - val_mae: 0.0777\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0778\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0804\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0631 - val_loss: 0.0166 - val_mae: 0.0806\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0807\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0166 - val_mae: 0.0808\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0166 - val_mae: 0.0805\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0802\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0796\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0788\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0798\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0800\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0802\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0801\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0167 - val_mae: 0.0798\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0167 - val_mae: 0.0802\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0802\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0167 - val_mae: 0.0801\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0800\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0799\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0797\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0167 - val_mae: 0.0794\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0545 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0539 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0556 - val_loss: 0.0165 - val_mae: 0.0799\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0555 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0162 - val_mae: 0.0812\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0163 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0031 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0533 - val_loss: 0.0163 - val_mae: 0.0800\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0542 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0162 - val_mae: 0.0798\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0162 - val_mae: 0.0800\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0567 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0161 - val_mae: 0.0799\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0509 - val_loss: 0.0161 - val_mae: 0.0798\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0541 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0027 - mae: 0.0511 - val_loss: 0.0161 - val_mae: 0.0791\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0027 - mae: 0.0514 - val_loss: 0.0160 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0159 - val_mae: 0.0796\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0531 - val_loss: 0.0158 - val_mae: 0.0805\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0819\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0154 - val_mae: 0.0836\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0154 - val_mae: 0.0830\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0486 - val_loss: 0.0155 - val_mae: 0.0825\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0156 - val_mae: 0.0822\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0520 - val_loss: 0.0156 - val_mae: 0.0831\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0157 - val_mae: 0.0821\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0158 - val_mae: 0.0813\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0160 - val_mae: 0.0804\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0490 - val_loss: 0.0161 - val_mae: 0.0800\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0160 - val_mae: 0.0802\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0480 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0828\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0159 - val_mae: 0.0810\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0453 - val_loss: 0.0160 - val_mae: 0.0803\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0457 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0450 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0485 - val_loss: 0.0158 - val_mae: 0.0833\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - mae: 0.0477 - val_loss: 0.0156 - val_mae: 0.0869\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0021 - mae: 0.0486 - val_loss: 0.0156 - val_mae: 0.0894\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0544 - val_loss: 0.0156 - val_mae: 0.0878\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0157 - val_mae: 0.0841\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0459 - val_loss: 0.0160 - val_mae: 0.0808\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0022 - mae: 0.0454 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0026 - mae: 0.0491 - val_loss: 0.0162 - val_mae: 0.0789\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0021 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0020 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0789\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0426 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0162 - val_mae: 0.0803\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0161 - val_mae: 0.0814\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0162 - val_mae: 0.0810\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0164 - val_mae: 0.0799\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0464 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0167 - val_mae: 0.0789\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.0790\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0451 - val_loss: 0.0166 - val_mae: 0.0793\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0164 - val_mae: 0.0803\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0163 - val_mae: 0.0813\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0163 - val_mae: 0.0814\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0455 - val_loss: 0.0162 - val_mae: 0.0822\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0162 - val_mae: 0.0831\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0161 - val_mae: 0.0846\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0160 - val_mae: 0.0862\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0160 - val_mae: 0.0876\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0159 - val_mae: 0.0881\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0160 - val_mae: 0.0840\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0162 - val_mae: 0.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:48:57,909] Trial 4 finished with value: 0.08233408629894257 and parameters: {'learning_rate': 0.0008503898313401599, 'weight_decay': 0.0005064752003096145}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1076 - val_loss: 0.0216 - val_mae: 0.0890\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0061 - mae: 0.0782 - val_loss: 0.0188 - val_mae: 0.0837\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0780 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0174 - val_mae: 0.0807\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0819\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0676 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - mae: 0.0650 - val_loss: 0.0169 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0820\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0822\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0828\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0840\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0841\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0550 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0171 - val_mae: 0.0812\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0035 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0174 - val_mae: 0.0794\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0169 - val_mae: 0.0808\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0024 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0816\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0175 - val_mae: 0.0820\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0176 - val_mae: 0.0824\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0176 - val_mae: 0.0825\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0026 - mae: 0.0507 - val_loss: 0.0175 - val_mae: 0.0829\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0577 - val_loss: 0.0175 - val_mae: 0.0824\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0024 - mae: 0.0528 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0176 - val_mae: 0.0814\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0174 - val_mae: 0.0787\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0462 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0022 - mae: 0.0450 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0468 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0769\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0181 - val_mae: 0.0791\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0184 - val_mae: 0.0806\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0464 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.0805\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0475 - val_loss: 0.0173 - val_mae: 0.0812\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0513 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - mae: 0.0512 - val_loss: 0.0173 - val_mae: 0.0837\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0472 - val_loss: 0.0181 - val_mae: 0.0858\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0186 - val_mae: 0.0883\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0185 - val_mae: 0.0888\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0179 - val_mae: 0.0847\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - mae: 0.0420 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0168 - val_mae: 0.0804\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0028 - mae: 0.0512 - val_loss: 0.0168 - val_mae: 0.0798\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0422 - val_loss: 0.0170 - val_mae: 0.0798\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0175 - val_mae: 0.0794\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 0.0178 - val_mae: 0.0800\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0019 - mae: 0.0409 - val_loss: 0.0179 - val_mae: 0.0813\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0432 - val_loss: 0.0180 - val_mae: 0.0827\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0181 - val_mae: 0.0839\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0182 - val_mae: 0.0846\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0184 - val_mae: 0.0855\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0409 - val_loss: 0.0186 - val_mae: 0.0856\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 0.0186 - val_mae: 0.0854\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 0.0185 - val_mae: 0.0859\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - mae: 0.0358 - val_loss: 0.0184 - val_mae: 0.0864\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0180 - val_mae: 0.0867\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 0.0178 - val_mae: 0.0879\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.0181 - val_mae: 0.0936\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - mae: 0.0375 - val_loss: 0.0186 - val_mae: 0.0983\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0417 - val_loss: 0.0197 - val_mae: 0.1021\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0189 - val_mae: 0.0919\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0364 - val_loss: 0.0184 - val_mae: 0.0849\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0367 - val_loss: 0.0182 - val_mae: 0.0826\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0426 - val_loss: 0.0180 - val_mae: 0.0815\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0023 - mae: 0.0449 - val_loss: 0.0178 - val_mae: 0.0813\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0023 - mae: 0.0463 - val_loss: 0.0177 - val_mae: 0.0816\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0177 - val_mae: 0.0824\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0374 - val_loss: 0.0178 - val_mae: 0.0842\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - mae: 0.0395 - val_loss: 0.0180 - val_mae: 0.0854\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0181 - val_mae: 0.0868\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0019 - mae: 0.0432 - val_loss: 0.0181 - val_mae: 0.0888\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0017 - mae: 0.0431 - val_loss: 0.0181 - val_mae: 0.0914\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0180 - val_mae: 0.0874\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0010 - mae: 0.0354 - val_loss: 0.0178 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0016 - mae: 0.0418 - val_loss: 0.0178 - val_mae: 0.0839\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0381 - val_loss: 0.0178 - val_mae: 0.0845\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0178 - val_mae: 0.0858\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0376 - val_loss: 0.0179 - val_mae: 0.0861\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.9292e-04 - mae: 0.0337 - val_loss: 0.0180 - val_mae: 0.0862\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0180 - val_mae: 0.0860\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - mae: 0.0363 - val_loss: 0.0182 - val_mae: 0.0864\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0361 - val_loss: 0.0183 - val_mae: 0.0875\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 8.0891e-04 - mae: 0.0299 - val_loss: 0.0185 - val_mae: 0.0894\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.5995e-04 - mae: 0.0301 - val_loss: 0.0186 - val_mae: 0.0910\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 0.0188 - val_mae: 0.0931\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 0.0192 - val_mae: 0.0958\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0195 - val_mae: 0.0984\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0416 - val_loss: 0.0195 - val_mae: 0.0973\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.0197 - val_mae: 0.0959\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0010 - mae: 0.0326 - val_loss: 0.0196 - val_mae: 0.0943\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0193 - val_mae: 0.0920\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0190 - val_mae: 0.0902\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0186 - val_mae: 0.0888\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.3080e-04 - mae: 0.0306 - val_loss: 0.0183 - val_mae: 0.0877\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - mae: 0.0365 - val_loss: 0.0181 - val_mae: 0.0883\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0012 - mae: 0.0327 - val_loss: 0.0182 - val_mae: 0.0904\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 0.0185 - val_mae: 0.0935\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.4379e-04 - mae: 0.0306 - val_loss: 0.0188 - val_mae: 0.0950\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 8.8408e-04 - mae: 0.0319 - val_loss: 0.0191 - val_mae: 0.0975\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.7720e-04 - mae: 0.0339 - val_loss: 0.0189 - val_mae: 0.0957\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0186 - val_mae: 0.0923\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 9.4327e-04 - mae: 0.0323 - val_loss: 0.0182 - val_mae: 0.0894\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0344 - val_loss: 0.0177 - val_mae: 0.0838\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0339 - val_loss: 0.0178 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - mae: 0.0417 - val_loss: 0.0181 - val_mae: 0.0853\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0401 - val_loss: 0.0184 - val_mae: 0.0881\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - mae: 0.0327 - val_loss: 0.0189 - val_mae: 0.0929\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 7.6897e-04 - mae: 0.0295 - val_loss: 0.0193 - val_mae: 0.0958\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0011 - mae: 0.0350 - val_loss: 0.0196 - val_mae: 0.0975\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0195 - val_mae: 0.0959\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0192 - val_mae: 0.0932\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0190 - val_mae: 0.0901\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0014 - mae: 0.0367 - val_loss: 0.0190 - val_mae: 0.0886\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0010 - mae: 0.0328 - val_loss: 0.0189 - val_mae: 0.0876\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 0.0189 - val_mae: 0.0876\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.9464e-04 - mae: 0.0274 - val_loss: 0.0188 - val_mae: 0.0876\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 0.0187 - val_mae: 0.0877\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.9107e-04 - mae: 0.0263 - val_loss: 0.0186 - val_mae: 0.0881\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0011 - mae: 0.0299 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 6.1058e-04 - mae: 0.0257 - val_loss: 0.0187 - val_mae: 0.0915\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0011 - mae: 0.0338 - val_loss: 0.0189 - val_mae: 0.0934\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - mae: 0.0322 - val_loss: 0.0191 - val_mae: 0.0952\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0352 - val_loss: 0.0195 - val_mae: 0.0968\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0338 - val_loss: 0.0192 - val_mae: 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:17,005] Trial 5 finished with value: 0.09466227144002914 and parameters: {'learning_rate': 0.005760987449990455, 'weight_decay': 9.096804077211612e-08}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1097 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1219\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0098 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0102 - mae: 0.1096 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1092 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0103 - mae: 0.1096 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0256 - val_mae: 0.1218\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1144 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1073 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1085 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1070 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0106 - mae: 0.1100 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0101 - mae: 0.1079 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - mae: 0.1118 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1113 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1109 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1086 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0101 - mae: 0.1077 - val_loss: 0.0256 - val_mae: 0.1216\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1089 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0105 - mae: 0.1094 - val_loss: 0.0256 - val_mae: 0.1215\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0101 - mae: 0.1106 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0255 - val_mae: 0.1215\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1119 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1076 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0101 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1085 - val_loss: 0.0255 - val_mae: 0.1214\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0101 - mae: 0.1097 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0104 - mae: 0.1097 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0106 - mae: 0.1112 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0103 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1057 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1213\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1099 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0099 - mae: 0.1068 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1038 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0255 - val_mae: 0.1212\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1056 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1089 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1080 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0101 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0255 - val_mae: 0.1211\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1061 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106 - mae: 0.1100 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1067 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0255 - val_mae: 0.1210\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1042 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0105 - mae: 0.1116 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1093 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1086 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1098 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1074 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0255 - val_mae: 0.1209\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1112 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0255 - val_mae: 0.1208\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0101 - mae: 0.1095 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1094 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1062 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1104 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1085 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0101 - mae: 0.1069 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1070 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0105 - mae: 0.1119 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0100 - mae: 0.1100 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1094 - val_loss: 0.0254 - val_mae: 0.1207\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0254 - val_mae: 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:36,536] Trial 6 finished with value: 0.12064401060342789 and parameters: {'learning_rate': 1.3782835654620857e-06, 'weight_decay': 2.7815292215940956e-09}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1071 - val_loss: 0.0231 - val_mae: 0.1130\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0231 - val_mae: 0.1129\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1032 - val_loss: 0.0230 - val_mae: 0.1128\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1031 - val_loss: 0.0230 - val_mae: 0.1126\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1069 - val_loss: 0.0230 - val_mae: 0.1124\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1051 - val_loss: 0.0230 - val_mae: 0.1123\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0229 - val_mae: 0.1121\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1052 - val_loss: 0.0229 - val_mae: 0.1120\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1026 - val_loss: 0.0229 - val_mae: 0.1118\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0229 - val_mae: 0.1117\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0229 - val_mae: 0.1115\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1046 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1035 - val_loss: 0.0228 - val_mae: 0.1110\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1011 - val_loss: 0.0228 - val_mae: 0.1109\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1022 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0227 - val_mae: 0.1104\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1017 - val_loss: 0.0227 - val_mae: 0.1103\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.1000 - val_loss: 0.0226 - val_mae: 0.1101\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0226 - val_mae: 0.1099\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0226 - val_mae: 0.1098\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0226 - val_mae: 0.1096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1029 - val_loss: 0.0225 - val_mae: 0.1095\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0225 - val_mae: 0.1093\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.0997 - val_loss: 0.0225 - val_mae: 0.1092\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1009 - val_loss: 0.0225 - val_mae: 0.1090\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0224 - val_mae: 0.1089\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0085 - mae: 0.0999 - val_loss: 0.0224 - val_mae: 0.1087\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0083 - mae: 0.0988 - val_loss: 0.0224 - val_mae: 0.1085\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0224 - val_mae: 0.1084\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1022 - val_loss: 0.0224 - val_mae: 0.1082\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0223 - val_mae: 0.1081\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0993 - val_loss: 0.0223 - val_mae: 0.1079\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0223 - val_mae: 0.1078\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0223 - val_mae: 0.1076\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0222 - val_mae: 0.1075\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0222 - val_mae: 0.1073\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0222 - val_mae: 0.1072\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - mae: 0.1006 - val_loss: 0.0222 - val_mae: 0.1070\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0222 - val_mae: 0.1069\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0221 - val_mae: 0.1067\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0973 - val_loss: 0.0221 - val_mae: 0.1066\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1018 - val_loss: 0.0221 - val_mae: 0.1064\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0221 - val_mae: 0.1063\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0967 - val_loss: 0.0220 - val_mae: 0.1061\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0084 - mae: 0.0985 - val_loss: 0.0220 - val_mae: 0.1060\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0979 - val_loss: 0.0220 - val_mae: 0.1058\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0220 - val_mae: 0.1057\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0962 - val_loss: 0.0220 - val_mae: 0.1056\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0929 - val_loss: 0.0219 - val_mae: 0.1054\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0957 - val_loss: 0.0219 - val_mae: 0.1053\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0219 - val_mae: 0.1051\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0219 - val_mae: 0.1050\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0218 - val_mae: 0.1048\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0963 - val_loss: 0.0218 - val_mae: 0.1047\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0218 - val_mae: 0.1045\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0922 - val_loss: 0.0218 - val_mae: 0.1044\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0218 - val_mae: 0.1043\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0217 - val_mae: 0.1041\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - mae: 0.0940 - val_loss: 0.0217 - val_mae: 0.1040\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0979 - val_loss: 0.0217 - val_mae: 0.1038\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0217 - val_mae: 0.1037\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0217 - val_mae: 0.1035\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0216 - val_mae: 0.1034\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0964 - val_loss: 0.0216 - val_mae: 0.1032\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0216 - val_mae: 0.1031\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0216 - val_mae: 0.1030\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0965 - val_loss: 0.0216 - val_mae: 0.1028\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0215 - val_mae: 0.1027\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0933 - val_loss: 0.0215 - val_mae: 0.1025\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0215 - val_mae: 0.1024\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0215 - val_mae: 0.1022\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0215 - val_mae: 0.1021\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0949 - val_loss: 0.0214 - val_mae: 0.1020\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0214 - val_mae: 0.1018\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0214 - val_mae: 0.1017\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0214 - val_mae: 0.1016\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0082 - mae: 0.0944 - val_loss: 0.0214 - val_mae: 0.1014\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0213 - val_mae: 0.1013\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0213 - val_mae: 0.1012\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0213 - val_mae: 0.1010\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0213 - val_mae: 0.1009\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0213 - val_mae: 0.1008\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0956 - val_loss: 0.0213 - val_mae: 0.1006\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0904 - val_loss: 0.0212 - val_mae: 0.1005\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0212 - val_mae: 0.1004\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0078 - mae: 0.0900 - val_loss: 0.0212 - val_mae: 0.1002\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0918 - val_loss: 0.0212 - val_mae: 0.1001\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0903 - val_loss: 0.0212 - val_mae: 0.1000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0080 - mae: 0.0915 - val_loss: 0.0211 - val_mae: 0.0999\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0211 - val_mae: 0.0997\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0211 - val_mae: 0.0996\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0211 - val_mae: 0.0995\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0930 - val_loss: 0.0211 - val_mae: 0.0993\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0211 - val_mae: 0.0992\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0076 - mae: 0.0914 - val_loss: 0.0210 - val_mae: 0.0991\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0210 - val_mae: 0.0990\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0877 - val_loss: 0.0210 - val_mae: 0.0988\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0210 - val_mae: 0.0987\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0923 - val_loss: 0.0210 - val_mae: 0.0986\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0210 - val_mae: 0.0984\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0209 - val_mae: 0.0983\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0074 - mae: 0.0904 - val_loss: 0.0209 - val_mae: 0.0982\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0066 - mae: 0.0857 - val_loss: 0.0209 - val_mae: 0.0980\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0910 - val_loss: 0.0209 - val_mae: 0.0979\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0209 - val_mae: 0.0978\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0849 - val_loss: 0.0209 - val_mae: 0.0976\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0208 - val_mae: 0.0975\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0208 - val_mae: 0.0973\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0848 - val_loss: 0.0208 - val_mae: 0.0972\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0900 - val_loss: 0.0208 - val_mae: 0.0971\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0208 - val_mae: 0.0969\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0207 - val_mae: 0.0968\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0207 - val_mae: 0.0966\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0070 - mae: 0.0868 - val_loss: 0.0207 - val_mae: 0.0965\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0869 - val_loss: 0.0207 - val_mae: 0.0964\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0916 - val_loss: 0.0207 - val_mae: 0.0962\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0206 - val_mae: 0.0961\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0206 - val_mae: 0.0960\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0068 - mae: 0.0873 - val_loss: 0.0206 - val_mae: 0.0958\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0862 - val_loss: 0.0206 - val_mae: 0.0957\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0866 - val_loss: 0.0206 - val_mae: 0.0955\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0867 - val_loss: 0.0205 - val_mae: 0.0954\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0920 - val_loss: 0.0205 - val_mae: 0.0953\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0205 - val_mae: 0.0951\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0893 - val_loss: 0.0205 - val_mae: 0.0950\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0924 - val_loss: 0.0205 - val_mae: 0.0948\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0867 - val_loss: 0.0205 - val_mae: 0.0947\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0204 - val_mae: 0.0946\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0860 - val_loss: 0.0204 - val_mae: 0.0944\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0071 - mae: 0.0869 - val_loss: 0.0204 - val_mae: 0.0943\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0818 - val_loss: 0.0204 - val_mae: 0.0941\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0204 - val_mae: 0.0940\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0891 - val_loss: 0.0203 - val_mae: 0.0938\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0203 - val_mae: 0.0937\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0203 - val_mae: 0.0936\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0880 - val_loss: 0.0203 - val_mae: 0.0934\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0848 - val_loss: 0.0203 - val_mae: 0.0933\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0071 - mae: 0.0840 - val_loss: 0.0202 - val_mae: 0.0931\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0839 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0202 - val_mae: 0.0929\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0062 - mae: 0.0806 - val_loss: 0.0202 - val_mae: 0.0927\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0202 - val_mae: 0.0926\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0850 - val_loss: 0.0202 - val_mae: 0.0924\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0849 - val_loss: 0.0201 - val_mae: 0.0923\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0068 - mae: 0.0854 - val_loss: 0.0201 - val_mae: 0.0922\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0861 - val_loss: 0.0201 - val_mae: 0.0921\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0066 - mae: 0.0834 - val_loss: 0.0201 - val_mae: 0.0919\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0201 - val_mae: 0.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:49:55,719] Trial 7 finished with value: 0.09181176871061325 and parameters: {'learning_rate': 2.72024464004361e-05, 'weight_decay': 7.212864515446065e-09}. Best is trial 4 with value: 0.08233408629894257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1079 - val_loss: 0.0245 - val_mae: 0.1174\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0243 - val_mae: 0.1158\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1142\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1126\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1111\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0235 - val_mae: 0.1095\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1078\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0936 - val_loss: 0.0230 - val_mae: 0.1061\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0228 - val_mae: 0.1043\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0913 - val_loss: 0.0226 - val_mae: 0.1025\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0890 - val_loss: 0.0224 - val_mae: 0.1007\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0221 - val_mae: 0.0990\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0867 - val_loss: 0.0219 - val_mae: 0.0971\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0849 - val_loss: 0.0217 - val_mae: 0.0953\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0826 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0212 - val_mae: 0.0922\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0209 - val_mae: 0.0909\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0063 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0204 - val_mae: 0.0888\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0202 - val_mae: 0.0878\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063 - mae: 0.0805 - val_loss: 0.0199 - val_mae: 0.0870\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0731 - val_loss: 0.0197 - val_mae: 0.0862\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0856\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0193 - val_mae: 0.0852\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0850\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0189 - val_mae: 0.0848\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0188 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0186 - val_mae: 0.0845\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0184 - val_mae: 0.0844\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0183 - val_mae: 0.0842\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0047 - mae: 0.0703 - val_loss: 0.0182 - val_mae: 0.0839\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0047 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0836\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0643 - val_loss: 0.0180 - val_mae: 0.0833\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0179 - val_mae: 0.0830\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0049 - mae: 0.0663 - val_loss: 0.0178 - val_mae: 0.0825\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0813\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0683 - val_loss: 0.0176 - val_mae: 0.0807\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0041 - mae: 0.0642 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0175 - val_mae: 0.0795\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0175 - val_mae: 0.0789\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - mae: 0.0673 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0042 - mae: 0.0642 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0768\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0764\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0174 - val_mae: 0.0761\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0039 - mae: 0.0621 - val_loss: 0.0174 - val_mae: 0.0762\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0044 - mae: 0.0673 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0768\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0172 - val_mae: 0.0770\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0771\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0770\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0594 - val_loss: 0.0173 - val_mae: 0.0768\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0605 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0649 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0761\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0760\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0759\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0171 - val_mae: 0.0762\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0762\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0171 - val_mae: 0.0761\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0539 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0760\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0170 - val_mae: 0.0760\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0170 - val_mae: 0.0761\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0168 - val_mae: 0.0760\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0758\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0756\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0753\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0751\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0749\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0746\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0512 - val_loss: 0.0170 - val_mae: 0.0745\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0744\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0170 - val_mae: 0.0744\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0169 - val_mae: 0.0743\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0168 - val_mae: 0.0742\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0027 - mae: 0.0505 - val_loss: 0.0167 - val_mae: 0.0742\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0164 - val_mae: 0.0742\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0162 - val_mae: 0.0743\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0539 - val_loss: 0.0160 - val_mae: 0.0744\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0160 - val_mae: 0.0743\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0160 - val_mae: 0.0740\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0162 - val_mae: 0.0739\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0164 - val_mae: 0.0739\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0165 - val_mae: 0.0740\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0167 - val_mae: 0.0741\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0488 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0480 - val_loss: 0.0166 - val_mae: 0.0742\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0164 - val_mae: 0.0741\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0162 - val_mae: 0.0739\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0026 - mae: 0.0508 - val_loss: 0.0159 - val_mae: 0.0737\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0157 - val_mae: 0.0735\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0155 - val_mae: 0.0734\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0155 - val_mae: 0.0734\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0157 - val_mae: 0.0735\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0160 - val_mae: 0.0737\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0027 - mae: 0.0523 - val_loss: 0.0163 - val_mae: 0.0740\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0501 - val_loss: 0.0163 - val_mae: 0.0741\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0026 - mae: 0.0489 - val_loss: 0.0162 - val_mae: 0.0740\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0025 - mae: 0.0472 - val_loss: 0.0160 - val_mae: 0.0738\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0157 - val_mae: 0.0734\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0157 - val_mae: 0.0734\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0478 - val_loss: 0.0160 - val_mae: 0.0737\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0487 - val_loss: 0.0163 - val_mae: 0.0741\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0482 - val_loss: 0.0165 - val_mae: 0.0744\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0024 - mae: 0.0470 - val_loss: 0.0165 - val_mae: 0.0745\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0465 - val_loss: 0.0164 - val_mae: 0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:16,002] Trial 8 finished with value: 0.07435319572687149 and parameters: {'learning_rate': 0.0003352877092827578, 'weight_decay': 0.005234392960100975}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1155\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.0992 - val_loss: 0.0242 - val_mae: 0.1120\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0943 - val_loss: 0.0238 - val_mae: 0.1083\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0233 - val_mae: 0.1044\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1005\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0829 - val_loss: 0.0223 - val_mae: 0.0967\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0219 - val_mae: 0.0936\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0214 - val_mae: 0.0908\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0771 - val_loss: 0.0210 - val_mae: 0.0886\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - mae: 0.0775 - val_loss: 0.0207 - val_mae: 0.0879\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0203 - val_mae: 0.0881\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0058 - mae: 0.0771 - val_loss: 0.0200 - val_mae: 0.0878\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0197 - val_mae: 0.0869\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0193 - val_mae: 0.0855\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0050 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0840\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0187 - val_mae: 0.0826\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0185 - val_mae: 0.0815\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0183 - val_mae: 0.0806\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0181 - val_mae: 0.0789\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0181 - val_mae: 0.0784\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0643 - val_loss: 0.0180 - val_mae: 0.0775\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0179 - val_mae: 0.0771\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0179 - val_mae: 0.0773\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0569 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0178 - val_mae: 0.0785\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0177 - val_mae: 0.0793\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0174 - val_mae: 0.0822\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0173 - val_mae: 0.0825\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0822\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0175 - val_mae: 0.0796\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0177 - val_mae: 0.0778\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0554 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0035 - mae: 0.0590 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0037 - mae: 0.0581 - val_loss: 0.0176 - val_mae: 0.0782\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0176 - val_mae: 0.0786\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0174 - val_mae: 0.0810\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0173 - val_mae: 0.0818\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0824\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0829\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0830\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0822\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0800\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0550 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0028 - mae: 0.0547 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0812\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0543 - val_loss: 0.0169 - val_mae: 0.0810\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0802\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0026 - mae: 0.0520 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0800\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0168 - val_mae: 0.0800\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0799\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0166 - val_mae: 0.0803\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - mae: 0.0562 - val_loss: 0.0165 - val_mae: 0.0799\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0024 - mae: 0.0508 - val_loss: 0.0164 - val_mae: 0.0790\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0166 - val_mae: 0.0775\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0030 - mae: 0.0525 - val_loss: 0.0165 - val_mae: 0.0773\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0024 - mae: 0.0509 - val_loss: 0.0163 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0027 - mae: 0.0526 - val_loss: 0.0162 - val_mae: 0.0773\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0161 - val_mae: 0.0777\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0163 - val_mae: 0.0769\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0165 - val_mae: 0.0771\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0026 - mae: 0.0499 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0161 - val_mae: 0.0811\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0501 - val_loss: 0.0173 - val_mae: 0.0790\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0501 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0024 - mae: 0.0475 - val_loss: 0.0173 - val_mae: 0.0813\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0468 - val_loss: 0.0171 - val_mae: 0.0839\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0169 - val_mae: 0.0871\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0167 - val_mae: 0.0894\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0023 - mae: 0.0508 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0506 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - mae: 0.0437 - val_loss: 0.0169 - val_mae: 0.0831\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0436 - val_loss: 0.0167 - val_mae: 0.0831\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0457 - val_loss: 0.0166 - val_mae: 0.0838\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0165 - val_mae: 0.0854\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0164 - val_mae: 0.0868\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0169 - val_mae: 0.0858\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0169 - val_mae: 0.0852\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0458 - val_loss: 0.0170 - val_mae: 0.0851\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0446 - val_loss: 0.0171 - val_mae: 0.0854\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0016 - mae: 0.0387 - val_loss: 0.0171 - val_mae: 0.0859\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.0172 - val_mae: 0.0869\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0018 - mae: 0.0440 - val_loss: 0.0172 - val_mae: 0.0884\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0172 - val_mae: 0.0892\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0016 - mae: 0.0423 - val_loss: 0.0174 - val_mae: 0.0897\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0174 - val_mae: 0.0898\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - mae: 0.0420 - val_loss: 0.0174 - val_mae: 0.0902\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - mae: 0.0399 - val_loss: 0.0174 - val_mae: 0.0910\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mae: 0.0433 - val_loss: 0.0174 - val_mae: 0.0921\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - mae: 0.0406 - val_loss: 0.0175 - val_mae: 0.0936\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0458 - val_loss: 0.0176 - val_mae: 0.0960\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0175 - val_mae: 0.0963\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0174 - val_mae: 0.0937\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0176 - val_mae: 0.0914\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0392 - val_loss: 0.0178 - val_mae: 0.0895\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0180 - val_mae: 0.0893\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 0.0182 - val_mae: 0.0908\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0184 - val_mae: 0.0934\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0183 - val_mae: 0.0944\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0016 - mae: 0.0388 - val_loss: 0.0182 - val_mae: 0.0953\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0180 - val_mae: 0.0954\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0511 - val_loss: 0.0181 - val_mae: 0.0923\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0016 - mae: 0.0415 - val_loss: 0.0182 - val_mae: 0.0905\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0183 - val_mae: 0.0900\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0185 - val_mae: 0.0901\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0013 - mae: 0.0351 - val_loss: 0.0186 - val_mae: 0.0911\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.0188 - val_mae: 0.0933\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - mae: 0.0354 - val_loss: 0.0190 - val_mae: 0.0960\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0193 - val_mae: 0.0988\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 0.0191 - val_mae: 0.0996\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0014 - mae: 0.0387 - val_loss: 0.0192 - val_mae: 0.1016\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0017 - mae: 0.0426 - val_loss: 0.0189 - val_mae: 0.1002\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - mae: 0.0421 - val_loss: 0.0188 - val_mae: 0.0983\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0013 - mae: 0.0383 - val_loss: 0.0187 - val_mae: 0.0966\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0013 - mae: 0.0370 - val_loss: 0.0187 - val_mae: 0.0955\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0010 - mae: 0.0349 - val_loss: 0.0188 - val_mae: 0.0954\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0190 - val_mae: 0.0967\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0390 - val_loss: 0.0194 - val_mae: 0.0995\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - mae: 0.0390 - val_loss: 0.0198 - val_mae: 0.1027\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0197 - val_mae: 0.1029\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0014 - mae: 0.0388 - val_loss: 0.0193 - val_mae: 0.1006\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0014 - mae: 0.0387 - val_loss: 0.0190 - val_mae: 0.0998\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0011 - mae: 0.0363 - val_loss: 0.0189 - val_mae: 0.0992\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0386 - val_loss: 0.0191 - val_mae: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:35,641] Trial 9 finished with value: 0.09938155114650726 and parameters: {'learning_rate': 0.000914675241246063, 'weight_decay': 0.0027154426589994975}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0252 - val_mae: 0.1212\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1077 - val_loss: 0.0252 - val_mae: 0.1210\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0251 - val_mae: 0.1207\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0251 - val_mae: 0.1204\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - mae: 0.1055 - val_loss: 0.0250 - val_mae: 0.1202\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0250 - val_mae: 0.1199\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0249 - val_mae: 0.1196\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1188\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1185\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1181\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1178\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1175\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1172\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1169\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1012 - val_loss: 0.0244 - val_mae: 0.1166\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0244 - val_mae: 0.1163\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1160\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0086 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1156\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0242 - val_mae: 0.1153\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1150\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0241 - val_mae: 0.1147\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0241 - val_mae: 0.1144\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1010 - val_loss: 0.0240 - val_mae: 0.1141\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0240 - val_mae: 0.1138\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0239 - val_mae: 0.1135\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1132\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0238 - val_mae: 0.1125\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0088 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1118\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0995 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0950 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0957 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0934 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0229 - val_mae: 0.1068\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - mae: 0.0946 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0953 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0227 - val_mae: 0.1054\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0075 - mae: 0.0901 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0959 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0225 - val_mae: 0.1044\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0076 - mae: 0.0925 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0224 - val_mae: 0.1038\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0223 - val_mae: 0.1035\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0223 - val_mae: 0.1032\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0897 - val_loss: 0.0222 - val_mae: 0.1029\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0894 - val_loss: 0.0222 - val_mae: 0.1026\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0887 - val_loss: 0.0221 - val_mae: 0.1023\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0221 - val_mae: 0.1020\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0882 - val_loss: 0.0220 - val_mae: 0.1017\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0219 - val_mae: 0.1015\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0219 - val_mae: 0.1012\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0218 - val_mae: 0.1010\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.1007\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0217 - val_mae: 0.1005\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0217 - val_mae: 0.1003\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.1000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0910 - val_loss: 0.0216 - val_mae: 0.0998\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0215 - val_mae: 0.0995\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0215 - val_mae: 0.0993\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0214 - val_mae: 0.0991\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0214 - val_mae: 0.0988\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - mae: 0.0880 - val_loss: 0.0213 - val_mae: 0.0986\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0213 - val_mae: 0.0984\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0066 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0981\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0212 - val_mae: 0.0979\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0868 - val_loss: 0.0211 - val_mae: 0.0977\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0070 - mae: 0.0863 - val_loss: 0.0211 - val_mae: 0.0974\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0210 - val_mae: 0.0972\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0840 - val_loss: 0.0210 - val_mae: 0.0970\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0210 - val_mae: 0.0968\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0855 - val_loss: 0.0209 - val_mae: 0.0965\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0209 - val_mae: 0.0963\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0208 - val_mae: 0.0961\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0208 - val_mae: 0.0959\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0956\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0207 - val_mae: 0.0954\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0066 - mae: 0.0826 - val_loss: 0.0206 - val_mae: 0.0952\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0950\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0206 - val_mae: 0.0948\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - mae: 0.0816 - val_loss: 0.0205 - val_mae: 0.0946\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0856 - val_loss: 0.0205 - val_mae: 0.0944\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0204 - val_mae: 0.0942\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - mae: 0.0822 - val_loss: 0.0204 - val_mae: 0.0940\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0062 - mae: 0.0815 - val_loss: 0.0204 - val_mae: 0.0938\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0203 - val_mae: 0.0936\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0064 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0935\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0202 - val_mae: 0.0933\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0064 - mae: 0.0807 - val_loss: 0.0202 - val_mae: 0.0931\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0202 - val_mae: 0.0930\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0789 - val_loss: 0.0201 - val_mae: 0.0928\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0781 - val_loss: 0.0201 - val_mae: 0.0926\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061 - mae: 0.0781 - val_loss: 0.0200 - val_mae: 0.0925\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0200 - val_mae: 0.0923\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0062 - mae: 0.0792 - val_loss: 0.0200 - val_mae: 0.0921\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0920\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0809 - val_loss: 0.0199 - val_mae: 0.0918\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0789 - val_loss: 0.0199 - val_mae: 0.0916\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0198 - val_mae: 0.0915\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - mae: 0.0784 - val_loss: 0.0198 - val_mae: 0.0913\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0799 - val_loss: 0.0198 - val_mae: 0.0912\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0197 - val_mae: 0.0910\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0058 - mae: 0.0790 - val_loss: 0.0197 - val_mae: 0.0908\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0061 - mae: 0.0786 - val_loss: 0.0197 - val_mae: 0.0907\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0061 - mae: 0.0777 - val_loss: 0.0196 - val_mae: 0.0905\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0062 - mae: 0.0805 - val_loss: 0.0196 - val_mae: 0.0903\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0196 - val_mae: 0.0902\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0900\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0899\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0897\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0777 - val_loss: 0.0194 - val_mae: 0.0896\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0760 - val_loss: 0.0194 - val_mae: 0.0894\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0194 - val_mae: 0.0893\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0060 - mae: 0.0787 - val_loss: 0.0194 - val_mae: 0.0891\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0059 - mae: 0.0767 - val_loss: 0.0193 - val_mae: 0.0890\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0770 - val_loss: 0.0193 - val_mae: 0.0889\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0193 - val_mae: 0.0887\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0058 - mae: 0.0767 - val_loss: 0.0193 - val_mae: 0.0886\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0192 - val_mae: 0.0884\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0883\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0192 - val_mae: 0.0882\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0796 - val_loss: 0.0191 - val_mae: 0.0880\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0191 - val_mae: 0.0879\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0191 - val_mae: 0.0877\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0060 - mae: 0.0802 - val_loss: 0.0191 - val_mae: 0.0876\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0757 - val_loss: 0.0191 - val_mae: 0.0875\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0735 - val_loss: 0.0190 - val_mae: 0.0873\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0765 - val_loss: 0.0190 - val_mae: 0.0872\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0741 - val_loss: 0.0190 - val_mae: 0.0870\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0706 - val_loss: 0.0190 - val_mae: 0.0868\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0867\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0756 - val_loss: 0.0189 - val_mae: 0.0865\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0059 - mae: 0.0765 - val_loss: 0.0189 - val_mae: 0.0864\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0189 - val_mae: 0.0862\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0189 - val_mae: 0.0861\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0189 - val_mae: 0.0859\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0057 - mae: 0.0734 - val_loss: 0.0189 - val_mae: 0.0858\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0767 - val_loss: 0.0188 - val_mae: 0.0856\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0720 - val_loss: 0.0188 - val_mae: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:50:55,140] Trial 10 finished with value: 0.0854678675532341 and parameters: {'learning_rate': 4.289683716756164e-05, 'weight_decay': 0.00028284680352012095}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0104 - mae: 0.1085 - val_loss: 0.0239 - val_mae: 0.1157\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0097 - mae: 0.1033 - val_loss: 0.0235 - val_mae: 0.1128\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0231 - val_mae: 0.1101\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0985 - val_loss: 0.0228 - val_mae: 0.1075\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0951 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0911 - val_loss: 0.0221 - val_mae: 0.1000\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0219 - val_mae: 0.0979\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0076 - mae: 0.0874 - val_loss: 0.0218 - val_mae: 0.0958\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0216 - val_mae: 0.0936\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0214 - val_mae: 0.0914\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0212 - val_mae: 0.0892\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0210 - val_mae: 0.0873\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0788 - val_loss: 0.0208 - val_mae: 0.0855\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0205 - val_mae: 0.0840\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0753 - val_loss: 0.0203 - val_mae: 0.0827\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0200 - val_mae: 0.0814\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0060 - mae: 0.0747 - val_loss: 0.0197 - val_mae: 0.0803\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0195 - val_mae: 0.0792\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0710 - val_loss: 0.0192 - val_mae: 0.0785\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0056 - mae: 0.0704 - val_loss: 0.0190 - val_mae: 0.0780\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0715 - val_loss: 0.0187 - val_mae: 0.0776\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0185 - val_mae: 0.0774\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0182 - val_mae: 0.0772\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0050 - mae: 0.0698 - val_loss: 0.0180 - val_mae: 0.0771\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0048 - mae: 0.0704 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0716 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0685 - val_loss: 0.0176 - val_mae: 0.0773\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0175 - val_mae: 0.0773\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0674 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - mae: 0.0662 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0634 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - mae: 0.0670 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0172 - val_mae: 0.0777\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0780\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0783\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0042 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0772\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - mae: 0.0547 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0778\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0784\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - mae: 0.0554 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0172 - val_mae: 0.0784\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0780\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0167 - val_mae: 0.0786\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0166 - val_mae: 0.0788\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.0165 - val_mae: 0.0788\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - mae: 0.0519 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0030 - mae: 0.0545 - val_loss: 0.0166 - val_mae: 0.0783\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0029 - mae: 0.0527 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0162 - val_mae: 0.0787\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0027 - mae: 0.0565 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0023 - mae: 0.0517 - val_loss: 0.0166 - val_mae: 0.0785\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0167 - val_mae: 0.0783\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0166 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0528 - val_loss: 0.0164 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0025 - mae: 0.0498 - val_loss: 0.0160 - val_mae: 0.0777\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0157 - val_mae: 0.0778\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0157 - val_mae: 0.0776\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0158 - val_mae: 0.0771\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0026 - mae: 0.0501 - val_loss: 0.0158 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0155 - val_mae: 0.0776\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0155 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0157 - val_mae: 0.0765\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0157 - val_mae: 0.0761\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0497 - val_loss: 0.0156 - val_mae: 0.0761\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0023 - mae: 0.0474 - val_loss: 0.0152 - val_mae: 0.0765\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0150 - val_mae: 0.0769\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0023 - mae: 0.0489 - val_loss: 0.0146 - val_mae: 0.0782\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0024 - mae: 0.0518 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0154 - val_mae: 0.0750\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0158 - val_mae: 0.0750\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0029 - mae: 0.0501 - val_loss: 0.0157 - val_mae: 0.0748\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0023 - mae: 0.0479 - val_loss: 0.0154 - val_mae: 0.0748\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0150 - val_mae: 0.0753\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0466 - val_loss: 0.0145 - val_mae: 0.0765\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0767\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0028 - mae: 0.0575 - val_loss: 0.0148 - val_mae: 0.0756\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0023 - mae: 0.0485 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0022 - mae: 0.0453 - val_loss: 0.0153 - val_mae: 0.0750\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0021 - mae: 0.0444 - val_loss: 0.0152 - val_mae: 0.0752\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0018 - mae: 0.0426 - val_loss: 0.0150 - val_mae: 0.0756\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0151 - val_mae: 0.0757\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0473 - val_loss: 0.0154 - val_mae: 0.0756\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.0155 - val_mae: 0.0756\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - mae: 0.0452 - val_loss: 0.0155 - val_mae: 0.0756\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - mae: 0.0457 - val_loss: 0.0154 - val_mae: 0.0757\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0022 - mae: 0.0457 - val_loss: 0.0152 - val_mae: 0.0760\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0149 - val_mae: 0.0766\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0023 - mae: 0.0480 - val_loss: 0.0146 - val_mae: 0.0775\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.0771\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0018 - mae: 0.0444 - val_loss: 0.0148 - val_mae: 0.0764\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0150 - val_mae: 0.0754\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0153 - val_mae: 0.0752\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - mae: 0.0419 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0442 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.0151 - val_mae: 0.0750\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 0.0149 - val_mae: 0.0752\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0149 - val_mae: 0.0755\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0147 - val_mae: 0.0761\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0019 - mae: 0.0451 - val_loss: 0.0146 - val_mae: 0.0767\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:15,144] Trial 11 finished with value: 0.07798068970441818 and parameters: {'learning_rate': 0.0005590431010763924, 'weight_decay': 0.0025714834255179736}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1035 - val_loss: 0.0242 - val_mae: 0.1115\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0239 - val_mae: 0.1091\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1065\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0930 - val_loss: 0.0231 - val_mae: 0.1038\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0227 - val_mae: 0.1012\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0224 - val_mae: 0.0987\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0069 - mae: 0.0862 - val_loss: 0.0221 - val_mae: 0.0963\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0071 - mae: 0.0861 - val_loss: 0.0217 - val_mae: 0.0941\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0214 - val_mae: 0.0922\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - mae: 0.0812 - val_loss: 0.0211 - val_mae: 0.0906\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0208 - val_mae: 0.0892\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0814 - val_loss: 0.0205 - val_mae: 0.0879\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0202 - val_mae: 0.0868\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0709 - val_loss: 0.0199 - val_mae: 0.0859\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0197 - val_mae: 0.0852\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0194 - val_mae: 0.0846\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0192 - val_mae: 0.0840\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0747 - val_loss: 0.0190 - val_mae: 0.0835\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0188 - val_mae: 0.0829\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0187 - val_mae: 0.0823\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0185 - val_mae: 0.0817\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0042 - mae: 0.0683 - val_loss: 0.0184 - val_mae: 0.0811\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0182 - val_mae: 0.0806\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0692 - val_loss: 0.0181 - val_mae: 0.0804\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0046 - mae: 0.0686 - val_loss: 0.0180 - val_mae: 0.0802\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0049 - mae: 0.0718 - val_loss: 0.0179 - val_mae: 0.0800\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0702 - val_loss: 0.0179 - val_mae: 0.0798\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0796\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0049 - mae: 0.0714 - val_loss: 0.0177 - val_mae: 0.0794\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0714 - val_loss: 0.0177 - val_mae: 0.0792\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0644 - val_loss: 0.0177 - val_mae: 0.0790\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0177 - val_mae: 0.0787\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0177 - val_mae: 0.0784\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0177 - val_mae: 0.0782\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0177 - val_mae: 0.0779\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0043 - mae: 0.0615 - val_loss: 0.0177 - val_mae: 0.0777\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0177 - val_mae: 0.0775\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.0773\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0601 - val_loss: 0.0177 - val_mae: 0.0772\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0771\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0176 - val_mae: 0.0765\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0596 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0043 - mae: 0.0663 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0763\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0043 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0171 - val_mae: 0.0770\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0171 - val_mae: 0.0772\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0035 - mae: 0.0558 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - mae: 0.0647 - val_loss: 0.0169 - val_mae: 0.0777\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0039 - mae: 0.0662 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0171 - val_mae: 0.0771\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0769\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0549 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0571 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0767\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0770\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0564 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0031 - mae: 0.0548 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0556 - val_loss: 0.0168 - val_mae: 0.0781\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0029 - mae: 0.0530 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0167 - val_mae: 0.0785\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0029 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0786\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0167 - val_mae: 0.0787\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0166 - val_mae: 0.0789\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0027 - mae: 0.0522 - val_loss: 0.0166 - val_mae: 0.0790\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.0791\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - mae: 0.0544 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0028 - mae: 0.0550 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0030 - mae: 0.0560 - val_loss: 0.0166 - val_mae: 0.0788\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0166 - val_mae: 0.0789\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0165 - val_mae: 0.0790\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0029 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0026 - mae: 0.0518 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0163 - val_mae: 0.0796\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0162 - val_mae: 0.0797\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0162 - val_mae: 0.0799\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0526 - val_loss: 0.0161 - val_mae: 0.0801\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0157 - val_mae: 0.0803\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0495 - val_loss: 0.0155 - val_mae: 0.0805\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0023 - mae: 0.0513 - val_loss: 0.0156 - val_mae: 0.0796\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0156 - val_mae: 0.0788\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0024 - mae: 0.0515 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0026 - mae: 0.0487 - val_loss: 0.0154 - val_mae: 0.0786\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0154 - val_mae: 0.0789\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0470 - val_loss: 0.0153 - val_mae: 0.0796\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0154 - val_mae: 0.0794\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0156 - val_mae: 0.0792\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0500 - val_loss: 0.0157 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0157 - val_mae: 0.0785\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0157 - val_mae: 0.0782\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0024 - mae: 0.0492 - val_loss: 0.0156 - val_mae: 0.0784\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0024 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.0155 - val_mae: 0.0793\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0021 - mae: 0.0474 - val_loss: 0.0156 - val_mae: 0.0793\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0520 - val_loss: 0.0158 - val_mae: 0.0794\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0020 - mae: 0.0431 - val_loss: 0.0159 - val_mae: 0.0796\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0494 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0161 - val_mae: 0.0803\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0161 - val_mae: 0.0807\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0021 - mae: 0.0454 - val_loss: 0.0159 - val_mae: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:35,158] Trial 12 finished with value: 0.08121491968631744 and parameters: {'learning_rate': 0.00043989489918975344, 'weight_decay': 0.007034459955486363}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0249 - val_mae: 0.1245\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0102 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1243\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0107 - mae: 0.1143 - val_loss: 0.0249 - val_mae: 0.1242\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0249 - val_mae: 0.1240\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0106 - mae: 0.1129 - val_loss: 0.0249 - val_mae: 0.1239\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1123 - val_loss: 0.0249 - val_mae: 0.1238\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1123 - val_loss: 0.0248 - val_mae: 0.1236\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0248 - val_mae: 0.1235\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1233\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0248 - val_mae: 0.1232\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0096 - mae: 0.1092 - val_loss: 0.0248 - val_mae: 0.1230\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0248 - val_mae: 0.1229\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1227\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1226\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1139 - val_loss: 0.0247 - val_mae: 0.1224\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0105 - mae: 0.1119 - val_loss: 0.0247 - val_mae: 0.1223\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1118 - val_loss: 0.0247 - val_mae: 0.1221\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0101 - mae: 0.1100 - val_loss: 0.0247 - val_mae: 0.1220\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0097 - mae: 0.1076 - val_loss: 0.0247 - val_mae: 0.1218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1080 - val_loss: 0.0247 - val_mae: 0.1217\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1216\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0095 - mae: 0.1084 - val_loss: 0.0246 - val_mae: 0.1214\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1213\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0246 - val_mae: 0.1211\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0246 - val_mae: 0.1210\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1209\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0100 - mae: 0.1101 - val_loss: 0.0246 - val_mae: 0.1207\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0245 - val_mae: 0.1206\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1100 - val_loss: 0.0245 - val_mae: 0.1205\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1064 - val_loss: 0.0245 - val_mae: 0.1203\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0245 - val_mae: 0.1202\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1201\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0245 - val_mae: 0.1200\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0245 - val_mae: 0.1198\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1037 - val_loss: 0.0244 - val_mae: 0.1196\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1194\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1193\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1190\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1189\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1188\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0243 - val_mae: 0.1185\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0243 - val_mae: 0.1184\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1099 - val_loss: 0.0243 - val_mae: 0.1183\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0243 - val_mae: 0.1182\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0093 - mae: 0.1066 - val_loss: 0.0243 - val_mae: 0.1180\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0243 - val_mae: 0.1179\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0243 - val_mae: 0.1178\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0242 - val_mae: 0.1177\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0242 - val_mae: 0.1175\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0242 - val_mae: 0.1174\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0242 - val_mae: 0.1173\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0242 - val_mae: 0.1172\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0242 - val_mae: 0.1171\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0242 - val_mae: 0.1169\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0242 - val_mae: 0.1168\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0242 - val_mae: 0.1167\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0241 - val_mae: 0.1166\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1165\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1164\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0241 - val_mae: 0.1163\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1161\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1160\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0241 - val_mae: 0.1159\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0240 - val_mae: 0.1157\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0240 - val_mae: 0.1156\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0240 - val_mae: 0.1154\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1153\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0240 - val_mae: 0.1150\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0240 - val_mae: 0.1148\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0239 - val_mae: 0.1147\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0239 - val_mae: 0.1145\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1031 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1139\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0239 - val_mae: 0.1138\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0086 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1134\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0088 - mae: 0.1015 - val_loss: 0.0238 - val_mae: 0.1132\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.1012 - val_loss: 0.0238 - val_mae: 0.1131\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0982 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0086 - mae: 0.1008 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1128\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0086 - mae: 0.0999 - val_loss: 0.0237 - val_mae: 0.1125\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1005 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0083 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0237 - val_mae: 0.1121\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1118\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1117\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0994 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0236 - val_mae: 0.1114\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1004 - val_loss: 0.0236 - val_mae: 0.1112\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0236 - val_mae: 0.1111\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0236 - val_mae: 0.1109\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0236 - val_mae: 0.1108\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1107\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0236 - val_mae: 0.1106\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1105\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1104\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0976 - val_loss: 0.0235 - val_mae: 0.1103\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0992 - val_loss: 0.0235 - val_mae: 0.1102\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0235 - val_mae: 0.1101\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0235 - val_mae: 0.1099\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1098\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0235 - val_mae: 0.1097\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0235 - val_mae: 0.1096\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1095\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1094\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0234 - val_mae: 0.1093\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0983 - val_loss: 0.0234 - val_mae: 0.1092\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0234 - val_mae: 0.1091\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0234 - val_mae: 0.1090\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1089\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0234 - val_mae: 0.1088\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0234 - val_mae: 0.1087\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1085\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1084\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1083\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0233 - val_mae: 0.1082\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0952 - val_loss: 0.0233 - val_mae: 0.1081\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0964 - val_loss: 0.0233 - val_mae: 0.1080\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0977 - val_loss: 0.0233 - val_mae: 0.1079\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0976 - val_loss: 0.0233 - val_mae: 0.1078\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0232 - val_mae: 0.1077\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0985 - val_loss: 0.0232 - val_mae: 0.1076\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0232 - val_mae: 0.1075\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0232 - val_mae: 0.1074\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0971 - val_loss: 0.0232 - val_mae: 0.1073\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1072\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0081 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1071\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0232 - val_mae: 0.1070\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0232 - val_mae: 0.1069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:51:54,883] Trial 13 finished with value: 0.1069079041481018 and parameters: {'learning_rate': 2.1001119062357468e-05, 'weight_decay': 0.001730172030387585}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0184 - val_mae: 0.0987\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0068 - mae: 0.0917 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0633 - val_loss: 0.0176 - val_mae: 0.0817\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0169 - val_mae: 0.0907\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - mae: 0.0688 - val_loss: 0.0172 - val_mae: 0.0941\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0039 - mae: 0.0677 - val_loss: 0.0173 - val_mae: 0.0939\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0920\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0036 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0881\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0568 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0167 - val_mae: 0.0830\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0167 - val_mae: 0.0835\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0856\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0828\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0168 - val_mae: 0.0847\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0604 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0850\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0854\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0868\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0867\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0565 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0168 - val_mae: 0.0851\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0167 - val_mae: 0.0847\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0837\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0029 - mae: 0.0545 - val_loss: 0.0167 - val_mae: 0.0839\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0031 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0564 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0580 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0851\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - mae: 0.0547 - val_loss: 0.0174 - val_mae: 0.0855\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0854\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0172 - val_mae: 0.0855\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0172 - val_mae: 0.0852\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0850\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0171 - val_mae: 0.0846\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0171 - val_mae: 0.0845\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0172 - val_mae: 0.0850\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0173 - val_mae: 0.0855\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0173 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0582 - val_loss: 0.0174 - val_mae: 0.0847\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0174 - val_mae: 0.0843\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0175 - val_mae: 0.0838\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0174 - val_mae: 0.0833\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0520 - val_loss: 0.0173 - val_mae: 0.0833\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0171 - val_mae: 0.0842\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0847\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0171 - val_mae: 0.0847\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0029 - mae: 0.0553 - val_loss: 0.0172 - val_mae: 0.0854\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0173 - val_mae: 0.0862\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0174 - val_mae: 0.0869\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0175 - val_mae: 0.0874\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0176 - val_mae: 0.0875\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0179 - val_mae: 0.0877\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0178 - val_mae: 0.0866\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0179 - val_mae: 0.0854\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0179 - val_mae: 0.0847\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0029 - mae: 0.0565 - val_loss: 0.0180 - val_mae: 0.0846\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0181 - val_mae: 0.0851\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0181 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0180 - val_mae: 0.0836\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0178 - val_mae: 0.0837\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0177 - val_mae: 0.0836\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - mae: 0.0541 - val_loss: 0.0177 - val_mae: 0.0836\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - mae: 0.0557 - val_loss: 0.0178 - val_mae: 0.0839\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0525 - val_loss: 0.0178 - val_mae: 0.0846\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0178 - val_mae: 0.0852\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0178 - val_mae: 0.0859\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - mae: 0.0599 - val_loss: 0.0178 - val_mae: 0.0865\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0179 - val_mae: 0.0866\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0180 - val_mae: 0.0866\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0024 - mae: 0.0500 - val_loss: 0.0181 - val_mae: 0.0864\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0027 - mae: 0.0546 - val_loss: 0.0178 - val_mae: 0.0844\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0518 - val_loss: 0.0177 - val_mae: 0.0833\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0177 - val_mae: 0.0825\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0552 - val_loss: 0.0177 - val_mae: 0.0822\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0536 - val_loss: 0.0178 - val_mae: 0.0823\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0022 - mae: 0.0470 - val_loss: 0.0180 - val_mae: 0.0836\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - mae: 0.0470 - val_loss: 0.0180 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.0178 - val_mae: 0.0832\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0179 - val_mae: 0.0855\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0179 - val_mae: 0.0861\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - mae: 0.0504 - val_loss: 0.0173 - val_mae: 0.0821\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0815\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0171 - val_mae: 0.0822\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0171 - val_mae: 0.0830\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0024 - mae: 0.0513 - val_loss: 0.0170 - val_mae: 0.0826\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - mae: 0.0515 - val_loss: 0.0170 - val_mae: 0.0832\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0171 - val_mae: 0.0857\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0024 - mae: 0.0526 - val_loss: 0.0173 - val_mae: 0.0871\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0173 - val_mae: 0.0861\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0023 - mae: 0.0494 - val_loss: 0.0174 - val_mae: 0.0837\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0175 - val_mae: 0.0822\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0020 - mae: 0.0467 - val_loss: 0.0177 - val_mae: 0.0819\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0181 - val_mae: 0.0835\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0024 - mae: 0.0506 - val_loss: 0.0185 - val_mae: 0.0862\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0027 - mae: 0.0529 - val_loss: 0.0186 - val_mae: 0.0861\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0512 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0021 - mae: 0.0423 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0037 - mae: 0.0585 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - mae: 0.0516 - val_loss: 0.0170 - val_mae: 0.0815\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0516 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0064 - mae: 0.0708 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0020 - mae: 0.0435 - val_loss: 0.0171 - val_mae: 0.0803\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0025 - mae: 0.0513 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - mae: 0.0482 - val_loss: 0.0173 - val_mae: 0.0819\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - mae: 0.0539 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0176 - val_mae: 0.0856\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0175 - val_mae: 0.0851\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0023 - mae: 0.0502 - val_loss: 0.0174 - val_mae: 0.0849\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0176 - val_mae: 0.0865\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - mae: 0.0504 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0173 - val_mae: 0.0835\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0024 - mae: 0.0510 - val_loss: 0.0175 - val_mae: 0.0842\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0027 - mae: 0.0530 - val_loss: 0.0179 - val_mae: 0.0872\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0027 - mae: 0.0524 - val_loss: 0.0177 - val_mae: 0.0848\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - mae: 0.0476 - val_loss: 0.0177 - val_mae: 0.0823\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0521 - val_loss: 0.0178 - val_mae: 0.0803\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0182 - val_mae: 0.0815\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0187 - val_mae: 0.0840\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0195 - val_mae: 0.0895\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0567 - val_loss: 0.0197 - val_mae: 0.0920\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0197 - val_mae: 0.0930\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0028 - mae: 0.0529 - val_loss: 0.0194 - val_mae: 0.0919\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0620 - val_loss: 0.0197 - val_mae: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:14,656] Trial 14 finished with value: 0.09371820092201233 and parameters: {'learning_rate': 0.011725304429684976, 'weight_decay': 0.0067212838944218254}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0087 - mae: 0.0991 - val_loss: 0.0234 - val_mae: 0.1103\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0081 - mae: 0.0965 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0929 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0077 - mae: 0.0884 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0969\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0214 - val_mae: 0.0950\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.0933\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0209 - val_mae: 0.0915\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0822 - val_loss: 0.0204 - val_mae: 0.0884\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0807 - val_loss: 0.0202 - val_mae: 0.0869\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0199 - val_mae: 0.0855\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - mae: 0.0789 - val_loss: 0.0197 - val_mae: 0.0841\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0194 - val_mae: 0.0828\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0192 - val_mae: 0.0817\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0054 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0806\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0051 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0796\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0055 - mae: 0.0739 - val_loss: 0.0185 - val_mae: 0.0788\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0183 - val_mae: 0.0782\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0740 - val_loss: 0.0181 - val_mae: 0.0776\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0052 - mae: 0.0738 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0175 - val_mae: 0.0769\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0174 - val_mae: 0.0771\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0734 - val_loss: 0.0174 - val_mae: 0.0770\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0173 - val_mae: 0.0768\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0672 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0767\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0680 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0050 - mae: 0.0702 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0040 - mae: 0.0651 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0041 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0763\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0172 - val_mae: 0.0762\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0762\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0603 - val_loss: 0.0173 - val_mae: 0.0763\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0765\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0616 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0635 - val_loss: 0.0171 - val_mae: 0.0779\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0617 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0039 - mae: 0.0612 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0040 - mae: 0.0660 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0652 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0039 - mae: 0.0609 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0785\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0786\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0787\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0594 - val_loss: 0.0172 - val_mae: 0.0788\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0039 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0041 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - mae: 0.0575 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0171 - val_mae: 0.0794\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0039 - mae: 0.0644 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0041 - mae: 0.0658 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0603 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - mae: 0.0619 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0614 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0038 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0787\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0040 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0795\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0026 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0798\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0036 - mae: 0.0593 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0172 - val_mae: 0.0793\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0584 - val_loss: 0.0172 - val_mae: 0.0795\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - mae: 0.0535 - val_loss: 0.0171 - val_mae: 0.0798\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0801\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0633 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0171 - val_mae: 0.0808\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0171 - val_mae: 0.0807\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0034 - mae: 0.0590 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0171 - val_mae: 0.0806\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - mae: 0.0559 - val_loss: 0.0172 - val_mae: 0.0804\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0172 - val_mae: 0.0806\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0172 - val_mae: 0.0807\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - mae: 0.0579 - val_loss: 0.0172 - val_mae: 0.0808\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0809\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0172 - val_mae: 0.0810\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - mae: 0.0574 - val_loss: 0.0171 - val_mae: 0.0810\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0028 - mae: 0.0544 - val_loss: 0.0171 - val_mae: 0.0811\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0171 - val_mae: 0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:35,304] Trial 15 finished with value: 0.08110315352678299 and parameters: {'learning_rate': 0.0003509553348993356, 'weight_decay': 1.5962506432695974e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0108 - mae: 0.1114 - val_loss: 0.0255 - val_mae: 0.1229\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1107 - val_loss: 0.0253 - val_mae: 0.1223\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0252 - val_mae: 0.1217\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1117 - val_loss: 0.0251 - val_mae: 0.1211\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1071 - val_loss: 0.0250 - val_mae: 0.1204\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0096 - mae: 0.1047 - val_loss: 0.0249 - val_mae: 0.1198\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1191\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0101 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0099 - mae: 0.1072 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1172\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1165\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0242 - val_mae: 0.1159\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1036 - val_loss: 0.0241 - val_mae: 0.1153\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1021 - val_loss: 0.0240 - val_mae: 0.1147\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.0986 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.1019 - val_loss: 0.0239 - val_mae: 0.1135\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0990 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1024 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0085 - mae: 0.0963 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0089 - mae: 0.0975 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1097\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1087\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1082\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1072\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0084 - mae: 0.0925 - val_loss: 0.0230 - val_mae: 0.1062\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1057\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0906 - val_loss: 0.0229 - val_mae: 0.1052\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0079 - mae: 0.0916 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1036\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0226 - val_mae: 0.1026\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.1021\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0882 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0224 - val_mae: 0.1010\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0223 - val_mae: 0.1005\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0223 - val_mae: 0.0999\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0222 - val_mae: 0.0994\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0222 - val_mae: 0.0989\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0221 - val_mae: 0.0983\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0853 - val_loss: 0.0221 - val_mae: 0.0978\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0881 - val_loss: 0.0220 - val_mae: 0.0972\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0220 - val_mae: 0.0967\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0862 - val_loss: 0.0219 - val_mae: 0.0961\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0949\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0064 - mae: 0.0789 - val_loss: 0.0217 - val_mae: 0.0944\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0217 - val_mae: 0.0938\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0070 - mae: 0.0833 - val_loss: 0.0216 - val_mae: 0.0933\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0073 - mae: 0.0852 - val_loss: 0.0216 - val_mae: 0.0927\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0215 - val_mae: 0.0922\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0214 - val_mae: 0.0916\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0911\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0071 - mae: 0.0826 - val_loss: 0.0213 - val_mae: 0.0905\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0212 - val_mae: 0.0900\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0065 - mae: 0.0783 - val_loss: 0.0212 - val_mae: 0.0894\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0068 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0884\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0797 - val_loss: 0.0210 - val_mae: 0.0878\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0061 - mae: 0.0773 - val_loss: 0.0209 - val_mae: 0.0873\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0209 - val_mae: 0.0869\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0208 - val_mae: 0.0864\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0068 - mae: 0.0815 - val_loss: 0.0207 - val_mae: 0.0860\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0207 - val_mae: 0.0856\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0065 - mae: 0.0814 - val_loss: 0.0206 - val_mae: 0.0852\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0061 - mae: 0.0761 - val_loss: 0.0205 - val_mae: 0.0846\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0843\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0789 - val_loss: 0.0204 - val_mae: 0.0841\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0775 - val_loss: 0.0204 - val_mae: 0.0838\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0061 - mae: 0.0783 - val_loss: 0.0203 - val_mae: 0.0836\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0750 - val_loss: 0.0202 - val_mae: 0.0831\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0725 - val_loss: 0.0202 - val_mae: 0.0828\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0059 - mae: 0.0738 - val_loss: 0.0201 - val_mae: 0.0826\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0060 - mae: 0.0767 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0056 - mae: 0.0738 - val_loss: 0.0200 - val_mae: 0.0821\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0200 - val_mae: 0.0818\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0199 - val_mae: 0.0816\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0059 - mae: 0.0739 - val_loss: 0.0199 - val_mae: 0.0813\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0060 - mae: 0.0768 - val_loss: 0.0198 - val_mae: 0.0811\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0198 - val_mae: 0.0809\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0056 - mae: 0.0731 - val_loss: 0.0197 - val_mae: 0.0806\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0197 - val_mae: 0.0804\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0197 - val_mae: 0.0802\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0053 - mae: 0.0709 - val_loss: 0.0196 - val_mae: 0.0798\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0713 - val_loss: 0.0195 - val_mae: 0.0793\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0055 - mae: 0.0719 - val_loss: 0.0194 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0194 - val_mae: 0.0789\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0052 - mae: 0.0687 - val_loss: 0.0193 - val_mae: 0.0787\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0051 - mae: 0.0691 - val_loss: 0.0193 - val_mae: 0.0785\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0697 - val_loss: 0.0192 - val_mae: 0.0783\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0192 - val_mae: 0.0782\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0656 - val_loss: 0.0192 - val_mae: 0.0780\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0191 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0054 - mae: 0.0693 - val_loss: 0.0191 - val_mae: 0.0776\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0190 - val_mae: 0.0774\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0190 - val_mae: 0.0773\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0189 - val_mae: 0.0771\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0734 - val_loss: 0.0189 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0685 - val_loss: 0.0188 - val_mae: 0.0768\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0052 - mae: 0.0705 - val_loss: 0.0188 - val_mae: 0.0766\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0684 - val_loss: 0.0187 - val_mae: 0.0765\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0762 - val_loss: 0.0187 - val_mae: 0.0764\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0050 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.0763\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0042 - mae: 0.0640 - val_loss: 0.0186 - val_mae: 0.0762\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0186 - val_mae: 0.0761\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0185 - val_mae: 0.0760\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0675 - val_loss: 0.0185 - val_mae: 0.0759\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0048 - mae: 0.0699 - val_loss: 0.0185 - val_mae: 0.0759\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0184 - val_mae: 0.0758\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0757\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0184 - val_mae: 0.0756\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0688 - val_loss: 0.0184 - val_mae: 0.0756\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0666 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0050 - mae: 0.0729 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0742 - val_loss: 0.0183 - val_mae: 0.0754\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0183 - val_mae: 0.0753\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0183 - val_mae: 0.0753\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0683 - val_loss: 0.0183 - val_mae: 0.0752\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0667 - val_loss: 0.0182 - val_mae: 0.0751\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0696 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0182 - val_mae: 0.0750\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0182 - val_mae: 0.0749\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0182 - val_mae: 0.0749\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0684 - val_loss: 0.0182 - val_mae: 0.0748\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0182 - val_mae: 0.0748\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0041 - mae: 0.0636 - val_loss: 0.0181 - val_mae: 0.0747\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0042 - mae: 0.0615 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0045 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0650 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0049 - mae: 0.0687 - val_loss: 0.0180 - val_mae: 0.0746\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0746\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0179 - val_mae: 0.0746\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0179 - val_mae: 0.0747\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:52:55,081] Trial 16 finished with value: 0.07469943165779114 and parameters: {'learning_rate': 0.00011375913831331624, 'weight_decay': 0.006909327268532185}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0242 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0097 - mae: 0.1078 - val_loss: 0.0242 - val_mae: 0.1205\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0241 - val_mae: 0.1203\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0100 - mae: 0.1078 - val_loss: 0.0241 - val_mae: 0.1201\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0096 - mae: 0.1048 - val_loss: 0.0241 - val_mae: 0.1199\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0240 - val_mae: 0.1197\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0099 - mae: 0.1094 - val_loss: 0.0240 - val_mae: 0.1195\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - mae: 0.1077 - val_loss: 0.0240 - val_mae: 0.1193\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0240 - val_mae: 0.1191\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0239 - val_mae: 0.1189\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0239 - val_mae: 0.1187\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0239 - val_mae: 0.1185\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0098 - mae: 0.1063 - val_loss: 0.0239 - val_mae: 0.1183\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0238 - val_mae: 0.1181\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0238 - val_mae: 0.1179\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0238 - val_mae: 0.1177\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1175\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1173\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1171\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0237 - val_mae: 0.1169\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0237 - val_mae: 0.1167\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0236 - val_mae: 0.1165\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1164\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1162\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0236 - val_mae: 0.1160\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0236 - val_mae: 0.1158\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1044 - val_loss: 0.0235 - val_mae: 0.1157\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1044 - val_loss: 0.0235 - val_mae: 0.1155\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0235 - val_mae: 0.1153\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0089 - mae: 0.1009 - val_loss: 0.0235 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0235 - val_mae: 0.1150\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1032 - val_loss: 0.0234 - val_mae: 0.1148\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0234 - val_mae: 0.1146\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.0994 - val_loss: 0.0234 - val_mae: 0.1145\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1025 - val_loss: 0.0234 - val_mae: 0.1143\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0234 - val_mae: 0.1141\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0233 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0233 - val_mae: 0.1138\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0233 - val_mae: 0.1137\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.1012 - val_loss: 0.0233 - val_mae: 0.1135\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0233 - val_mae: 0.1133\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1011 - val_loss: 0.0232 - val_mae: 0.1132\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0232 - val_mae: 0.1130\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1020 - val_loss: 0.0232 - val_mae: 0.1129\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1127\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0232 - val_mae: 0.1126\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0231 - val_mae: 0.1124\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0231 - val_mae: 0.1122\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0231 - val_mae: 0.1121\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - mae: 0.1011 - val_loss: 0.0231 - val_mae: 0.1119\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0231 - val_mae: 0.1118\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0085 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1116\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0230 - val_mae: 0.1114\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0230 - val_mae: 0.1113\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0230 - val_mae: 0.1111\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0991 - val_loss: 0.0230 - val_mae: 0.1110\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0229 - val_mae: 0.1108\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0085 - mae: 0.0974 - val_loss: 0.0229 - val_mae: 0.1106\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1105\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0229 - val_mae: 0.1103\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0229 - val_mae: 0.1101\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.0993 - val_loss: 0.0228 - val_mae: 0.1100\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0957 - val_loss: 0.0228 - val_mae: 0.1098\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0228 - val_mae: 0.1096\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0985 - val_loss: 0.0228 - val_mae: 0.1095\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0988 - val_loss: 0.0228 - val_mae: 0.1093\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0959 - val_loss: 0.0227 - val_mae: 0.1091\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0227 - val_mae: 0.1090\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0227 - val_mae: 0.1088\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0227 - val_mae: 0.1087\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0227 - val_mae: 0.1085\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0946 - val_loss: 0.0226 - val_mae: 0.1083\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0226 - val_mae: 0.1081\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0226 - val_mae: 0.1080\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0226 - val_mae: 0.1078\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0226 - val_mae: 0.1076\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0225 - val_mae: 0.1074\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1073\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0225 - val_mae: 0.1071\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0225 - val_mae: 0.1069\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1067\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0224 - val_mae: 0.1066\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0224 - val_mae: 0.1064\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0224 - val_mae: 0.1062\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0224 - val_mae: 0.1060\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0224 - val_mae: 0.1058\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0917 - val_loss: 0.0223 - val_mae: 0.1057\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0223 - val_mae: 0.1055\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0932 - val_loss: 0.0223 - val_mae: 0.1053\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0223 - val_mae: 0.1051\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0223 - val_mae: 0.1049\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0222 - val_mae: 0.1048\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0082 - mae: 0.0937 - val_loss: 0.0222 - val_mae: 0.1046\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0222 - val_mae: 0.1044\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0077 - mae: 0.0916 - val_loss: 0.0222 - val_mae: 0.1042\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0222 - val_mae: 0.1041\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0902 - val_loss: 0.0221 - val_mae: 0.1039\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0221 - val_mae: 0.1037\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0221 - val_mae: 0.1035\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0077 - mae: 0.0902 - val_loss: 0.0221 - val_mae: 0.1033\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0918 - val_loss: 0.0221 - val_mae: 0.1032\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0220 - val_mae: 0.1030\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0220 - val_mae: 0.1028\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0220 - val_mae: 0.1026\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0220 - val_mae: 0.1024\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0884 - val_loss: 0.0220 - val_mae: 0.1022\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0903 - val_loss: 0.0219 - val_mae: 0.1020\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0883 - val_loss: 0.0219 - val_mae: 0.1019\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0219 - val_mae: 0.1017\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0219 - val_mae: 0.1015\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0218 - val_mae: 0.1013\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0078 - mae: 0.0916 - val_loss: 0.0218 - val_mae: 0.1011\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.1009\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0078 - mae: 0.0903 - val_loss: 0.0218 - val_mae: 0.1007\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0218 - val_mae: 0.1005\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0217 - val_mae: 0.1003\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0898 - val_loss: 0.0217 - val_mae: 0.1002\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0074 - mae: 0.0868 - val_loss: 0.0217 - val_mae: 0.1000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0217 - val_mae: 0.0998\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - mae: 0.0888 - val_loss: 0.0217 - val_mae: 0.0996\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0861 - val_loss: 0.0216 - val_mae: 0.0994\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0074 - mae: 0.0866 - val_loss: 0.0216 - val_mae: 0.0992\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0216 - val_mae: 0.0990\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0877 - val_loss: 0.0216 - val_mae: 0.0988\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0870 - val_loss: 0.0215 - val_mae: 0.0986\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0215 - val_mae: 0.0984\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0068 - mae: 0.0823 - val_loss: 0.0215 - val_mae: 0.0982\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0215 - val_mae: 0.0980\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0073 - mae: 0.0881 - val_loss: 0.0215 - val_mae: 0.0978\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0078 - mae: 0.0888 - val_loss: 0.0214 - val_mae: 0.0976\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0071 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0974\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0214 - val_mae: 0.0972\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0837 - val_loss: 0.0214 - val_mae: 0.0970\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0847 - val_loss: 0.0213 - val_mae: 0.0968\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0213 - val_mae: 0.0966\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0213 - val_mae: 0.0964\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0846 - val_loss: 0.0213 - val_mae: 0.0962\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0212 - val_mae: 0.0960\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0829 - val_loss: 0.0212 - val_mae: 0.0958\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0071 - mae: 0.0858 - val_loss: 0.0212 - val_mae: 0.0956\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0212 - val_mae: 0.0953\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0212 - val_mae: 0.0951\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0211 - val_mae: 0.0949\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0211 - val_mae: 0.0947\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0847 - val_loss: 0.0211 - val_mae: 0.0945\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0846 - val_loss: 0.0211 - val_mae: 0.0943\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0210 - val_mae: 0.0941\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0068 - mae: 0.0818 - val_loss: 0.0210 - val_mae: 0.0939\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0075 - mae: 0.0857 - val_loss: 0.0210 - val_mae: 0.0937\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0210 - val_mae: 0.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:14,732] Trial 17 finished with value: 0.09353812783956528 and parameters: {'learning_rate': 3.8861585707874365e-05, 'weight_decay': 0.0061637418399309715}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0248 - val_mae: 0.1198\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1049 - val_loss: 0.0248 - val_mae: 0.1197\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0248 - val_mae: 0.1196\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1057 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1193\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0247 - val_mae: 0.1192\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0247 - val_mae: 0.1191\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1064 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1190\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0247 - val_mae: 0.1189\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0247 - val_mae: 0.1188\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0089 - mae: 0.1037 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0094 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0090 - mae: 0.1035 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1042 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1186\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1185\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0091 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1184\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0093 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1183\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1029 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1182\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0246 - val_mae: 0.1181\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0091 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1180\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1179\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1178\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0090 - mae: 0.1021 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1050 - val_loss: 0.0245 - val_mae: 0.1177\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1176\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1036 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0090 - mae: 0.1025 - val_loss: 0.0245 - val_mae: 0.1175\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:34,268] Trial 18 finished with value: 0.11748065054416656 and parameters: {'learning_rate': 3.9091321312414766e-06, 'weight_decay': 7.95255895567331e-07}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0249 - val_mae: 0.1162\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0093 - mae: 0.1038 - val_loss: 0.0248 - val_mae: 0.1156\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0247 - val_mae: 0.1149\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0246 - val_mae: 0.1143\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0093 - mae: 0.1030 - val_loss: 0.0245 - val_mae: 0.1137\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1131\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.0987 - val_loss: 0.0244 - val_mae: 0.1124\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0243 - val_mae: 0.1118\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1112\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0241 - val_mae: 0.1106\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0086 - mae: 0.0983 - val_loss: 0.0240 - val_mae: 0.1100\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0240 - val_mae: 0.1094\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0085 - mae: 0.0972 - val_loss: 0.0239 - val_mae: 0.1089\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0081 - mae: 0.0939 - val_loss: 0.0238 - val_mae: 0.1083\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0237 - val_mae: 0.1078\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0237 - val_mae: 0.1072\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0962 - val_loss: 0.0236 - val_mae: 0.1067\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0235 - val_mae: 0.1061\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0079 - mae: 0.0937 - val_loss: 0.0235 - val_mae: 0.1055\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0079 - mae: 0.0927 - val_loss: 0.0234 - val_mae: 0.1049\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0922 - val_loss: 0.0233 - val_mae: 0.1044\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0232 - val_mae: 0.1038\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0232 - val_mae: 0.1032\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0910 - val_loss: 0.0231 - val_mae: 0.1027\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0077 - mae: 0.0887 - val_loss: 0.0230 - val_mae: 0.1021\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0885 - val_loss: 0.0230 - val_mae: 0.1016\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0076 - mae: 0.0901 - val_loss: 0.0229 - val_mae: 0.1011\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0228 - val_mae: 0.1006\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0896 - val_loss: 0.0228 - val_mae: 0.1001\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0878 - val_loss: 0.0227 - val_mae: 0.0996\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0846 - val_loss: 0.0227 - val_mae: 0.0991\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0226 - val_mae: 0.0987\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0226 - val_mae: 0.0983\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0225 - val_mae: 0.0978\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0863 - val_loss: 0.0224 - val_mae: 0.0974\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0224 - val_mae: 0.0969\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - mae: 0.0865 - val_loss: 0.0223 - val_mae: 0.0965\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0223 - val_mae: 0.0960\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0222 - val_mae: 0.0955\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0854 - val_loss: 0.0222 - val_mae: 0.0951\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0073 - mae: 0.0865 - val_loss: 0.0221 - val_mae: 0.0946\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0220 - val_mae: 0.0941\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0220 - val_mae: 0.0936\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0065 - mae: 0.0808 - val_loss: 0.0219 - val_mae: 0.0932\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0066 - mae: 0.0825 - val_loss: 0.0219 - val_mae: 0.0927\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0218 - val_mae: 0.0922\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0217 - val_mae: 0.0918\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0065 - mae: 0.0800 - val_loss: 0.0217 - val_mae: 0.0914\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0797 - val_loss: 0.0216 - val_mae: 0.0910\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0215 - val_mae: 0.0905\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0215 - val_mae: 0.0901\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0214 - val_mae: 0.0897\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0065 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0892\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0066 - mae: 0.0802 - val_loss: 0.0213 - val_mae: 0.0888\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0060 - mae: 0.0762 - val_loss: 0.0212 - val_mae: 0.0884\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0061 - mae: 0.0756 - val_loss: 0.0212 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0062 - mae: 0.0761 - val_loss: 0.0211 - val_mae: 0.0876\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0798 - val_loss: 0.0211 - val_mae: 0.0872\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0210 - val_mae: 0.0868\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0209 - val_mae: 0.0864\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0063 - mae: 0.0788 - val_loss: 0.0209 - val_mae: 0.0860\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0764 - val_loss: 0.0208 - val_mae: 0.0856\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0766 - val_loss: 0.0208 - val_mae: 0.0852\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0059 - mae: 0.0752 - val_loss: 0.0207 - val_mae: 0.0848\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0206 - val_mae: 0.0845\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0206 - val_mae: 0.0842\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0062 - mae: 0.0776 - val_loss: 0.0205 - val_mae: 0.0839\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0718 - val_loss: 0.0205 - val_mae: 0.0836\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0763 - val_loss: 0.0204 - val_mae: 0.0833\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0055 - mae: 0.0734 - val_loss: 0.0203 - val_mae: 0.0831\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0748 - val_loss: 0.0203 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0066 - mae: 0.0813 - val_loss: 0.0202 - val_mae: 0.0827\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0202 - val_mae: 0.0825\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0746 - val_loss: 0.0200 - val_mae: 0.0821\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0696 - val_loss: 0.0200 - val_mae: 0.0819\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0199 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0198 - val_mae: 0.0815\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0198 - val_mae: 0.0814\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0197 - val_mae: 0.0812\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0197 - val_mae: 0.0810\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0196 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0196 - val_mae: 0.0806\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0195 - val_mae: 0.0805\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0056 - mae: 0.0717 - val_loss: 0.0195 - val_mae: 0.0803\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0194 - val_mae: 0.0801\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0715 - val_loss: 0.0194 - val_mae: 0.0799\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0193 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0051 - mae: 0.0712 - val_loss: 0.0193 - val_mae: 0.0795\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0193 - val_mae: 0.0794\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0192 - val_mae: 0.0793\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0192 - val_mae: 0.0791\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0192 - val_mae: 0.0790\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0046 - mae: 0.0687 - val_loss: 0.0191 - val_mae: 0.0788\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0191 - val_mae: 0.0787\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0055 - mae: 0.0721 - val_loss: 0.0191 - val_mae: 0.0786\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0190 - val_mae: 0.0785\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0046 - mae: 0.0692 - val_loss: 0.0190 - val_mae: 0.0783\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0190 - val_mae: 0.0782\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0189 - val_mae: 0.0781\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0047 - mae: 0.0723 - val_loss: 0.0189 - val_mae: 0.0779\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0052 - mae: 0.0727 - val_loss: 0.0188 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0050 - mae: 0.0679 - val_loss: 0.0188 - val_mae: 0.0777\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0049 - mae: 0.0708 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0048 - mae: 0.0680 - val_loss: 0.0188 - val_mae: 0.0776\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0691 - val_loss: 0.0187 - val_mae: 0.0775\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0187 - val_mae: 0.0774\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0186 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0048 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0047 - mae: 0.0700 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.0773\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0687 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0185 - val_mae: 0.0772\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0709 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0048 - mae: 0.0677 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0651 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0048 - mae: 0.0692 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0051 - mae: 0.0723 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0662 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0043 - mae: 0.0634 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0703 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0671 - val_loss: 0.0182 - val_mae: 0.0769\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0046 - mae: 0.0703 - val_loss: 0.0182 - val_mae: 0.0768\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0182 - val_mae: 0.0767\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0048 - mae: 0.0702 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0045 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0639 - val_loss: 0.0181 - val_mae: 0.0764\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.0763\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0180 - val_mae: 0.0763\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0042 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0764\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0180 - val_mae: 0.0764\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0180 - val_mae: 0.0765\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - mae: 0.0656 - val_loss: 0.0180 - val_mae: 0.0765\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0179 - val_mae: 0.0766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:53:54,116] Trial 19 finished with value: 0.07661332190036774 and parameters: {'learning_rate': 0.00010865799893817708, 'weight_decay': 3.7195109665761165e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0109 - mae: 0.1195 - val_loss: 0.0257 - val_mae: 0.1312\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0110 - mae: 0.1159 - val_loss: 0.0257 - val_mae: 0.1312\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0257 - val_mae: 0.1311\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0108 - mae: 0.1164 - val_loss: 0.0256 - val_mae: 0.1311\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0256 - val_mae: 0.1311\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1165 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0108 - mae: 0.1155 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0256 - val_mae: 0.1310\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1170 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0110 - mae: 0.1176 - val_loss: 0.0256 - val_mae: 0.1309\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1167 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0110 - mae: 0.1171 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108 - mae: 0.1159 - val_loss: 0.0256 - val_mae: 0.1308\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0116 - mae: 0.1200 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0108 - mae: 0.1173 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0105 - mae: 0.1137 - val_loss: 0.0256 - val_mae: 0.1307\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1115 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0111 - mae: 0.1171 - val_loss: 0.0256 - val_mae: 0.1306\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0113 - mae: 0.1179 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0110 - mae: 0.1164 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0114 - mae: 0.1196 - val_loss: 0.0256 - val_mae: 0.1305\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0110 - mae: 0.1172 - val_loss: 0.0256 - val_mae: 0.1304\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0112 - mae: 0.1205 - val_loss: 0.0255 - val_mae: 0.1304\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0255 - val_mae: 0.1304\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0106 - mae: 0.1147 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0110 - mae: 0.1159 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0105 - mae: 0.1150 - val_loss: 0.0255 - val_mae: 0.1303\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0116 - mae: 0.1233 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0106 - mae: 0.1146 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0106 - mae: 0.1138 - val_loss: 0.0255 - val_mae: 0.1302\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0111 - mae: 0.1174 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0255 - val_mae: 0.1301\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - mae: 0.1158 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0255 - val_mae: 0.1300\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0110 - mae: 0.1189 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0109 - mae: 0.1176 - val_loss: 0.0255 - val_mae: 0.1299\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1160 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0117 - mae: 0.1227 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0255 - val_mae: 0.1298\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0106 - mae: 0.1154 - val_loss: 0.0255 - val_mae: 0.1297\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0109 - mae: 0.1165 - val_loss: 0.0254 - val_mae: 0.1297\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0112 - mae: 0.1194 - val_loss: 0.0254 - val_mae: 0.1297\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0107 - mae: 0.1167 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0106 - mae: 0.1150 - val_loss: 0.0254 - val_mae: 0.1296\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0107 - mae: 0.1149 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0109 - mae: 0.1186 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1295\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0104 - mae: 0.1142 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1177 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0102 - mae: 0.1129 - val_loss: 0.0254 - val_mae: 0.1294\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0112 - mae: 0.1196 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1117 - val_loss: 0.0254 - val_mae: 0.1293\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1141 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0110 - mae: 0.1151 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0108 - mae: 0.1134 - val_loss: 0.0254 - val_mae: 0.1292\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0104 - mae: 0.1150 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0254 - val_mae: 0.1291\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0111 - mae: 0.1172 - val_loss: 0.0254 - val_mae: 0.1290\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1160 - val_loss: 0.0253 - val_mae: 0.1290\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0253 - val_mae: 0.1290\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0111 - mae: 0.1180 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0253 - val_mae: 0.1289\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - mae: 0.1161 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0109 - mae: 0.1163 - val_loss: 0.0253 - val_mae: 0.1288\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0110 - mae: 0.1157 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0103 - mae: 0.1112 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1152 - val_loss: 0.0253 - val_mae: 0.1287\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0108 - mae: 0.1170 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1121 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0253 - val_mae: 0.1286\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0102 - mae: 0.1140 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0253 - val_mae: 0.1285\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0106 - mae: 0.1145 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0101 - mae: 0.1115 - val_loss: 0.0253 - val_mae: 0.1284\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0109 - mae: 0.1159 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1122 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0108 - mae: 0.1158 - val_loss: 0.0253 - val_mae: 0.1283\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0252 - val_mae: 0.1283\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0100 - mae: 0.1111 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0252 - val_mae: 0.1282\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - mae: 0.1148 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0107 - mae: 0.1163 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0107 - mae: 0.1156 - val_loss: 0.0252 - val_mae: 0.1281\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0106 - mae: 0.1134 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0099 - mae: 0.1104 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0252 - val_mae: 0.1280\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0108 - mae: 0.1145 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1125 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - mae: 0.1143 - val_loss: 0.0252 - val_mae: 0.1279\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - mae: 0.1121 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0252 - val_mae: 0.1278\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0102 - mae: 0.1131 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0252 - val_mae: 0.1277\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0106 - mae: 0.1141 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0252 - val_mae: 0.1276\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1112 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0251 - val_mae: 0.1275\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0106 - mae: 0.1158 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0103 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0103 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0251 - val_mae: 0.1274\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0107 - mae: 0.1164 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0106 - mae: 0.1126 - val_loss: 0.0251 - val_mae: 0.1273\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0102 - mae: 0.1111 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0105 - mae: 0.1139 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0099 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1272\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0106 - mae: 0.1151 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0105 - mae: 0.1126 - val_loss: 0.0251 - val_mae: 0.1271\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0106 - mae: 0.1136 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0102 - mae: 0.1133 - val_loss: 0.0251 - val_mae: 0.1270\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0101 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0105 - mae: 0.1146 - val_loss: 0.0251 - val_mae: 0.1269\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0102 - mae: 0.1122 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0250 - val_mae: 0.1268\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0105 - mae: 0.1133 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0106 - mae: 0.1143 - val_loss: 0.0250 - val_mae: 0.1267\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0101 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0104 - mae: 0.1111 - val_loss: 0.0250 - val_mae: 0.1266\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0101 - mae: 0.1121 - val_loss: 0.0250 - val_mae: 0.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:13,744] Trial 20 finished with value: 0.12655121088027954 and parameters: {'learning_rate': 4.122553152958873e-06, 'weight_decay': 0.004568530675075751}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0092 - mae: 0.1026 - val_loss: 0.0245 - val_mae: 0.1154\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1151\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0244 - val_mae: 0.1148\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1021 - val_loss: 0.0244 - val_mae: 0.1145\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0243 - val_mae: 0.1142\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0094 - mae: 0.1011 - val_loss: 0.0243 - val_mae: 0.1139\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0093 - mae: 0.1020 - val_loss: 0.0242 - val_mae: 0.1132\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1129\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1125\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1122\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0240 - val_mae: 0.1118\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1115\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0090 - mae: 0.0993 - val_loss: 0.0239 - val_mae: 0.1112\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0239 - val_mae: 0.1108\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0238 - val_mae: 0.1105\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0238 - val_mae: 0.1101\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0958 - val_loss: 0.0237 - val_mae: 0.1098\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0237 - val_mae: 0.1095\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0236 - val_mae: 0.1091\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0236 - val_mae: 0.1088\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0235 - val_mae: 0.1084\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0235 - val_mae: 0.1081\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1077\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1073\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0233 - val_mae: 0.1070\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1066\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0232 - val_mae: 0.1062\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0232 - val_mae: 0.1059\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0922 - val_loss: 0.0231 - val_mae: 0.1055\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0231 - val_mae: 0.1052\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0087 - mae: 0.0963 - val_loss: 0.0230 - val_mae: 0.1048\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0229 - val_mae: 0.1044\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1041\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0926 - val_loss: 0.0228 - val_mae: 0.1037\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1033\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0922 - val_loss: 0.0227 - val_mae: 0.1030\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0227 - val_mae: 0.1026\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0079 - mae: 0.0903 - val_loss: 0.0226 - val_mae: 0.1022\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0226 - val_mae: 0.1019\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0078 - mae: 0.0887 - val_loss: 0.0225 - val_mae: 0.1015\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0895 - val_loss: 0.0225 - val_mae: 0.1011\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0920 - val_loss: 0.0224 - val_mae: 0.1008\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0892 - val_loss: 0.0224 - val_mae: 0.1004\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0223 - val_mae: 0.0996\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0222 - val_mae: 0.0993\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0911 - val_loss: 0.0222 - val_mae: 0.0989\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0878 - val_loss: 0.0221 - val_mae: 0.0985\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.0982\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0220 - val_mae: 0.0978\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0870 - val_loss: 0.0220 - val_mae: 0.0974\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0839 - val_loss: 0.0219 - val_mae: 0.0970\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0219 - val_mae: 0.0967\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0218 - val_mae: 0.0963\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0218 - val_mae: 0.0959\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0217 - val_mae: 0.0956\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0217 - val_mae: 0.0952\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.0948\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0076 - mae: 0.0862 - val_loss: 0.0216 - val_mae: 0.0945\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0215 - val_mae: 0.0941\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0848 - val_loss: 0.0215 - val_mae: 0.0937\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0214 - val_mae: 0.0933\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0863 - val_loss: 0.0214 - val_mae: 0.0930\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0072 - mae: 0.0850 - val_loss: 0.0213 - val_mae: 0.0926\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0213 - val_mae: 0.0922\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0827 - val_loss: 0.0213 - val_mae: 0.0919\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0068 - mae: 0.0823 - val_loss: 0.0212 - val_mae: 0.0916\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0212 - val_mae: 0.0913\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0800 - val_loss: 0.0211 - val_mae: 0.0909\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0071 - mae: 0.0841 - val_loss: 0.0211 - val_mae: 0.0906\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0903\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0210 - val_mae: 0.0900\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0819 - val_loss: 0.0209 - val_mae: 0.0897\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0816 - val_loss: 0.0209 - val_mae: 0.0894\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0891\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0208 - val_mae: 0.0888\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0798 - val_loss: 0.0208 - val_mae: 0.0885\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0808 - val_loss: 0.0207 - val_mae: 0.0882\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0207 - val_mae: 0.0880\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0206 - val_mae: 0.0877\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0800 - val_loss: 0.0206 - val_mae: 0.0874\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0791 - val_loss: 0.0205 - val_mae: 0.0872\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0061 - mae: 0.0775 - val_loss: 0.0205 - val_mae: 0.0869\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0204 - val_mae: 0.0866\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0204 - val_mae: 0.0863\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0063 - mae: 0.0766 - val_loss: 0.0204 - val_mae: 0.0860\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0066 - mae: 0.0785 - val_loss: 0.0203 - val_mae: 0.0857\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0203 - val_mae: 0.0855\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0067 - mae: 0.0789 - val_loss: 0.0202 - val_mae: 0.0852\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0063 - mae: 0.0763 - val_loss: 0.0202 - val_mae: 0.0849\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0201 - val_mae: 0.0846\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0754 - val_loss: 0.0201 - val_mae: 0.0843\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0062 - mae: 0.0752 - val_loss: 0.0200 - val_mae: 0.0840\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0060 - mae: 0.0755 - val_loss: 0.0200 - val_mae: 0.0838\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0059 - mae: 0.0758 - val_loss: 0.0199 - val_mae: 0.0835\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0059 - mae: 0.0757 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0059 - mae: 0.0754 - val_loss: 0.0198 - val_mae: 0.0828\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0062 - mae: 0.0768 - val_loss: 0.0197 - val_mae: 0.0826\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0062 - mae: 0.0769 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0064 - mae: 0.0786 - val_loss: 0.0197 - val_mae: 0.0821\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0765 - val_loss: 0.0196 - val_mae: 0.0819\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0195 - val_mae: 0.0815\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0813\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0058 - mae: 0.0761 - val_loss: 0.0194 - val_mae: 0.0811\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0194 - val_mae: 0.0810\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - mae: 0.0762 - val_loss: 0.0193 - val_mae: 0.0808\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0193 - val_mae: 0.0806\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0060 - mae: 0.0749 - val_loss: 0.0193 - val_mae: 0.0804\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0059 - mae: 0.0749 - val_loss: 0.0192 - val_mae: 0.0801\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0057 - mae: 0.0717 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0191 - val_mae: 0.0797\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0052 - mae: 0.0715 - val_loss: 0.0191 - val_mae: 0.0796\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0056 - mae: 0.0728 - val_loss: 0.0190 - val_mae: 0.0794\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - mae: 0.0738 - val_loss: 0.0190 - val_mae: 0.0792\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - mae: 0.0698 - val_loss: 0.0190 - val_mae: 0.0791\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0055 - mae: 0.0722 - val_loss: 0.0189 - val_mae: 0.0789\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0189 - val_mae: 0.0788\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0705 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0056 - mae: 0.0708 - val_loss: 0.0188 - val_mae: 0.0785\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - mae: 0.0688 - val_loss: 0.0188 - val_mae: 0.0784\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0187 - val_mae: 0.0783\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0695 - val_loss: 0.0187 - val_mae: 0.0781\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0056 - mae: 0.0725 - val_loss: 0.0187 - val_mae: 0.0780\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0186 - val_mae: 0.0778\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.0777\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0185 - val_mae: 0.0776\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0057 - mae: 0.0742 - val_loss: 0.0185 - val_mae: 0.0775\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0669 - val_loss: 0.0185 - val_mae: 0.0774\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0054 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0695 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0055 - mae: 0.0712 - val_loss: 0.0184 - val_mae: 0.0771\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0058 - mae: 0.0744 - val_loss: 0.0184 - val_mae: 0.0770\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0732 - val_loss: 0.0183 - val_mae: 0.0768\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0731 - val_loss: 0.0183 - val_mae: 0.0767\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0049 - mae: 0.0685 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0052 - mae: 0.0732 - val_loss: 0.0181 - val_mae: 0.0763\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0050 - mae: 0.0678 - val_loss: 0.0181 - val_mae: 0.0762\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0053 - mae: 0.0697 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0180 - val_mae: 0.0762\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0050 - mae: 0.0668 - val_loss: 0.0179 - val_mae: 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:33,378] Trial 21 finished with value: 0.07620437443256378 and parameters: {'learning_rate': 5.5459229085853306e-05, 'weight_decay': 3.0257277936324145e-05}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0099 - mae: 0.1063 - val_loss: 0.0254 - val_mae: 0.1150\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0098 - mae: 0.1056 - val_loss: 0.0252 - val_mae: 0.1138\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1127\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0094 - mae: 0.1028 - val_loss: 0.0248 - val_mae: 0.1115\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0247 - val_mae: 0.1103\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0087 - mae: 0.0988 - val_loss: 0.0245 - val_mae: 0.1091\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0243 - val_mae: 0.1079\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.0981 - val_loss: 0.0242 - val_mae: 0.1069\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0240 - val_mae: 0.1058\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0969 - val_loss: 0.0239 - val_mae: 0.1047\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0081 - mae: 0.0934 - val_loss: 0.0237 - val_mae: 0.1037\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0084 - mae: 0.0944 - val_loss: 0.0236 - val_mae: 0.1027\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0952 - val_loss: 0.0234 - val_mae: 0.1017\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0233 - val_mae: 0.1008\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0232 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0917 - val_loss: 0.0230 - val_mae: 0.0989\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0229 - val_mae: 0.0980\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.0972\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0226 - val_mae: 0.0964\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0860 - val_loss: 0.0225 - val_mae: 0.0956\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0224 - val_mae: 0.0948\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - mae: 0.0856 - val_loss: 0.0223 - val_mae: 0.0940\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.0932\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0070 - mae: 0.0852 - val_loss: 0.0220 - val_mae: 0.0925\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0833 - val_loss: 0.0219 - val_mae: 0.0918\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0217 - val_mae: 0.0910\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0069 - mae: 0.0822 - val_loss: 0.0216 - val_mae: 0.0904\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0215 - val_mae: 0.0897\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0066 - mae: 0.0801 - val_loss: 0.0214 - val_mae: 0.0890\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0063 - mae: 0.0792 - val_loss: 0.0212 - val_mae: 0.0883\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0061 - mae: 0.0797 - val_loss: 0.0211 - val_mae: 0.0877\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0210 - val_mae: 0.0870\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0208 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0058 - mae: 0.0734 - val_loss: 0.0207 - val_mae: 0.0857\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0061 - mae: 0.0771 - val_loss: 0.0206 - val_mae: 0.0851\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0205 - val_mae: 0.0845\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0057 - mae: 0.0758 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0724 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0059 - mae: 0.0778 - val_loss: 0.0201 - val_mae: 0.0828\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0058 - mae: 0.0777 - val_loss: 0.0199 - val_mae: 0.0818\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0058 - mae: 0.0753 - val_loss: 0.0198 - val_mae: 0.0813\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0197 - val_mae: 0.0808\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0051 - mae: 0.0722 - val_loss: 0.0196 - val_mae: 0.0804\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0195 - val_mae: 0.0802\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0194 - val_mae: 0.0799\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0057 - mae: 0.0772 - val_loss: 0.0193 - val_mae: 0.0797\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0049 - mae: 0.0668 - val_loss: 0.0192 - val_mae: 0.0794\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0191 - val_mae: 0.0792\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0190 - val_mae: 0.0790\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0048 - mae: 0.0690 - val_loss: 0.0189 - val_mae: 0.0788\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0186 - val_mae: 0.0785\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0049 - mae: 0.0681 - val_loss: 0.0185 - val_mae: 0.0784\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0049 - mae: 0.0699 - val_loss: 0.0184 - val_mae: 0.0784\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0183 - val_mae: 0.0784\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0050 - mae: 0.0707 - val_loss: 0.0182 - val_mae: 0.0784\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0043 - mae: 0.0619 - val_loss: 0.0181 - val_mae: 0.0785\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0181 - val_mae: 0.0786\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - mae: 0.0700 - val_loss: 0.0180 - val_mae: 0.0786\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0047 - mae: 0.0696 - val_loss: 0.0179 - val_mae: 0.0787\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0178 - val_mae: 0.0787\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0048 - mae: 0.0698 - val_loss: 0.0178 - val_mae: 0.0788\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0044 - mae: 0.0626 - val_loss: 0.0177 - val_mae: 0.0788\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0177 - val_mae: 0.0789\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0679 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0176 - val_mae: 0.0788\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0044 - mae: 0.0661 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0040 - mae: 0.0634 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - mae: 0.0645 - val_loss: 0.0175 - val_mae: 0.0786\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0038 - mae: 0.0592 - val_loss: 0.0174 - val_mae: 0.0783\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0042 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0039 - mae: 0.0614 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0620 - val_loss: 0.0174 - val_mae: 0.0784\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0043 - mae: 0.0635 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0045 - mae: 0.0667 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0636 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0041 - mae: 0.0641 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0041 - mae: 0.0622 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0041 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0786\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0044 - mae: 0.0682 - val_loss: 0.0173 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0045 - mae: 0.0672 - val_loss: 0.0173 - val_mae: 0.0784\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0783\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0782\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0627 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0038 - mae: 0.0599 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - mae: 0.0611 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0781\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - mae: 0.0613 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0038 - mae: 0.0603 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0171 - val_mae: 0.0784\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0171 - val_mae: 0.0785\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0045 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0793\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0038 - mae: 0.0607 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - mae: 0.0674 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0036 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0649 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0039 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - mae: 0.0647 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0035 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0635 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039 - mae: 0.0634 - val_loss: 0.0170 - val_mae: 0.0785\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0170 - val_mae: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:54:53,014] Trial 22 finished with value: 0.07842803001403809 and parameters: {'learning_rate': 0.00017642286827236882, 'weight_decay': 4.869910553316675e-06}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1008 - val_loss: 0.0239 - val_mae: 0.1136\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1134\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0238 - val_mae: 0.1131\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0097 - mae: 0.1029 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0098 - mae: 0.1039 - val_loss: 0.0238 - val_mae: 0.1127\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0093 - mae: 0.1028 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.0998 - val_loss: 0.0237 - val_mae: 0.1122\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0237 - val_mae: 0.1120\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0236 - val_mae: 0.1117\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0236 - val_mae: 0.1115\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0236 - val_mae: 0.1113\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0092 - mae: 0.1004 - val_loss: 0.0235 - val_mae: 0.1111\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0235 - val_mae: 0.1109\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0091 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1106\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0092 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0093 - mae: 0.1005 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0091 - mae: 0.0992 - val_loss: 0.0234 - val_mae: 0.1098\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0233 - val_mae: 0.1096\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0233 - val_mae: 0.1093\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0091 - mae: 0.0996 - val_loss: 0.0233 - val_mae: 0.1091\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0089 - mae: 0.0987 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0087 - mae: 0.0967 - val_loss: 0.0232 - val_mae: 0.1087\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0090 - mae: 0.0989 - val_loss: 0.0232 - val_mae: 0.1084\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0088 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1082\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0231 - val_mae: 0.1081\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0090 - mae: 0.0984 - val_loss: 0.0231 - val_mae: 0.1079\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0942 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0088 - mae: 0.0980 - val_loss: 0.0230 - val_mae: 0.1070\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1068\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0088 - mae: 0.0973 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0089 - mae: 0.0970 - val_loss: 0.0229 - val_mae: 0.1065\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0087 - mae: 0.0976 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0085 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1059\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0951 - val_loss: 0.0228 - val_mae: 0.1057\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0089 - mae: 0.0970 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0089 - mae: 0.0978 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0227 - val_mae: 0.1051\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0083 - mae: 0.0942 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.0946 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0080 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1046\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0226 - val_mae: 0.1044\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0078 - mae: 0.0933 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0226 - val_mae: 0.1041\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - mae: 0.0971 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0225 - val_mae: 0.1037\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0921 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0080 - mae: 0.0911 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0081 - mae: 0.0912 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0082 - mae: 0.0934 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - mae: 0.0927 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0944 - val_loss: 0.0223 - val_mae: 0.1020\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0082 - mae: 0.0946 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0919 - val_loss: 0.0222 - val_mae: 0.1017\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0083 - mae: 0.0931 - val_loss: 0.0222 - val_mae: 0.1015\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0079 - mae: 0.0915 - val_loss: 0.0222 - val_mae: 0.1013\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0904 - val_loss: 0.0221 - val_mae: 0.1012\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0221 - val_mae: 0.1010\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0081 - mae: 0.0916 - val_loss: 0.0221 - val_mae: 0.1008\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0908 - val_loss: 0.0220 - val_mae: 0.1005\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0220 - val_mae: 0.1003\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0079 - mae: 0.0921 - val_loss: 0.0220 - val_mae: 0.1002\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0917 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0080 - mae: 0.0912 - val_loss: 0.0220 - val_mae: 0.0998\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0219 - val_mae: 0.0995\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0079 - mae: 0.0902 - val_loss: 0.0219 - val_mae: 0.0993\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0080 - mae: 0.0895 - val_loss: 0.0219 - val_mae: 0.0991\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0079 - mae: 0.0896 - val_loss: 0.0218 - val_mae: 0.0988\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0908 - val_loss: 0.0218 - val_mae: 0.0986\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0075 - mae: 0.0881 - val_loss: 0.0218 - val_mae: 0.0985\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0217 - val_mae: 0.0983\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0981\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0904 - val_loss: 0.0217 - val_mae: 0.0980\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0217 - val_mae: 0.0978\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0074 - mae: 0.0878 - val_loss: 0.0216 - val_mae: 0.0976\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0908 - val_loss: 0.0216 - val_mae: 0.0975\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0073 - mae: 0.0872 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0216 - val_mae: 0.0971\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0906 - val_loss: 0.0215 - val_mae: 0.0970\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0873 - val_loss: 0.0215 - val_mae: 0.0968\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0215 - val_mae: 0.0966\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0215 - val_mae: 0.0965\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0846 - val_loss: 0.0215 - val_mae: 0.0963\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0072 - mae: 0.0868 - val_loss: 0.0214 - val_mae: 0.0961\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0214 - val_mae: 0.0960\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0858 - val_loss: 0.0214 - val_mae: 0.0958\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0076 - mae: 0.0879 - val_loss: 0.0214 - val_mae: 0.0956\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0873 - val_loss: 0.0213 - val_mae: 0.0955\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0895 - val_loss: 0.0213 - val_mae: 0.0953\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0213 - val_mae: 0.0952\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0213 - val_mae: 0.0950\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0213 - val_mae: 0.0948\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.0947\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0075 - mae: 0.0893 - val_loss: 0.0212 - val_mae: 0.0945\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0212 - val_mae: 0.0943\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0842 - val_loss: 0.0212 - val_mae: 0.0942\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0211 - val_mae: 0.0940\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0848 - val_loss: 0.0211 - val_mae: 0.0939\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0211 - val_mae: 0.0937\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0073 - mae: 0.0868 - val_loss: 0.0211 - val_mae: 0.0935\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0069 - mae: 0.0819 - val_loss: 0.0211 - val_mae: 0.0934\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0210 - val_mae: 0.0932\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0864 - val_loss: 0.0210 - val_mae: 0.0931\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0210 - val_mae: 0.0929\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0210 - val_mae: 0.0928\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0209 - val_mae: 0.0926\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0070 - mae: 0.0844 - val_loss: 0.0209 - val_mae: 0.0925\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0069 - mae: 0.0845 - val_loss: 0.0209 - val_mae: 0.0923\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0073 - mae: 0.0846 - val_loss: 0.0209 - val_mae: 0.0922\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - mae: 0.0828 - val_loss: 0.0208 - val_mae: 0.0920\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0815 - val_loss: 0.0208 - val_mae: 0.0919\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0070 - mae: 0.0830 - val_loss: 0.0208 - val_mae: 0.0917\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0208 - val_mae: 0.0916\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0069 - mae: 0.0840 - val_loss: 0.0208 - val_mae: 0.0914\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0070 - mae: 0.0829 - val_loss: 0.0207 - val_mae: 0.0913\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0067 - mae: 0.0802 - val_loss: 0.0207 - val_mae: 0.0911\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0072 - mae: 0.0860 - val_loss: 0.0207 - val_mae: 0.0910\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0207 - val_mae: 0.0908\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0907\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0206 - val_mae: 0.0905\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0065 - mae: 0.0784 - val_loss: 0.0206 - val_mae: 0.0904\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0070 - mae: 0.0841 - val_loss: 0.0206 - val_mae: 0.0902\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0206 - val_mae: 0.0900\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0803 - val_loss: 0.0205 - val_mae: 0.0899\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0066 - mae: 0.0819 - val_loss: 0.0205 - val_mae: 0.0897\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0811 - val_loss: 0.0205 - val_mae: 0.0896\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0067 - mae: 0.0818 - val_loss: 0.0205 - val_mae: 0.0894\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0065 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.0892\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0070 - mae: 0.0849 - val_loss: 0.0204 - val_mae: 0.0891\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - mae: 0.0813 - val_loss: 0.0204 - val_mae: 0.0889\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0204 - val_mae: 0.0888\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0068 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0886\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0857 - val_loss: 0.0203 - val_mae: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:13,487] Trial 23 finished with value: 0.0884561687707901 and parameters: {'learning_rate': 2.7288091431829393e-05, 'weight_decay': 3.910451638426145e-07}. Best is trial 8 with value: 0.07435319572687149.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0093 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0095 - mae: 0.1073 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1051 - val_loss: 0.0246 - val_mae: 0.1188\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0094 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1187\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0092 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0092 - mae: 0.1043 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1183\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0093 - mae: 0.1049 - val_loss: 0.0245 - val_mae: 0.1181\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0244 - val_mae: 0.1180\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0089 - mae: 0.1031 - val_loss: 0.0244 - val_mae: 0.1178\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0244 - val_mae: 0.1177\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1175\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1173\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0243 - val_mae: 0.1172\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1025 - val_loss: 0.0243 - val_mae: 0.1170\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0243 - val_mae: 0.1169\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1022 - val_loss: 0.0243 - val_mae: 0.1167\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0242 - val_mae: 0.1166\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0242 - val_mae: 0.1164\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0242 - val_mae: 0.1163\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.1021 - val_loss: 0.0242 - val_mae: 0.1161\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0086 - mae: 0.1009 - val_loss: 0.0242 - val_mae: 0.1160\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0089 - mae: 0.1026 - val_loss: 0.0241 - val_mae: 0.1158\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0087 - mae: 0.1016 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0241 - val_mae: 0.1155\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0241 - val_mae: 0.1154\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1033 - val_loss: 0.0240 - val_mae: 0.1152\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0086 - mae: 0.0997 - val_loss: 0.0240 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0090 - mae: 0.1015 - val_loss: 0.0240 - val_mae: 0.1149\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0240 - val_mae: 0.1147\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0084 - mae: 0.0989 - val_loss: 0.0240 - val_mae: 0.1146\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1143\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0087 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1141\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0987 - val_loss: 0.0239 - val_mae: 0.1140\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0239 - val_mae: 0.1138\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0238 - val_mae: 0.1137\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0238 - val_mae: 0.1135\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0084 - mae: 0.0982 - val_loss: 0.0238 - val_mae: 0.1133\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0238 - val_mae: 0.1132\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0238 - val_mae: 0.1130\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0237 - val_mae: 0.1129\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0091 - mae: 0.1022 - val_loss: 0.0237 - val_mae: 0.1127\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0988 - val_loss: 0.0237 - val_mae: 0.1126\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - mae: 0.0977 - val_loss: 0.0237 - val_mae: 0.1124\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0237 - val_mae: 0.1123\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0084 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1121\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0085 - mae: 0.1007 - val_loss: 0.0236 - val_mae: 0.1120\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1118\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0972 - val_loss: 0.0235 - val_mae: 0.1115\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0086 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1113\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1112\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0084 - mae: 0.0987 - val_loss: 0.0235 - val_mae: 0.1110\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0984 - val_loss: 0.0235 - val_mae: 0.1109\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0081 - mae: 0.0969 - val_loss: 0.0235 - val_mae: 0.1107\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - mae: 0.0988 - val_loss: 0.0234 - val_mae: 0.1106\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1104\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1103\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0234 - val_mae: 0.1101\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0082 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1100\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0081 - mae: 0.0960 - val_loss: 0.0233 - val_mae: 0.1098\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0083 - mae: 0.0978 - val_loss: 0.0233 - val_mae: 0.1097\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0233 - val_mae: 0.1095\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - mae: 0.0971 - val_loss: 0.0233 - val_mae: 0.1094\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0233 - val_mae: 0.1092\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0232 - val_mae: 0.1091\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0083 - mae: 0.0964 - val_loss: 0.0232 - val_mae: 0.1089\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0084 - mae: 0.0974 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0232 - val_mae: 0.1086\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0232 - val_mae: 0.1085\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0079 - mae: 0.0947 - val_loss: 0.0231 - val_mae: 0.1083\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0942 - val_loss: 0.0231 - val_mae: 0.1082\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0078 - mae: 0.0929 - val_loss: 0.0231 - val_mae: 0.1080\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0079 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1078\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0231 - val_mae: 0.1077\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1075\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0951 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0230 - val_mae: 0.1072\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0230 - val_mae: 0.1071\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0230 - val_mae: 0.1069\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0943 - val_loss: 0.0230 - val_mae: 0.1067\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0080 - mae: 0.0948 - val_loss: 0.0229 - val_mae: 0.1066\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0229 - val_mae: 0.1064\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0229 - val_mae: 0.1063\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0077 - mae: 0.0927 - val_loss: 0.0229 - val_mae: 0.1060\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1058\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0078 - mae: 0.0934 - val_loss: 0.0228 - val_mae: 0.1056\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0080 - mae: 0.0954 - val_loss: 0.0228 - val_mae: 0.1055\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0077 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1053\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0076 - mae: 0.0912 - val_loss: 0.0228 - val_mae: 0.1052\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0080 - mae: 0.0945 - val_loss: 0.0227 - val_mae: 0.1050\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0227 - val_mae: 0.1048\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0078 - mae: 0.0919 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0227 - val_mae: 0.1043\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0077 - mae: 0.0922 - val_loss: 0.0226 - val_mae: 0.1042\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0080 - mae: 0.0935 - val_loss: 0.0226 - val_mae: 0.1040\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0076 - mae: 0.0917 - val_loss: 0.0226 - val_mae: 0.1039\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - mae: 0.0924 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0078 - mae: 0.0926 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.1032\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0225 - val_mae: 0.1029\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0075 - mae: 0.0911 - val_loss: 0.0225 - val_mae: 0.1028\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0077 - mae: 0.0928 - val_loss: 0.0224 - val_mae: 0.1026\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0224 - val_mae: 0.1023\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0075 - mae: 0.0903 - val_loss: 0.0224 - val_mae: 0.1022\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0881 - val_loss: 0.0224 - val_mae: 0.1020\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0076 - mae: 0.0895 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.1017\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0223 - val_mae: 0.1015\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0074 - mae: 0.0899 - val_loss: 0.0223 - val_mae: 0.1014\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0887 - val_loss: 0.0223 - val_mae: 0.1012\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0075 - mae: 0.0904 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - mae: 0.0893 - val_loss: 0.0222 - val_mae: 0.1009\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0222 - val_mae: 0.1006\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0222 - val_mae: 0.1004\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0881 - val_loss: 0.0221 - val_mae: 0.1003\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0221 - val_mae: 0.1001\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0221 - val_mae: 0.1000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0995\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0073 - mae: 0.0889 - val_loss: 0.0220 - val_mae: 0.0993\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0861 - val_loss: 0.0220 - val_mae: 0.0991\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0220 - val_mae: 0.0990\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - mae: 0.0878 - val_loss: 0.0220 - val_mae: 0.0988\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0072 - mae: 0.0874 - val_loss: 0.0219 - val_mae: 0.0987\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0071 - mae: 0.0860 - val_loss: 0.0219 - val_mae: 0.0985\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0072 - mae: 0.0871 - val_loss: 0.0219 - val_mae: 0.0983\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0069 - mae: 0.0858 - val_loss: 0.0219 - val_mae: 0.0980\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0218 - val_mae: 0.0978\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0070 - mae: 0.0865 - val_loss: 0.0218 - val_mae: 0.0977\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0847 - val_loss: 0.0218 - val_mae: 0.0975\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0071 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.0973\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - mae: 0.0850 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0065 - mae: 0.0826 - val_loss: 0.0217 - val_mae: 0.0970\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0072 - mae: 0.0859 - val_loss: 0.0217 - val_mae: 0.0968\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0217 - val_mae: 0.0967\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0071 - mae: 0.0866 - val_loss: 0.0217 - val_mae: 0.0965\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0068 - mae: 0.0843 - val_loss: 0.0216 - val_mae: 0.0963\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0069 - mae: 0.0875 - val_loss: 0.0216 - val_mae: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:33,217] Trial 24 finished with value: 0.09614313393831253 and parameters: {'learning_rate': 2.773439054168492e-05, 'weight_decay': 4.8348310433217596e-05}. Best is trial 8 with value: 0.07435319572687149.\n",
      "[I 2023-12-04 18:55:33,289] A new study created in RDB with name: no-name-cad62541-f293-4d49-bc69-9590d47d90bf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1091 - val_loss: 0.0193 - val_mae: 0.0869\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0067 - mae: 0.0846 - val_loss: 0.0180 - val_mae: 0.0862\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0745 - val_loss: 0.0176 - val_mae: 0.0828\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0880\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0665 - val_loss: 0.0170 - val_mae: 0.0861\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0171 - val_mae: 0.0851\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0628 - val_loss: 0.0173 - val_mae: 0.0835\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0858\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0573 - val_loss: 0.0168 - val_mae: 0.0894\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0166 - val_mae: 0.0919\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0666 - val_loss: 0.0167 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0623 - val_loss: 0.0168 - val_mae: 0.0878\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0867\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0633 - val_loss: 0.0165 - val_mae: 0.0851\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0627 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0162 - val_mae: 0.0862\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0860\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0159 - val_mae: 0.0871\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0159 - val_mae: 0.0850\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0165 - val_mae: 0.0791\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - mae: 0.0569 - val_loss: 0.0163 - val_mae: 0.0794\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0159 - val_mae: 0.0822\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0166 - val_mae: 0.0792\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0164 - val_mae: 0.0806\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0831\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0158 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0159 - val_mae: 0.0820\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0159 - val_mae: 0.0817\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - mae: 0.0525 - val_loss: 0.0157 - val_mae: 0.0814\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0153 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0164 - val_mae: 0.0797\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0159 - val_mae: 0.0789\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0535 - val_loss: 0.0139 - val_mae: 0.0846\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0156 - val_mae: 0.0784\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0493 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0563 - val_loss: 0.0162 - val_mae: 0.0801\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0546 - val_loss: 0.0141 - val_mae: 0.0861\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0028 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0837\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0161 - val_mae: 0.0834\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - mae: 0.0535 - val_loss: 0.0161 - val_mae: 0.0832\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0153 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0142 - val_mae: 0.0849\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0156 - val_mae: 0.0783\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - mae: 0.0527 - val_loss: 0.0161 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0557 - val_loss: 0.0162 - val_mae: 0.0779\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0513 - val_loss: 0.0156 - val_mae: 0.0791\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0148 - val_mae: 0.0831\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0148 - val_mae: 0.0839\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0149 - val_mae: 0.0836\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0150 - val_mae: 0.0826\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0151 - val_mae: 0.0814\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0157 - val_mae: 0.0795\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0156 - val_mae: 0.0804\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0494 - val_loss: 0.0148 - val_mae: 0.0837\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0494 - val_loss: 0.0140 - val_mae: 0.0875\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0553 - val_loss: 0.0153 - val_mae: 0.0817\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0160 - val_mae: 0.0814\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0471 - val_loss: 0.0152 - val_mae: 0.0832\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0144 - val_mae: 0.0860\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0452 - val_loss: 0.0140 - val_mae: 0.0874\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0139 - val_mae: 0.0853\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - mae: 0.0493 - val_loss: 0.0141 - val_mae: 0.0859\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0499 - val_loss: 0.0146 - val_mae: 0.0847\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - mae: 0.0469 - val_loss: 0.0155 - val_mae: 0.0822\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0500 - val_loss: 0.0153 - val_mae: 0.0843\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - mae: 0.0463 - val_loss: 0.0148 - val_mae: 0.0854\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - mae: 0.0466 - val_loss: 0.0147 - val_mae: 0.0838\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0142 - val_mae: 0.0885\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0147 - val_mae: 0.0878\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0148 - val_mae: 0.0870\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0150 - val_mae: 0.0844\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0151 - val_mae: 0.0826\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0151 - val_mae: 0.0876\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0021 - mae: 0.0473 - val_loss: 0.0148 - val_mae: 0.0920\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0481 - val_loss: 0.0150 - val_mae: 0.0909\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - mae: 0.0461 - val_loss: 0.0151 - val_mae: 0.0896\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0151 - val_mae: 0.0865\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0526 - val_loss: 0.0149 - val_mae: 0.0887\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0472 - val_loss: 0.0149 - val_mae: 0.0929\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0507 - val_loss: 0.0148 - val_mae: 0.0968\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0148 - val_mae: 0.0943\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0584 - val_loss: 0.0169 - val_mae: 0.0815\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0554 - val_loss: 0.0169 - val_mae: 0.0869\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0540 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0605 - val_loss: 0.0162 - val_mae: 0.0902\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0593 - val_loss: 0.0156 - val_mae: 0.0919\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0570 - val_loss: 0.0151 - val_mae: 0.0938\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0541 - val_loss: 0.0148 - val_mae: 0.0929\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - mae: 0.0520 - val_loss: 0.0147 - val_mae: 0.0883\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0151 - val_mae: 0.0836\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0153 - val_mae: 0.0832\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - mae: 0.0505 - val_loss: 0.0152 - val_mae: 0.0865\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0436 - val_loss: 0.0153 - val_mae: 0.0883\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0153 - val_mae: 0.0900\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0152 - val_mae: 0.0910\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0149 - val_mae: 0.0908\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0477 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0450 - val_loss: 0.0147 - val_mae: 0.0851\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0023 - mae: 0.0478 - val_loss: 0.0143 - val_mae: 0.0856\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0150 - val_mae: 0.0801\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0509 - val_loss: 0.0151 - val_mae: 0.0786\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0489 - val_loss: 0.0145 - val_mae: 0.0824\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.0139 - val_mae: 0.0905\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0139 - val_mae: 0.0938\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0874\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0444 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0522 - val_loss: 0.0163 - val_mae: 0.0859\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0020 - mae: 0.0458 - val_loss: 0.0156 - val_mae: 0.0868\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0147 - val_mae: 0.0893\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0024 - mae: 0.0485 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0546 - val_loss: 0.0141 - val_mae: 0.0922\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0452 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0151 - val_mae: 0.0836\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0156 - val_mae: 0.0829\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - mae: 0.0403 - val_loss: 0.0157 - val_mae: 0.0858\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0022 - mae: 0.0478 - val_loss: 0.0155 - val_mae: 0.0897\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0461 - val_loss: 0.0154 - val_mae: 0.0911\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0021 - mae: 0.0488 - val_loss: 0.0153 - val_mae: 0.0901\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0475 - val_loss: 0.0152 - val_mae: 0.0877\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0149 - val_mae: 0.0849\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0144 - val_mae: 0.0843\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0446 - val_loss: 0.0145 - val_mae: 0.0816\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0020 - mae: 0.0449 - val_loss: 0.0149 - val_mae: 0.0807\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.0151 - val_mae: 0.0841\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0389 - val_loss: 0.0151 - val_mae: 0.0866\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0150 - val_mae: 0.0899\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0148 - val_mae: 0.0920\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0474 - val_loss: 0.0149 - val_mae: 0.0897\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0460 - val_loss: 0.0150 - val_mae: 0.0872\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0152 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0408 - val_loss: 0.0150 - val_mae: 0.0858\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0391 - val_loss: 0.0148 - val_mae: 0.0878\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0425 - val_loss: 0.0147 - val_mae: 0.0883\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0395 - val_loss: 0.0148 - val_mae: 0.0891\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0437 - val_loss: 0.0147 - val_mae: 0.0898\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0020 - mae: 0.0439 - val_loss: 0.0145 - val_mae: 0.0917\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mae: 0.0375 - val_loss: 0.0144 - val_mae: 0.0925\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0393 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0023 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - mae: 0.0412 - val_loss: 0.0146 - val_mae: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:55:48,577] Trial 0 finished with value: 0.09042628854513168 and parameters: {'learning_rate': 0.005428992715125547, 'weight_decay': 1.1721142106834856e-08}. Best is trial 0 with value: 0.09042628854513168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0176 - val_mae: 0.0948\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0909 - val_loss: 0.0192 - val_mae: 0.0831\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0693 - val_loss: 0.0184 - val_mae: 0.0836\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0174 - val_mae: 0.0896\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0695 - val_loss: 0.0168 - val_mae: 0.0934\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0693 - val_loss: 0.0167 - val_mae: 0.0867\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.0904\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0636 - val_loss: 0.0166 - val_mae: 0.0910\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0674 - val_loss: 0.0166 - val_mae: 0.0902\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0890\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0890\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0886\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0622 - val_loss: 0.0169 - val_mae: 0.0865\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0625 - val_loss: 0.0168 - val_mae: 0.0827\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0566 - val_loss: 0.0167 - val_mae: 0.0818\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0886\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0570 - val_loss: 0.0170 - val_mae: 0.0833\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0885\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0585 - val_loss: 0.0164 - val_mae: 0.0840\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0162 - val_mae: 0.0840\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0553 - val_loss: 0.0161 - val_mae: 0.0853\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0160 - val_mae: 0.0845\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0798\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0556 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0561 - val_loss: 0.0155 - val_mae: 0.0823\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0155 - val_mae: 0.0815\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0790\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0563 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0562 - val_loss: 0.0158 - val_mae: 0.0784\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0533 - val_loss: 0.0149 - val_mae: 0.0833\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0170 - val_mae: 0.0782\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0027 - mae: 0.0510 - val_loss: 0.0174 - val_mae: 0.0792\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0173 - val_mae: 0.0803\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0170 - val_mae: 0.0852\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0169 - val_mae: 0.0877\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0168 - val_mae: 0.0897\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0635 - val_loss: 0.0167 - val_mae: 0.0907\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0167 - val_mae: 0.0909\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0901\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0630 - val_loss: 0.0167 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0590 - val_loss: 0.0170 - val_mae: 0.0828\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0822\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0170 - val_mae: 0.0829\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0839\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0548 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0855\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0031 - mae: 0.0564 - val_loss: 0.0164 - val_mae: 0.0861\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0606 - val_loss: 0.0163 - val_mae: 0.0868\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0161 - val_mae: 0.0867\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0034 - mae: 0.0617 - val_loss: 0.0162 - val_mae: 0.0836\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0807\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0517 - val_loss: 0.0146 - val_mae: 0.0901\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0660 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0507 - val_loss: 0.0178 - val_mae: 0.0786\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0570 - val_loss: 0.0178 - val_mae: 0.0794\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - mae: 0.0562 - val_loss: 0.0175 - val_mae: 0.0808\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0036 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.0832\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0170 - val_mae: 0.0870\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0906\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0935\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0675 - val_loss: 0.0167 - val_mae: 0.0926\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0659 - val_loss: 0.0166 - val_mae: 0.0889\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0641 - val_loss: 0.0166 - val_mae: 0.0849\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0579 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0167 - val_mae: 0.0809\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0168 - val_mae: 0.0806\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0567 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0542 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0878\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0608 - val_loss: 0.0168 - val_mae: 0.0871\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0168 - val_mae: 0.0856\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0825\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0826\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0830\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0169 - val_mae: 0.0838\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0169 - val_mae: 0.0847\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0857\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0867\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0169 - val_mae: 0.0872\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0031 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0869\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0859\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0844\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0830\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0823\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0169 - val_mae: 0.0824\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0565 - val_loss: 0.0169 - val_mae: 0.0837\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0169 - val_mae: 0.0839\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0556 - val_loss: 0.0169 - val_mae: 0.0846\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0169 - val_mae: 0.0843\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0551 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0168 - val_mae: 0.0831\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0533 - val_loss: 0.0169 - val_mae: 0.0833\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0562 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0539 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0859\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0571 - val_loss: 0.0167 - val_mae: 0.0832\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - mae: 0.0573 - val_loss: 0.0172 - val_mae: 0.0805\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0173 - val_mae: 0.0801\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0172 - val_mae: 0.0800\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0538 - val_loss: 0.0170 - val_mae: 0.0807\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0163 - val_mae: 0.0828\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0583 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0832\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0028 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0827\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0591 - val_loss: 0.0170 - val_mae: 0.0823\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0576 - val_loss: 0.0169 - val_mae: 0.0826\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0168 - val_mae: 0.0833\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0850\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0566 - val_loss: 0.0165 - val_mae: 0.0860\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0882\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0027 - mae: 0.0543 - val_loss: 0.0168 - val_mae: 0.0816\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0170 - val_mae: 0.0804\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0033 - mae: 0.0557 - val_loss: 0.0169 - val_mae: 0.0803\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0526 - val_loss: 0.0166 - val_mae: 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:04,155] Trial 1 finished with value: 0.08078546077013016 and parameters: {'learning_rate': 0.007265683364565975, 'weight_decay': 0.0004977395872680223}. Best is trial 1 with value: 0.08078546077013016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0249 - val_mae: 0.1229\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0096 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1224\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1077 - val_loss: 0.0247 - val_mae: 0.1219\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1036 - val_loss: 0.0247 - val_mae: 0.1214\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1208\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0245 - val_mae: 0.1203\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1040 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1038 - val_loss: 0.0244 - val_mae: 0.1192\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0243 - val_mae: 0.1187\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0242 - val_mae: 0.1181\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1025 - val_loss: 0.0241 - val_mae: 0.1176\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0241 - val_mae: 0.1171\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1166\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0239 - val_mae: 0.1161\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1017 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0975 - val_loss: 0.0238 - val_mae: 0.1150\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1145\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0981 - val_loss: 0.0236 - val_mae: 0.1135\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1130\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - mae: 0.0954 - val_loss: 0.0234 - val_mae: 0.1120\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1114\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0232 - val_mae: 0.1109\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0915 - val_loss: 0.0231 - val_mae: 0.1099\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0930 - val_loss: 0.0230 - val_mae: 0.1093\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0920 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0915 - val_loss: 0.0229 - val_mae: 0.1082\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0228 - val_mae: 0.1076\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0907 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0227 - val_mae: 0.1064\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0884 - val_loss: 0.0226 - val_mae: 0.1058\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0225 - val_mae: 0.1046\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0073 - mae: 0.0874 - val_loss: 0.0224 - val_mae: 0.1040\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0224 - val_mae: 0.1033\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0071 - mae: 0.0855 - val_loss: 0.0223 - val_mae: 0.1027\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0073 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.1020\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0882 - val_loss: 0.0221 - val_mae: 0.1014\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0875 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0846 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0219 - val_mae: 0.0994\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0219 - val_mae: 0.0987\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0872 - val_loss: 0.0218 - val_mae: 0.0980\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0843 - val_loss: 0.0217 - val_mae: 0.0972\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0069 - mae: 0.0832 - val_loss: 0.0216 - val_mae: 0.0965\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0068 - mae: 0.0824 - val_loss: 0.0216 - val_mae: 0.0958\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0843 - val_loss: 0.0215 - val_mae: 0.0952\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0804 - val_loss: 0.0214 - val_mae: 0.0945\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0067 - mae: 0.0785 - val_loss: 0.0214 - val_mae: 0.0939\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0811 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0212 - val_mae: 0.0927\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0064 - mae: 0.0810 - val_loss: 0.0211 - val_mae: 0.0921\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0064 - mae: 0.0783 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0845 - val_loss: 0.0210 - val_mae: 0.0909\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0793 - val_loss: 0.0209 - val_mae: 0.0903\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0208 - val_mae: 0.0897\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0208 - val_mae: 0.0892\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0207 - val_mae: 0.0886\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0744 - val_loss: 0.0206 - val_mae: 0.0881\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0782 - val_loss: 0.0206 - val_mae: 0.0876\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.0871\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.0866\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0203 - val_mae: 0.0862\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0203 - val_mae: 0.0857\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0767 - val_loss: 0.0202 - val_mae: 0.0853\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0849\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0062 - mae: 0.0764 - val_loss: 0.0201 - val_mae: 0.0845\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0055 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0841\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0724 - val_loss: 0.0200 - val_mae: 0.0837\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0741 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0760 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0766 - val_loss: 0.0198 - val_mae: 0.0827\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0694 - val_loss: 0.0196 - val_mae: 0.0820\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0698 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - mae: 0.0767 - val_loss: 0.0195 - val_mae: 0.0814\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0195 - val_mae: 0.0812\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0770 - val_loss: 0.0194 - val_mae: 0.0809\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0050 - mae: 0.0729 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0193 - val_mae: 0.0805\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0666 - val_loss: 0.0192 - val_mae: 0.0802\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0762 - val_loss: 0.0191 - val_mae: 0.0800\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0190 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0056 - mae: 0.0734 - val_loss: 0.0190 - val_mae: 0.0796\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0189 - val_mae: 0.0794\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0799 - val_loss: 0.0189 - val_mae: 0.0792\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0055 - mae: 0.0708 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0188 - val_mae: 0.0789\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0188 - val_mae: 0.0788\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0686 - val_loss: 0.0188 - val_mae: 0.0786\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0671 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0049 - mae: 0.0678 - val_loss: 0.0187 - val_mae: 0.0784\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0186 - val_mae: 0.0783\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0692 - val_loss: 0.0186 - val_mae: 0.0781\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0713 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0721 - val_loss: 0.0185 - val_mae: 0.0776\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0683 - val_loss: 0.0184 - val_mae: 0.0774\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0690 - val_loss: 0.0184 - val_mae: 0.0773\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0728 - val_loss: 0.0184 - val_mae: 0.0772\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0721 - val_loss: 0.0183 - val_mae: 0.0771\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0644 - val_loss: 0.0183 - val_mae: 0.0770\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0694 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0747 - val_loss: 0.0183 - val_mae: 0.0769\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0690 - val_loss: 0.0183 - val_mae: 0.0768\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0182 - val_mae: 0.0767\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0045 - mae: 0.0647 - val_loss: 0.0182 - val_mae: 0.0766\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0182 - val_mae: 0.0765\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0764\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0728 - val_loss: 0.0182 - val_mae: 0.0763\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0762\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0642 - val_loss: 0.0182 - val_mae: 0.0762\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0182 - val_mae: 0.0761\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0181 - val_mae: 0.0760\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0181 - val_mae: 0.0758\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0704 - val_loss: 0.0181 - val_mae: 0.0757\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0659 - val_loss: 0.0181 - val_mae: 0.0756\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0657 - val_loss: 0.0181 - val_mae: 0.0755\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0711 - val_loss: 0.0181 - val_mae: 0.0755\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0754\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0181 - val_mae: 0.0753\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0181 - val_mae: 0.0753\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0695 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0676 - val_loss: 0.0180 - val_mae: 0.0752\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0180 - val_mae: 0.0751\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0670 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0619 - val_loss: 0.0180 - val_mae: 0.0750\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - mae: 0.0684 - val_loss: 0.0180 - val_mae: 0.0749\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0179 - val_mae: 0.0749\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0749\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0042 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0179 - val_mae: 0.0750\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0047 - mae: 0.0680 - val_loss: 0.0178 - val_mae: 0.0750\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0650 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0629 - val_loss: 0.0178 - val_mae: 0.0751\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0568 - val_loss: 0.0177 - val_mae: 0.0751\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0648 - val_loss: 0.0177 - val_mae: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:19,382] Trial 2 finished with value: 0.07521326839923859 and parameters: {'learning_rate': 5.6552381262809115e-05, 'weight_decay': 1.0101788305887493e-08}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0105 - mae: 0.1129 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0104 - mae: 0.1124 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1071 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0107 - mae: 0.1131 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0111 - mae: 0.1162 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1150 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0106 - mae: 0.1135 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1162 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1166 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1105 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0103 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1091 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0106 - mae: 0.1133 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1114 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1080 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0105 - mae: 0.1134 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1135 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1119 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0101 - mae: 0.1109 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1088 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0104 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1117 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1208\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1029 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1098 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1110 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0096 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0105 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1086 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1107 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1084 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0098 - mae: 0.1065 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0095 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1149 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1109 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0102 - mae: 0.1105 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1083 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1202\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0106 - mae: 0.1156 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0103 - mae: 0.1094 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0104 - mae: 0.1103 - val_loss: 0.0247 - val_mae: 0.1201\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0103 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1200\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0104 - mae: 0.1121 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0099 - mae: 0.1075 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - mae: 0.1105 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1104 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0108 - mae: 0.1142 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - mae: 0.1050 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1195\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1054 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1107 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1194\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0106 - mae: 0.1149 - val_loss: 0.0246 - val_mae: 0.1193\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1047 - val_loss: 0.0246 - val_mae: 0.1192\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0107 - mae: 0.1123 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0246 - val_mae: 0.1191\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1113 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1066 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1087 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0246 - val_mae: 0.1190\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0102 - mae: 0.1097 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1189\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1098 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0245 - val_mae: 0.1188\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1092 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1046 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1029 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1099 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1096 - val_loss: 0.0245 - val_mae: 0.1187\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1186\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1061 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0100 - mae: 0.1090 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1057 - val_loss: 0.0245 - val_mae: 0.1185\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0245 - val_mae: 0.1184\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1056 - val_loss: 0.0245 - val_mae: 0.1184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:34,824] Trial 3 finished with value: 0.11841195076704025 and parameters: {'learning_rate': 1.8726726900712746e-06, 'weight_decay': 3.794393529925343e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1157\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0239 - val_mae: 0.1144\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0237 - val_mae: 0.1132\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0233 - val_mae: 0.1112\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0232 - val_mae: 0.1103\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0970 - val_loss: 0.0230 - val_mae: 0.1095\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0229 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0227 - val_mae: 0.1078\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0225 - val_mae: 0.1063\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0941 - val_loss: 0.0224 - val_mae: 0.1056\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0084 - mae: 0.0936 - val_loss: 0.0222 - val_mae: 0.1050\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0221 - val_mae: 0.1043\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0220 - val_mae: 0.1036\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0219 - val_mae: 0.1030\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0218 - val_mae: 0.1023\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0882 - val_loss: 0.0217 - val_mae: 0.1017\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.1010\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0859 - val_loss: 0.0215 - val_mae: 0.1003\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0214 - val_mae: 0.0997\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0866 - val_loss: 0.0213 - val_mae: 0.0990\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0212 - val_mae: 0.0983\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0976\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0827 - val_loss: 0.0210 - val_mae: 0.0969\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0209 - val_mae: 0.0962\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0819 - val_loss: 0.0208 - val_mae: 0.0955\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0825 - val_loss: 0.0207 - val_mae: 0.0948\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0814 - val_loss: 0.0206 - val_mae: 0.0941\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0205 - val_mae: 0.0935\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0064 - mae: 0.0772 - val_loss: 0.0204 - val_mae: 0.0929\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0203 - val_mae: 0.0923\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0066 - mae: 0.0814 - val_loss: 0.0202 - val_mae: 0.0917\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0201 - val_mae: 0.0911\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0059 - mae: 0.0745 - val_loss: 0.0200 - val_mae: 0.0906\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0199 - val_mae: 0.0900\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0759 - val_loss: 0.0198 - val_mae: 0.0895\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0197 - val_mae: 0.0889\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0197 - val_mae: 0.0884\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0788 - val_loss: 0.0196 - val_mae: 0.0878\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0059 - mae: 0.0777 - val_loss: 0.0195 - val_mae: 0.0873\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - mae: 0.0747 - val_loss: 0.0194 - val_mae: 0.0867\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0727 - val_loss: 0.0193 - val_mae: 0.0862\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0857\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0743 - val_loss: 0.0192 - val_mae: 0.0852\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0708 - val_loss: 0.0191 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0723 - val_loss: 0.0190 - val_mae: 0.0843\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0839\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0720 - val_loss: 0.0189 - val_mae: 0.0835\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0189 - val_mae: 0.0831\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0712 - val_loss: 0.0188 - val_mae: 0.0827\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0051 - mae: 0.0718 - val_loss: 0.0188 - val_mae: 0.0822\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0188 - val_mae: 0.0818\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0814\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0718 - val_loss: 0.0187 - val_mae: 0.0810\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0186 - val_mae: 0.0806\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0050 - mae: 0.0688 - val_loss: 0.0186 - val_mae: 0.0802\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0185 - val_mae: 0.0799\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0055 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0796\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0185 - val_mae: 0.0793\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0694 - val_loss: 0.0184 - val_mae: 0.0790\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0684 - val_loss: 0.0183 - val_mae: 0.0788\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0733 - val_loss: 0.0183 - val_mae: 0.0786\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0784\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0728 - val_loss: 0.0181 - val_mae: 0.0781\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0643 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0180 - val_mae: 0.0779\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0682 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0643 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0639 - val_loss: 0.0179 - val_mae: 0.0769\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0684 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0657 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0658 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0623 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0656 - val_loss: 0.0177 - val_mae: 0.0771\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0668 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0652 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0045 - mae: 0.0670 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0717 - val_loss: 0.0177 - val_mae: 0.0770\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0618 - val_loss: 0.0177 - val_mae: 0.0769\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0644 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0614 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0600 - val_loss: 0.0176 - val_mae: 0.0769\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0040 - mae: 0.0603 - val_loss: 0.0176 - val_mae: 0.0770\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0573 - val_loss: 0.0175 - val_mae: 0.0771\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0175 - val_mae: 0.0772\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0656 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0174 - val_mae: 0.0773\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0597 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0612 - val_loss: 0.0174 - val_mae: 0.0772\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0631 - val_loss: 0.0173 - val_mae: 0.0772\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0046 - mae: 0.0639 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0773\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0615 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0637 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0577 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0620 - val_loss: 0.0173 - val_mae: 0.0776\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0629 - val_loss: 0.0173 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0173 - val_mae: 0.0778\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0779\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0172 - val_mae: 0.0779\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0779\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0583 - val_loss: 0.0173 - val_mae: 0.0780\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0780\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0036 - mae: 0.0612 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0172 - val_mae: 0.0781\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0570 - val_loss: 0.0172 - val_mae: 0.0782\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0599 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0171 - val_mae: 0.0786\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0610 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0170 - val_mae: 0.0789\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0790\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0791\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - mae: 0.0580 - val_loss: 0.0169 - val_mae: 0.0793\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0547 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0797\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0796\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0169 - val_mae: 0.0794\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0169 - val_mae: 0.0790\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0629 - val_loss: 0.0170 - val_mae: 0.0787\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0557 - val_loss: 0.0170 - val_mae: 0.0786\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0169 - val_mae: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:56:49,950] Trial 4 finished with value: 0.07861979305744171 and parameters: {'learning_rate': 0.00011812135409253702, 'weight_decay': 3.7502188217098465e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1108 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1202\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1079 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0100 - mae: 0.1109 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1121 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1059 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1054 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0102 - mae: 0.1102 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0101 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1076 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1081 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1062 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0097 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1200\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0096 - mae: 0.1084 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1074 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1067 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1093 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1055 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1080 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1083 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1053 - val_loss: 0.0244 - val_mae: 0.1199\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0103 - mae: 0.1101 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1092 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1089 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1060 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1198\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1058 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1069 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1057 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0093 - mae: 0.1061 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0098 - mae: 0.1088 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1085 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1042 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1048 - val_loss: 0.0244 - val_mae: 0.1197\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1092 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1085 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1099 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1045 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1064 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1041 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0102 - mae: 0.1101 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1101 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1046 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1048 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1070 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1068 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1196\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0099 - mae: 0.1082 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1067 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0099 - mae: 0.1084 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1044 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1068 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1111 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1088 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1113 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0243 - val_mae: 0.1195\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1094 - val_loss: 0.0243 - val_mae: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:05,334] Trial 5 finished with value: 0.1194608062505722 and parameters: {'learning_rate': 4.1754399140450693e-07, 'weight_decay': 1.9546629942638687e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0102 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1167\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0241 - val_mae: 0.1126\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0987 - val_loss: 0.0236 - val_mae: 0.1087\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0954 - val_loss: 0.0232 - val_mae: 0.1054\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0224 - val_mae: 0.0997\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0877 - val_loss: 0.0221 - val_mae: 0.0966\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0068 - mae: 0.0833 - val_loss: 0.0217 - val_mae: 0.0943\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0214 - val_mae: 0.0923\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0819 - val_loss: 0.0211 - val_mae: 0.0905\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0207 - val_mae: 0.0888\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0205 - val_mae: 0.0873\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0751 - val_loss: 0.0202 - val_mae: 0.0862\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0199 - val_mae: 0.0850\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0060 - mae: 0.0760 - val_loss: 0.0194 - val_mae: 0.0834\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0046 - mae: 0.0709 - val_loss: 0.0192 - val_mae: 0.0829\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0190 - val_mae: 0.0824\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0050 - mae: 0.0720 - val_loss: 0.0187 - val_mae: 0.0821\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0049 - mae: 0.0721 - val_loss: 0.0186 - val_mae: 0.0817\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0661 - val_loss: 0.0184 - val_mae: 0.0812\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0660 - val_loss: 0.0182 - val_mae: 0.0807\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0181 - val_mae: 0.0803\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0674 - val_loss: 0.0179 - val_mae: 0.0804\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0608 - val_loss: 0.0178 - val_mae: 0.0806\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0658 - val_loss: 0.0176 - val_mae: 0.0808\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0600 - val_loss: 0.0175 - val_mae: 0.0811\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0602 - val_loss: 0.0173 - val_mae: 0.0817\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0632 - val_loss: 0.0172 - val_mae: 0.0823\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0821\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0600 - val_loss: 0.0170 - val_mae: 0.0818\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0170 - val_mae: 0.0813\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0811\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0168 - val_mae: 0.0811\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0814\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0166 - val_mae: 0.0814\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0166 - val_mae: 0.0818\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0585 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0164 - val_mae: 0.0831\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0163 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0163 - val_mae: 0.0840\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - mae: 0.0559 - val_loss: 0.0162 - val_mae: 0.0846\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0563 - val_loss: 0.0161 - val_mae: 0.0850\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0161 - val_mae: 0.0845\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0160 - val_mae: 0.0831\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0817\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0601 - val_loss: 0.0161 - val_mae: 0.0804\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0561 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0816\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0158 - val_mae: 0.0832\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0575 - val_loss: 0.0157 - val_mae: 0.0863\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0874\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0569 - val_loss: 0.0157 - val_mae: 0.0864\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - mae: 0.0538 - val_loss: 0.0156 - val_mae: 0.0860\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0569 - val_loss: 0.0156 - val_mae: 0.0858\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0558 - val_loss: 0.0156 - val_mae: 0.0854\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0512 - val_loss: 0.0156 - val_mae: 0.0864\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0563 - val_loss: 0.0155 - val_mae: 0.0870\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0538 - val_loss: 0.0155 - val_mae: 0.0880\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0546 - val_loss: 0.0154 - val_mae: 0.0889\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0154 - val_mae: 0.0893\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0544 - val_loss: 0.0153 - val_mae: 0.0898\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0557 - val_loss: 0.0153 - val_mae: 0.0894\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0153 - val_mae: 0.0887\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0529 - val_loss: 0.0152 - val_mae: 0.0894\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - mae: 0.0526 - val_loss: 0.0152 - val_mae: 0.0892\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0553 - val_loss: 0.0152 - val_mae: 0.0893\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0152 - val_mae: 0.0903\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0152 - val_mae: 0.0904\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0152 - val_mae: 0.0907\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - mae: 0.0506 - val_loss: 0.0152 - val_mae: 0.0926\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0151 - val_mae: 0.0946\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0532 - val_loss: 0.0151 - val_mae: 0.0972\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0151 - val_mae: 0.0980\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0546 - val_loss: 0.0150 - val_mae: 0.0952\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0025 - mae: 0.0508 - val_loss: 0.0150 - val_mae: 0.0941\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0515 - val_loss: 0.0149 - val_mae: 0.0939\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0487 - val_loss: 0.0149 - val_mae: 0.0955\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0149 - val_mae: 0.1000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0511 - val_loss: 0.0151 - val_mae: 0.1056\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - mae: 0.0522 - val_loss: 0.0150 - val_mae: 0.1061\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0148 - val_mae: 0.1030\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0146 - val_mae: 0.0932\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0483 - val_loss: 0.0145 - val_mae: 0.0877\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0462 - val_loss: 0.0145 - val_mae: 0.0854\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0484 - val_loss: 0.0145 - val_mae: 0.0859\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0025 - mae: 0.0489 - val_loss: 0.0144 - val_mae: 0.0892\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0947\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0520 - val_loss: 0.0145 - val_mae: 0.1014\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0022 - mae: 0.0490 - val_loss: 0.0148 - val_mae: 0.1075\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0146 - val_mae: 0.1031\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0026 - mae: 0.0545 - val_loss: 0.0145 - val_mae: 0.0975\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - mae: 0.0516 - val_loss: 0.0144 - val_mae: 0.0935\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0024 - mae: 0.0488 - val_loss: 0.0144 - val_mae: 0.0912\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0481 - val_loss: 0.0144 - val_mae: 0.0907\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0488 - val_loss: 0.0144 - val_mae: 0.0922\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0144 - val_mae: 0.0949\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0145 - val_mae: 0.0982\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0146 - val_mae: 0.1014\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0147 - val_mae: 0.1046\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0147 - val_mae: 0.1054\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0025 - mae: 0.0501 - val_loss: 0.0148 - val_mae: 0.1067\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0147 - val_mae: 0.1063\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0534 - val_loss: 0.0148 - val_mae: 0.1067\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0020 - mae: 0.0501 - val_loss: 0.0145 - val_mae: 0.1020\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0143 - val_mae: 0.0961\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0143 - val_mae: 0.0927\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0492 - val_loss: 0.0143 - val_mae: 0.0937\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.0143 - val_mae: 0.0974\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0145 - val_mae: 0.1009\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0482 - val_loss: 0.0146 - val_mae: 0.1049\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0471 - val_loss: 0.0147 - val_mae: 0.1065\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0531 - val_loss: 0.0144 - val_mae: 0.0990\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0471 - val_loss: 0.0144 - val_mae: 0.0916\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0145 - val_mae: 0.0877\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0024 - mae: 0.0486 - val_loss: 0.0145 - val_mae: 0.0873\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0495 - val_loss: 0.0145 - val_mae: 0.0893\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0463 - val_loss: 0.0145 - val_mae: 0.0931\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0496 - val_loss: 0.0146 - val_mae: 0.0979\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0466 - val_loss: 0.0148 - val_mae: 0.1039\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0488 - val_loss: 0.0150 - val_mae: 0.1078\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0149 - val_mae: 0.1076\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0502 - val_loss: 0.0147 - val_mae: 0.1049\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0144 - val_mae: 0.0988\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0143 - val_mae: 0.0939\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0505 - val_loss: 0.0142 - val_mae: 0.0909\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0426 - val_loss: 0.0142 - val_mae: 0.0895\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - mae: 0.0500 - val_loss: 0.0142 - val_mae: 0.0897\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0143 - val_mae: 0.0922\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0961\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.1001\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - mae: 0.0466 - val_loss: 0.0146 - val_mae: 0.1028\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0148 - val_mae: 0.1047\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0018 - mae: 0.0452 - val_loss: 0.0147 - val_mae: 0.1031\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0479 - val_loss: 0.0146 - val_mae: 0.1000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0145 - val_mae: 0.0969\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0144 - val_mae: 0.0943\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0474 - val_loss: 0.0144 - val_mae: 0.0936\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0456 - val_loss: 0.0144 - val_mae: 0.0954\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0503 - val_loss: 0.0145 - val_mae: 0.0991\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0146 - val_mae: 0.1026\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0424 - val_loss: 0.0146 - val_mae: 0.1025\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0018 - mae: 0.0455 - val_loss: 0.0146 - val_mae: 0.1027\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0145 - val_mae: 0.1024\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0499 - val_loss: 0.0143 - val_mae: 0.0954\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0142 - val_mae: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:21,449] Trial 6 finished with value: 0.09161888808012009 and parameters: {'learning_rate': 0.0005070288039802264, 'weight_decay': 2.6845325685304623e-08}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0099 - mae: 0.1048 - val_loss: 0.0252 - val_mae: 0.1181\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0252 - val_mae: 0.1180\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0099 - mae: 0.1048 - val_loss: 0.0251 - val_mae: 0.1179\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0251 - val_mae: 0.1178\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0099 - mae: 0.1069 - val_loss: 0.0251 - val_mae: 0.1177\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1065 - val_loss: 0.0251 - val_mae: 0.1176\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1011 - val_loss: 0.0251 - val_mae: 0.1175\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1065 - val_loss: 0.0250 - val_mae: 0.1174\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0250 - val_mae: 0.1173\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1059 - val_loss: 0.0250 - val_mae: 0.1172\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1019 - val_loss: 0.0250 - val_mae: 0.1171\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1022 - val_loss: 0.0250 - val_mae: 0.1170\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1017 - val_loss: 0.0250 - val_mae: 0.1169\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1037 - val_loss: 0.0249 - val_mae: 0.1168\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1060 - val_loss: 0.0249 - val_mae: 0.1167\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1039 - val_loss: 0.0249 - val_mae: 0.1165\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1009 - val_loss: 0.0249 - val_mae: 0.1164\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1009 - val_loss: 0.0249 - val_mae: 0.1163\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1162\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1062 - val_loss: 0.0248 - val_mae: 0.1161\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1160\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0101 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1159\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1044 - val_loss: 0.0248 - val_mae: 0.1158\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1032 - val_loss: 0.0248 - val_mae: 0.1157\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0247 - val_mae: 0.1156\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1033 - val_loss: 0.0247 - val_mae: 0.1155\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1003 - val_loss: 0.0247 - val_mae: 0.1154\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1059 - val_loss: 0.0247 - val_mae: 0.1153\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1152\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1038 - val_loss: 0.0247 - val_mae: 0.1151\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0106 - mae: 0.1098 - val_loss: 0.0247 - val_mae: 0.1150\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0094 - mae: 0.1024 - val_loss: 0.0246 - val_mae: 0.1149\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0246 - val_mae: 0.1148\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0101 - mae: 0.1067 - val_loss: 0.0246 - val_mae: 0.1147\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0091 - mae: 0.1007 - val_loss: 0.0246 - val_mae: 0.1146\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0093 - mae: 0.1006 - val_loss: 0.0246 - val_mae: 0.1145\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1023 - val_loss: 0.0246 - val_mae: 0.1144\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0245 - val_mae: 0.1143\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1045 - val_loss: 0.0245 - val_mae: 0.1142\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1040 - val_loss: 0.0245 - val_mae: 0.1141\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1140\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0096 - mae: 0.1032 - val_loss: 0.0245 - val_mae: 0.1139\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1019 - val_loss: 0.0245 - val_mae: 0.1139\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1042 - val_loss: 0.0245 - val_mae: 0.1138\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0989 - val_loss: 0.0244 - val_mae: 0.1137\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1136\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0096 - mae: 0.1036 - val_loss: 0.0244 - val_mae: 0.1135\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0093 - mae: 0.1013 - val_loss: 0.0244 - val_mae: 0.1134\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.0995 - val_loss: 0.0244 - val_mae: 0.1133\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.0990 - val_loss: 0.0244 - val_mae: 0.1132\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0244 - val_mae: 0.1131\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0098 - mae: 0.1054 - val_loss: 0.0243 - val_mae: 0.1130\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1043 - val_loss: 0.0243 - val_mae: 0.1129\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1008 - val_loss: 0.0243 - val_mae: 0.1128\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1127\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1020 - val_loss: 0.0243 - val_mae: 0.1126\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1000 - val_loss: 0.0243 - val_mae: 0.1125\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1001 - val_loss: 0.0243 - val_mae: 0.1125\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.0992 - val_loss: 0.0242 - val_mae: 0.1124\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1026 - val_loss: 0.0242 - val_mae: 0.1123\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1020 - val_loss: 0.0242 - val_mae: 0.1122\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1007 - val_loss: 0.0242 - val_mae: 0.1121\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.0976 - val_loss: 0.0242 - val_mae: 0.1120\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1013 - val_loss: 0.0242 - val_mae: 0.1119\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1034 - val_loss: 0.0242 - val_mae: 0.1118\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.0998 - val_loss: 0.0241 - val_mae: 0.1117\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.0996 - val_loss: 0.0241 - val_mae: 0.1117\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.0989 - val_loss: 0.0241 - val_mae: 0.1116\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1004 - val_loss: 0.0241 - val_mae: 0.1115\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.0994 - val_loss: 0.0241 - val_mae: 0.1114\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0090 - mae: 0.0983 - val_loss: 0.0241 - val_mae: 0.1113\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.0994 - val_loss: 0.0241 - val_mae: 0.1112\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0241 - val_mae: 0.1111\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1111\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1110\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.0991 - val_loss: 0.0240 - val_mae: 0.1109\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0945 - val_loss: 0.0240 - val_mae: 0.1108\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1107\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.0979 - val_loss: 0.0240 - val_mae: 0.1106\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1024 - val_loss: 0.0240 - val_mae: 0.1106\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.0995 - val_loss: 0.0240 - val_mae: 0.1105\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0980 - val_loss: 0.0240 - val_mae: 0.1104\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0994 - val_loss: 0.0239 - val_mae: 0.1103\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0974 - val_loss: 0.0239 - val_mae: 0.1103\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0089 - mae: 0.0991 - val_loss: 0.0239 - val_mae: 0.1102\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0091 - mae: 0.0988 - val_loss: 0.0239 - val_mae: 0.1101\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0239 - val_mae: 0.1100\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0976 - val_loss: 0.0239 - val_mae: 0.1099\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0979 - val_loss: 0.0239 - val_mae: 0.1099\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0239 - val_mae: 0.1098\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0988 - val_loss: 0.0238 - val_mae: 0.1097\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0238 - val_mae: 0.1096\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0085 - mae: 0.0967 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.0963 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0238 - val_mae: 0.1094\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0972 - val_loss: 0.0238 - val_mae: 0.1093\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0977 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0956 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0946 - val_loss: 0.0238 - val_mae: 0.1091\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.0968 - val_loss: 0.0238 - val_mae: 0.1090\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0082 - mae: 0.0935 - val_loss: 0.0237 - val_mae: 0.1089\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0082 - mae: 0.0929 - val_loss: 0.0237 - val_mae: 0.1089\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0985 - val_loss: 0.0237 - val_mae: 0.1088\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1086\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0237 - val_mae: 0.1086\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0955 - val_loss: 0.0237 - val_mae: 0.1085\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0963 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0946 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0085 - mae: 0.0940 - val_loss: 0.0237 - val_mae: 0.1083\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0236 - val_mae: 0.1082\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0086 - mae: 0.0967 - val_loss: 0.0236 - val_mae: 0.1082\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1081\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0971 - val_loss: 0.0236 - val_mae: 0.1080\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0927 - val_loss: 0.0236 - val_mae: 0.1080\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0941 - val_loss: 0.0236 - val_mae: 0.1079\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0959 - val_loss: 0.0236 - val_mae: 0.1078\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0236 - val_mae: 0.1077\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0938 - val_loss: 0.0236 - val_mae: 0.1077\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0948 - val_loss: 0.0236 - val_mae: 0.1076\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0235 - val_mae: 0.1075\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0961 - val_loss: 0.0235 - val_mae: 0.1075\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0929 - val_loss: 0.0235 - val_mae: 0.1074\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.0999 - val_loss: 0.0235 - val_mae: 0.1073\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0958 - val_loss: 0.0235 - val_mae: 0.1073\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0928 - val_loss: 0.0235 - val_mae: 0.1072\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0079 - mae: 0.0924 - val_loss: 0.0235 - val_mae: 0.1071\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0077 - mae: 0.0897 - val_loss: 0.0235 - val_mae: 0.1070\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0962 - val_loss: 0.0235 - val_mae: 0.1070\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0945 - val_loss: 0.0235 - val_mae: 0.1069\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1068\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0234 - val_mae: 0.1068\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0077 - mae: 0.0882 - val_loss: 0.0234 - val_mae: 0.1067\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0234 - val_mae: 0.1066\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0234 - val_mae: 0.1066\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0963 - val_loss: 0.0234 - val_mae: 0.1065\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0919 - val_loss: 0.0234 - val_mae: 0.1064\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0923 - val_loss: 0.0234 - val_mae: 0.1064\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0085 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1063\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0234 - val_mae: 0.1062\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0907 - val_loss: 0.0233 - val_mae: 0.1062\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0940 - val_loss: 0.0233 - val_mae: 0.1061\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0233 - val_mae: 0.1060\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1060\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1059\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0938 - val_loss: 0.0233 - val_mae: 0.1058\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0920 - val_loss: 0.0233 - val_mae: 0.1058\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0922 - val_loss: 0.0233 - val_mae: 0.1057\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0939 - val_loss: 0.0233 - val_mae: 0.1056\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0944 - val_loss: 0.0233 - val_mae: 0.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:36,649] Trial 7 finished with value: 0.10555362701416016 and parameters: {'learning_rate': 7.033233877060463e-06, 'weight_decay': 1.612821650191405e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0103 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1231\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1231\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0101 - mae: 0.1102 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1083 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1146 - val_loss: 0.0252 - val_mae: 0.1230\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1116 - val_loss: 0.0252 - val_mae: 0.1229\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0099 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0251 - val_mae: 0.1229\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1102 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0251 - val_mae: 0.1228\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0102 - mae: 0.1125 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0098 - mae: 0.1098 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0251 - val_mae: 0.1227\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0101 - mae: 0.1110 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0251 - val_mae: 0.1226\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1096 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1084 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0251 - val_mae: 0.1225\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1119 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1125 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1111 - val_loss: 0.0251 - val_mae: 0.1224\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0103 - mae: 0.1116 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0096 - mae: 0.1076 - val_loss: 0.0251 - val_mae: 0.1223\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1095 - val_loss: 0.0251 - val_mae: 0.1222\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1081 - val_loss: 0.0251 - val_mae: 0.1222\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0250 - val_mae: 0.1222\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0100 - mae: 0.1117 - val_loss: 0.0250 - val_mae: 0.1222\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0097 - mae: 0.1072 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1114 - val_loss: 0.0250 - val_mae: 0.1221\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1113 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - mae: 0.1125 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0100 - mae: 0.1102 - val_loss: 0.0250 - val_mae: 0.1220\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1119 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1219\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0099 - mae: 0.1098 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - mae: 0.1108 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1084 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0090 - mae: 0.1068 - val_loss: 0.0250 - val_mae: 0.1218\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1112 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0101 - mae: 0.1120 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1091 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0250 - val_mae: 0.1217\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0250 - val_mae: 0.1216\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1069 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1094 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - mae: 0.1127 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1215\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1079 - val_loss: 0.0250 - val_mae: 0.1214\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1214\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1054 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1086 - val_loss: 0.0249 - val_mae: 0.1213\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0098 - mae: 0.1095 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0249 - val_mae: 0.1212\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0100 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0099 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1211\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0101 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1082 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0249 - val_mae: 0.1210\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1067 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0100 - mae: 0.1108 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1078 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0096 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1209\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1101 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1074 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1087 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1208\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1073 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0097 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0098 - mae: 0.1092 - val_loss: 0.0249 - val_mae: 0.1207\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0098 - mae: 0.1115 - val_loss: 0.0248 - val_mae: 0.1207\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0098 - mae: 0.1073 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0092 - mae: 0.1066 - val_loss: 0.0248 - val_mae: 0.1206\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0092 - mae: 0.1056 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0096 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1098 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0099 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1205\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0094 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0097 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1204\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1082 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0095 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1077 - val_loss: 0.0248 - val_mae: 0.1203\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1103 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1093 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1056 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1075 - val_loss: 0.0248 - val_mae: 0.1202\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1071 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1100 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1080 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1099 - val_loss: 0.0248 - val_mae: 0.1201\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1088 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0100 - mae: 0.1097 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0097 - mae: 0.1090 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1085 - val_loss: 0.0248 - val_mae: 0.1200\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0099 - mae: 0.1108 - val_loss: 0.0248 - val_mae: 0.1199\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0096 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0098 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0099 - mae: 0.1118 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1080 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1096 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0098 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1198\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1067 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1083 - val_loss: 0.0247 - val_mae: 0.1197\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1053 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0097 - mae: 0.1091 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0096 - mae: 0.1073 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0092 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1196\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0095 - mae: 0.1062 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0093 - mae: 0.1058 - val_loss: 0.0247 - val_mae: 0.1195\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - mae: 0.1048 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0247 - val_mae: 0.1194\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0096 - mae: 0.1089 - val_loss: 0.0247 - val_mae: 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:57:51,938] Trial 8 finished with value: 0.11939509958028793 and parameters: {'learning_rate': 2.080888101485016e-06, 'weight_decay': 2.1126546111542145e-09}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0222 - val_mae: 0.0998\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0190 - val_mae: 0.0848\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0724 - val_loss: 0.0178 - val_mae: 0.0921\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0741 - val_loss: 0.0175 - val_mae: 0.0851\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0641 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0848\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0888\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0630 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0637 - val_loss: 0.0165 - val_mae: 0.0931\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0623 - val_loss: 0.0165 - val_mae: 0.0925\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0686 - val_loss: 0.0166 - val_mae: 0.0874\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0168 - val_mae: 0.0823\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0822\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0168 - val_mae: 0.0829\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0612 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0625 - val_loss: 0.0165 - val_mae: 0.0868\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0872\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0645 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0861\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0605 - val_loss: 0.0169 - val_mae: 0.0854\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0170 - val_mae: 0.0850\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0033 - mae: 0.0592 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0848\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0167 - val_mae: 0.0856\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0863\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0862\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0613 - val_loss: 0.0164 - val_mae: 0.0867\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - mae: 0.0592 - val_loss: 0.0163 - val_mae: 0.0875\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0027 - mae: 0.0545 - val_loss: 0.0161 - val_mae: 0.0897\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0161 - val_mae: 0.0892\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0581 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0029 - mae: 0.0516 - val_loss: 0.0165 - val_mae: 0.0831\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0581 - val_loss: 0.0166 - val_mae: 0.0826\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0542 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - mae: 0.0531 - val_loss: 0.0165 - val_mae: 0.0834\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0588 - val_loss: 0.0164 - val_mae: 0.0843\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0163 - val_mae: 0.0861\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0029 - mae: 0.0548 - val_loss: 0.0162 - val_mae: 0.0885\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0034 - mae: 0.0593 - val_loss: 0.0162 - val_mae: 0.0900\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0619 - val_loss: 0.0162 - val_mae: 0.0895\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0162 - val_mae: 0.0867\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0548 - val_loss: 0.0162 - val_mae: 0.0858\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - mae: 0.0588 - val_loss: 0.0160 - val_mae: 0.0858\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0556 - val_loss: 0.0158 - val_mae: 0.0870\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0567 - val_loss: 0.0156 - val_mae: 0.0871\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0154 - val_mae: 0.0859\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0156 - val_mae: 0.0815\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0560 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0577 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0026 - mae: 0.0514 - val_loss: 0.0155 - val_mae: 0.0842\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0555 - val_loss: 0.0153 - val_mae: 0.0861\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0574 - val_loss: 0.0154 - val_mae: 0.0849\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0532 - val_loss: 0.0154 - val_mae: 0.0841\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0151 - val_mae: 0.0848\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0557 - val_loss: 0.0145 - val_mae: 0.0883\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - mae: 0.0566 - val_loss: 0.0154 - val_mae: 0.0816\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0164 - val_mae: 0.0816\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0170 - val_mae: 0.0827\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0548 - val_loss: 0.0170 - val_mae: 0.0835\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0165 - val_mae: 0.0833\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - mae: 0.0549 - val_loss: 0.0152 - val_mae: 0.0838\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0026 - mae: 0.0529 - val_loss: 0.0141 - val_mae: 0.0887\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0608 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0029 - mae: 0.0541 - val_loss: 0.0170 - val_mae: 0.0825\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0546 - val_loss: 0.0173 - val_mae: 0.0830\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0567 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0171 - val_mae: 0.0843\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0559 - val_loss: 0.0169 - val_mae: 0.0855\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0167 - val_mae: 0.0873\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0030 - mae: 0.0553 - val_loss: 0.0166 - val_mae: 0.0893\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - mae: 0.0555 - val_loss: 0.0165 - val_mae: 0.0911\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - mae: 0.0578 - val_loss: 0.0165 - val_mae: 0.0933\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0165 - val_mae: 0.0952\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - mae: 0.0530 - val_loss: 0.0165 - val_mae: 0.0964\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0035 - mae: 0.0672 - val_loss: 0.0163 - val_mae: 0.0909\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0932\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0167 - val_mae: 0.0966\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - mae: 0.0581 - val_loss: 0.0169 - val_mae: 0.0967\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0645 - val_loss: 0.0168 - val_mae: 0.0923\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0628 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0170 - val_mae: 0.0912\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0930\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0647 - val_loss: 0.0171 - val_mae: 0.0921\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0646 - val_loss: 0.0170 - val_mae: 0.0902\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0877\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0596 - val_loss: 0.0170 - val_mae: 0.0853\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0831\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0171 - val_mae: 0.0816\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0560 - val_loss: 0.0171 - val_mae: 0.0809\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0822\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0166 - val_mae: 0.0833\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0598 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0584 - val_loss: 0.0164 - val_mae: 0.0855\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0164 - val_mae: 0.0864\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - mae: 0.0597 - val_loss: 0.0164 - val_mae: 0.0872\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0628 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0622 - val_loss: 0.0166 - val_mae: 0.0871\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0166 - val_mae: 0.0866\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0851\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0170 - val_mae: 0.0846\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0841\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0575 - val_loss: 0.0170 - val_mae: 0.0838\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0581 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0169 - val_mae: 0.0842\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0033 - mae: 0.0564 - val_loss: 0.0169 - val_mae: 0.0849\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0168 - val_mae: 0.0854\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0858\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0167 - val_mae: 0.0860\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0861\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0623 - val_loss: 0.0166 - val_mae: 0.0857\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0586 - val_loss: 0.0166 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0166 - val_mae: 0.0845\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0841\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0033 - mae: 0.0593 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0836\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0571 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0168 - val_mae: 0.0842\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0850\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0167 - val_mae: 0.0857\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0601 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0621 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0167 - val_mae: 0.0863\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0858\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0850\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0588 - val_loss: 0.0168 - val_mae: 0.0846\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0577 - val_loss: 0.0168 - val_mae: 0.0834\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0835\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0167 - val_mae: 0.0843\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:07,242] Trial 9 finished with value: 0.08507339656352997 and parameters: {'learning_rate': 0.0052334938223625, 'weight_decay': 1.9701345544264473e-05}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0093 - mae: 0.1031 - val_loss: 0.0235 - val_mae: 0.1127\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0093 - mae: 0.0997 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0097 - mae: 0.1044 - val_loss: 0.0233 - val_mae: 0.1108\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.0978 - val_loss: 0.0232 - val_mae: 0.1099\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1090\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0230 - val_mae: 0.1081\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1071\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0968 - val_loss: 0.0227 - val_mae: 0.1061\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1052\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0226 - val_mae: 0.1043\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0933 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0224 - val_mae: 0.1025\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0889 - val_loss: 0.0223 - val_mae: 0.1016\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0077 - mae: 0.0877 - val_loss: 0.0222 - val_mae: 0.1007\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0221 - val_mae: 0.0998\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0877 - val_loss: 0.0220 - val_mae: 0.0989\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0219 - val_mae: 0.0981\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - mae: 0.0862 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0217 - val_mae: 0.0963\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0853 - val_loss: 0.0216 - val_mae: 0.0955\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0071 - mae: 0.0832 - val_loss: 0.0215 - val_mae: 0.0947\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0214 - val_mae: 0.0940\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0212 - val_mae: 0.0926\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0065 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0063 - mae: 0.0783 - val_loss: 0.0210 - val_mae: 0.0912\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0786 - val_loss: 0.0208 - val_mae: 0.0905\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0801 - val_loss: 0.0206 - val_mae: 0.0892\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0205 - val_mae: 0.0887\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0780 - val_loss: 0.0204 - val_mae: 0.0881\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0823 - val_loss: 0.0203 - val_mae: 0.0875\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0711 - val_loss: 0.0202 - val_mae: 0.0870\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0751 - val_loss: 0.0201 - val_mae: 0.0864\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0765 - val_loss: 0.0200 - val_mae: 0.0859\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0199 - val_mae: 0.0854\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0198 - val_mae: 0.0849\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0738 - val_loss: 0.0197 - val_mae: 0.0845\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0784 - val_loss: 0.0196 - val_mae: 0.0841\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0734 - val_loss: 0.0195 - val_mae: 0.0838\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0788 - val_loss: 0.0194 - val_mae: 0.0834\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0054 - mae: 0.0744 - val_loss: 0.0194 - val_mae: 0.0831\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0193 - val_mae: 0.0828\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - mae: 0.0733 - val_loss: 0.0192 - val_mae: 0.0826\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0769 - val_loss: 0.0191 - val_mae: 0.0823\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0191 - val_mae: 0.0821\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0052 - mae: 0.0733 - val_loss: 0.0190 - val_mae: 0.0819\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0189 - val_mae: 0.0818\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0704 - val_loss: 0.0189 - val_mae: 0.0816\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - mae: 0.0745 - val_loss: 0.0188 - val_mae: 0.0814\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0187 - val_mae: 0.0813\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0811\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0186 - val_mae: 0.0810\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0185 - val_mae: 0.0809\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0744 - val_loss: 0.0185 - val_mae: 0.0807\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0049 - mae: 0.0673 - val_loss: 0.0184 - val_mae: 0.0806\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0184 - val_mae: 0.0804\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0183 - val_mae: 0.0803\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0757 - val_loss: 0.0183 - val_mae: 0.0801\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0049 - mae: 0.0705 - val_loss: 0.0183 - val_mae: 0.0799\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0710 - val_loss: 0.0182 - val_mae: 0.0798\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0182 - val_mae: 0.0797\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0182 - val_mae: 0.0796\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0698 - val_loss: 0.0181 - val_mae: 0.0795\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0180 - val_mae: 0.0794\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0048 - mae: 0.0701 - val_loss: 0.0180 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0179 - val_mae: 0.0792\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0043 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0177 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0176 - val_mae: 0.0791\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - mae: 0.0636 - val_loss: 0.0176 - val_mae: 0.0790\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0670 - val_loss: 0.0176 - val_mae: 0.0789\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0175 - val_mae: 0.0788\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0656 - val_loss: 0.0175 - val_mae: 0.0787\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0697 - val_loss: 0.0175 - val_mae: 0.0785\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0175 - val_mae: 0.0784\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0175 - val_mae: 0.0782\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0780\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0174 - val_mae: 0.0778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0174 - val_mae: 0.0776\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0174 - val_mae: 0.0775\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0173 - val_mae: 0.0775\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0608 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0616 - val_loss: 0.0173 - val_mae: 0.0774\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0172 - val_mae: 0.0774\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0172 - val_mae: 0.0775\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0636 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0688 - val_loss: 0.0171 - val_mae: 0.0776\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0043 - mae: 0.0642 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0041 - mae: 0.0620 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0601 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0042 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0772\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0170 - val_mae: 0.0771\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0659 - val_loss: 0.0170 - val_mae: 0.0770\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0626 - val_loss: 0.0170 - val_mae: 0.0769\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0587 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0635 - val_loss: 0.0169 - val_mae: 0.0772\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0626 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0599 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0168 - val_mae: 0.0774\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0587 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0640 - val_loss: 0.0168 - val_mae: 0.0773\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0585 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0035 - mae: 0.0606 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0037 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - mae: 0.0591 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0552 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0615 - val_loss: 0.0166 - val_mae: 0.0777\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0600 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0042 - mae: 0.0666 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0166 - val_mae: 0.0780\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0597 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0608 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0605 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0166 - val_mae: 0.0777\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0625 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0775\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0616 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0775\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - mae: 0.0607 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0164 - val_mae: 0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:22,463] Trial 10 finished with value: 0.0778498575091362 and parameters: {'learning_rate': 0.00010069278459625918, 'weight_decay': 4.335902388646887e-06}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1139 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0101 - mae: 0.1094 - val_loss: 0.0244 - val_mae: 0.1211\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0100 - mae: 0.1099 - val_loss: 0.0242 - val_mae: 0.1192\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0097 - mae: 0.1057 - val_loss: 0.0240 - val_mae: 0.1174\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0238 - val_mae: 0.1156\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0237 - val_mae: 0.1138\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0235 - val_mae: 0.1121\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0973 - val_loss: 0.0233 - val_mae: 0.1104\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0230 - val_mae: 0.1073\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0933 - val_loss: 0.0227 - val_mae: 0.1045\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0226 - val_mae: 0.1030\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0076 - mae: 0.0905 - val_loss: 0.0224 - val_mae: 0.1016\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0075 - mae: 0.0886 - val_loss: 0.0223 - val_mae: 0.1001\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0221 - val_mae: 0.0986\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0219 - val_mae: 0.0971\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0072 - mae: 0.0855 - val_loss: 0.0218 - val_mae: 0.0955\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0071 - mae: 0.0849 - val_loss: 0.0216 - val_mae: 0.0939\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0923\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0061 - mae: 0.0791 - val_loss: 0.0211 - val_mae: 0.0905\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0812 - val_loss: 0.0209 - val_mae: 0.0889\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0780 - val_loss: 0.0207 - val_mae: 0.0876\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0797 - val_loss: 0.0205 - val_mae: 0.0862\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0850\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0200 - val_mae: 0.0838\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - mae: 0.0732 - val_loss: 0.0197 - val_mae: 0.0827\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0195 - val_mae: 0.0819\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0738 - val_loss: 0.0193 - val_mae: 0.0811\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0755 - val_loss: 0.0191 - val_mae: 0.0804\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0787 - val_loss: 0.0189 - val_mae: 0.0798\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0187 - val_mae: 0.0792\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0678 - val_loss: 0.0185 - val_mae: 0.0788\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0767 - val_loss: 0.0184 - val_mae: 0.0784\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - mae: 0.0699 - val_loss: 0.0182 - val_mae: 0.0782\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0047 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0782\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0055 - mae: 0.0759 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0046 - mae: 0.0694 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0706 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0742 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0700 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0055 - mae: 0.0735 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0751 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0726 - val_loss: 0.0179 - val_mae: 0.0767\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0692 - val_loss: 0.0179 - val_mae: 0.0767\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0643 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0658 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0663 - val_loss: 0.0179 - val_mae: 0.0766\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0048 - mae: 0.0686 - val_loss: 0.0179 - val_mae: 0.0765\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0179 - val_mae: 0.0765\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0042 - mae: 0.0652 - val_loss: 0.0179 - val_mae: 0.0764\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0650 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0659 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0177 - val_mae: 0.0762\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0176 - val_mae: 0.0762\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0626 - val_loss: 0.0175 - val_mae: 0.0764\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0672 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0767\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0715 - val_loss: 0.0173 - val_mae: 0.0769\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0770\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - mae: 0.0613 - val_loss: 0.0173 - val_mae: 0.0770\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0771\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0172 - val_mae: 0.0772\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0773\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0651 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0035 - mae: 0.0616 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0615 - val_loss: 0.0170 - val_mae: 0.0773\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0170 - val_mae: 0.0774\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0039 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0771\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0770\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0661 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0606 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0636 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0645 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0574 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - mae: 0.0598 - val_loss: 0.0169 - val_mae: 0.0768\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0576 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0642 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0041 - mae: 0.0631 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0772\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0773\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0604 - val_loss: 0.0167 - val_mae: 0.0774\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0580 - val_loss: 0.0166 - val_mae: 0.0778\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0598 - val_loss: 0.0166 - val_mae: 0.0779\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0588 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0559 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0037 - mae: 0.0618 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0616 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0631 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0640 - val_loss: 0.0164 - val_mae: 0.0784\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0602 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0781\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0165 - val_mae: 0.0782\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0165 - val_mae: 0.0783\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0594 - val_loss: 0.0165 - val_mae: 0.0784\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - mae: 0.0582 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.0784\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0543 - val_loss: 0.0165 - val_mae: 0.0785\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0563 - val_loss: 0.0165 - val_mae: 0.0786\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0589 - val_loss: 0.0165 - val_mae: 0.0786\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0576 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - mae: 0.0608 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0037 - mae: 0.0595 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0637 - val_loss: 0.0164 - val_mae: 0.0785\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0030 - mae: 0.0543 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0568 - val_loss: 0.0162 - val_mae: 0.0791\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0599 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0585 - val_loss: 0.0161 - val_mae: 0.0795\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0036 - mae: 0.0628 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0038 - mae: 0.0630 - val_loss: 0.0161 - val_mae: 0.0795\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - mae: 0.0574 - val_loss: 0.0161 - val_mae: 0.0794\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0583 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0161 - val_mae: 0.0792\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0161 - val_mae: 0.0793\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0559 - val_loss: 0.0161 - val_mae: 0.0796\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0035 - mae: 0.0578 - val_loss: 0.0160 - val_mae: 0.0798\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - mae: 0.0583 - val_loss: 0.0160 - val_mae: 0.0799\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0561 - val_loss: 0.0159 - val_mae: 0.0801\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0606 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0028 - mae: 0.0523 - val_loss: 0.0159 - val_mae: 0.0800\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - mae: 0.0560 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0588 - val_loss: 0.0159 - val_mae: 0.0798\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0033 - mae: 0.0541 - val_loss: 0.0159 - val_mae: 0.0799\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0562 - val_loss: 0.0158 - val_mae: 0.0803\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0032 - mae: 0.0572 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0573 - val_loss: 0.0158 - val_mae: 0.0803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:37,727] Trial 11 finished with value: 0.0803346261382103 and parameters: {'learning_rate': 0.0001927304968401452, 'weight_decay': 4.947706962106966e-06}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0138 - mae: 0.1324 - val_loss: 0.0270 - val_mae: 0.1429\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0132 - mae: 0.1287 - val_loss: 0.0270 - val_mae: 0.1428\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0123 - mae: 0.1283 - val_loss: 0.0269 - val_mae: 0.1427\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - mae: 0.1284 - val_loss: 0.0269 - val_mae: 0.1425\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0130 - mae: 0.1269 - val_loss: 0.0269 - val_mae: 0.1424\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0148 - mae: 0.1350 - val_loss: 0.0269 - val_mae: 0.1423\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0130 - mae: 0.1280 - val_loss: 0.0269 - val_mae: 0.1422\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0132 - mae: 0.1282 - val_loss: 0.0268 - val_mae: 0.1420\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - mae: 0.1277 - val_loss: 0.0268 - val_mae: 0.1419\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0126 - mae: 0.1277 - val_loss: 0.0268 - val_mae: 0.1418\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0143 - mae: 0.1326 - val_loss: 0.0268 - val_mae: 0.1416\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0140 - mae: 0.1333 - val_loss: 0.0268 - val_mae: 0.1415\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0137 - mae: 0.1350 - val_loss: 0.0268 - val_mae: 0.1414\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0133 - mae: 0.1281 - val_loss: 0.0267 - val_mae: 0.1413\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0126 - mae: 0.1273 - val_loss: 0.0267 - val_mae: 0.1411\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0129 - mae: 0.1305 - val_loss: 0.0267 - val_mae: 0.1410\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0124 - mae: 0.1234 - val_loss: 0.0267 - val_mae: 0.1409\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0130 - mae: 0.1249 - val_loss: 0.0267 - val_mae: 0.1408\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0121 - mae: 0.1255 - val_loss: 0.0266 - val_mae: 0.1406\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0134 - mae: 0.1307 - val_loss: 0.0266 - val_mae: 0.1405\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1249 - val_loss: 0.0266 - val_mae: 0.1404\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0133 - mae: 0.1312 - val_loss: 0.0266 - val_mae: 0.1403\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0148 - mae: 0.1330 - val_loss: 0.0266 - val_mae: 0.1401\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0127 - mae: 0.1266 - val_loss: 0.0265 - val_mae: 0.1400\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0130 - mae: 0.1229 - val_loss: 0.0265 - val_mae: 0.1399\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0127 - mae: 0.1239 - val_loss: 0.0265 - val_mae: 0.1398\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - mae: 0.1307 - val_loss: 0.0265 - val_mae: 0.1396\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0130 - mae: 0.1289 - val_loss: 0.0265 - val_mae: 0.1395\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0124 - mae: 0.1278 - val_loss: 0.0264 - val_mae: 0.1394\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0132 - mae: 0.1309 - val_loss: 0.0264 - val_mae: 0.1393\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0119 - mae: 0.1233 - val_loss: 0.0264 - val_mae: 0.1392\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0129 - mae: 0.1299 - val_loss: 0.0264 - val_mae: 0.1390\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0123 - mae: 0.1232 - val_loss: 0.0264 - val_mae: 0.1389\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0130 - mae: 0.1269 - val_loss: 0.0264 - val_mae: 0.1388\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0132 - mae: 0.1284 - val_loss: 0.0263 - val_mae: 0.1387\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0127 - mae: 0.1266 - val_loss: 0.0263 - val_mae: 0.1386\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0137 - mae: 0.1304 - val_loss: 0.0263 - val_mae: 0.1385\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0129 - mae: 0.1262 - val_loss: 0.0263 - val_mae: 0.1383\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1203 - val_loss: 0.0263 - val_mae: 0.1382\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0124 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1381\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0127 - mae: 0.1262 - val_loss: 0.0262 - val_mae: 0.1380\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0132 - mae: 0.1272 - val_loss: 0.0262 - val_mae: 0.1379\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0123 - mae: 0.1236 - val_loss: 0.0262 - val_mae: 0.1378\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0136 - mae: 0.1296 - val_loss: 0.0262 - val_mae: 0.1376\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0120 - mae: 0.1209 - val_loss: 0.0262 - val_mae: 0.1375\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0122 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1374\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0117 - mae: 0.1211 - val_loss: 0.0261 - val_mae: 0.1373\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0124 - mae: 0.1239 - val_loss: 0.0261 - val_mae: 0.1372\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0130 - mae: 0.1233 - val_loss: 0.0261 - val_mae: 0.1371\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0122 - mae: 0.1266 - val_loss: 0.0261 - val_mae: 0.1370\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0126 - mae: 0.1257 - val_loss: 0.0261 - val_mae: 0.1369\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0124 - mae: 0.1248 - val_loss: 0.0261 - val_mae: 0.1367\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0125 - mae: 0.1263 - val_loss: 0.0260 - val_mae: 0.1366\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1238 - val_loss: 0.0260 - val_mae: 0.1365\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1214 - val_loss: 0.0260 - val_mae: 0.1364\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0124 - mae: 0.1266 - val_loss: 0.0260 - val_mae: 0.1363\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0117 - mae: 0.1202 - val_loss: 0.0260 - val_mae: 0.1362\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0123 - mae: 0.1232 - val_loss: 0.0260 - val_mae: 0.1361\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1209 - val_loss: 0.0259 - val_mae: 0.1360\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0119 - mae: 0.1202 - val_loss: 0.0259 - val_mae: 0.1359\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1233 - val_loss: 0.0259 - val_mae: 0.1358\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0118 - mae: 0.1225 - val_loss: 0.0259 - val_mae: 0.1357\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0117 - mae: 0.1209 - val_loss: 0.0259 - val_mae: 0.1356\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0130 - mae: 0.1266 - val_loss: 0.0259 - val_mae: 0.1355\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1216 - val_loss: 0.0259 - val_mae: 0.1353\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1255 - val_loss: 0.0258 - val_mae: 0.1352\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0118 - mae: 0.1230 - val_loss: 0.0258 - val_mae: 0.1351\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - mae: 0.1186 - val_loss: 0.0258 - val_mae: 0.1350\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0122 - mae: 0.1221 - val_loss: 0.0258 - val_mae: 0.1349\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0122 - mae: 0.1233 - val_loss: 0.0258 - val_mae: 0.1348\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1211 - val_loss: 0.0258 - val_mae: 0.1347\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0120 - mae: 0.1244 - val_loss: 0.0258 - val_mae: 0.1346\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0121 - mae: 0.1230 - val_loss: 0.0257 - val_mae: 0.1345\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0118 - mae: 0.1213 - val_loss: 0.0257 - val_mae: 0.1344\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1188 - val_loss: 0.0257 - val_mae: 0.1343\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0118 - mae: 0.1221 - val_loss: 0.0257 - val_mae: 0.1342\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0122 - mae: 0.1245 - val_loss: 0.0257 - val_mae: 0.1341\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0109 - mae: 0.1170 - val_loss: 0.0257 - val_mae: 0.1340\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0116 - mae: 0.1207 - val_loss: 0.0257 - val_mae: 0.1339\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1161 - val_loss: 0.0256 - val_mae: 0.1338\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1192 - val_loss: 0.0256 - val_mae: 0.1337\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1208 - val_loss: 0.0256 - val_mae: 0.1336\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1183 - val_loss: 0.0256 - val_mae: 0.1335\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0124 - mae: 0.1245 - val_loss: 0.0256 - val_mae: 0.1334\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0111 - mae: 0.1178 - val_loss: 0.0256 - val_mae: 0.1333\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0122 - mae: 0.1211 - val_loss: 0.0256 - val_mae: 0.1333\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1217 - val_loss: 0.0255 - val_mae: 0.1332\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1147 - val_loss: 0.0255 - val_mae: 0.1331\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0119 - mae: 0.1204 - val_loss: 0.0255 - val_mae: 0.1330\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0118 - mae: 0.1201 - val_loss: 0.0255 - val_mae: 0.1329\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0107 - mae: 0.1155 - val_loss: 0.0255 - val_mae: 0.1328\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1202 - val_loss: 0.0255 - val_mae: 0.1327\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1326\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0116 - mae: 0.1194 - val_loss: 0.0255 - val_mae: 0.1325\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0111 - mae: 0.1181 - val_loss: 0.0254 - val_mae: 0.1324\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1188 - val_loss: 0.0254 - val_mae: 0.1323\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0116 - mae: 0.1219 - val_loss: 0.0254 - val_mae: 0.1322\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0111 - mae: 0.1163 - val_loss: 0.0254 - val_mae: 0.1321\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1193 - val_loss: 0.0254 - val_mae: 0.1320\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1156 - val_loss: 0.0254 - val_mae: 0.1319\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1193 - val_loss: 0.0254 - val_mae: 0.1318\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0112 - mae: 0.1176 - val_loss: 0.0254 - val_mae: 0.1317\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1192 - val_loss: 0.0253 - val_mae: 0.1316\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0106 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1315\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0110 - mae: 0.1177 - val_loss: 0.0253 - val_mae: 0.1315\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0108 - mae: 0.1153 - val_loss: 0.0253 - val_mae: 0.1314\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0109 - mae: 0.1147 - val_loss: 0.0253 - val_mae: 0.1313\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0253 - val_mae: 0.1312\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1201 - val_loss: 0.0253 - val_mae: 0.1311\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1165 - val_loss: 0.0253 - val_mae: 0.1310\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1309\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1142 - val_loss: 0.0252 - val_mae: 0.1308\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0106 - mae: 0.1120 - val_loss: 0.0252 - val_mae: 0.1307\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0252 - val_mae: 0.1306\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1193 - val_loss: 0.0252 - val_mae: 0.1305\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0252 - val_mae: 0.1305\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1173 - val_loss: 0.0252 - val_mae: 0.1304\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0115 - mae: 0.1224 - val_loss: 0.0252 - val_mae: 0.1303\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1157 - val_loss: 0.0252 - val_mae: 0.1302\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0110 - mae: 0.1158 - val_loss: 0.0251 - val_mae: 0.1301\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0106 - mae: 0.1147 - val_loss: 0.0251 - val_mae: 0.1300\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1175 - val_loss: 0.0251 - val_mae: 0.1299\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1157 - val_loss: 0.0251 - val_mae: 0.1298\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0116 - mae: 0.1197 - val_loss: 0.0251 - val_mae: 0.1297\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1161 - val_loss: 0.0251 - val_mae: 0.1297\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0111 - mae: 0.1182 - val_loss: 0.0251 - val_mae: 0.1296\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0251 - val_mae: 0.1295\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - mae: 0.1143 - val_loss: 0.0250 - val_mae: 0.1294\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0113 - mae: 0.1177 - val_loss: 0.0250 - val_mae: 0.1293\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0250 - val_mae: 0.1292\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0101 - mae: 0.1123 - val_loss: 0.0250 - val_mae: 0.1291\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0107 - mae: 0.1119 - val_loss: 0.0250 - val_mae: 0.1290\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1166 - val_loss: 0.0250 - val_mae: 0.1289\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0250 - val_mae: 0.1289\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0114 - mae: 0.1150 - val_loss: 0.0250 - val_mae: 0.1288\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0111 - mae: 0.1168 - val_loss: 0.0250 - val_mae: 0.1287\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0250 - val_mae: 0.1286\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0249 - val_mae: 0.1285\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0106 - mae: 0.1137 - val_loss: 0.0249 - val_mae: 0.1284\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0249 - val_mae: 0.1283\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1168 - val_loss: 0.0249 - val_mae: 0.1282\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0105 - mae: 0.1132 - val_loss: 0.0249 - val_mae: 0.1281\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0102 - mae: 0.1115 - val_loss: 0.0249 - val_mae: 0.1281\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0249 - val_mae: 0.1280\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0106 - mae: 0.1131 - val_loss: 0.0249 - val_mae: 0.1279\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0109 - mae: 0.1164 - val_loss: 0.0249 - val_mae: 0.1278\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0112 - mae: 0.1170 - val_loss: 0.0248 - val_mae: 0.1277\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0106 - mae: 0.1114 - val_loss: 0.0248 - val_mae: 0.1276\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0107 - mae: 0.1150 - val_loss: 0.0248 - val_mae: 0.1275\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1157 - val_loss: 0.0248 - val_mae: 0.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:58:53,062] Trial 12 finished with value: 0.12744535505771637 and parameters: {'learning_rate': 7.546446707754693e-06, 'weight_decay': 3.587578917655504e-07}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0238 - val_mae: 0.1124\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0237 - val_mae: 0.1119\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0983 - val_loss: 0.0236 - val_mae: 0.1114\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0954 - val_loss: 0.0236 - val_mae: 0.1110\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0960 - val_loss: 0.0235 - val_mae: 0.1105\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0234 - val_mae: 0.1096\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0082 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1091\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0232 - val_mae: 0.1081\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0083 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1076\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - mae: 0.0905 - val_loss: 0.0231 - val_mae: 0.1071\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0078 - mae: 0.0901 - val_loss: 0.0230 - val_mae: 0.1066\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0077 - mae: 0.0894 - val_loss: 0.0229 - val_mae: 0.1061\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0918 - val_loss: 0.0229 - val_mae: 0.1056\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0228 - val_mae: 0.1051\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0904 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0876 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0079 - mae: 0.0907 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0881 - val_loss: 0.0226 - val_mae: 0.1031\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0864 - val_loss: 0.0225 - val_mae: 0.1026\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0224 - val_mae: 0.1021\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0224 - val_mae: 0.1015\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0867 - val_loss: 0.0223 - val_mae: 0.1011\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0079 - mae: 0.0904 - val_loss: 0.0223 - val_mae: 0.1006\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0860 - val_loss: 0.0222 - val_mae: 0.1001\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0859 - val_loss: 0.0221 - val_mae: 0.0996\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0857 - val_loss: 0.0221 - val_mae: 0.0991\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0220 - val_mae: 0.0986\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0219 - val_mae: 0.0982\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0812 - val_loss: 0.0219 - val_mae: 0.0977\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0845 - val_loss: 0.0218 - val_mae: 0.0972\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0073 - mae: 0.0858 - val_loss: 0.0217 - val_mae: 0.0967\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0815 - val_loss: 0.0217 - val_mae: 0.0962\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0840 - val_loss: 0.0216 - val_mae: 0.0957\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0215 - val_mae: 0.0952\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0215 - val_mae: 0.0947\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0214 - val_mae: 0.0942\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0214 - val_mae: 0.0937\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0213 - val_mae: 0.0933\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0807 - val_loss: 0.0212 - val_mae: 0.0928\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0824 - val_loss: 0.0212 - val_mae: 0.0924\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0067 - mae: 0.0814 - val_loss: 0.0211 - val_mae: 0.0919\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0776 - val_loss: 0.0211 - val_mae: 0.0915\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - mae: 0.0793 - val_loss: 0.0210 - val_mae: 0.0910\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0820 - val_loss: 0.0209 - val_mae: 0.0906\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - mae: 0.0839 - val_loss: 0.0209 - val_mae: 0.0902\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0766 - val_loss: 0.0208 - val_mae: 0.0898\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0803 - val_loss: 0.0208 - val_mae: 0.0894\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.0063 - mae: 0.0780 - val_loss: 0.0207 - val_mae: 0.0891\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0063 - mae: 0.0777 - val_loss: 0.0206 - val_mae: 0.0887\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0064 - mae: 0.0776 - val_loss: 0.0206 - val_mae: 0.0884\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0764 - val_loss: 0.0205 - val_mae: 0.0880\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0810 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0770 - val_loss: 0.0204 - val_mae: 0.0874\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0204 - val_mae: 0.0870\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0063 - mae: 0.0757 - val_loss: 0.0203 - val_mae: 0.0867\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0741 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0202 - val_mae: 0.0861\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0771 - val_loss: 0.0202 - val_mae: 0.0857\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0793 - val_loss: 0.0201 - val_mae: 0.0854\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0720 - val_loss: 0.0201 - val_mae: 0.0851\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0200 - val_mae: 0.0847\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0731 - val_loss: 0.0200 - val_mae: 0.0844\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0059 - mae: 0.0732 - val_loss: 0.0199 - val_mae: 0.0841\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0796 - val_loss: 0.0199 - val_mae: 0.0838\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0198 - val_mae: 0.0836\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0775 - val_loss: 0.0198 - val_mae: 0.0833\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0197 - val_mae: 0.0830\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0721 - val_loss: 0.0197 - val_mae: 0.0827\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0057 - mae: 0.0749 - val_loss: 0.0196 - val_mae: 0.0825\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0196 - val_mae: 0.0822\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0763 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0060 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0819\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0195 - val_mae: 0.0817\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0057 - mae: 0.0722 - val_loss: 0.0194 - val_mae: 0.0815\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0194 - val_mae: 0.0813\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0752 - val_loss: 0.0193 - val_mae: 0.0811\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0193 - val_mae: 0.0809\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0714 - val_loss: 0.0193 - val_mae: 0.0808\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0761 - val_loss: 0.0193 - val_mae: 0.0807\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0056 - mae: 0.0726 - val_loss: 0.0192 - val_mae: 0.0806\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0767 - val_loss: 0.0192 - val_mae: 0.0805\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0743 - val_loss: 0.0192 - val_mae: 0.0804\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0711 - val_loss: 0.0192 - val_mae: 0.0803\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0686 - val_loss: 0.0192 - val_mae: 0.0802\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0733 - val_loss: 0.0191 - val_mae: 0.0801\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0692 - val_loss: 0.0191 - val_mae: 0.0799\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0191 - val_mae: 0.0798\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0730 - val_loss: 0.0190 - val_mae: 0.0797\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0704 - val_loss: 0.0190 - val_mae: 0.0796\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0055 - mae: 0.0738 - val_loss: 0.0190 - val_mae: 0.0795\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0690 - val_loss: 0.0189 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0729 - val_loss: 0.0189 - val_mae: 0.0792\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0189 - val_mae: 0.0791\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0667 - val_loss: 0.0188 - val_mae: 0.0790\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0188 - val_mae: 0.0788\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0187 - val_mae: 0.0786\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0741 - val_loss: 0.0187 - val_mae: 0.0785\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0655 - val_loss: 0.0186 - val_mae: 0.0784\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - mae: 0.0683 - val_loss: 0.0186 - val_mae: 0.0783\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0739 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0735 - val_loss: 0.0186 - val_mae: 0.0782\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0685 - val_loss: 0.0186 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - mae: 0.0734 - val_loss: 0.0185 - val_mae: 0.0780\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0672 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0689 - val_loss: 0.0185 - val_mae: 0.0779\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0053 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0674 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0700 - val_loss: 0.0185 - val_mae: 0.0778\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0672 - val_loss: 0.0185 - val_mae: 0.0777\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0619 - val_loss: 0.0185 - val_mae: 0.0777\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0664 - val_loss: 0.0184 - val_mae: 0.0777\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0657 - val_loss: 0.0184 - val_mae: 0.0776\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0676 - val_loss: 0.0184 - val_mae: 0.0775\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0671 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0649 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0183 - val_mae: 0.0774\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0673 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0048 - mae: 0.0657 - val_loss: 0.0182 - val_mae: 0.0773\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0048 - mae: 0.0695 - val_loss: 0.0182 - val_mae: 0.0772\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0049 - mae: 0.0711 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0181 - val_mae: 0.0772\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0047 - mae: 0.0682 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0181 - val_mae: 0.0771\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0688 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0674 - val_loss: 0.0181 - val_mae: 0.0770\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0181 - val_mae: 0.0769\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0051 - mae: 0.0687 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0681 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0668 - val_loss: 0.0181 - val_mae: 0.0768\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0047 - mae: 0.0675 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - mae: 0.0654 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0181 - val_mae: 0.0767\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0045 - mae: 0.0680 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0664 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0180 - val_mae: 0.0766\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0042 - mae: 0.0634 - val_loss: 0.0180 - val_mae: 0.0767\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0043 - mae: 0.0637 - val_loss: 0.0179 - val_mae: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:08,831] Trial 13 finished with value: 0.07676756381988525 and parameters: {'learning_rate': 4.867515363143382e-05, 'weight_decay': 1.1172288894024361e-07}. Best is trial 2 with value: 0.07521326839923859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0097 - mae: 0.1063 - val_loss: 0.0237 - val_mae: 0.1170\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0095 - mae: 0.1045 - val_loss: 0.0236 - val_mae: 0.1165\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0236 - val_mae: 0.1161\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0096 - mae: 0.1024 - val_loss: 0.0235 - val_mae: 0.1156\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0235 - val_mae: 0.1152\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1147\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1036 - val_loss: 0.0234 - val_mae: 0.1143\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0233 - val_mae: 0.1139\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1003 - val_loss: 0.0232 - val_mae: 0.1134\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1025 - val_loss: 0.0232 - val_mae: 0.1130\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1012 - val_loss: 0.0231 - val_mae: 0.1127\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1123\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0231 - val_mae: 0.1119\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1115\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0230 - val_mae: 0.1112\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0230 - val_mae: 0.1108\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0938 - val_loss: 0.0229 - val_mae: 0.1104\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0940 - val_loss: 0.0229 - val_mae: 0.1101\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0959 - val_loss: 0.0228 - val_mae: 0.1097\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1093\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0980 - val_loss: 0.0228 - val_mae: 0.1089\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0947 - val_loss: 0.0227 - val_mae: 0.1086\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1082\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0953 - val_loss: 0.0227 - val_mae: 0.1078\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0226 - val_mae: 0.1075\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0226 - val_mae: 0.1071\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0919 - val_loss: 0.0226 - val_mae: 0.1067\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - mae: 0.0924 - val_loss: 0.0225 - val_mae: 0.1064\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0927 - val_loss: 0.0225 - val_mae: 0.1060\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0923 - val_loss: 0.0225 - val_mae: 0.1056\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0892 - val_loss: 0.0224 - val_mae: 0.1053\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0907 - val_loss: 0.0224 - val_mae: 0.1049\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0885 - val_loss: 0.0223 - val_mae: 0.1045\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0917 - val_loss: 0.0223 - val_mae: 0.1042\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0223 - val_mae: 0.1038\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0921 - val_loss: 0.0222 - val_mae: 0.1034\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0078 - mae: 0.0890 - val_loss: 0.0222 - val_mae: 0.1030\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0896 - val_loss: 0.0221 - val_mae: 0.1026\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0889 - val_loss: 0.0221 - val_mae: 0.1022\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0888 - val_loss: 0.0221 - val_mae: 0.1018\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0220 - val_mae: 0.1014\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0883 - val_loss: 0.0220 - val_mae: 0.1010\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0219 - val_mae: 0.1006\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0219 - val_mae: 0.1002\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0853 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0854 - val_loss: 0.0218 - val_mae: 0.0994\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0986\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0073 - mae: 0.0856 - val_loss: 0.0217 - val_mae: 0.0982\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - mae: 0.0831 - val_loss: 0.0216 - val_mae: 0.0977\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0851 - val_loss: 0.0216 - val_mae: 0.0973\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0215 - val_mae: 0.0969\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - mae: 0.0827 - val_loss: 0.0215 - val_mae: 0.0965\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0070 - mae: 0.0842 - val_loss: 0.0214 - val_mae: 0.0960\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0070 - mae: 0.0813 - val_loss: 0.0214 - val_mae: 0.0956\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0065 - mae: 0.0817 - val_loss: 0.0213 - val_mae: 0.0951\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0823 - val_loss: 0.0213 - val_mae: 0.0946\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0069 - mae: 0.0813 - val_loss: 0.0212 - val_mae: 0.0942\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0212 - val_mae: 0.0937\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0069 - mae: 0.0821 - val_loss: 0.0211 - val_mae: 0.0932\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0800 - val_loss: 0.0210 - val_mae: 0.0928\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0803 - val_loss: 0.0210 - val_mae: 0.0923\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0209 - val_mae: 0.0918\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0795 - val_loss: 0.0209 - val_mae: 0.0914\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0771 - val_loss: 0.0208 - val_mae: 0.0909\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - mae: 0.0840 - val_loss: 0.0208 - val_mae: 0.0904\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0061 - mae: 0.0773 - val_loss: 0.0207 - val_mae: 0.0899\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0805 - val_loss: 0.0207 - val_mae: 0.0895\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0206 - val_mae: 0.0890\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0068 - mae: 0.0816 - val_loss: 0.0206 - val_mae: 0.0886\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0062 - mae: 0.0753 - val_loss: 0.0205 - val_mae: 0.0881\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0063 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.0877\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0736 - val_loss: 0.0204 - val_mae: 0.0873\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0778 - val_loss: 0.0204 - val_mae: 0.0868\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0780 - val_loss: 0.0203 - val_mae: 0.0864\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0754 - val_loss: 0.0203 - val_mae: 0.0860\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066 - mae: 0.0767 - val_loss: 0.0202 - val_mae: 0.0856\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.0853\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0755 - val_loss: 0.0201 - val_mae: 0.0849\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0201 - val_mae: 0.0846\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0843\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - mae: 0.0779 - val_loss: 0.0200 - val_mae: 0.0840\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0061 - mae: 0.0760 - val_loss: 0.0199 - val_mae: 0.0836\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - mae: 0.0732 - val_loss: 0.0199 - val_mae: 0.0833\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - mae: 0.0752 - val_loss: 0.0198 - val_mae: 0.0830\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0694 - val_loss: 0.0198 - val_mae: 0.0827\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - mae: 0.0716 - val_loss: 0.0197 - val_mae: 0.0823\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0056 - mae: 0.0707 - val_loss: 0.0197 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0063 - mae: 0.0760 - val_loss: 0.0196 - val_mae: 0.0817\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0059 - mae: 0.0756 - val_loss: 0.0196 - val_mae: 0.0814\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0057 - mae: 0.0748 - val_loss: 0.0195 - val_mae: 0.0812\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0707 - val_loss: 0.0195 - val_mae: 0.0809\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0194 - val_mae: 0.0806\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0737 - val_loss: 0.0194 - val_mae: 0.0803\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0054 - mae: 0.0713 - val_loss: 0.0193 - val_mae: 0.0800\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0193 - val_mae: 0.0798\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0057 - mae: 0.0745 - val_loss: 0.0192 - val_mae: 0.0795\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0760 - val_loss: 0.0192 - val_mae: 0.0793\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0746 - val_loss: 0.0192 - val_mae: 0.0791\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0686 - val_loss: 0.0191 - val_mae: 0.0789\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0191 - val_mae: 0.0787\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0757 - val_loss: 0.0190 - val_mae: 0.0785\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0737 - val_loss: 0.0190 - val_mae: 0.0784\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0059 - mae: 0.0753 - val_loss: 0.0190 - val_mae: 0.0782\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0059 - mae: 0.0734 - val_loss: 0.0190 - val_mae: 0.0781\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0683 - val_loss: 0.0189 - val_mae: 0.0780\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0059 - mae: 0.0743 - val_loss: 0.0189 - val_mae: 0.0779\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0189 - val_mae: 0.0778\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0189 - val_mae: 0.0776\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - mae: 0.0730 - val_loss: 0.0188 - val_mae: 0.0775\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0052 - mae: 0.0722 - val_loss: 0.0188 - val_mae: 0.0775\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0188 - val_mae: 0.0774\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0727 - val_loss: 0.0188 - val_mae: 0.0773\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0052 - mae: 0.0701 - val_loss: 0.0188 - val_mae: 0.0772\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0687 - val_loss: 0.0187 - val_mae: 0.0771\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0711 - val_loss: 0.0187 - val_mae: 0.0770\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0747 - val_loss: 0.0187 - val_mae: 0.0769\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0051 - mae: 0.0709 - val_loss: 0.0187 - val_mae: 0.0769\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0052 - mae: 0.0702 - val_loss: 0.0186 - val_mae: 0.0768\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0186 - val_mae: 0.0767\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0678 - val_loss: 0.0186 - val_mae: 0.0766\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0050 - mae: 0.0703 - val_loss: 0.0186 - val_mae: 0.0766\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0701 - val_loss: 0.0186 - val_mae: 0.0765\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0047 - mae: 0.0687 - val_loss: 0.0186 - val_mae: 0.0764\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0049 - mae: 0.0709 - val_loss: 0.0185 - val_mae: 0.0764\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0729 - val_loss: 0.0185 - val_mae: 0.0763\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0048 - mae: 0.0676 - val_loss: 0.0185 - val_mae: 0.0762\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0645 - val_loss: 0.0185 - val_mae: 0.0761\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0728 - val_loss: 0.0184 - val_mae: 0.0761\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0051 - mae: 0.0681 - val_loss: 0.0184 - val_mae: 0.0760\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0184 - val_mae: 0.0760\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0049 - mae: 0.0701 - val_loss: 0.0184 - val_mae: 0.0759\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0184 - val_mae: 0.0759\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0053 - mae: 0.0730 - val_loss: 0.0184 - val_mae: 0.0758\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0183 - val_mae: 0.0758\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0183 - val_mae: 0.0757\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0052 - mae: 0.0727 - val_loss: 0.0183 - val_mae: 0.0757\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0183 - val_mae: 0.0756\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0695 - val_loss: 0.0183 - val_mae: 0.0756\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0051 - mae: 0.0705 - val_loss: 0.0183 - val_mae: 0.0755\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0704 - val_loss: 0.0182 - val_mae: 0.0755\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0666 - val_loss: 0.0182 - val_mae: 0.0754\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0182 - val_mae: 0.0754\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0670 - val_loss: 0.0182 - val_mae: 0.0753\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0182 - val_mae: 0.0753\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0693 - val_loss: 0.0182 - val_mae: 0.0752\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0706 - val_loss: 0.0182 - val_mae: 0.0752\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0656 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0677 - val_loss: 0.0181 - val_mae: 0.0752\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0679 - val_loss: 0.0181 - val_mae: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:24,498] Trial 14 finished with value: 0.07514270395040512 and parameters: {'learning_rate': 4.3829884598771095e-05, 'weight_decay': 1.0768675501384835e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0100 - mae: 0.1083 - val_loss: 0.0252 - val_mae: 0.1202\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0102 - mae: 0.1103 - val_loss: 0.0251 - val_mae: 0.1198\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0103 - mae: 0.1118 - val_loss: 0.0251 - val_mae: 0.1193\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1189\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0100 - mae: 0.1105 - val_loss: 0.0249 - val_mae: 0.1185\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0096 - mae: 0.1061 - val_loss: 0.0249 - val_mae: 0.1181\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1070 - val_loss: 0.0248 - val_mae: 0.1176\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0098 - mae: 0.1075 - val_loss: 0.0247 - val_mae: 0.1172\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0097 - mae: 0.1068 - val_loss: 0.0247 - val_mae: 0.1168\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0100 - mae: 0.1088 - val_loss: 0.0246 - val_mae: 0.1164\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0098 - mae: 0.1057 - val_loss: 0.0246 - val_mae: 0.1160\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0092 - mae: 0.1038 - val_loss: 0.0245 - val_mae: 0.1156\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - mae: 0.1070 - val_loss: 0.0244 - val_mae: 0.1152\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0095 - mae: 0.1025 - val_loss: 0.0244 - val_mae: 0.1147\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1033 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - mae: 0.1056 - val_loss: 0.0243 - val_mae: 0.1139\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1008 - val_loss: 0.0241 - val_mae: 0.1131\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1013 - val_loss: 0.0241 - val_mae: 0.1127\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1020 - val_loss: 0.0240 - val_mae: 0.1123\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0240 - val_mae: 0.1119\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0239 - val_mae: 0.1114\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0239 - val_mae: 0.1110\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0238 - val_mae: 0.1106\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.0997 - val_loss: 0.0238 - val_mae: 0.1102\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0237 - val_mae: 0.1098\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.0990 - val_loss: 0.0236 - val_mae: 0.1094\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0236 - val_mae: 0.1090\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0940 - val_loss: 0.0235 - val_mae: 0.1085\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0235 - val_mae: 0.1082\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1078\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0234 - val_mae: 0.1074\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0965 - val_loss: 0.0233 - val_mae: 0.1070\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0949 - val_loss: 0.0233 - val_mae: 0.1066\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0942 - val_loss: 0.0232 - val_mae: 0.1062\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0960 - val_loss: 0.0232 - val_mae: 0.1058\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0925 - val_loss: 0.0231 - val_mae: 0.1054\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0939 - val_loss: 0.0231 - val_mae: 0.1050\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0958 - val_loss: 0.0231 - val_mae: 0.1046\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0940 - val_loss: 0.0230 - val_mae: 0.1043\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0959 - val_loss: 0.0230 - val_mae: 0.1039\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0966 - val_loss: 0.0229 - val_mae: 0.1036\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0080 - mae: 0.0922 - val_loss: 0.0229 - val_mae: 0.1032\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0907 - val_loss: 0.0228 - val_mae: 0.1028\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0911 - val_loss: 0.0228 - val_mae: 0.1025\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0912 - val_loss: 0.0228 - val_mae: 0.1021\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0928 - val_loss: 0.0227 - val_mae: 0.1018\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0926 - val_loss: 0.0227 - val_mae: 0.1014\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0943 - val_loss: 0.0226 - val_mae: 0.1011\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0226 - val_mae: 0.1008\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0912 - val_loss: 0.0226 - val_mae: 0.1004\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0931 - val_loss: 0.0225 - val_mae: 0.1001\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0225 - val_mae: 0.0998\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.0995\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0082 - mae: 0.0906 - val_loss: 0.0224 - val_mae: 0.0991\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0078 - mae: 0.0897 - val_loss: 0.0224 - val_mae: 0.0988\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0895 - val_loss: 0.0223 - val_mae: 0.0985\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0223 - val_mae: 0.0982\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.0979\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0908 - val_loss: 0.0222 - val_mae: 0.0976\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0885 - val_loss: 0.0222 - val_mae: 0.0973\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0077 - mae: 0.0889 - val_loss: 0.0221 - val_mae: 0.0970\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0080 - mae: 0.0897 - val_loss: 0.0221 - val_mae: 0.0967\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0073 - mae: 0.0866 - val_loss: 0.0221 - val_mae: 0.0964\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0872 - val_loss: 0.0220 - val_mae: 0.0961\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0078 - mae: 0.0912 - val_loss: 0.0220 - val_mae: 0.0958\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0899 - val_loss: 0.0220 - val_mae: 0.0955\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0219 - val_mae: 0.0952\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0898 - val_loss: 0.0219 - val_mae: 0.0948\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0219 - val_mae: 0.0945\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0867 - val_loss: 0.0218 - val_mae: 0.0942\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0871 - val_loss: 0.0218 - val_mae: 0.0939\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0218 - val_mae: 0.0937\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0217 - val_mae: 0.0934\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0072 - mae: 0.0851 - val_loss: 0.0217 - val_mae: 0.0931\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - mae: 0.0829 - val_loss: 0.0217 - val_mae: 0.0927\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0861 - val_loss: 0.0216 - val_mae: 0.0924\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0857 - val_loss: 0.0216 - val_mae: 0.0921\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0068 - mae: 0.0835 - val_loss: 0.0216 - val_mae: 0.0918\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0072 - mae: 0.0844 - val_loss: 0.0215 - val_mae: 0.0915\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0066 - mae: 0.0804 - val_loss: 0.0215 - val_mae: 0.0912\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0214 - val_mae: 0.0909\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0838 - val_loss: 0.0214 - val_mae: 0.0906\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0846 - val_loss: 0.0214 - val_mae: 0.0903\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0213 - val_mae: 0.0900\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0830 - val_loss: 0.0213 - val_mae: 0.0897\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0069 - mae: 0.0831 - val_loss: 0.0213 - val_mae: 0.0894\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0212 - val_mae: 0.0891\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0068 - mae: 0.0827 - val_loss: 0.0212 - val_mae: 0.0888\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0794 - val_loss: 0.0212 - val_mae: 0.0886\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0821 - val_loss: 0.0211 - val_mae: 0.0883\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0820 - val_loss: 0.0211 - val_mae: 0.0880\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0878\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0832 - val_loss: 0.0210 - val_mae: 0.0875\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0809 - val_loss: 0.0210 - val_mae: 0.0873\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0840 - val_loss: 0.0209 - val_mae: 0.0870\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0209 - val_mae: 0.0868\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0062 - mae: 0.0755 - val_loss: 0.0209 - val_mae: 0.0865\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0065 - mae: 0.0801 - val_loss: 0.0208 - val_mae: 0.0863\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0829 - val_loss: 0.0208 - val_mae: 0.0860\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0067 - mae: 0.0815 - val_loss: 0.0208 - val_mae: 0.0858\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0207 - val_mae: 0.0856\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0802 - val_loss: 0.0207 - val_mae: 0.0854\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0763 - val_loss: 0.0206 - val_mae: 0.0851\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0759 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0065 - mae: 0.0790 - val_loss: 0.0206 - val_mae: 0.0847\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0794 - val_loss: 0.0205 - val_mae: 0.0845\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0064 - mae: 0.0798 - val_loss: 0.0205 - val_mae: 0.0843\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0777 - val_loss: 0.0205 - val_mae: 0.0841\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0067 - mae: 0.0820 - val_loss: 0.0204 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.0838\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0204 - val_mae: 0.0836\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0064 - mae: 0.0788 - val_loss: 0.0203 - val_mae: 0.0835\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0203 - val_mae: 0.0833\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0832\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0755 - val_loss: 0.0203 - val_mae: 0.0830\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0202 - val_mae: 0.0829\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0065 - mae: 0.0795 - val_loss: 0.0202 - val_mae: 0.0827\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0780 - val_loss: 0.0202 - val_mae: 0.0826\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0201 - val_mae: 0.0825\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - mae: 0.0752 - val_loss: 0.0201 - val_mae: 0.0823\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0062 - mae: 0.0773 - val_loss: 0.0201 - val_mae: 0.0822\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0201 - val_mae: 0.0821\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0060 - mae: 0.0778 - val_loss: 0.0200 - val_mae: 0.0820\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0055 - mae: 0.0740 - val_loss: 0.0200 - val_mae: 0.0818\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0200 - val_mae: 0.0817\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0774 - val_loss: 0.0200 - val_mae: 0.0816\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0733 - val_loss: 0.0199 - val_mae: 0.0815\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0067 - mae: 0.0801 - val_loss: 0.0199 - val_mae: 0.0814\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0199 - val_mae: 0.0812\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0058 - mae: 0.0745 - val_loss: 0.0199 - val_mae: 0.0811\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0810\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0809\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0762 - val_loss: 0.0198 - val_mae: 0.0808\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0062 - mae: 0.0794 - val_loss: 0.0198 - val_mae: 0.0807\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0700 - val_loss: 0.0197 - val_mae: 0.0806\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0060 - mae: 0.0791 - val_loss: 0.0197 - val_mae: 0.0805\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0785 - val_loss: 0.0197 - val_mae: 0.0803\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0778 - val_loss: 0.0197 - val_mae: 0.0802\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0064 - mae: 0.0773 - val_loss: 0.0197 - val_mae: 0.0801\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0736 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0718 - val_loss: 0.0196 - val_mae: 0.0800\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.0799\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0701 - val_loss: 0.0196 - val_mae: 0.0798\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0752 - val_loss: 0.0196 - val_mae: 0.0797\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0061 - mae: 0.0774 - val_loss: 0.0195 - val_mae: 0.0797\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0735 - val_loss: 0.0195 - val_mae: 0.0796\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0723 - val_loss: 0.0195 - val_mae: 0.0795\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0060 - mae: 0.0756 - val_loss: 0.0195 - val_mae: 0.0795\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0760 - val_loss: 0.0195 - val_mae: 0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:41,001] Trial 15 finished with value: 0.07944000512361526 and parameters: {'learning_rate': 2.767487152987574e-05, 'weight_decay': 2.91625247096876e-08}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1097 - val_loss: 0.0218 - val_mae: 0.1024\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0077 - mae: 0.0878 - val_loss: 0.0203 - val_mae: 0.0898\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0064 - mae: 0.0791 - val_loss: 0.0189 - val_mae: 0.0802\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0689 - val_loss: 0.0175 - val_mae: 0.0827\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0681 - val_loss: 0.0168 - val_mae: 0.0875\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0047 - mae: 0.0746 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mae: 0.0697 - val_loss: 0.0172 - val_mae: 0.0811\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0637 - val_loss: 0.0174 - val_mae: 0.0802\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0174 - val_mae: 0.0806\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0812\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0037 - mae: 0.0599 - val_loss: 0.0171 - val_mae: 0.0824\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0169 - val_mae: 0.0844\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0167 - val_mae: 0.0862\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0878\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - mae: 0.0653 - val_loss: 0.0166 - val_mae: 0.0873\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0861\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0600 - val_loss: 0.0167 - val_mae: 0.0851\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0575 - val_loss: 0.0167 - val_mae: 0.0846\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0578 - val_loss: 0.0164 - val_mae: 0.0849\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0567 - val_loss: 0.0163 - val_mae: 0.0853\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0030 - mae: 0.0575 - val_loss: 0.0162 - val_mae: 0.0859\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - mae: 0.0611 - val_loss: 0.0160 - val_mae: 0.0864\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - mae: 0.0598 - val_loss: 0.0159 - val_mae: 0.0866\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0590 - val_loss: 0.0158 - val_mae: 0.0853\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0573 - val_loss: 0.0158 - val_mae: 0.0831\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - mae: 0.0554 - val_loss: 0.0156 - val_mae: 0.0834\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - mae: 0.0547 - val_loss: 0.0154 - val_mae: 0.0874\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0633 - val_loss: 0.0154 - val_mae: 0.0835\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0540 - val_loss: 0.0156 - val_mae: 0.0805\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0535 - val_loss: 0.0154 - val_mae: 0.0814\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0151 - val_mae: 0.0858\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0152 - val_mae: 0.0830\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - mae: 0.0550 - val_loss: 0.0151 - val_mae: 0.0822\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0531 - val_loss: 0.0149 - val_mae: 0.0841\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0146 - val_mae: 0.0871\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0145 - val_mae: 0.0890\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0025 - mae: 0.0519 - val_loss: 0.0143 - val_mae: 0.0897\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0141 - val_mae: 0.0898\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0505 - val_loss: 0.0139 - val_mae: 0.0897\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0024 - mae: 0.0533 - val_loss: 0.0137 - val_mae: 0.0934\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0022 - mae: 0.0507 - val_loss: 0.0140 - val_mae: 0.0839\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0527 - val_loss: 0.0138 - val_mae: 0.0853\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - mae: 0.0514 - val_loss: 0.0136 - val_mae: 0.0983\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0025 - mae: 0.0539 - val_loss: 0.0138 - val_mae: 0.1029\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0028 - mae: 0.0578 - val_loss: 0.0142 - val_mae: 0.0822\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0027 - mae: 0.0502 - val_loss: 0.0151 - val_mae: 0.0755\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - mae: 0.0493 - val_loss: 0.0155 - val_mae: 0.0748\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0772\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0149 - val_mae: 0.0806\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - mae: 0.0536 - val_loss: 0.0145 - val_mae: 0.0876\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - mae: 0.0543 - val_loss: 0.0144 - val_mae: 0.0916\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - mae: 0.0527 - val_loss: 0.0144 - val_mae: 0.0924\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - mae: 0.0537 - val_loss: 0.0146 - val_mae: 0.0871\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0489 - val_loss: 0.0148 - val_mae: 0.0831\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0474 - val_loss: 0.0150 - val_mae: 0.0815\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0572 - val_loss: 0.0150 - val_mae: 0.0814\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0524 - val_loss: 0.0147 - val_mae: 0.0835\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0145 - val_mae: 0.0872\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0022 - mae: 0.0498 - val_loss: 0.0144 - val_mae: 0.0907\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - mae: 0.0545 - val_loss: 0.0144 - val_mae: 0.0892\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0024 - mae: 0.0523 - val_loss: 0.0147 - val_mae: 0.0835\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.0150 - val_mae: 0.0795\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0020 - mae: 0.0438 - val_loss: 0.0152 - val_mae: 0.0771\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0483 - val_loss: 0.0150 - val_mae: 0.0776\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0147 - val_mae: 0.0799\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0143 - val_mae: 0.0828\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0435 - val_loss: 0.0140 - val_mae: 0.0896\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0476 - val_loss: 0.0138 - val_mae: 0.0924\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0463 - val_loss: 0.0138 - val_mae: 0.0871\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0023 - mae: 0.0510 - val_loss: 0.0137 - val_mae: 0.0869\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0423 - val_loss: 0.0139 - val_mae: 0.0820\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0021 - mae: 0.0447 - val_loss: 0.0139 - val_mae: 0.0817\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mae: 0.0410 - val_loss: 0.0138 - val_mae: 0.0851\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0138 - val_mae: 0.0886\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - mae: 0.0429 - val_loss: 0.0138 - val_mae: 0.0868\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0139 - val_mae: 0.0826\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0418 - val_loss: 0.0139 - val_mae: 0.0821\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0402 - val_loss: 0.0137 - val_mae: 0.0851\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0137 - val_mae: 0.0893\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0017 - mae: 0.0425 - val_loss: 0.0139 - val_mae: 0.0924\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0441 - val_loss: 0.0141 - val_mae: 0.0889\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0015 - mae: 0.0424 - val_loss: 0.0146 - val_mae: 0.0852\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0150 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0403 - val_loss: 0.0151 - val_mae: 0.0875\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0377 - val_loss: 0.0151 - val_mae: 0.0869\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 0.0149 - val_mae: 0.0873\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0399 - val_loss: 0.0147 - val_mae: 0.0856\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0144 - val_mae: 0.0855\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0020 - mae: 0.0438 - val_loss: 0.0142 - val_mae: 0.0892\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0016 - mae: 0.0378 - val_loss: 0.0141 - val_mae: 0.0924\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0020 - mae: 0.0467 - val_loss: 0.0141 - val_mae: 0.0896\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 0.0145 - val_mae: 0.0848\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0379 - val_loss: 0.0149 - val_mae: 0.0824\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0015 - mae: 0.0373 - val_loss: 0.0153 - val_mae: 0.0815\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0016 - mae: 0.0409 - val_loss: 0.0154 - val_mae: 0.0830\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0387 - val_loss: 0.0157 - val_mae: 0.0842\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - mae: 0.0397 - val_loss: 0.0157 - val_mae: 0.0850\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0017 - mae: 0.0419 - val_loss: 0.0156 - val_mae: 0.0887\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0152 - val_mae: 0.0895\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - mae: 0.0356 - val_loss: 0.0148 - val_mae: 0.0900\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0014 - mae: 0.0384 - val_loss: 0.0145 - val_mae: 0.0904\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - mae: 0.0413 - val_loss: 0.0142 - val_mae: 0.0913\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0371 - val_loss: 0.0143 - val_mae: 0.0948\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - mae: 0.0393 - val_loss: 0.0144 - val_mae: 0.0861\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0148 - val_mae: 0.0793\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0152 - val_mae: 0.0769\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 0.0152 - val_mae: 0.0777\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0408 - val_loss: 0.0149 - val_mae: 0.0820\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0013 - mae: 0.0372 - val_loss: 0.0147 - val_mae: 0.0895\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0015 - mae: 0.0407 - val_loss: 0.0148 - val_mae: 0.0930\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0016 - mae: 0.0412 - val_loss: 0.0148 - val_mae: 0.0932\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - mae: 0.0409 - val_loss: 0.0147 - val_mae: 0.0895\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - mae: 0.0380 - val_loss: 0.0148 - val_mae: 0.0881\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0394 - val_loss: 0.0150 - val_mae: 0.0873\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0152 - val_mae: 0.0886\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0012 - mae: 0.0371 - val_loss: 0.0149 - val_mae: 0.0839\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.8490e-04 - mae: 0.0296 - val_loss: 0.0146 - val_mae: 0.0810\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - mae: 0.0378 - val_loss: 0.0145 - val_mae: 0.0800\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0145 - val_mae: 0.0819\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0350 - val_loss: 0.0148 - val_mae: 0.0857\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.8548e-04 - mae: 0.0332 - val_loss: 0.0149 - val_mae: 0.0887\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0141 - val_mae: 0.0888\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.9006e-04 - mae: 0.0311 - val_loss: 0.0138 - val_mae: 0.0878\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - mae: 0.0390 - val_loss: 0.0140 - val_mae: 0.0883\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.6222e-04 - mae: 0.0343 - val_loss: 0.0146 - val_mae: 0.0854\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.8729e-04 - mae: 0.0326 - val_loss: 0.0151 - val_mae: 0.0851\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 8.4718e-04 - mae: 0.0299 - val_loss: 0.0155 - val_mae: 0.0844\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0378 - val_loss: 0.0160 - val_mae: 0.0830\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0163 - val_mae: 0.0821\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 9.6936e-04 - mae: 0.0304 - val_loss: 0.0159 - val_mae: 0.0828\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 7.7649e-04 - mae: 0.0289 - val_loss: 0.0156 - val_mae: 0.0854\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 0.0152 - val_mae: 0.0916\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1835e-04 - mae: 0.0318 - val_loss: 0.0150 - val_mae: 0.0934\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1148e-04 - mae: 0.0333 - val_loss: 0.0151 - val_mae: 0.0898\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 9.8539e-04 - mae: 0.0320 - val_loss: 0.0157 - val_mae: 0.0869\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7770e-04 - mae: 0.0307 - val_loss: 0.0161 - val_mae: 0.0858\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0011 - mae: 0.0337 - val_loss: 0.0158 - val_mae: 0.0876\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.0528e-04 - mae: 0.0322 - val_loss: 0.0157 - val_mae: 0.0913\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.5622e-04 - mae: 0.0336 - val_loss: 0.0158 - val_mae: 0.0910\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 7.8016e-04 - mae: 0.0289 - val_loss: 0.0159 - val_mae: 0.0882\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - mae: 0.0327 - val_loss: 0.0159 - val_mae: 0.0876\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0013 - mae: 0.0348 - val_loss: 0.0164 - val_mae: 0.0872\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.1594e-04 - mae: 0.0295 - val_loss: 0.0169 - val_mae: 0.0873\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.5982e-04 - mae: 0.0311 - val_loss: 0.0174 - val_mae: 0.0897\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 7.7868e-04 - mae: 0.0301 - val_loss: 0.0182 - val_mae: 0.0938\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.2536e-04 - mae: 0.0321 - val_loss: 0.0171 - val_mae: 0.0965\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 0.0154 - val_mae: 0.0966\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 9.5818e-04 - mae: 0.0330 - val_loss: 0.0148 - val_mae: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 18:59:56,378] Trial 16 finished with value: 0.09393008053302765 and parameters: {'learning_rate': 0.0029239353775467212, 'weight_decay': 2.6027070959021956e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0239 - val_mae: 0.1142\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1009 - val_loss: 0.0238 - val_mae: 0.1129\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1011 - val_loss: 0.0236 - val_mae: 0.1116\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0084 - mae: 0.0984 - val_loss: 0.0234 - val_mae: 0.1102\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0232 - val_mae: 0.1088\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0965 - val_loss: 0.0230 - val_mae: 0.1074\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0086 - mae: 0.0965 - val_loss: 0.0228 - val_mae: 0.1061\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0226 - val_mae: 0.1049\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - mae: 0.0926 - val_loss: 0.0223 - val_mae: 0.1026\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0909 - val_loss: 0.0220 - val_mae: 0.1005\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0218 - val_mae: 0.0995\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0876 - val_loss: 0.0217 - val_mae: 0.0987\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0075 - mae: 0.0920 - val_loss: 0.0216 - val_mae: 0.0979\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0896 - val_loss: 0.0214 - val_mae: 0.0971\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0071 - mae: 0.0879 - val_loss: 0.0213 - val_mae: 0.0963\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0898 - val_loss: 0.0212 - val_mae: 0.0956\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0072 - mae: 0.0884 - val_loss: 0.0210 - val_mae: 0.0949\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0850 - val_loss: 0.0209 - val_mae: 0.0942\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0862 - val_loss: 0.0208 - val_mae: 0.0936\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0072 - mae: 0.0842 - val_loss: 0.0207 - val_mae: 0.0930\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0811 - val_loss: 0.0205 - val_mae: 0.0925\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0837 - val_loss: 0.0204 - val_mae: 0.0919\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0831 - val_loss: 0.0203 - val_mae: 0.0913\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0202 - val_mae: 0.0908\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0776 - val_loss: 0.0200 - val_mae: 0.0902\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0065 - mae: 0.0843 - val_loss: 0.0199 - val_mae: 0.0896\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0823 - val_loss: 0.0198 - val_mae: 0.0891\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0059 - mae: 0.0788 - val_loss: 0.0197 - val_mae: 0.0886\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0065 - mae: 0.0824 - val_loss: 0.0196 - val_mae: 0.0880\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0819 - val_loss: 0.0195 - val_mae: 0.0874\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0194 - val_mae: 0.0868\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0795 - val_loss: 0.0194 - val_mae: 0.0862\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0782 - val_loss: 0.0193 - val_mae: 0.0857\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - mae: 0.0782 - val_loss: 0.0192 - val_mae: 0.0851\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0066 - mae: 0.0796 - val_loss: 0.0192 - val_mae: 0.0846\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0058 - mae: 0.0743 - val_loss: 0.0191 - val_mae: 0.0841\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0801 - val_loss: 0.0190 - val_mae: 0.0837\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0056 - mae: 0.0736 - val_loss: 0.0190 - val_mae: 0.0832\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0189 - val_mae: 0.0828\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0061 - mae: 0.0811 - val_loss: 0.0189 - val_mae: 0.0825\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0189 - val_mae: 0.0821\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0056 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0817\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0053 - mae: 0.0729 - val_loss: 0.0188 - val_mae: 0.0814\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0063 - mae: 0.0773 - val_loss: 0.0188 - val_mae: 0.0811\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0058 - mae: 0.0748 - val_loss: 0.0188 - val_mae: 0.0809\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0060 - mae: 0.0774 - val_loss: 0.0187 - val_mae: 0.0806\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0187 - val_mae: 0.0804\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0187 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0063 - mae: 0.0775 - val_loss: 0.0187 - val_mae: 0.0800\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0062 - mae: 0.0762 - val_loss: 0.0186 - val_mae: 0.0798\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0063 - mae: 0.0803 - val_loss: 0.0186 - val_mae: 0.0797\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0186 - val_mae: 0.0795\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0054 - mae: 0.0736 - val_loss: 0.0186 - val_mae: 0.0794\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0051 - mae: 0.0722 - val_loss: 0.0185 - val_mae: 0.0792\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0051 - mae: 0.0700 - val_loss: 0.0185 - val_mae: 0.0791\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0055 - mae: 0.0743 - val_loss: 0.0184 - val_mae: 0.0789\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0055 - mae: 0.0737 - val_loss: 0.0184 - val_mae: 0.0788\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0053 - mae: 0.0724 - val_loss: 0.0183 - val_mae: 0.0786\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0052 - mae: 0.0710 - val_loss: 0.0183 - val_mae: 0.0785\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0050 - mae: 0.0730 - val_loss: 0.0182 - val_mae: 0.0783\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0182 - val_mae: 0.0782\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0049 - mae: 0.0696 - val_loss: 0.0181 - val_mae: 0.0780\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0066 - mae: 0.0788 - val_loss: 0.0181 - val_mae: 0.0779\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0050 - mae: 0.0743 - val_loss: 0.0180 - val_mae: 0.0778\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0180 - val_mae: 0.0777\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0053 - mae: 0.0718 - val_loss: 0.0180 - val_mae: 0.0776\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0049 - mae: 0.0683 - val_loss: 0.0179 - val_mae: 0.0775\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0717 - val_loss: 0.0179 - val_mae: 0.0774\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0054 - mae: 0.0726 - val_loss: 0.0179 - val_mae: 0.0772\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0062 - mae: 0.0757 - val_loss: 0.0179 - val_mae: 0.0771\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0179 - val_mae: 0.0770\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0053 - mae: 0.0722 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0178 - val_mae: 0.0767\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0050 - mae: 0.0696 - val_loss: 0.0178 - val_mae: 0.0766\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0178 - val_mae: 0.0764\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0045 - mae: 0.0665 - val_loss: 0.0178 - val_mae: 0.0763\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0055 - mae: 0.0715 - val_loss: 0.0178 - val_mae: 0.0762\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0054 - mae: 0.0718 - val_loss: 0.0178 - val_mae: 0.0760\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0054 - mae: 0.0712 - val_loss: 0.0177 - val_mae: 0.0759\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - mae: 0.0672 - val_loss: 0.0177 - val_mae: 0.0758\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0177 - val_mae: 0.0757\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0044 - mae: 0.0667 - val_loss: 0.0177 - val_mae: 0.0756\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0046 - mae: 0.0682 - val_loss: 0.0177 - val_mae: 0.0755\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0051 - mae: 0.0697 - val_loss: 0.0176 - val_mae: 0.0754\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0176 - val_mae: 0.0753\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0049 - mae: 0.0689 - val_loss: 0.0176 - val_mae: 0.0752\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0708 - val_loss: 0.0175 - val_mae: 0.0752\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0726 - val_loss: 0.0175 - val_mae: 0.0751\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0685 - val_loss: 0.0175 - val_mae: 0.0751\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0696 - val_loss: 0.0175 - val_mae: 0.0750\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0041 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0681 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0655 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0719 - val_loss: 0.0174 - val_mae: 0.0750\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0663 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0045 - mae: 0.0669 - val_loss: 0.0173 - val_mae: 0.0750\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0173 - val_mae: 0.0751\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0652 - val_loss: 0.0172 - val_mae: 0.0751\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0751\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0171 - val_mae: 0.0752\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0657 - val_loss: 0.0171 - val_mae: 0.0753\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0662 - val_loss: 0.0171 - val_mae: 0.0754\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0170 - val_mae: 0.0754\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0044 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0755\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0170 - val_mae: 0.0755\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0645 - val_loss: 0.0170 - val_mae: 0.0756\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0756\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0653 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0046 - mae: 0.0658 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0041 - mae: 0.0637 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0630 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0677 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0638 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0170 - val_mae: 0.0757\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0050 - mae: 0.0700 - val_loss: 0.0170 - val_mae: 0.0758\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0629 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0592 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.0761\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0671 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - mae: 0.0606 - val_loss: 0.0168 - val_mae: 0.0763\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0046 - mae: 0.0665 - val_loss: 0.0168 - val_mae: 0.0763\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0168 - val_mae: 0.0762\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0038 - mae: 0.0633 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0652 - val_loss: 0.0168 - val_mae: 0.0761\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0634 - val_loss: 0.0168 - val_mae: 0.0760\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0662 - val_loss: 0.0168 - val_mae: 0.0759\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0042 - mae: 0.0655 - val_loss: 0.0168 - val_mae: 0.0758\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0040 - mae: 0.0623 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0047 - mae: 0.0654 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - mae: 0.0589 - val_loss: 0.0169 - val_mae: 0.0757\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0050 - mae: 0.0662 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0618 - val_loss: 0.0169 - val_mae: 0.0758\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0630 - val_loss: 0.0169 - val_mae: 0.0759\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:12,281] Trial 17 finished with value: 0.07601465284824371 and parameters: {'learning_rate': 8.53920780601743e-05, 'weight_decay': 1.5440012645274747e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0119 - mae: 0.1236 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0112 - mae: 0.1172 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0110 - mae: 0.1212 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0115 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1188 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0122 - mae: 0.1250 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1216 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1161 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1210 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1215 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0121 - mae: 0.1252 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0116 - mae: 0.1217 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0113 - mae: 0.1200 - val_loss: 0.0263 - val_mae: 0.1328\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1195 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1235 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0115 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1175 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0111 - mae: 0.1185 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0122 - mae: 0.1234 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1213 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0113 - mae: 0.1196 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0119 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0117 - mae: 0.1229 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0120 - mae: 0.1246 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0113 - mae: 0.1210 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0118 - mae: 0.1227 - val_loss: 0.0263 - val_mae: 0.1327\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0120 - mae: 0.1235 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1211 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0112 - mae: 0.1193 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1168 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1209 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0118 - mae: 0.1212 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0105 - mae: 0.1157 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0110 - mae: 0.1189 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0118 - mae: 0.1198 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0119 - mae: 0.1243 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1161 - val_loss: 0.0263 - val_mae: 0.1326\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1203 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0118 - mae: 0.1253 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0117 - mae: 0.1239 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1269 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0115 - mae: 0.1223 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0119 - mae: 0.1250 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0118 - mae: 0.1249 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1163 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1214 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1202 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1219 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1207 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1217 - val_loss: 0.0263 - val_mae: 0.1325\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0104 - mae: 0.1151 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1174 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1189 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1215 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1208 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1206 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0106 - mae: 0.1168 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1182 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0108 - mae: 0.1163 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0115 - mae: 0.1193 - val_loss: 0.0263 - val_mae: 0.1324\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1197 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0109 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0114 - mae: 0.1231 - val_loss: 0.0262 - val_mae: 0.1324\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0118 - mae: 0.1219 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0100 - mae: 0.1141 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0121 - mae: 0.1245 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1201 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0110 - mae: 0.1170 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1191 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0110 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1228 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0116 - mae: 0.1238 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0124 - mae: 0.1251 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0115 - mae: 0.1200 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1208 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1267 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0115 - mae: 0.1201 - val_loss: 0.0262 - val_mae: 0.1323\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0116 - mae: 0.1215 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1210 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1167 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0119 - mae: 0.1252 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0117 - mae: 0.1224 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0116 - mae: 0.1204 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0116 - mae: 0.1241 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1155 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0106 - mae: 0.1169 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1151 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0112 - mae: 0.1203 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1157 - val_loss: 0.0262 - val_mae: 0.1322\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0123 - mae: 0.1255 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0121 - mae: 0.1223 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.0115 - mae: 0.1218 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0108 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0114 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0119 - mae: 0.1240 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0107 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0112 - mae: 0.1193 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0112 - mae: 0.1218 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0117 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0114 - mae: 0.1226 - val_loss: 0.0262 - val_mae: 0.1321\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0110 - mae: 0.1180 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0114 - mae: 0.1181 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0108 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0111 - mae: 0.1184 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0114 - mae: 0.1208 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1204 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0113 - mae: 0.1199 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1187 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1212 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1190 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - mae: 0.1198 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0110 - mae: 0.1152 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0109 - mae: 0.1179 - val_loss: 0.0262 - val_mae: 0.1320\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0113 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0107 - mae: 0.1171 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0113 - mae: 0.1220 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0120 - mae: 0.1239 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0109 - mae: 0.1185 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1155 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0114 - mae: 0.1215 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0108 - mae: 0.1186 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0120 - mae: 0.1246 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0113 - mae: 0.1217 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1195 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0116 - mae: 0.1217 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1179 - val_loss: 0.0262 - val_mae: 0.1319\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1203 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0108 - mae: 0.1150 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0115 - mae: 0.1195 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110 - mae: 0.1172 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0109 - mae: 0.1182 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0119 - mae: 0.1233 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0117 - mae: 0.1196 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0106 - mae: 0.1176 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0121 - mae: 0.1251 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0112 - mae: 0.1207 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0115 - mae: 0.1189 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0112 - mae: 0.1178 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0114 - mae: 0.1220 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0108 - mae: 0.1177 - val_loss: 0.0262 - val_mae: 0.1318\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0115 - mae: 0.1196 - val_loss: 0.0262 - val_mae: 0.1317\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0262 - val_mae: 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:27,718] Trial 18 finished with value: 0.131738543510437 and parameters: {'learning_rate': 3.5226798981107034e-07, 'weight_decay': 2.3544590325283316e-07}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0238 - val_mae: 0.1204\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1052 - val_loss: 0.0238 - val_mae: 0.1203\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1032 - val_loss: 0.0238 - val_mae: 0.1202\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0238 - val_mae: 0.1202\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1063 - val_loss: 0.0238 - val_mae: 0.1201\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0098 - mae: 0.1070 - val_loss: 0.0237 - val_mae: 0.1200\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0093 - mae: 0.1055 - val_loss: 0.0237 - val_mae: 0.1199\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1041 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0092 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1198\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0091 - mae: 0.1043 - val_loss: 0.0237 - val_mae: 0.1197\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0096 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1196\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0096 - mae: 0.1058 - val_loss: 0.0237 - val_mae: 0.1195\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0091 - mae: 0.1037 - val_loss: 0.0237 - val_mae: 0.1194\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0237 - val_mae: 0.1193\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1052 - val_loss: 0.0237 - val_mae: 0.1193\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0237 - val_mae: 0.1192\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0236 - val_mae: 0.1191\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0092 - mae: 0.1058 - val_loss: 0.0236 - val_mae: 0.1190\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0095 - mae: 0.1050 - val_loss: 0.0236 - val_mae: 0.1189\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1023 - val_loss: 0.0236 - val_mae: 0.1189\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1028 - val_loss: 0.0236 - val_mae: 0.1188\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0236 - val_mae: 0.1187\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0236 - val_mae: 0.1186\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1049 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1050 - val_loss: 0.0236 - val_mae: 0.1185\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0236 - val_mae: 0.1184\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1016 - val_loss: 0.0236 - val_mae: 0.1183\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1033 - val_loss: 0.0235 - val_mae: 0.1182\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0089 - mae: 0.1030 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0093 - mae: 0.1031 - val_loss: 0.0235 - val_mae: 0.1181\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0235 - val_mae: 0.1180\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0092 - mae: 0.1047 - val_loss: 0.0235 - val_mae: 0.1179\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0235 - val_mae: 0.1178\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1039 - val_loss: 0.0235 - val_mae: 0.1177\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0235 - val_mae: 0.1177\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0235 - val_mae: 0.1176\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1039 - val_loss: 0.0235 - val_mae: 0.1175\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0094 - mae: 0.1048 - val_loss: 0.0235 - val_mae: 0.1174\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0090 - mae: 0.1030 - val_loss: 0.0234 - val_mae: 0.1174\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1039 - val_loss: 0.0234 - val_mae: 0.1173\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0234 - val_mae: 0.1172\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0234 - val_mae: 0.1171\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1031 - val_loss: 0.0234 - val_mae: 0.1171\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1021 - val_loss: 0.0234 - val_mae: 0.1170\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1018 - val_loss: 0.0234 - val_mae: 0.1169\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0234 - val_mae: 0.1168\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.0996 - val_loss: 0.0234 - val_mae: 0.1168\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1167\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0234 - val_mae: 0.1166\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1014 - val_loss: 0.0234 - val_mae: 0.1165\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - mae: 0.1027 - val_loss: 0.0233 - val_mae: 0.1165\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0233 - val_mae: 0.1164\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0089 - mae: 0.1013 - val_loss: 0.0233 - val_mae: 0.1163\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.1002 - val_loss: 0.0233 - val_mae: 0.1163\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1016 - val_loss: 0.0233 - val_mae: 0.1162\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1033 - val_loss: 0.0233 - val_mae: 0.1161\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093 - mae: 0.1024 - val_loss: 0.0233 - val_mae: 0.1160\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1001 - val_loss: 0.0233 - val_mae: 0.1160\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0090 - mae: 0.1012 - val_loss: 0.0233 - val_mae: 0.1159\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1014 - val_loss: 0.0233 - val_mae: 0.1158\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0233 - val_mae: 0.1158\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1007 - val_loss: 0.0233 - val_mae: 0.1157\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1016 - val_loss: 0.0233 - val_mae: 0.1156\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - mae: 0.1025 - val_loss: 0.0232 - val_mae: 0.1156\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1155\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1017 - val_loss: 0.0232 - val_mae: 0.1154\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1036 - val_loss: 0.0232 - val_mae: 0.1154\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0991 - val_loss: 0.0232 - val_mae: 0.1153\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0232 - val_mae: 0.1152\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1019 - val_loss: 0.0232 - val_mae: 0.1151\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0090 - mae: 0.1001 - val_loss: 0.0232 - val_mae: 0.1151\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0232 - val_mae: 0.1150\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0996 - val_loss: 0.0232 - val_mae: 0.1149\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.1000 - val_loss: 0.0232 - val_mae: 0.1149\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1008 - val_loss: 0.0232 - val_mae: 0.1148\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0232 - val_mae: 0.1147\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1017 - val_loss: 0.0231 - val_mae: 0.1147\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0231 - val_mae: 0.1146\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1002 - val_loss: 0.0231 - val_mae: 0.1146\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0231 - val_mae: 0.1145\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0231 - val_mae: 0.1144\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - mae: 0.0997 - val_loss: 0.0231 - val_mae: 0.1144\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0231 - val_mae: 0.1143\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0231 - val_mae: 0.1142\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0090 - mae: 0.1031 - val_loss: 0.0231 - val_mae: 0.1142\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0090 - mae: 0.1006 - val_loss: 0.0231 - val_mae: 0.1141\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0231 - val_mae: 0.1140\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1012 - val_loss: 0.0231 - val_mae: 0.1140\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1010 - val_loss: 0.0231 - val_mae: 0.1139\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0979 - val_loss: 0.0231 - val_mae: 0.1138\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1005 - val_loss: 0.0230 - val_mae: 0.1138\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0230 - val_mae: 0.1137\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1137\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0086 - mae: 0.0985 - val_loss: 0.0230 - val_mae: 0.1136\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0088 - mae: 0.1013 - val_loss: 0.0230 - val_mae: 0.1135\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.1004 - val_loss: 0.0230 - val_mae: 0.1135\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0986 - val_loss: 0.0230 - val_mae: 0.1134\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0987 - val_loss: 0.0230 - val_mae: 0.1133\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1133\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0230 - val_mae: 0.1132\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0230 - val_mae: 0.1132\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0230 - val_mae: 0.1131\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0981 - val_loss: 0.0230 - val_mae: 0.1130\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.0989 - val_loss: 0.0229 - val_mae: 0.1130\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0086 - mae: 0.0966 - val_loss: 0.0229 - val_mae: 0.1129\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0993 - val_loss: 0.0229 - val_mae: 0.1128\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.0982 - val_loss: 0.0229 - val_mae: 0.1128\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.0990 - val_loss: 0.0229 - val_mae: 0.1127\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0984 - val_loss: 0.0229 - val_mae: 0.1127\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0088 - mae: 0.0997 - val_loss: 0.0229 - val_mae: 0.1126\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.0998 - val_loss: 0.0229 - val_mae: 0.1126\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.1012 - val_loss: 0.0229 - val_mae: 0.1125\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0986 - val_loss: 0.0229 - val_mae: 0.1124\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1124\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0976 - val_loss: 0.0229 - val_mae: 0.1123\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0978 - val_loss: 0.0229 - val_mae: 0.1123\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0229 - val_mae: 0.1122\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0987 - val_loss: 0.0229 - val_mae: 0.1122\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0087 - mae: 0.1001 - val_loss: 0.0229 - val_mae: 0.1121\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0964 - val_loss: 0.0228 - val_mae: 0.1121\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0966 - val_loss: 0.0228 - val_mae: 0.1120\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0983 - val_loss: 0.0228 - val_mae: 0.1119\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0086 - mae: 0.0969 - val_loss: 0.0228 - val_mae: 0.1119\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0228 - val_mae: 0.1118\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0228 - val_mae: 0.1118\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0988 - val_loss: 0.0228 - val_mae: 0.1117\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0084 - mae: 0.0963 - val_loss: 0.0228 - val_mae: 0.1117\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0085 - mae: 0.0979 - val_loss: 0.0228 - val_mae: 0.1116\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0991 - val_loss: 0.0228 - val_mae: 0.1116\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0228 - val_mae: 0.1115\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0086 - mae: 0.0971 - val_loss: 0.0228 - val_mae: 0.1114\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0980 - val_loss: 0.0228 - val_mae: 0.1114\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0967 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0088 - mae: 0.0986 - val_loss: 0.0228 - val_mae: 0.1113\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.0975 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0087 - mae: 0.0982 - val_loss: 0.0228 - val_mae: 0.1112\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0965 - val_loss: 0.0227 - val_mae: 0.1111\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0951 - val_loss: 0.0227 - val_mae: 0.1110\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.0981 - val_loss: 0.0227 - val_mae: 0.1110\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0085 - mae: 0.0968 - val_loss: 0.0227 - val_mae: 0.1109\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0081 - mae: 0.0971 - val_loss: 0.0227 - val_mae: 0.1109\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0944 - val_loss: 0.0227 - val_mae: 0.1108\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0948 - val_loss: 0.0227 - val_mae: 0.1108\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0082 - mae: 0.0958 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0970 - val_loss: 0.0227 - val_mae: 0.1107\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.1013 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0975 - val_loss: 0.0227 - val_mae: 0.1105\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0963 - val_loss: 0.0227 - val_mae: 0.1104\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0227 - val_mae: 0.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:42,926] Trial 19 finished with value: 0.11038880795240402 and parameters: {'learning_rate': 6.2991928017388976e-06, 'weight_decay': 0.0028634289587533748}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0095 - mae: 0.1090 - val_loss: 0.0241 - val_mae: 0.1207\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0097 - mae: 0.1097 - val_loss: 0.0240 - val_mae: 0.1200\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0093 - mae: 0.1067 - val_loss: 0.0239 - val_mae: 0.1192\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0095 - mae: 0.1072 - val_loss: 0.0238 - val_mae: 0.1184\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0093 - mae: 0.1059 - val_loss: 0.0237 - val_mae: 0.1176\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0089 - mae: 0.1040 - val_loss: 0.0237 - val_mae: 0.1168\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1035 - val_loss: 0.0236 - val_mae: 0.1160\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0086 - mae: 0.1021 - val_loss: 0.0235 - val_mae: 0.1152\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0087 - mae: 0.1015 - val_loss: 0.0234 - val_mae: 0.1145\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0993 - val_loss: 0.0233 - val_mae: 0.1138\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0995 - val_loss: 0.0232 - val_mae: 0.1131\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0083 - mae: 0.0983 - val_loss: 0.0231 - val_mae: 0.1123\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0980 - val_loss: 0.0231 - val_mae: 0.1116\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0230 - val_mae: 0.1108\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0968 - val_loss: 0.0229 - val_mae: 0.1100\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0938 - val_loss: 0.0228 - val_mae: 0.1092\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0959 - val_loss: 0.0227 - val_mae: 0.1084\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0965 - val_loss: 0.0226 - val_mae: 0.1076\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0225 - val_mae: 0.1068\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0224 - val_mae: 0.1060\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0924 - val_loss: 0.0223 - val_mae: 0.1052\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0077 - mae: 0.0920 - val_loss: 0.0222 - val_mae: 0.1044\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0079 - mae: 0.0936 - val_loss: 0.0222 - val_mae: 0.1037\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0923 - val_loss: 0.0221 - val_mae: 0.1029\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0220 - val_mae: 0.1022\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0072 - mae: 0.0885 - val_loss: 0.0219 - val_mae: 0.1014\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0878 - val_loss: 0.0218 - val_mae: 0.1006\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0217 - val_mae: 0.0998\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0073 - mae: 0.0879 - val_loss: 0.0216 - val_mae: 0.0990\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0865 - val_loss: 0.0215 - val_mae: 0.0982\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0071 - mae: 0.0872 - val_loss: 0.0214 - val_mae: 0.0974\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0839 - val_loss: 0.0212 - val_mae: 0.0965\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0211 - val_mae: 0.0957\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0823 - val_loss: 0.0210 - val_mae: 0.0948\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0065 - mae: 0.0824 - val_loss: 0.0209 - val_mae: 0.0939\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - mae: 0.0834 - val_loss: 0.0208 - val_mae: 0.0931\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0804 - val_loss: 0.0207 - val_mae: 0.0923\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0063 - mae: 0.0806 - val_loss: 0.0205 - val_mae: 0.0915\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0808 - val_loss: 0.0204 - val_mae: 0.0907\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0064 - mae: 0.0817 - val_loss: 0.0203 - val_mae: 0.0901\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0060 - mae: 0.0793 - val_loss: 0.0202 - val_mae: 0.0896\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0063 - mae: 0.0801 - val_loss: 0.0200 - val_mae: 0.0890\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0058 - mae: 0.0786 - val_loss: 0.0199 - val_mae: 0.0885\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0757 - val_loss: 0.0198 - val_mae: 0.0880\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0197 - val_mae: 0.0875\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0778 - val_loss: 0.0196 - val_mae: 0.0870\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0194 - val_mae: 0.0865\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0765 - val_loss: 0.0193 - val_mae: 0.0860\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0058 - mae: 0.0750 - val_loss: 0.0192 - val_mae: 0.0855\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0766 - val_loss: 0.0191 - val_mae: 0.0851\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0051 - mae: 0.0726 - val_loss: 0.0190 - val_mae: 0.0847\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0758 - val_loss: 0.0189 - val_mae: 0.0843\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0057 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0839\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0052 - mae: 0.0730 - val_loss: 0.0188 - val_mae: 0.0837\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - mae: 0.0773 - val_loss: 0.0187 - val_mae: 0.0834\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0051 - mae: 0.0714 - val_loss: 0.0186 - val_mae: 0.0832\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0717 - val_loss: 0.0186 - val_mae: 0.0830\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0723 - val_loss: 0.0186 - val_mae: 0.0828\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0056 - mae: 0.0756 - val_loss: 0.0185 - val_mae: 0.0825\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0719 - val_loss: 0.0185 - val_mae: 0.0823\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0726 - val_loss: 0.0184 - val_mae: 0.0821\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0052 - mae: 0.0767 - val_loss: 0.0184 - val_mae: 0.0819\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0184 - val_mae: 0.0817\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0714 - val_loss: 0.0183 - val_mae: 0.0815\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0047 - mae: 0.0709 - val_loss: 0.0183 - val_mae: 0.0813\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0047 - mae: 0.0681 - val_loss: 0.0183 - val_mae: 0.0811\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0182 - val_mae: 0.0810\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0182 - val_mae: 0.0809\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0044 - mae: 0.0668 - val_loss: 0.0181 - val_mae: 0.0808\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0670 - val_loss: 0.0180 - val_mae: 0.0807\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0692 - val_loss: 0.0180 - val_mae: 0.0806\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0049 - mae: 0.0704 - val_loss: 0.0179 - val_mae: 0.0805\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0049 - mae: 0.0697 - val_loss: 0.0179 - val_mae: 0.0804\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0178 - val_mae: 0.0803\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0046 - mae: 0.0691 - val_loss: 0.0178 - val_mae: 0.0802\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0627 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0675 - val_loss: 0.0177 - val_mae: 0.0802\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0044 - mae: 0.0666 - val_loss: 0.0176 - val_mae: 0.0802\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0651 - val_loss: 0.0176 - val_mae: 0.0801\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0045 - mae: 0.0686 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0699 - val_loss: 0.0175 - val_mae: 0.0801\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0048 - mae: 0.0694 - val_loss: 0.0175 - val_mae: 0.0800\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0633 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0799\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0048 - mae: 0.0675 - val_loss: 0.0174 - val_mae: 0.0798\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0692 - val_loss: 0.0174 - val_mae: 0.0797\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0624 - val_loss: 0.0173 - val_mae: 0.0797\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0626 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0173 - val_mae: 0.0796\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0038 - mae: 0.0640 - val_loss: 0.0173 - val_mae: 0.0795\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0038 - mae: 0.0646 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0043 - mae: 0.0661 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0047 - mae: 0.0664 - val_loss: 0.0173 - val_mae: 0.0794\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - mae: 0.0653 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0793\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0039 - mae: 0.0656 - val_loss: 0.0173 - val_mae: 0.0792\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0039 - mae: 0.0625 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0044 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - mae: 0.0618 - val_loss: 0.0172 - val_mae: 0.0790\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0619 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0665 - val_loss: 0.0171 - val_mae: 0.0791\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0048 - mae: 0.0706 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0648 - val_loss: 0.0171 - val_mae: 0.0789\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0638 - val_loss: 0.0171 - val_mae: 0.0788\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0040 - mae: 0.0602 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0043 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0788\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0655 - val_loss: 0.0169 - val_mae: 0.0787\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0660 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0786\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0614 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0656 - val_loss: 0.0168 - val_mae: 0.0785\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0045 - mae: 0.0668 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0034 - mae: 0.0584 - val_loss: 0.0168 - val_mae: 0.0783\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0782\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0043 - mae: 0.0641 - val_loss: 0.0167 - val_mae: 0.0782\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0622 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - mae: 0.0609 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - mae: 0.0611 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0647 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0040 - mae: 0.0653 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - mae: 0.0678 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0631 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0040 - mae: 0.0639 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0039 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0609 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0597 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - mae: 0.0591 - val_loss: 0.0169 - val_mae: 0.0780\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0628 - val_loss: 0.0169 - val_mae: 0.0781\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0043 - mae: 0.0646 - val_loss: 0.0169 - val_mae: 0.0782\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0783\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0644 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0617 - val_loss: 0.0169 - val_mae: 0.0785\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0037 - mae: 0.0598 - val_loss: 0.0168 - val_mae: 0.0786\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - mae: 0.0601 - val_loss: 0.0168 - val_mae: 0.0788\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - mae: 0.0621 - val_loss: 0.0168 - val_mae: 0.0789\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0168 - val_mae: 0.0790\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - mae: 0.0604 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0036 - mae: 0.0610 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0792\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0615 - val_loss: 0.0167 - val_mae: 0.0792\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0167 - val_mae: 0.0793\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0578 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0561 - val_loss: 0.0166 - val_mae: 0.0794\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0166 - val_mae: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:00:58,436] Trial 20 finished with value: 0.07950785011053085 and parameters: {'learning_rate': 0.00010968476219703535, 'weight_decay': 0.0031104598274814352}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0107 - mae: 0.1130 - val_loss: 0.0254 - val_mae: 0.1208\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0107 - mae: 0.1132 - val_loss: 0.0250 - val_mae: 0.1189\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0097 - mae: 0.1074 - val_loss: 0.0247 - val_mae: 0.1170\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0103 - mae: 0.1077 - val_loss: 0.0244 - val_mae: 0.1152\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0241 - val_mae: 0.1133\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0092 - mae: 0.1019 - val_loss: 0.0238 - val_mae: 0.1116\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0959 - val_loss: 0.0235 - val_mae: 0.1100\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0084 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1086\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1072\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1059\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0911 - val_loss: 0.0227 - val_mae: 0.1047\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0882 - val_loss: 0.0225 - val_mae: 0.1035\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0075 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0074 - mae: 0.0879 - val_loss: 0.0222 - val_mae: 0.1010\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0220 - val_mae: 0.0999\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0860 - val_loss: 0.0218 - val_mae: 0.0987\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0857 - val_loss: 0.0217 - val_mae: 0.0976\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0857 - val_loss: 0.0215 - val_mae: 0.0964\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0072 - mae: 0.0852 - val_loss: 0.0214 - val_mae: 0.0953\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - mae: 0.0835 - val_loss: 0.0212 - val_mae: 0.0941\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0070 - mae: 0.0866 - val_loss: 0.0211 - val_mae: 0.0930\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0787 - val_loss: 0.0209 - val_mae: 0.0919\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0828 - val_loss: 0.0208 - val_mae: 0.0910\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0065 - mae: 0.0789 - val_loss: 0.0207 - val_mae: 0.0900\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0065 - mae: 0.0799 - val_loss: 0.0205 - val_mae: 0.0890\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0060 - mae: 0.0769 - val_loss: 0.0204 - val_mae: 0.0880\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0065 - mae: 0.0794 - val_loss: 0.0203 - val_mae: 0.0871\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0060 - mae: 0.0753 - val_loss: 0.0201 - val_mae: 0.0862\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0200 - val_mae: 0.0853\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0059 - mae: 0.0729 - val_loss: 0.0198 - val_mae: 0.0844\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - mae: 0.0765 - val_loss: 0.0197 - val_mae: 0.0836\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0059 - mae: 0.0774 - val_loss: 0.0196 - val_mae: 0.0829\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0195 - val_mae: 0.0821\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0052 - mae: 0.0697 - val_loss: 0.0193 - val_mae: 0.0814\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0709 - val_loss: 0.0192 - val_mae: 0.0808\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0051 - mae: 0.0711 - val_loss: 0.0191 - val_mae: 0.0802\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0054 - mae: 0.0709 - val_loss: 0.0189 - val_mae: 0.0796\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0740 - val_loss: 0.0188 - val_mae: 0.0791\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0734 - val_loss: 0.0187 - val_mae: 0.0787\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - mae: 0.0679 - val_loss: 0.0186 - val_mae: 0.0784\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0732 - val_loss: 0.0185 - val_mae: 0.0782\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0736 - val_loss: 0.0184 - val_mae: 0.0780\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - mae: 0.0695 - val_loss: 0.0183 - val_mae: 0.0781\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0053 - mae: 0.0716 - val_loss: 0.0182 - val_mae: 0.0781\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0052 - mae: 0.0709 - val_loss: 0.0181 - val_mae: 0.0781\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0636 - val_loss: 0.0180 - val_mae: 0.0781\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0050 - mae: 0.0741 - val_loss: 0.0180 - val_mae: 0.0780\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0055 - mae: 0.0730 - val_loss: 0.0179 - val_mae: 0.0780\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0053 - mae: 0.0725 - val_loss: 0.0179 - val_mae: 0.0779\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0053 - mae: 0.0713 - val_loss: 0.0178 - val_mae: 0.0778\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0049 - mae: 0.0724 - val_loss: 0.0178 - val_mae: 0.0776\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0048 - mae: 0.0686 - val_loss: 0.0178 - val_mae: 0.0775\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0044 - mae: 0.0649 - val_loss: 0.0178 - val_mae: 0.0773\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0050 - mae: 0.0682 - val_loss: 0.0178 - val_mae: 0.0772\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0041 - mae: 0.0603 - val_loss: 0.0178 - val_mae: 0.0771\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0649 - val_loss: 0.0178 - val_mae: 0.0770\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0178 - val_mae: 0.0769\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0049 - mae: 0.0655 - val_loss: 0.0178 - val_mae: 0.0768\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0049 - mae: 0.0670 - val_loss: 0.0178 - val_mae: 0.0767\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0045 - mae: 0.0655 - val_loss: 0.0177 - val_mae: 0.0767\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0045 - mae: 0.0642 - val_loss: 0.0177 - val_mae: 0.0766\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - mae: 0.0647 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0766\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0043 - mae: 0.0660 - val_loss: 0.0175 - val_mae: 0.0765\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0047 - mae: 0.0654 - val_loss: 0.0174 - val_mae: 0.0765\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0618 - val_loss: 0.0174 - val_mae: 0.0766\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0044 - mae: 0.0647 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0042 - mae: 0.0645 - val_loss: 0.0173 - val_mae: 0.0766\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0673 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0173 - val_mae: 0.0765\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0627 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0655 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0043 - mae: 0.0650 - val_loss: 0.0173 - val_mae: 0.0764\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0172 - val_mae: 0.0764\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0605 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0044 - mae: 0.0648 - val_loss: 0.0172 - val_mae: 0.0767\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0039 - mae: 0.0610 - val_loss: 0.0172 - val_mae: 0.0769\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0600 - val_loss: 0.0172 - val_mae: 0.0771\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0605 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0171 - val_mae: 0.0775\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0045 - mae: 0.0666 - val_loss: 0.0171 - val_mae: 0.0777\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0045 - mae: 0.0689 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0046 - mae: 0.0677 - val_loss: 0.0170 - val_mae: 0.0779\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0041 - mae: 0.0621 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0038 - mae: 0.0617 - val_loss: 0.0170 - val_mae: 0.0779\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0572 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0040 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0776\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0169 - val_mae: 0.0777\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - mae: 0.0602 - val_loss: 0.0169 - val_mae: 0.0778\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0039 - mae: 0.0590 - val_loss: 0.0169 - val_mae: 0.0779\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0035 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0779\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0033 - mae: 0.0580 - val_loss: 0.0168 - val_mae: 0.0780\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0045 - mae: 0.0657 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - mae: 0.0607 - val_loss: 0.0167 - val_mae: 0.0780\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0648 - val_loss: 0.0167 - val_mae: 0.0779\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0649 - val_loss: 0.0167 - val_mae: 0.0775\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0042 - mae: 0.0620 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0034 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0039 - mae: 0.0619 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0039 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0043 - mae: 0.0630 - val_loss: 0.0168 - val_mae: 0.0767\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0595 - val_loss: 0.0168 - val_mae: 0.0768\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - mae: 0.0597 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0589 - val_loss: 0.0167 - val_mae: 0.0771\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - mae: 0.0610 - val_loss: 0.0166 - val_mae: 0.0772\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - mae: 0.0603 - val_loss: 0.0166 - val_mae: 0.0774\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0036 - mae: 0.0567 - val_loss: 0.0166 - val_mae: 0.0776\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0606 - val_loss: 0.0165 - val_mae: 0.0777\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0591 - val_loss: 0.0165 - val_mae: 0.0780\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0637 - val_loss: 0.0164 - val_mae: 0.0781\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0041 - mae: 0.0624 - val_loss: 0.0164 - val_mae: 0.0782\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0037 - mae: 0.0605 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0041 - mae: 0.0627 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0565 - val_loss: 0.0164 - val_mae: 0.0784\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0034 - mae: 0.0609 - val_loss: 0.0164 - val_mae: 0.0786\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - mae: 0.0601 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0615 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0613 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0037 - mae: 0.0589 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0042 - mae: 0.0610 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0034 - mae: 0.0579 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0602 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - mae: 0.0605 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0038 - mae: 0.0581 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0164 - val_mae: 0.0788\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0575 - val_loss: 0.0164 - val_mae: 0.0787\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0788\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mae: 0.0562 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0036 - mae: 0.0579 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0560 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - mae: 0.0617 - val_loss: 0.0163 - val_mae: 0.0787\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0588 - val_loss: 0.0163 - val_mae: 0.0786\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0568 - val_loss: 0.0162 - val_mae: 0.0786\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0027 - mae: 0.0532 - val_loss: 0.0162 - val_mae: 0.0786\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0162 - val_mae: 0.0787\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0162 - val_mae: 0.0789\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0034 - mae: 0.0573 - val_loss: 0.0162 - val_mae: 0.0792\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0032 - mae: 0.0570 - val_loss: 0.0162 - val_mae: 0.0793\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0566 - val_loss: 0.0162 - val_mae: 0.0794\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0619 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0590 - val_loss: 0.0162 - val_mae: 0.0795\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0036 - mae: 0.0596 - val_loss: 0.0161 - val_mae: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:13,609] Trial 21 finished with value: 0.07987676560878754 and parameters: {'learning_rate': 0.00015760818403581418, 'weight_decay': 2.3508196247321765e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0246 - val_mae: 0.1226\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0098 - mae: 0.1086 - val_loss: 0.0246 - val_mae: 0.1224\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0103 - mae: 0.1122 - val_loss: 0.0246 - val_mae: 0.1223\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0099 - mae: 0.1088 - val_loss: 0.0245 - val_mae: 0.1220\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0245 - val_mae: 0.1218\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1066 - val_loss: 0.0245 - val_mae: 0.1216\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0101 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1214\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0102 - mae: 0.1113 - val_loss: 0.0244 - val_mae: 0.1212\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0099 - mae: 0.1096 - val_loss: 0.0244 - val_mae: 0.1210\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0094 - mae: 0.1065 - val_loss: 0.0244 - val_mae: 0.1208\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0243 - val_mae: 0.1206\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1204\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1060 - val_loss: 0.0243 - val_mae: 0.1202\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0094 - mae: 0.1074 - val_loss: 0.0243 - val_mae: 0.1201\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0242 - val_mae: 0.1199\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0092 - mae: 0.1046 - val_loss: 0.0242 - val_mae: 0.1197\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1056 - val_loss: 0.0242 - val_mae: 0.1195\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1053 - val_loss: 0.0242 - val_mae: 0.1193\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0097 - mae: 0.1071 - val_loss: 0.0241 - val_mae: 0.1191\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0096 - mae: 0.1066 - val_loss: 0.0241 - val_mae: 0.1190\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0093 - mae: 0.1046 - val_loss: 0.0241 - val_mae: 0.1188\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0093 - mae: 0.1043 - val_loss: 0.0241 - val_mae: 0.1186\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0094 - mae: 0.1045 - val_loss: 0.0241 - val_mae: 0.1184\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1030 - val_loss: 0.0240 - val_mae: 0.1183\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0089 - mae: 0.1023 - val_loss: 0.0240 - val_mae: 0.1181\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0240 - val_mae: 0.1179\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - mae: 0.1048 - val_loss: 0.0240 - val_mae: 0.1178\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0091 - mae: 0.1027 - val_loss: 0.0240 - val_mae: 0.1176\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0090 - mae: 0.1028 - val_loss: 0.0239 - val_mae: 0.1175\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0090 - mae: 0.1026 - val_loss: 0.0239 - val_mae: 0.1173\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0089 - mae: 0.1011 - val_loss: 0.0239 - val_mae: 0.1171\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0091 - mae: 0.1034 - val_loss: 0.0239 - val_mae: 0.1170\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0089 - mae: 0.1014 - val_loss: 0.0239 - val_mae: 0.1168\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0091 - mae: 0.1033 - val_loss: 0.0239 - val_mae: 0.1167\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1028 - val_loss: 0.0238 - val_mae: 0.1165\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0091 - mae: 0.1026 - val_loss: 0.0238 - val_mae: 0.1164\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0090 - mae: 0.1023 - val_loss: 0.0238 - val_mae: 0.1162\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0091 - mae: 0.1020 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1014 - val_loss: 0.0238 - val_mae: 0.1159\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1006 - val_loss: 0.0238 - val_mae: 0.1158\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1004 - val_loss: 0.0237 - val_mae: 0.1156\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1001 - val_loss: 0.0237 - val_mae: 0.1155\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1018 - val_loss: 0.0237 - val_mae: 0.1153\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1024 - val_loss: 0.0237 - val_mae: 0.1151\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1006 - val_loss: 0.0237 - val_mae: 0.1150\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0237 - val_mae: 0.1149\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0236 - val_mae: 0.1147\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0088 - mae: 0.1009 - val_loss: 0.0236 - val_mae: 0.1146\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.1001 - val_loss: 0.0236 - val_mae: 0.1144\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0993 - val_loss: 0.0236 - val_mae: 0.1143\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0085 - mae: 0.1004 - val_loss: 0.0236 - val_mae: 0.1141\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0086 - mae: 0.0995 - val_loss: 0.0236 - val_mae: 0.1140\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0236 - val_mae: 0.1138\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0087 - mae: 0.1002 - val_loss: 0.0235 - val_mae: 0.1137\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0235 - val_mae: 0.1135\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0986 - val_loss: 0.0235 - val_mae: 0.1134\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0083 - mae: 0.0980 - val_loss: 0.0235 - val_mae: 0.1132\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0090 - mae: 0.1011 - val_loss: 0.0235 - val_mae: 0.1131\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0086 - mae: 0.0996 - val_loss: 0.0235 - val_mae: 0.1129\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0235 - val_mae: 0.1128\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0084 - mae: 0.0975 - val_loss: 0.0234 - val_mae: 0.1126\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0085 - mae: 0.0987 - val_loss: 0.0234 - val_mae: 0.1125\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0085 - mae: 0.0977 - val_loss: 0.0234 - val_mae: 0.1123\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0972 - val_loss: 0.0234 - val_mae: 0.1122\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0960 - val_loss: 0.0234 - val_mae: 0.1121\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0085 - mae: 0.0986 - val_loss: 0.0234 - val_mae: 0.1119\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0083 - mae: 0.0976 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0085 - mae: 0.0982 - val_loss: 0.0233 - val_mae: 0.1116\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1115\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0083 - mae: 0.0955 - val_loss: 0.0233 - val_mae: 0.1113\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0086 - mae: 0.0962 - val_loss: 0.0233 - val_mae: 0.1112\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0081 - mae: 0.0957 - val_loss: 0.0233 - val_mae: 0.1110\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0081 - mae: 0.0958 - val_loss: 0.0233 - val_mae: 0.1109\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0081 - mae: 0.0937 - val_loss: 0.0233 - val_mae: 0.1107\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0084 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1106\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0232 - val_mae: 0.1104\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0957 - val_loss: 0.0232 - val_mae: 0.1103\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0963 - val_loss: 0.0232 - val_mae: 0.1101\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0932 - val_loss: 0.0232 - val_mae: 0.1100\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0084 - mae: 0.0958 - val_loss: 0.0232 - val_mae: 0.1098\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0081 - mae: 0.0938 - val_loss: 0.0231 - val_mae: 0.1097\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0081 - mae: 0.0933 - val_loss: 0.0231 - val_mae: 0.1095\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0085 - mae: 0.0959 - val_loss: 0.0231 - val_mae: 0.1094\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0952 - val_loss: 0.0231 - val_mae: 0.1093\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0231 - val_mae: 0.1091\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0921 - val_loss: 0.0231 - val_mae: 0.1090\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0941 - val_loss: 0.0230 - val_mae: 0.1088\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0230 - val_mae: 0.1086\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0230 - val_mae: 0.1085\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0230 - val_mae: 0.1083\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0949 - val_loss: 0.0230 - val_mae: 0.1082\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0929 - val_loss: 0.0229 - val_mae: 0.1080\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0229 - val_mae: 0.1079\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0080 - mae: 0.0928 - val_loss: 0.0229 - val_mae: 0.1078\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0080 - mae: 0.0944 - val_loss: 0.0229 - val_mae: 0.1076\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0943 - val_loss: 0.0229 - val_mae: 0.1075\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0078 - mae: 0.0907 - val_loss: 0.0229 - val_mae: 0.1073\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0079 - mae: 0.0923 - val_loss: 0.0228 - val_mae: 0.1072\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0228 - val_mae: 0.1070\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0077 - mae: 0.0918 - val_loss: 0.0228 - val_mae: 0.1069\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0914 - val_loss: 0.0228 - val_mae: 0.1067\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0076 - mae: 0.0894 - val_loss: 0.0228 - val_mae: 0.1065\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0228 - val_mae: 0.1064\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0080 - mae: 0.0924 - val_loss: 0.0227 - val_mae: 0.1062\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0082 - mae: 0.0936 - val_loss: 0.0227 - val_mae: 0.1061\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0081 - mae: 0.0935 - val_loss: 0.0227 - val_mae: 0.1059\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0931 - val_loss: 0.0227 - val_mae: 0.1058\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0078 - mae: 0.0925 - val_loss: 0.0227 - val_mae: 0.1056\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0074 - mae: 0.0890 - val_loss: 0.0227 - val_mae: 0.1055\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0932 - val_loss: 0.0226 - val_mae: 0.1053\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1051\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0077 - mae: 0.0905 - val_loss: 0.0226 - val_mae: 0.1050\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0079 - mae: 0.0914 - val_loss: 0.0226 - val_mae: 0.1048\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0078 - mae: 0.0905 - val_loss: 0.0226 - val_mae: 0.1047\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0876 - val_loss: 0.0225 - val_mae: 0.1045\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1044\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0075 - mae: 0.0874 - val_loss: 0.0225 - val_mae: 0.1042\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0073 - mae: 0.0899 - val_loss: 0.0225 - val_mae: 0.1041\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0893 - val_loss: 0.0225 - val_mae: 0.1039\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0887 - val_loss: 0.0224 - val_mae: 0.1037\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0869 - val_loss: 0.0224 - val_mae: 0.1036\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0847 - val_loss: 0.0224 - val_mae: 0.1034\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0900 - val_loss: 0.0224 - val_mae: 0.1032\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.1031\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0075 - mae: 0.0879 - val_loss: 0.0223 - val_mae: 0.1029\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0886 - val_loss: 0.0223 - val_mae: 0.1027\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0075 - mae: 0.0890 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0075 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0853 - val_loss: 0.0222 - val_mae: 0.1022\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0222 - val_mae: 0.1020\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0075 - mae: 0.0883 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0874 - val_loss: 0.0222 - val_mae: 0.1017\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0075 - mae: 0.0862 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0073 - mae: 0.0883 - val_loss: 0.0221 - val_mae: 0.1013\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0072 - mae: 0.0853 - val_loss: 0.0221 - val_mae: 0.1011\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0880 - val_loss: 0.0221 - val_mae: 0.1009\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0221 - val_mae: 0.1007\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0220 - val_mae: 0.1006\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.1004\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0073 - mae: 0.0851 - val_loss: 0.0220 - val_mae: 0.1002\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0072 - mae: 0.0842 - val_loss: 0.0220 - val_mae: 0.1000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0071 - mae: 0.0864 - val_loss: 0.0219 - val_mae: 0.0998\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0859 - val_loss: 0.0219 - val_mae: 0.0996\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0848 - val_loss: 0.0219 - val_mae: 0.0994\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0847 - val_loss: 0.0219 - val_mae: 0.0992\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0074 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0990\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - mae: 0.0830 - val_loss: 0.0218 - val_mae: 0.0988\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - mae: 0.0873 - val_loss: 0.0218 - val_mae: 0.0986\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0071 - mae: 0.0835 - val_loss: 0.0217 - val_mae: 0.0984\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0843 - val_loss: 0.0217 - val_mae: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:29,019] Trial 22 finished with value: 0.09822196513414383 and parameters: {'learning_rate': 2.1474716435142536e-05, 'weight_decay': 4.968988684168505e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0098 - mae: 0.1078 - val_loss: 0.0250 - val_mae: 0.1198\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0095 - mae: 0.1060 - val_loss: 0.0250 - val_mae: 0.1196\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0098 - mae: 0.1077 - val_loss: 0.0249 - val_mae: 0.1193\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0092 - mae: 0.1060 - val_loss: 0.0249 - val_mae: 0.1190\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0093 - mae: 0.1042 - val_loss: 0.0248 - val_mae: 0.1186\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0093 - mae: 0.1041 - val_loss: 0.0248 - val_mae: 0.1183\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0095 - mae: 0.1061 - val_loss: 0.0248 - val_mae: 0.1180\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0092 - mae: 0.1034 - val_loss: 0.0247 - val_mae: 0.1177\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0094 - mae: 0.1040 - val_loss: 0.0247 - val_mae: 0.1174\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0091 - mae: 0.1040 - val_loss: 0.0246 - val_mae: 0.1171\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1055 - val_loss: 0.0246 - val_mae: 0.1168\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0092 - mae: 0.1039 - val_loss: 0.0246 - val_mae: 0.1166\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0245 - val_mae: 0.1163\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0091 - mae: 0.1044 - val_loss: 0.0245 - val_mae: 0.1160\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0088 - mae: 0.1003 - val_loss: 0.0245 - val_mae: 0.1157\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0094 - mae: 0.1035 - val_loss: 0.0244 - val_mae: 0.1154\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1016 - val_loss: 0.0244 - val_mae: 0.1151\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1019 - val_loss: 0.0244 - val_mae: 0.1148\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0089 - mae: 0.1015 - val_loss: 0.0243 - val_mae: 0.1146\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0086 - mae: 0.1007 - val_loss: 0.0243 - val_mae: 0.1143\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0089 - mae: 0.1024 - val_loss: 0.0243 - val_mae: 0.1140\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0089 - mae: 0.1000 - val_loss: 0.0242 - val_mae: 0.1138\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0089 - mae: 0.1003 - val_loss: 0.0242 - val_mae: 0.1135\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.0993 - val_loss: 0.0242 - val_mae: 0.1132\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0087 - mae: 0.0993 - val_loss: 0.0241 - val_mae: 0.1130\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0089 - mae: 0.0998 - val_loss: 0.0241 - val_mae: 0.1127\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0087 - mae: 0.0992 - val_loss: 0.0241 - val_mae: 0.1124\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0990 - val_loss: 0.0241 - val_mae: 0.1122\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0086 - mae: 0.0992 - val_loss: 0.0240 - val_mae: 0.1119\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0088 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1117\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0090 - mae: 0.1005 - val_loss: 0.0240 - val_mae: 0.1114\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - mae: 0.0970 - val_loss: 0.0240 - val_mae: 0.1112\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0083 - mae: 0.0979 - val_loss: 0.0239 - val_mae: 0.1109\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0084 - mae: 0.0969 - val_loss: 0.0239 - val_mae: 0.1106\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0239 - val_mae: 0.1104\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0086 - mae: 0.0981 - val_loss: 0.0239 - val_mae: 0.1101\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0083 - mae: 0.0953 - val_loss: 0.0238 - val_mae: 0.1098\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0083 - mae: 0.0966 - val_loss: 0.0238 - val_mae: 0.1095\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0082 - mae: 0.0955 - val_loss: 0.0238 - val_mae: 0.1092\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - mae: 0.0978 - val_loss: 0.0238 - val_mae: 0.1090\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0082 - mae: 0.0952 - val_loss: 0.0237 - val_mae: 0.1087\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0081 - mae: 0.0941 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0083 - mae: 0.0947 - val_loss: 0.0237 - val_mae: 0.1081\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0081 - mae: 0.0932 - val_loss: 0.0237 - val_mae: 0.1078\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0082 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1075\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0080 - mae: 0.0941 - val_loss: 0.0236 - val_mae: 0.1072\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0083 - mae: 0.0956 - val_loss: 0.0236 - val_mae: 0.1069\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0080 - mae: 0.0927 - val_loss: 0.0236 - val_mae: 0.1066\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0080 - mae: 0.0950 - val_loss: 0.0235 - val_mae: 0.1063\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0080 - mae: 0.0952 - val_loss: 0.0235 - val_mae: 0.1060\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0082 - mae: 0.0950 - val_loss: 0.0235 - val_mae: 0.1057\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0940 - val_loss: 0.0235 - val_mae: 0.1054\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0081 - mae: 0.0927 - val_loss: 0.0234 - val_mae: 0.1051\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0936 - val_loss: 0.0234 - val_mae: 0.1048\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0079 - mae: 0.0909 - val_loss: 0.0234 - val_mae: 0.1045\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0079 - mae: 0.0913 - val_loss: 0.0234 - val_mae: 0.1042\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0082 - mae: 0.0920 - val_loss: 0.0233 - val_mae: 0.1039\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0079 - mae: 0.0931 - val_loss: 0.0233 - val_mae: 0.1037\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0078 - mae: 0.0927 - val_loss: 0.0233 - val_mae: 0.1034\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0077 - mae: 0.0906 - val_loss: 0.0233 - val_mae: 0.1031\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0075 - mae: 0.0902 - val_loss: 0.0232 - val_mae: 0.1028\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0076 - mae: 0.0907 - val_loss: 0.0232 - val_mae: 0.1026\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0232 - val_mae: 0.1023\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0897 - val_loss: 0.0231 - val_mae: 0.1020\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0077 - mae: 0.0898 - val_loss: 0.0231 - val_mae: 0.1017\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0081 - mae: 0.0915 - val_loss: 0.0231 - val_mae: 0.1015\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0076 - mae: 0.0890 - val_loss: 0.0230 - val_mae: 0.1012\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0875 - val_loss: 0.0230 - val_mae: 0.1009\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0904 - val_loss: 0.0230 - val_mae: 0.1006\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0076 - mae: 0.0886 - val_loss: 0.0229 - val_mae: 0.1003\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0072 - mae: 0.0863 - val_loss: 0.0229 - val_mae: 0.1000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0079 - mae: 0.0888 - val_loss: 0.0229 - val_mae: 0.0998\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0076 - mae: 0.0884 - val_loss: 0.0228 - val_mae: 0.0995\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0074 - mae: 0.0876 - val_loss: 0.0228 - val_mae: 0.0992\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0076 - mae: 0.0891 - val_loss: 0.0228 - val_mae: 0.0989\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0852 - val_loss: 0.0227 - val_mae: 0.0986\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0075 - mae: 0.0888 - val_loss: 0.0227 - val_mae: 0.0983\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0074 - mae: 0.0870 - val_loss: 0.0227 - val_mae: 0.0981\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0073 - mae: 0.0871 - val_loss: 0.0226 - val_mae: 0.0978\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0072 - mae: 0.0879 - val_loss: 0.0226 - val_mae: 0.0975\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0073 - mae: 0.0877 - val_loss: 0.0226 - val_mae: 0.0972\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0225 - val_mae: 0.0969\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0066 - mae: 0.0850 - val_loss: 0.0225 - val_mae: 0.0966\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0842 - val_loss: 0.0224 - val_mae: 0.0962\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0074 - mae: 0.0871 - val_loss: 0.0224 - val_mae: 0.0959\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0067 - mae: 0.0842 - val_loss: 0.0224 - val_mae: 0.0956\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0072 - mae: 0.0876 - val_loss: 0.0223 - val_mae: 0.0953\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0073 - mae: 0.0869 - val_loss: 0.0223 - val_mae: 0.0950\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0068 - mae: 0.0828 - val_loss: 0.0223 - val_mae: 0.0947\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0069 - mae: 0.0836 - val_loss: 0.0222 - val_mae: 0.0944\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0832 - val_loss: 0.0222 - val_mae: 0.0941\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0068 - mae: 0.0852 - val_loss: 0.0221 - val_mae: 0.0938\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0073 - mae: 0.0863 - val_loss: 0.0221 - val_mae: 0.0935\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0070 - mae: 0.0845 - val_loss: 0.0221 - val_mae: 0.0932\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0070 - mae: 0.0856 - val_loss: 0.0220 - val_mae: 0.0928\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0067 - mae: 0.0832 - val_loss: 0.0220 - val_mae: 0.0925\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0071 - mae: 0.0853 - val_loss: 0.0220 - val_mae: 0.0922\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0781 - val_loss: 0.0219 - val_mae: 0.0919\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - mae: 0.0836 - val_loss: 0.0219 - val_mae: 0.0916\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0068 - mae: 0.0822 - val_loss: 0.0218 - val_mae: 0.0913\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0071 - mae: 0.0852 - val_loss: 0.0218 - val_mae: 0.0910\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - mae: 0.0851 - val_loss: 0.0218 - val_mae: 0.0908\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0066 - mae: 0.0799 - val_loss: 0.0217 - val_mae: 0.0905\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0833 - val_loss: 0.0217 - val_mae: 0.0903\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0067 - mae: 0.0804 - val_loss: 0.0217 - val_mae: 0.0901\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0060 - mae: 0.0764 - val_loss: 0.0216 - val_mae: 0.0898\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0060 - mae: 0.0783 - val_loss: 0.0216 - val_mae: 0.0896\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0817 - val_loss: 0.0215 - val_mae: 0.0893\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0064 - mae: 0.0805 - val_loss: 0.0215 - val_mae: 0.0891\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0065 - mae: 0.0802 - val_loss: 0.0215 - val_mae: 0.0888\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0818 - val_loss: 0.0214 - val_mae: 0.0886\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0214 - val_mae: 0.0884\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0062 - mae: 0.0803 - val_loss: 0.0214 - val_mae: 0.0881\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0066 - mae: 0.0806 - val_loss: 0.0213 - val_mae: 0.0879\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0061 - mae: 0.0768 - val_loss: 0.0213 - val_mae: 0.0877\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - mae: 0.0809 - val_loss: 0.0212 - val_mae: 0.0874\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0780 - val_loss: 0.0212 - val_mae: 0.0872\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0069 - mae: 0.0844 - val_loss: 0.0212 - val_mae: 0.0870\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0066 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0867\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0062 - mae: 0.0804 - val_loss: 0.0211 - val_mae: 0.0865\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0796 - val_loss: 0.0211 - val_mae: 0.0863\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0060 - mae: 0.0785 - val_loss: 0.0210 - val_mae: 0.0860\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - mae: 0.0785 - val_loss: 0.0210 - val_mae: 0.0858\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0062 - mae: 0.0792 - val_loss: 0.0210 - val_mae: 0.0856\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0062 - mae: 0.0782 - val_loss: 0.0209 - val_mae: 0.0854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0209 - val_mae: 0.0851\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0062 - mae: 0.0770 - val_loss: 0.0208 - val_mae: 0.0849\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0745 - val_loss: 0.0208 - val_mae: 0.0847\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - mae: 0.0776 - val_loss: 0.0208 - val_mae: 0.0845\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0764 - val_loss: 0.0207 - val_mae: 0.0842\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - mae: 0.0799 - val_loss: 0.0207 - val_mae: 0.0840\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0790 - val_loss: 0.0207 - val_mae: 0.0838\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - mae: 0.0725 - val_loss: 0.0206 - val_mae: 0.0836\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - mae: 0.0765 - val_loss: 0.0206 - val_mae: 0.0834\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054 - mae: 0.0742 - val_loss: 0.0205 - val_mae: 0.0832\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - mae: 0.0799 - val_loss: 0.0205 - val_mae: 0.0830\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0058 - mae: 0.0751 - val_loss: 0.0205 - val_mae: 0.0828\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0056 - mae: 0.0768 - val_loss: 0.0204 - val_mae: 0.0827\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0064 - mae: 0.0784 - val_loss: 0.0204 - val_mae: 0.0825\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0053 - mae: 0.0749 - val_loss: 0.0204 - val_mae: 0.0823\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0061 - mae: 0.0758 - val_loss: 0.0203 - val_mae: 0.0822\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0057 - mae: 0.0764 - val_loss: 0.0203 - val_mae: 0.0820\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0063 - mae: 0.0790 - val_loss: 0.0203 - val_mae: 0.0819\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0056 - mae: 0.0750 - val_loss: 0.0202 - val_mae: 0.0818\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0054 - mae: 0.0715 - val_loss: 0.0202 - val_mae: 0.0817\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0058 - mae: 0.0768 - val_loss: 0.0202 - val_mae: 0.0816\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0058 - mae: 0.0772 - val_loss: 0.0201 - val_mae: 0.0815\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0057 - mae: 0.0761 - val_loss: 0.0201 - val_mae: 0.0814\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0055 - mae: 0.0748 - val_loss: 0.0201 - val_mae: 0.0813\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0060 - mae: 0.0776 - val_loss: 0.0201 - val_mae: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:44,107] Trial 23 finished with value: 0.08120827376842499 and parameters: {'learning_rate': 3.0123667573852025e-05, 'weight_decay': 1.0962226254424494e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0088 - mae: 0.0999 - val_loss: 0.0219 - val_mae: 0.1054\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - mae: 0.0956 - val_loss: 0.0213 - val_mae: 0.1008\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0076 - mae: 0.0871 - val_loss: 0.0206 - val_mae: 0.0960\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0076 - mae: 0.0851 - val_loss: 0.0200 - val_mae: 0.0912\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0068 - mae: 0.0790 - val_loss: 0.0193 - val_mae: 0.0869\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0070 - mae: 0.0815 - val_loss: 0.0188 - val_mae: 0.0843\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0064 - mae: 0.0769 - val_loss: 0.0184 - val_mae: 0.0819\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0061 - mae: 0.0780 - val_loss: 0.0180 - val_mae: 0.0799\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0053 - mae: 0.0700 - val_loss: 0.0177 - val_mae: 0.0788\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - mae: 0.0695 - val_loss: 0.0174 - val_mae: 0.0779\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0054 - mae: 0.0722 - val_loss: 0.0171 - val_mae: 0.0773\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0050 - mae: 0.0699 - val_loss: 0.0169 - val_mae: 0.0769\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0051 - mae: 0.0701 - val_loss: 0.0168 - val_mae: 0.0765\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0040 - mae: 0.0618 - val_loss: 0.0167 - val_mae: 0.0762\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0046 - mae: 0.0674 - val_loss: 0.0166 - val_mae: 0.0758\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0046 - mae: 0.0661 - val_loss: 0.0165 - val_mae: 0.0758\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0045 - mae: 0.0656 - val_loss: 0.0164 - val_mae: 0.0761\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0624 - val_loss: 0.0163 - val_mae: 0.0766\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0042 - mae: 0.0641 - val_loss: 0.0161 - val_mae: 0.0774\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0041 - mae: 0.0646 - val_loss: 0.0160 - val_mae: 0.0780\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0044 - mae: 0.0665 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0040 - mae: 0.0621 - val_loss: 0.0162 - val_mae: 0.0781\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0040 - mae: 0.0654 - val_loss: 0.0163 - val_mae: 0.0780\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0037 - mae: 0.0620 - val_loss: 0.0164 - val_mae: 0.0783\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0036 - mae: 0.0586 - val_loss: 0.0165 - val_mae: 0.0787\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0576 - val_loss: 0.0165 - val_mae: 0.0793\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0603 - val_loss: 0.0164 - val_mae: 0.0801\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - mae: 0.0622 - val_loss: 0.0164 - val_mae: 0.0810\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - mae: 0.0614 - val_loss: 0.0163 - val_mae: 0.0819\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0587 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0036 - mae: 0.0597 - val_loss: 0.0163 - val_mae: 0.0827\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0036 - mae: 0.0607 - val_loss: 0.0162 - val_mae: 0.0833\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0031 - mae: 0.0586 - val_loss: 0.0162 - val_mae: 0.0837\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0033 - mae: 0.0603 - val_loss: 0.0161 - val_mae: 0.0836\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0037 - mae: 0.0592 - val_loss: 0.0161 - val_mae: 0.0833\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0596 - val_loss: 0.0159 - val_mae: 0.0837\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0032 - mae: 0.0581 - val_loss: 0.0158 - val_mae: 0.0836\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0571 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0031 - mae: 0.0555 - val_loss: 0.0157 - val_mae: 0.0834\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0033 - mae: 0.0575 - val_loss: 0.0155 - val_mae: 0.0837\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.0156 - val_mae: 0.0831\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - mae: 0.0595 - val_loss: 0.0157 - val_mae: 0.0818\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0029 - mae: 0.0549 - val_loss: 0.0157 - val_mae: 0.0813\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0033 - mae: 0.0572 - val_loss: 0.0156 - val_mae: 0.0813\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - mae: 0.0542 - val_loss: 0.0155 - val_mae: 0.0819\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0154 - val_mae: 0.0827\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0031 - mae: 0.0565 - val_loss: 0.0153 - val_mae: 0.0840\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0034 - mae: 0.0598 - val_loss: 0.0152 - val_mae: 0.0849\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0031 - mae: 0.0576 - val_loss: 0.0151 - val_mae: 0.0857\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0028 - mae: 0.0551 - val_loss: 0.0151 - val_mae: 0.0857\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0151 - val_mae: 0.0852\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0034 - mae: 0.0571 - val_loss: 0.0151 - val_mae: 0.0844\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - mae: 0.0525 - val_loss: 0.0152 - val_mae: 0.0838\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0031 - mae: 0.0552 - val_loss: 0.0151 - val_mae: 0.0840\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0031 - mae: 0.0561 - val_loss: 0.0150 - val_mae: 0.0842\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0150 - val_mae: 0.0841\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0027 - mae: 0.0517 - val_loss: 0.0149 - val_mae: 0.0854\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0029 - mae: 0.0533 - val_loss: 0.0148 - val_mae: 0.0868\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0027 - mae: 0.0536 - val_loss: 0.0147 - val_mae: 0.0875\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0146 - val_mae: 0.0887\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0026 - mae: 0.0524 - val_loss: 0.0145 - val_mae: 0.0889\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - mae: 0.0554 - val_loss: 0.0145 - val_mae: 0.0880\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0027 - mae: 0.0538 - val_loss: 0.0145 - val_mae: 0.0863\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0863\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0143 - val_mae: 0.0889\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - mae: 0.0537 - val_loss: 0.0141 - val_mae: 0.0927\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0141 - val_mae: 0.0950\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0541 - val_loss: 0.0141 - val_mae: 0.0932\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - mae: 0.0528 - val_loss: 0.0142 - val_mae: 0.0893\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0024 - mae: 0.0491 - val_loss: 0.0144 - val_mae: 0.0864\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0499 - val_loss: 0.0144 - val_mae: 0.0863\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - mae: 0.0535 - val_loss: 0.0142 - val_mae: 0.0888\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - mae: 0.0517 - val_loss: 0.0141 - val_mae: 0.0934\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0505 - val_loss: 0.0140 - val_mae: 0.0963\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0030 - mae: 0.0573 - val_loss: 0.0140 - val_mae: 0.0966\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0140 - val_mae: 0.0965\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - mae: 0.0537 - val_loss: 0.0140 - val_mae: 0.0939\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0495 - val_loss: 0.0140 - val_mae: 0.0911\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0510 - val_loss: 0.0140 - val_mae: 0.0900\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - mae: 0.0479 - val_loss: 0.0139 - val_mae: 0.0918\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0138 - val_mae: 0.0944\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0023 - mae: 0.0511 - val_loss: 0.0138 - val_mae: 0.0966\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - mae: 0.0498 - val_loss: 0.0138 - val_mae: 0.0989\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0515 - val_loss: 0.0138 - val_mae: 0.0978\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - mae: 0.0514 - val_loss: 0.0138 - val_mae: 0.0963\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0506 - val_loss: 0.0139 - val_mae: 0.0936\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0024 - mae: 0.0496 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0022 - mae: 0.0460 - val_loss: 0.0139 - val_mae: 0.0926\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0487 - val_loss: 0.0138 - val_mae: 0.0950\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - mae: 0.0477 - val_loss: 0.0138 - val_mae: 0.0992\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0024 - mae: 0.0498 - val_loss: 0.0138 - val_mae: 0.1036\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0023 - mae: 0.0483 - val_loss: 0.0138 - val_mae: 0.1023\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - mae: 0.0530 - val_loss: 0.0138 - val_mae: 0.0958\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0139 - val_mae: 0.0920\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - mae: 0.0517 - val_loss: 0.0140 - val_mae: 0.0929\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0140 - val_mae: 0.0970\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0140 - val_mae: 0.1019\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0021 - mae: 0.0481 - val_loss: 0.0141 - val_mae: 0.0984\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0454 - val_loss: 0.0141 - val_mae: 0.0977\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0022 - mae: 0.0478 - val_loss: 0.0141 - val_mae: 0.0993\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0439 - val_loss: 0.0140 - val_mae: 0.0997\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - mae: 0.0507 - val_loss: 0.0139 - val_mae: 0.0995\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0018 - mae: 0.0449 - val_loss: 0.0139 - val_mae: 0.0984\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0021 - mae: 0.0461 - val_loss: 0.0138 - val_mae: 0.1006\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0021 - mae: 0.0475 - val_loss: 0.0137 - val_mae: 0.0992\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0019 - mae: 0.0455 - val_loss: 0.0137 - val_mae: 0.0967\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0473 - val_loss: 0.0137 - val_mae: 0.0948\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0017 - mae: 0.0422 - val_loss: 0.0138 - val_mae: 0.0931\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0022 - mae: 0.0472 - val_loss: 0.0137 - val_mae: 0.0951\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0018 - mae: 0.0443 - val_loss: 0.0137 - val_mae: 0.1000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0138 - val_mae: 0.1028\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - mae: 0.0479 - val_loss: 0.0139 - val_mae: 0.1061\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - mae: 0.0514 - val_loss: 0.0138 - val_mae: 0.1024\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - mae: 0.0490 - val_loss: 0.0137 - val_mae: 0.0981\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0018 - mae: 0.0450 - val_loss: 0.0137 - val_mae: 0.0960\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0019 - mae: 0.0469 - val_loss: 0.0137 - val_mae: 0.0956\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0019 - mae: 0.0464 - val_loss: 0.0137 - val_mae: 0.0988\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0438 - val_loss: 0.0138 - val_mae: 0.1025\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0019 - mae: 0.0447 - val_loss: 0.0138 - val_mae: 0.1009\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0467 - val_loss: 0.0139 - val_mae: 0.0976\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0019 - mae: 0.0470 - val_loss: 0.0139 - val_mae: 0.0966\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0446 - val_loss: 0.0140 - val_mae: 0.0973\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0017 - mae: 0.0430 - val_loss: 0.0141 - val_mae: 0.0975\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0017 - mae: 0.0414 - val_loss: 0.0141 - val_mae: 0.1001\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0017 - mae: 0.0421 - val_loss: 0.0142 - val_mae: 0.1041\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0142 - val_mae: 0.1070\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0020 - mae: 0.0479 - val_loss: 0.0141 - val_mae: 0.1030\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0020 - mae: 0.0454 - val_loss: 0.0141 - val_mae: 0.1003\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0017 - mae: 0.0435 - val_loss: 0.0140 - val_mae: 0.0963\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0020 - mae: 0.0470 - val_loss: 0.0139 - val_mae: 0.0952\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0019 - mae: 0.0433 - val_loss: 0.0138 - val_mae: 0.0962\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0015 - mae: 0.0398 - val_loss: 0.0138 - val_mae: 0.0991\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.0017 - mae: 0.0432 - val_loss: 0.0137 - val_mae: 0.1020\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0137 - val_mae: 0.1051\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0021 - mae: 0.0502 - val_loss: 0.0136 - val_mae: 0.0982\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0015 - mae: 0.0400 - val_loss: 0.0137 - val_mae: 0.0926\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0139 - val_mae: 0.0923\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0018 - mae: 0.0442 - val_loss: 0.0139 - val_mae: 0.0953\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mae: 0.0420 - val_loss: 0.0139 - val_mae: 0.0999\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - mae: 0.0406 - val_loss: 0.0140 - val_mae: 0.1031\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0140 - val_mae: 0.1028\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0016 - mae: 0.0447 - val_loss: 0.0139 - val_mae: 0.1003\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0017 - mae: 0.0429 - val_loss: 0.0140 - val_mae: 0.0940\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - mae: 0.0391 - val_loss: 0.0141 - val_mae: 0.0889\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0020 - mae: 0.0428 - val_loss: 0.0142 - val_mae: 0.0872\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - mae: 0.0406 - val_loss: 0.0141 - val_mae: 0.0888\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - mae: 0.0425 - val_loss: 0.0139 - val_mae: 0.0933\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0016 - mae: 0.0405 - val_loss: 0.0139 - val_mae: 0.0992\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0016 - mae: 0.0436 - val_loss: 0.0140 - val_mae: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 19:01:59,316] Trial 24 finished with value: 0.10374455153942108 and parameters: {'learning_rate': 0.0006066225916548129, 'weight_decay': 1.5656201579880057e-09}. Best is trial 14 with value: 0.07514270395040512.\n"
     ]
    }
   ],
   "source": [
    "cnn_study = create_study(model_fun=cnn_model,\n",
    "                         train=train_df,\n",
    "                         val=val_df)\n",
    "lstm_study = create_study(model_fun=lstm_model,\n",
    "                          train=train_df,\n",
    "                          val=val_df)\n",
    "stacked_study = create_study(model_fun=lstm_cnn_model,\n",
    "                             train=train_df,\n",
    "                             val=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.08045151829719543\n",
      "\n",
      "LSTM Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07435319572687149\n",
      "\n",
      "LSTM-CNN Study Results\n",
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  25\n",
      "Best trial:\n",
      "  Value:  0.07514270395040512\n"
     ]
    }
   ],
   "source": [
    "print('CNN Study Results')\n",
    "cnn_params = get_optimized_parameters(cnn_study)\n",
    "print('\\nLSTM Study Results')\n",
    "lstm_params = get_optimized_parameters(lstm_study)\n",
    "print('\\nLSTM-CNN Study Results')\n",
    "stacked_params = get_optimized_parameters(stacked_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = dict()\n",
    "path = './src/rv_sentiment.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Compile Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            1984      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               123008    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140440 (548.59 KB)\n",
      "Trainable params: 140440 (548.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_model(cnn_params['learning_rate'], cnn_params['weight_decay'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 72, 72)            22464     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55064 (215.09 KB)\n",
      "Trainable params: 55064 (215.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(lstm_params['learning_rate'], lstm_params['weight_decay'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 64)            1984      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 33, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 31, 64)            12352     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 15, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15, 72)            39456     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 48)                23232     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6272      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86392 (337.47 KB)\n",
      "Trainable params: 86392 (337.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked = lstm_cnn_model(stacked_params['learning_rate'], stacked_params['weight_decay'])\n",
    "stacked.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0425 - mae: 0.2344 - val_loss: 0.0963 - val_mae: 0.3516\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1006 - mae: 0.3538 - val_loss: 0.0219 - val_mae: 0.1157\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0114 - mae: 0.1148 - val_loss: 0.0213 - val_mae: 0.0946\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0071 - mae: 0.0873 - val_loss: 0.0207 - val_mae: 0.0857\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0062 - mae: 0.0762 - val_loss: 0.0186 - val_mae: 0.0804\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0717 - val_loss: 0.0167 - val_mae: 0.0852\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0052 - mae: 0.0800 - val_loss: 0.0172 - val_mae: 0.0766\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - mae: 0.0685 - val_loss: 0.0185 - val_mae: 0.0763\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0043 - mae: 0.0632 - val_loss: 0.0185 - val_mae: 0.0773\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0047 - mae: 0.0662 - val_loss: 0.0179 - val_mae: 0.0794\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0038 - mae: 0.0611 - val_loss: 0.0174 - val_mae: 0.0876\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0042 - mae: 0.0710 - val_loss: 0.0171 - val_mae: 0.0877\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0043 - mae: 0.0710 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0032 - mae: 0.0578 - val_loss: 0.0176 - val_mae: 0.0787\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0034 - mae: 0.0533 - val_loss: 0.0175 - val_mae: 0.0791\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - mae: 0.0537 - val_loss: 0.0171 - val_mae: 0.0804\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0030 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0857\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mae: 0.0570 - val_loss: 0.0167 - val_mae: 0.0848\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0031 - mae: 0.0585 - val_loss: 0.0168 - val_mae: 0.0841\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0034 - mae: 0.0592 - val_loss: 0.0168 - val_mae: 0.0849\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mae: 0.0596 - val_loss: 0.0167 - val_mae: 0.0853\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - mae: 0.0566 - val_loss: 0.0166 - val_mae: 0.0852\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0164 - val_mae: 0.0863\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0164 - val_mae: 0.0887\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mae: 0.0529 - val_loss: 0.0164 - val_mae: 0.0851\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0032 - mae: 0.0604 - val_loss: 0.0166 - val_mae: 0.0842\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0025 - mae: 0.0528 - val_loss: 0.0167 - val_mae: 0.0838\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0531 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0462 - val_loss: 0.0164 - val_mae: 0.0819\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0530 - val_loss: 0.0162 - val_mae: 0.0820\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0525 - val_loss: 0.0161 - val_mae: 0.0830\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0588 - val_loss: 0.0160 - val_mae: 0.0815\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - mae: 0.0528 - val_loss: 0.0162 - val_mae: 0.0809\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0034 - mae: 0.0599 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - mae: 0.0519 - val_loss: 0.0165 - val_mae: 0.0847\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0022 - mae: 0.0477 - val_loss: 0.0164 - val_mae: 0.0838\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0551 - val_loss: 0.0164 - val_mae: 0.0821\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0017 - mae: 0.0403 - val_loss: 0.0160 - val_mae: 0.0805\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0432 - val_loss: 0.0158 - val_mae: 0.0818\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0477 - val_loss: 0.0164 - val_mae: 0.0831\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0412 - val_loss: 0.0165 - val_mae: 0.0849\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - mae: 0.0483 - val_loss: 0.0166 - val_mae: 0.0860\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0411 - val_loss: 0.0166 - val_mae: 0.0863\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - mae: 0.0565 - val_loss: 0.0166 - val_mae: 0.0848\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0018 - mae: 0.0398 - val_loss: 0.0160 - val_mae: 0.0808\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0020 - mae: 0.0447 - val_loss: 0.0159 - val_mae: 0.0802\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0019 - mae: 0.0437 - val_loss: 0.0160 - val_mae: 0.0794\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0028 - mae: 0.0516 - val_loss: 0.0164 - val_mae: 0.0830\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0523 - val_loss: 0.0166 - val_mae: 0.0859\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0400 - val_loss: 0.0166 - val_mae: 0.0879\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0492 - val_loss: 0.0166 - val_mae: 0.0885\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0554 - val_loss: 0.0164 - val_mae: 0.0880\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0019 - mae: 0.0439 - val_loss: 0.0163 - val_mae: 0.0869\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - mae: 0.0414 - val_loss: 0.0161 - val_mae: 0.0856\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0447 - val_loss: 0.0155 - val_mae: 0.0836\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - mae: 0.0480 - val_loss: 0.0154 - val_mae: 0.0828\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0025 - mae: 0.0516 - val_loss: 0.0154 - val_mae: 0.0832\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0492 - val_loss: 0.0156 - val_mae: 0.0827\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0433 - val_loss: 0.0160 - val_mae: 0.0840\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0423 - val_loss: 0.0162 - val_mae: 0.0847\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0023 - mae: 0.0518 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0406 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0426 - val_loss: 0.0162 - val_mae: 0.0821\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0160 - val_mae: 0.0790\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0460 - val_loss: 0.0161 - val_mae: 0.0784\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0022 - mae: 0.0486 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0441 - val_loss: 0.0166 - val_mae: 0.0853\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - mae: 0.0450 - val_loss: 0.0166 - val_mae: 0.0862\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0493 - val_loss: 0.0165 - val_mae: 0.0861\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0399 - val_loss: 0.0164 - val_mae: 0.0860\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0164 - val_mae: 0.0856\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0163 - val_mae: 0.0848\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0456 - val_loss: 0.0162 - val_mae: 0.0823\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0160 - val_mae: 0.0806\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0516 - val_loss: 0.0162 - val_mae: 0.0822\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0577 - val_loss: 0.0164 - val_mae: 0.0835\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - mae: 0.0396 - val_loss: 0.0166 - val_mae: 0.0847\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0398 - val_loss: 0.0168 - val_mae: 0.0866\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - mae: 0.0489 - val_loss: 0.0168 - val_mae: 0.0872\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0513 - val_loss: 0.0167 - val_mae: 0.0866\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0032 - mae: 0.0558 - val_loss: 0.0166 - val_mae: 0.0858\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - mae: 0.0464 - val_loss: 0.0164 - val_mae: 0.0850\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0464 - val_loss: 0.0162 - val_mae: 0.0827\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0457 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0502 - val_loss: 0.0160 - val_mae: 0.0812\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0453 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0425 - val_loss: 0.0159 - val_mae: 0.0832\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0465 - val_loss: 0.0164 - val_mae: 0.0861\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0421 - val_loss: 0.0164 - val_mae: 0.0871\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0436 - val_loss: 0.0165 - val_mae: 0.0873\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0164 - val_mae: 0.0866\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0162 - val_mae: 0.0860\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - mae: 0.0412 - val_loss: 0.0157 - val_mae: 0.0830\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0470 - val_loss: 0.0158 - val_mae: 0.0829\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0408 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0384 - val_loss: 0.0166 - val_mae: 0.0844\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0027 - mae: 0.0488 - val_loss: 0.0165 - val_mae: 0.0843\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0022 - mae: 0.0452 - val_loss: 0.0161 - val_mae: 0.0836\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0443 - val_loss: 0.0157 - val_mae: 0.0810\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0160 - val_mae: 0.0819\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0482 - val_loss: 0.0158 - val_mae: 0.0820\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - mae: 0.0404 - val_loss: 0.0163 - val_mae: 0.0843\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - mae: 0.0396 - val_loss: 0.0164 - val_mae: 0.0846\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0029 - mae: 0.0501 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0421 - val_loss: 0.0162 - val_mae: 0.0839\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0019 - mae: 0.0425 - val_loss: 0.0157 - val_mae: 0.0809\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - mae: 0.0416 - val_loss: 0.0157 - val_mae: 0.0792\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - mae: 0.0424 - val_loss: 0.0156 - val_mae: 0.0787\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0476 - val_loss: 0.0155 - val_mae: 0.0831\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - mae: 0.0416 - val_loss: 0.0159 - val_mae: 0.0866\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0468 - val_loss: 0.0161 - val_mae: 0.0880\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0017 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.0886\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.0885\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0162 - val_mae: 0.0878\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0160 - val_mae: 0.0866\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - mae: 0.0472 - val_loss: 0.0158 - val_mae: 0.0849\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0445 - val_loss: 0.0155 - val_mae: 0.0828\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0508 - val_loss: 0.0162 - val_mae: 0.0843\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0028 - mae: 0.0513 - val_loss: 0.0164 - val_mae: 0.0852\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0424 - val_loss: 0.0163 - val_mae: 0.0849\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0449 - val_loss: 0.0163 - val_mae: 0.0839\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0020 - mae: 0.0426 - val_loss: 0.0159 - val_mae: 0.0821\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - mae: 0.0394 - val_loss: 0.0153 - val_mae: 0.0799\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0428 - val_loss: 0.0151 - val_mae: 0.0792\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - mae: 0.0430 - val_loss: 0.0150 - val_mae: 0.0810\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0487 - val_loss: 0.0158 - val_mae: 0.0855\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0466 - val_loss: 0.0163 - val_mae: 0.0880\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0021 - mae: 0.0487 - val_loss: 0.0164 - val_mae: 0.0887\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0491 - val_loss: 0.0165 - val_mae: 0.0883\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - mae: 0.0465 - val_loss: 0.0163 - val_mae: 0.0865\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0496 - val_loss: 0.0157 - val_mae: 0.0838\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - mae: 0.0377 - val_loss: 0.0155 - val_mae: 0.0804\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - mae: 0.0352 - val_loss: 0.0156 - val_mae: 0.0787\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0019 - mae: 0.0412 - val_loss: 0.0155 - val_mae: 0.0787\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0418 - val_loss: 0.0159 - val_mae: 0.0812\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - mae: 0.0397 - val_loss: 0.0163 - val_mae: 0.0820\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - mae: 0.0430 - val_loss: 0.0168 - val_mae: 0.0836\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - mae: 0.0442 - val_loss: 0.0168 - val_mae: 0.0843\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0018 - mae: 0.0410 - val_loss: 0.0167 - val_mae: 0.0845\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0406 - val_loss: 0.0164 - val_mae: 0.0843\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0159 - val_mae: 0.0846\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - mae: 0.0453 - val_loss: 0.0156 - val_mae: 0.0852\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - mae: 0.0380 - val_loss: 0.0155 - val_mae: 0.0855\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - mae: 0.0427 - val_loss: 0.0155 - val_mae: 0.0848\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0457 - val_loss: 0.0158 - val_mae: 0.0845\n",
      "--- Training LSTM ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0979 - mae: 0.3572 - val_loss: 0.0512 - val_mae: 0.2330\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0619 - mae: 0.2805 - val_loss: 0.0380 - val_mae: 0.1892\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0546 - mae: 0.2650 - val_loss: 0.0294 - val_mae: 0.1569\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0401 - mae: 0.2240 - val_loss: 0.0244 - val_mae: 0.1370\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0334 - mae: 0.2042 - val_loss: 0.0217 - val_mae: 0.1249\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0289 - mae: 0.1864 - val_loss: 0.0205 - val_mae: 0.1167\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0231 - mae: 0.1781 - val_loss: 0.0198 - val_mae: 0.1122\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0249 - mae: 0.1724 - val_loss: 0.0194 - val_mae: 0.1111\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0195 - mae: 0.1563 - val_loss: 0.0190 - val_mae: 0.1099\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0194 - mae: 0.1545 - val_loss: 0.0187 - val_mae: 0.1078\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0171 - mae: 0.1483 - val_loss: 0.0185 - val_mae: 0.1051\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0179 - mae: 0.1453 - val_loss: 0.0184 - val_mae: 0.1021\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0178 - mae: 0.1474 - val_loss: 0.0184 - val_mae: 0.0991\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0147 - mae: 0.1329 - val_loss: 0.0184 - val_mae: 0.0971\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0113 - mae: 0.1181 - val_loss: 0.0184 - val_mae: 0.0959\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - mae: 0.1252 - val_loss: 0.0185 - val_mae: 0.0952\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0106 - mae: 0.1146 - val_loss: 0.0186 - val_mae: 0.0945\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0120 - mae: 0.1189 - val_loss: 0.0187 - val_mae: 0.0944\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0107 - mae: 0.1145 - val_loss: 0.0188 - val_mae: 0.0939\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0099 - mae: 0.1125 - val_loss: 0.0188 - val_mae: 0.0934\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0073 - mae: 0.0960 - val_loss: 0.0188 - val_mae: 0.0929\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1008 - val_loss: 0.0188 - val_mae: 0.0924\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0082 - mae: 0.0961 - val_loss: 0.0189 - val_mae: 0.0919\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0079 - mae: 0.0957 - val_loss: 0.0189 - val_mae: 0.0915\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0189 - val_mae: 0.0913\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - mae: 0.0871 - val_loss: 0.0188 - val_mae: 0.0908\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0069 - mae: 0.0916 - val_loss: 0.0187 - val_mae: 0.0903\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - mae: 0.0862 - val_loss: 0.0187 - val_mae: 0.0897\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0065 - mae: 0.0888 - val_loss: 0.0186 - val_mae: 0.0890\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0064 - mae: 0.0820 - val_loss: 0.0185 - val_mae: 0.0883\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - mae: 0.0862 - val_loss: 0.0184 - val_mae: 0.0876\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0058 - mae: 0.0803 - val_loss: 0.0183 - val_mae: 0.0870\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0757 - val_loss: 0.0182 - val_mae: 0.0865\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0056 - mae: 0.0816 - val_loss: 0.0181 - val_mae: 0.0860\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - mae: 0.0761 - val_loss: 0.0180 - val_mae: 0.0854\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0052 - mae: 0.0725 - val_loss: 0.0179 - val_mae: 0.0848\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0048 - mae: 0.0742 - val_loss: 0.0179 - val_mae: 0.0845\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0045 - mae: 0.0736 - val_loss: 0.0178 - val_mae: 0.0843\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0046 - mae: 0.0718 - val_loss: 0.0177 - val_mae: 0.0842\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0051 - mae: 0.0768 - val_loss: 0.0176 - val_mae: 0.0840\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0052 - mae: 0.0763 - val_loss: 0.0176 - val_mae: 0.0838\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - mae: 0.0673 - val_loss: 0.0175 - val_mae: 0.0835\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.0049 - mae: 0.0742 - val_loss: 0.0175 - val_mae: 0.0834\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0052 - mae: 0.0750 - val_loss: 0.0175 - val_mae: 0.0832\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0041 - mae: 0.0675 - val_loss: 0.0175 - val_mae: 0.0831\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0044 - mae: 0.0716 - val_loss: 0.0174 - val_mae: 0.0830\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0040 - mae: 0.0677 - val_loss: 0.0174 - val_mae: 0.0829\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.0827\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0041 - mae: 0.0702 - val_loss: 0.0174 - val_mae: 0.0825\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - mae: 0.0667 - val_loss: 0.0174 - val_mae: 0.0821\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - mae: 0.0664 - val_loss: 0.0174 - val_mae: 0.0817\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0044 - mae: 0.0714 - val_loss: 0.0174 - val_mae: 0.0813\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0035 - mae: 0.0638 - val_loss: 0.0174 - val_mae: 0.0808\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0044 - mae: 0.0685 - val_loss: 0.0174 - val_mae: 0.0804\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0037 - mae: 0.0632 - val_loss: 0.0174 - val_mae: 0.0801\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0036 - mae: 0.0638 - val_loss: 0.0173 - val_mae: 0.0799\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0037 - mae: 0.0656 - val_loss: 0.0172 - val_mae: 0.0797\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0037 - mae: 0.0651 - val_loss: 0.0172 - val_mae: 0.0796\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0036 - mae: 0.0626 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - mae: 0.0607 - val_loss: 0.0171 - val_mae: 0.0795\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - mae: 0.0640 - val_loss: 0.0170 - val_mae: 0.0795\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - mae: 0.0610 - val_loss: 0.0170 - val_mae: 0.0794\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0033 - mae: 0.0634 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - mae: 0.0604 - val_loss: 0.0171 - val_mae: 0.0792\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0568 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0036 - mae: 0.0635 - val_loss: 0.0172 - val_mae: 0.0792\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - mae: 0.0585 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0032 - mae: 0.0580 - val_loss: 0.0171 - val_mae: 0.0793\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - mae: 0.0632 - val_loss: 0.0170 - val_mae: 0.0792\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - mae: 0.0540 - val_loss: 0.0169 - val_mae: 0.0792\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0169 - val_mae: 0.0791\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - mae: 0.0602 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - mae: 0.0617 - val_loss: 0.0168 - val_mae: 0.0791\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mae: 0.0582 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0792\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - mae: 0.0590 - val_loss: 0.0168 - val_mae: 0.0793\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mae: 0.0586 - val_loss: 0.0168 - val_mae: 0.0794\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0796\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - mae: 0.0572 - val_loss: 0.0169 - val_mae: 0.0799\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - mae: 0.0549 - val_loss: 0.0169 - val_mae: 0.0802\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - mae: 0.0578 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0031 - mae: 0.0587 - val_loss: 0.0170 - val_mae: 0.0808\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0031 - mae: 0.0584 - val_loss: 0.0170 - val_mae: 0.0810\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0027 - mae: 0.0534 - val_loss: 0.0169 - val_mae: 0.0813\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0535 - val_loss: 0.0169 - val_mae: 0.0816\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - mae: 0.0579 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0555 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - mae: 0.0558 - val_loss: 0.0168 - val_mae: 0.0820\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - mae: 0.0549 - val_loss: 0.0168 - val_mae: 0.0820\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0023 - mae: 0.0533 - val_loss: 0.0168 - val_mae: 0.0819\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - mae: 0.0532 - val_loss: 0.0168 - val_mae: 0.0818\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.0168 - val_mae: 0.0817\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - mae: 0.0556 - val_loss: 0.0167 - val_mae: 0.0817\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - mae: 0.0579 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0023 - mae: 0.0530 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0477 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - mae: 0.0478 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0020 - mae: 0.0500 - val_loss: 0.0167 - val_mae: 0.0815\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0025 - mae: 0.0524 - val_loss: 0.0167 - val_mae: 0.0816\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - mae: 0.0504 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0462 - val_loss: 0.0166 - val_mae: 0.0819\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - mae: 0.0501 - val_loss: 0.0166 - val_mae: 0.0822\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - mae: 0.0489 - val_loss: 0.0165 - val_mae: 0.0824\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0503 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0022 - mae: 0.0509 - val_loss: 0.0165 - val_mae: 0.0827\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0021 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - mae: 0.0484 - val_loss: 0.0165 - val_mae: 0.0829\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0022 - mae: 0.0488 - val_loss: 0.0166 - val_mae: 0.0829\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0027 - mae: 0.0535 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0021 - mae: 0.0480 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0167 - val_mae: 0.0828\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0452 - val_loss: 0.0166 - val_mae: 0.0828\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0473 - val_loss: 0.0165 - val_mae: 0.0828\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0019 - mae: 0.0485 - val_loss: 0.0165 - val_mae: 0.0829\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0017 - mae: 0.0471 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - mae: 0.0467 - val_loss: 0.0164 - val_mae: 0.0827\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0475 - val_loss: 0.0164 - val_mae: 0.0825\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - mae: 0.0480 - val_loss: 0.0164 - val_mae: 0.0823\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0022 - mae: 0.0482 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - mae: 0.0448 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - mae: 0.0456 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - mae: 0.0468 - val_loss: 0.0165 - val_mae: 0.0821\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - mae: 0.0497 - val_loss: 0.0165 - val_mae: 0.0823\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - mae: 0.0465 - val_loss: 0.0165 - val_mae: 0.0826\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0017 - mae: 0.0451 - val_loss: 0.0164 - val_mae: 0.0828\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - mae: 0.0494 - val_loss: 0.0164 - val_mae: 0.0830\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - mae: 0.0451 - val_loss: 0.0163 - val_mae: 0.0832\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0017 - mae: 0.0443 - val_loss: 0.0163 - val_mae: 0.0834\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0456 - val_loss: 0.0163 - val_mae: 0.0835\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - mae: 0.0438 - val_loss: 0.0163 - val_mae: 0.0837\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - mae: 0.0417 - val_loss: 0.0164 - val_mae: 0.0836\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mae: 0.0420 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - mae: 0.0472 - val_loss: 0.0165 - val_mae: 0.0835\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0427 - val_loss: 0.0165 - val_mae: 0.0836\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - mae: 0.0459 - val_loss: 0.0165 - val_mae: 0.0837\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0013 - mae: 0.0398 - val_loss: 0.0164 - val_mae: 0.0836\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0420 - val_loss: 0.0163 - val_mae: 0.0836\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0162 - val_mae: 0.0841\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - mae: 0.0439 - val_loss: 0.0161 - val_mae: 0.0844\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - mae: 0.0484 - val_loss: 0.0162 - val_mae: 0.0846\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - mae: 0.0412 - val_loss: 0.0162 - val_mae: 0.0845\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - mae: 0.0484 - val_loss: 0.0163 - val_mae: 0.0845\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - mae: 0.0430 - val_loss: 0.0164 - val_mae: 0.0844\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - mae: 0.0422 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0018 - mae: 0.0460 - val_loss: 0.0165 - val_mae: 0.0841\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0013 - mae: 0.0388 - val_loss: 0.0165 - val_mae: 0.0842\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0015 - mae: 0.0414 - val_loss: 0.0165 - val_mae: 0.0844\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - mae: 0.0424 - val_loss: 0.0165 - val_mae: 0.0846\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - mae: 0.0449 - val_loss: 0.0164 - val_mae: 0.0848\n",
      "--- Training LSTM-CNN ---\n",
      "Prediction lookback (n_steps): 72\n",
      "Prediction horizon (n_horizon): 24\n",
      "Batch Size: 256\n",
      "Datasets:\n",
      "(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0491 - mae: 0.2460 - val_loss: 0.0328 - val_mae: 0.1820\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0495 - mae: 0.2583 - val_loss: 0.0320 - val_mae: 0.1782\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0442 - mae: 0.2414 - val_loss: 0.0312 - val_mae: 0.1739\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0377 - mae: 0.2161 - val_loss: 0.0304 - val_mae: 0.1697\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0425 - mae: 0.2434 - val_loss: 0.0297 - val_mae: 0.1654\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0397 - mae: 0.2259 - val_loss: 0.0290 - val_mae: 0.1614\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0384 - mae: 0.2226 - val_loss: 0.0283 - val_mae: 0.1577\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0369 - mae: 0.2207 - val_loss: 0.0277 - val_mae: 0.1541\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0387 - mae: 0.2289 - val_loss: 0.0271 - val_mae: 0.1509\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0305 - mae: 0.2015 - val_loss: 0.0266 - val_mae: 0.1479\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0314 - mae: 0.2025 - val_loss: 0.0262 - val_mae: 0.1452\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0360 - mae: 0.2187 - val_loss: 0.0257 - val_mae: 0.1424\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0349 - mae: 0.2043 - val_loss: 0.0253 - val_mae: 0.1396\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0325 - mae: 0.2063 - val_loss: 0.0250 - val_mae: 0.1371\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0355 - mae: 0.2154 - val_loss: 0.0246 - val_mae: 0.1346\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0243 - mae: 0.1724 - val_loss: 0.0243 - val_mae: 0.1321\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0257 - mae: 0.1845 - val_loss: 0.0240 - val_mae: 0.1297\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0307 - mae: 0.1981 - val_loss: 0.0237 - val_mae: 0.1274\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0336 - mae: 0.2094 - val_loss: 0.0234 - val_mae: 0.1253\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0247 - mae: 0.1746 - val_loss: 0.0231 - val_mae: 0.1234\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0241 - mae: 0.1792 - val_loss: 0.0229 - val_mae: 0.1216\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0280 - mae: 0.1898 - val_loss: 0.0227 - val_mae: 0.1199\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0271 - mae: 0.1901 - val_loss: 0.0225 - val_mae: 0.1181\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0258 - mae: 0.1797 - val_loss: 0.0222 - val_mae: 0.1164\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0268 - mae: 0.1827 - val_loss: 0.0221 - val_mae: 0.1148\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0224 - mae: 0.1732 - val_loss: 0.0219 - val_mae: 0.1132\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0238 - mae: 0.1734 - val_loss: 0.0217 - val_mae: 0.1117\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0270 - mae: 0.1809 - val_loss: 0.0214 - val_mae: 0.1100\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0219 - mae: 0.1704 - val_loss: 0.0212 - val_mae: 0.1084\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0212 - mae: 0.1626 - val_loss: 0.0210 - val_mae: 0.1069\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0253 - mae: 0.1768 - val_loss: 0.0208 - val_mae: 0.1055\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0219 - mae: 0.1681 - val_loss: 0.0206 - val_mae: 0.1041\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0221 - mae: 0.1683 - val_loss: 0.0204 - val_mae: 0.1027\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0224 - mae: 0.1740 - val_loss: 0.0202 - val_mae: 0.1015\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0171 - mae: 0.1451 - val_loss: 0.0200 - val_mae: 0.1003\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0221 - mae: 0.1633 - val_loss: 0.0199 - val_mae: 0.0993\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0165 - mae: 0.1462 - val_loss: 0.0197 - val_mae: 0.0984\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0218 - mae: 0.1679 - val_loss: 0.0196 - val_mae: 0.0977\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0189 - mae: 0.1568 - val_loss: 0.0195 - val_mae: 0.0971\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0203 - mae: 0.1591 - val_loss: 0.0194 - val_mae: 0.0964\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0159 - mae: 0.1392 - val_loss: 0.0192 - val_mae: 0.0958\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0186 - mae: 0.1517 - val_loss: 0.0191 - val_mae: 0.0952\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0195 - mae: 0.1556 - val_loss: 0.0191 - val_mae: 0.0946\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - mae: 0.1552 - val_loss: 0.0190 - val_mae: 0.0941\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0186 - mae: 0.1480 - val_loss: 0.0189 - val_mae: 0.0936\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0184 - mae: 0.1527 - val_loss: 0.0189 - val_mae: 0.0931\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0163 - mae: 0.1425 - val_loss: 0.0188 - val_mae: 0.0925\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0171 - mae: 0.1484 - val_loss: 0.0187 - val_mae: 0.0920\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.0219 - mae: 0.1657 - val_loss: 0.0186 - val_mae: 0.0916\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - mae: 0.1409 - val_loss: 0.0186 - val_mae: 0.0912\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0157 - mae: 0.1393 - val_loss: 0.0185 - val_mae: 0.0909\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0182 - mae: 0.1516 - val_loss: 0.0185 - val_mae: 0.0906\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0177 - mae: 0.1543 - val_loss: 0.0184 - val_mae: 0.0903\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0174 - mae: 0.1486 - val_loss: 0.0184 - val_mae: 0.0900\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0142 - mae: 0.1362 - val_loss: 0.0183 - val_mae: 0.0898\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0184 - mae: 0.1494 - val_loss: 0.0183 - val_mae: 0.0896\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0141 - mae: 0.1352 - val_loss: 0.0182 - val_mae: 0.0895\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0153 - mae: 0.1381 - val_loss: 0.0182 - val_mae: 0.0894\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0171 - mae: 0.1445 - val_loss: 0.0182 - val_mae: 0.0893\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0158 - mae: 0.1410 - val_loss: 0.0181 - val_mae: 0.0893\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0184 - mae: 0.1498 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0148 - mae: 0.1356 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0148 - mae: 0.1360 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0153 - mae: 0.1381 - val_loss: 0.0181 - val_mae: 0.0892\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0144 - mae: 0.1344 - val_loss: 0.0181 - val_mae: 0.0894\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0135 - mae: 0.1329 - val_loss: 0.0181 - val_mae: 0.0895\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0131 - mae: 0.1300 - val_loss: 0.0181 - val_mae: 0.0897\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0144 - mae: 0.1330 - val_loss: 0.0182 - val_mae: 0.0900\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0165 - mae: 0.1481 - val_loss: 0.0182 - val_mae: 0.0903\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0168 - mae: 0.1475 - val_loss: 0.0182 - val_mae: 0.0905\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0139 - mae: 0.1257 - val_loss: 0.0183 - val_mae: 0.0907\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0136 - mae: 0.1309 - val_loss: 0.0183 - val_mae: 0.0909\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0140 - mae: 0.1346 - val_loss: 0.0183 - val_mae: 0.0910\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0121 - mae: 0.1260 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0139 - mae: 0.1328 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0142 - mae: 0.1345 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0136 - mae: 0.1291 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0125 - mae: 0.1258 - val_loss: 0.0183 - val_mae: 0.0913\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0136 - mae: 0.1325 - val_loss: 0.0183 - val_mae: 0.0912\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0117 - mae: 0.1238 - val_loss: 0.0182 - val_mae: 0.0911\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0125 - mae: 0.1242 - val_loss: 0.0182 - val_mae: 0.0910\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0146 - mae: 0.1356 - val_loss: 0.0182 - val_mae: 0.0908\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0134 - mae: 0.1302 - val_loss: 0.0181 - val_mae: 0.0906\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0129 - mae: 0.1269 - val_loss: 0.0181 - val_mae: 0.0905\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0100 - mae: 0.1120 - val_loss: 0.0181 - val_mae: 0.0904\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0108 - mae: 0.1206 - val_loss: 0.0181 - val_mae: 0.0903\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0181 - val_mae: 0.0902\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0110 - mae: 0.1169 - val_loss: 0.0180 - val_mae: 0.0901\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0131 - mae: 0.1257 - val_loss: 0.0180 - val_mae: 0.0900\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0121 - mae: 0.1250 - val_loss: 0.0180 - val_mae: 0.0898\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0112 - mae: 0.1195 - val_loss: 0.0180 - val_mae: 0.0897\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0132 - mae: 0.1316 - val_loss: 0.0180 - val_mae: 0.0896\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0104 - mae: 0.1138 - val_loss: 0.0180 - val_mae: 0.0895\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0105 - mae: 0.1142 - val_loss: 0.0180 - val_mae: 0.0894\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0124 - mae: 0.1213 - val_loss: 0.0179 - val_mae: 0.0893\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0123 - mae: 0.1246 - val_loss: 0.0179 - val_mae: 0.0891\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0097 - mae: 0.1087 - val_loss: 0.0179 - val_mae: 0.0889\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0098 - mae: 0.1104 - val_loss: 0.0179 - val_mae: 0.0887\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0124 - mae: 0.1230 - val_loss: 0.0179 - val_mae: 0.0885\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0123 - mae: 0.1248 - val_loss: 0.0179 - val_mae: 0.0884\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0109 - mae: 0.1199 - val_loss: 0.0179 - val_mae: 0.0883\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0124 - mae: 0.1251 - val_loss: 0.0179 - val_mae: 0.0881\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0108 - mae: 0.1177 - val_loss: 0.0179 - val_mae: 0.0879\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0095 - mae: 0.1093 - val_loss: 0.0179 - val_mae: 0.0877\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0112 - mae: 0.1180 - val_loss: 0.0180 - val_mae: 0.0876\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0092 - mae: 0.1104 - val_loss: 0.0180 - val_mae: 0.0875\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0180 - val_mae: 0.0874\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0110 - mae: 0.1195 - val_loss: 0.0180 - val_mae: 0.0873\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0108 - mae: 0.1156 - val_loss: 0.0180 - val_mae: 0.0873\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0107 - mae: 0.1151 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0115 - mae: 0.1199 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0084 - mae: 0.1004 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1152 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0101 - mae: 0.1149 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0096 - mae: 0.1097 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0088 - mae: 0.1067 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0106 - mae: 0.1133 - val_loss: 0.0180 - val_mae: 0.0870\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0096 - mae: 0.1093 - val_loss: 0.0179 - val_mae: 0.0869\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0111 - mae: 0.1201 - val_loss: 0.0179 - val_mae: 0.0868\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0088 - mae: 0.1062 - val_loss: 0.0179 - val_mae: 0.0866\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0100 - mae: 0.1104 - val_loss: 0.0179 - val_mae: 0.0865\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0102 - mae: 0.1124 - val_loss: 0.0178 - val_mae: 0.0865\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0090 - mae: 0.1063 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0091 - mae: 0.1071 - val_loss: 0.0178 - val_mae: 0.0864\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0091 - mae: 0.1047 - val_loss: 0.0178 - val_mae: 0.0863\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0088 - mae: 0.1022 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0093 - mae: 0.1062 - val_loss: 0.0177 - val_mae: 0.0862\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0098 - mae: 0.1090 - val_loss: 0.0177 - val_mae: 0.0861\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0105 - mae: 0.1141 - val_loss: 0.0176 - val_mae: 0.0860\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0082 - mae: 0.1018 - val_loss: 0.0176 - val_mae: 0.0859\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0087 - mae: 0.1021 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0082 - mae: 0.1031 - val_loss: 0.0176 - val_mae: 0.0858\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0074 - mae: 0.0992 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0087 - mae: 0.1056 - val_loss: 0.0175 - val_mae: 0.0857\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0102 - mae: 0.1132 - val_loss: 0.0175 - val_mae: 0.0856\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0076 - mae: 0.0953 - val_loss: 0.0175 - val_mae: 0.0855\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0092 - mae: 0.1079 - val_loss: 0.0175 - val_mae: 0.0854\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0086 - mae: 0.1035 - val_loss: 0.0174 - val_mae: 0.0854\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0080 - mae: 0.0985 - val_loss: 0.0174 - val_mae: 0.0853\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0077 - mae: 0.0933 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0097 - mae: 0.1081 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0089 - mae: 0.1076 - val_loss: 0.0174 - val_mae: 0.0852\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0097 - mae: 0.1089 - val_loss: 0.0174 - val_mae: 0.0851\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0084 - mae: 0.0998 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0080 - mae: 0.0980 - val_loss: 0.0174 - val_mae: 0.0850\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0080 - mae: 0.0982 - val_loss: 0.0173 - val_mae: 0.0849\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0076 - mae: 0.0979 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0070 - mae: 0.0916 - val_loss: 0.0173 - val_mae: 0.0848\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0078 - mae: 0.0956 - val_loss: 0.0173 - val_mae: 0.0847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 5), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--- Training CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=cnn_params)\n",
    "print('--- Training LSTM ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=lstm_params)\n",
    "print('--- Training LSTM-CNN ---')\n",
    "run_model(fname=path,\n",
    "          model_name='LSTM-CNN',\n",
    "          model_func=cnn_model,\n",
    "          model_configs=model_configs,\n",
    "          model_parms=stacked_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Training/Validation Results\n",
    "\n",
    "Loss curves across the models are fairly stable. All models show a decreasing validation curve with different epoch thresholds for when the model stops learning against the validation set. The LSTM appears to begin to have the slowest learning curve, while the CNN takes around 20 epochs to reach a loss close to 0. Some options to help improve this are to introduce learning rate decline, or train on longer input sequences.\n",
    "\n",
    "Plots of the MAE show a similar pattern to the loss plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "legend = list()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "\n",
    "def plot_graphs(metric, val, ax, upper):\n",
    "    ax.plot(val['history'].history[metric])\n",
    "    ax.plot(val['history'].history[f'val_{metric}'])\n",
    "    ax.set_title(key)\n",
    "    ax.legend([metric, f\"val_{metric}\"])\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_ylim([0, upper])\n",
    "    \n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    \n",
    "    plot_graphs('loss', val, ax, 0.05)\n",
    "print(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Curves\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"MAE Curves\")\n",
    "fig, axs = plt.subplots(1, 3, figsize=(25,5))\n",
    "for (key, val), ax in zip(model_configs.items(), axs.flatten()):\n",
    "    plot_graphs('mae', val, ax, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Test Results\n",
    "It's surprising to see how well a CNN did. LSTM would be expected to perform well because of its ability to learn and remember longer trends in the data.\n",
    "\n",
    "Putting the models' performance in perspective however the results show how with a limited lookback window, and simple features a lstm, and a cnn stacked with an lstm are a good starting choice for architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0034 - mae: 0.0749\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0038 - mae: 0.0758\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - mae: 0.0640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.074863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.075830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM-CNN</th>\n",
       "      <td>0.063964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mae\n",
       "CNN       0.074863\n",
       "LSTM      0.075830\n",
       "LSTM-CNN  0.063964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list()\n",
    "performance = list()\n",
    "\n",
    "for key, value in model_configs.items():\n",
    "    names.append(key)\n",
    "    mae = value['model'].evaluate(value['test_ds'])\n",
    "    performance.append(mae[1])\n",
    "    \n",
    "performance_df = pd.DataFrame(performance, index=names, columns=['mae'])\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Predictions\n",
    "\n",
    "Plot the actual and predicted 24 hour intervals. Below is the first 14 days of predictions. Interesting to note how the LSTM appears to oscilate over a longer frequency compared with the other models. The CNN also seems to capture the intra day oscillations (within the 24 hour period). Looking at the CNN stacked LSTM we can see how these two characteristics of the model's learning combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(18, 10))\n",
    "days = 5\n",
    "\n",
    "vline = np.linspace(0, days*24, days+1)\n",
    "\n",
    "for (key, val), ax in zip(model_configs.items(), axs):\n",
    "\n",
    "    test = val['test_ds']\n",
    "    preds = val['model'].predict(test)\n",
    "\n",
    "    xbatch, ybatch = iter(test).get_next()\n",
    "\n",
    "    ax.plot(ybatch.numpy()[:days].reshape(-1))\n",
    "    ax.plot(preds[:days].reshape(-1))\n",
    "    ax.set_title(key)\n",
    "    ax.vlines(vline, ymin=0, ymax=1, linestyle='dotted', transform = ax.get_xaxis_transform())\n",
    "    ax.legend([\"Actual\", \"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
